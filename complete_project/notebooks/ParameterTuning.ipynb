{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:09:31.677854Z",
     "start_time": "2025-06-06T11:08:49.729752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/caspar/thesis_code/complete_project/notebooks\n",
      "/home/caspar/thesis_code\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('../../complete_project/../')\n",
    "print(os.getcwd())\n",
    "# Then set up the paths\n",
    "# import sys\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTHONPATH'] = os.getcwd()  # Now points to thesis_code directory\n",
    "# sys.path.append(os.environ['PYTHONPATH'])\n",
    "sys.path.append(\"/home/caspar/thesis_code/CellOracle\")\n",
    "sys.path.append(\"/home/caspar/thesis_code/complete_project/py files\")\n",
    "sys.path.append(\"/home/caspar/thesis_code/complete_project/py files/AIFiles\")\n",
    "sys.path.append(\"/home/caspar/thesis_code/complete_project/py files/baseGRNConstructionFiles\")\n",
    "sys.path.append(\"/home/caspar/thesis_code/complete_project/py files/oracleInferenceFiles\")\n",
    "sys.path.append(\"/home/caspar/thesis_code/complete_project/py files/oracleSetup\")\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import anndata\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import optuna\n",
    "#import modified_celloracle as mco\n",
    "from CellOracle import celloracle as co\n",
    "\n",
    "import CellOracleSetup as setup_module\n",
    "import GRNClusterAnalysis as analysis_module\n",
    "import GRNInference as inference_module\n",
    "import GRNInferenceTest as inference_test_module\n",
    "\n",
    "log_dir = 'logs'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_filename = os.path.join(log_dir, f\"app_{datetime.now().strftime('%Y_%m_%d')}.log\")\n",
    "\n",
    "# Configure the basic logging\n",
    "logging.basicConfig(\n",
    "    filename=log_filename,\n",
    "    filemode='a',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16321a793b701881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:09:32.563493Z",
     "start_time": "2025-06-06T11:09:31.717948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  6 13:09:31 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA RTX 6000 Ada Gene...    Off |   00000000:AC:00.0  On |                  Off |\r\n",
      "| 30%   38C    P8             25W /  300W |   14810MiB /  49140MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX 6000 Ada Gene...    Off |   00000000:CA:00.0 Off |                  Off |\r\n",
      "| 71%   74C    P0            295W /  300W |   35934MiB /  49140MiB |    100%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    0   N/A  N/A     69090      C   ...da3/envs/gpu_cell_oracle/bin/python      14776MiB |\r\n",
      "|    1   N/A  N/A   3776787      C   python                                      35924MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f20e7620b98679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T15:35:06.520189Z",
     "start_time": "2025-06-06T15:30:19.992473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 17:44:44,207] A new study created in RDB with name: ppo_celloracle_hpo_20250606_1744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Optuna HPO Study: ppo_celloracle_hpo_20250606_1744 ---\n",
      "test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4742602bce92411f82327ac6fdb2da0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Starting Optuna Trial 0 <---\n",
      "  LR: 7.107e-05, ENT_COEF: 0.017, GOAL: 19.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcaspar-christiaan\u001b[0m (\u001b[33mcaspar-christiaan-utrecht-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/caspar/thesis_code/wandb/run-20250606_174447-optuna_hpo_trial_0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caspar-christiaan-utrecht-university/celloracle/runs/optuna_hpo_trial_0' target=\"_blank\">2025-06-06_17-44-44_19.548647782429917_-3_-0.19608894608379754_16.305687346221475_True</a></strong> to <a href='https://wandb.ai/caspar-christiaan-utrecht-university/celloracle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caspar-christiaan-utrecht-university/celloracle' target=\"_blank\">https://wandb.ai/caspar-christiaan-utrecht-university/celloracle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caspar-christiaan-utrecht-university/celloracle/runs/optuna_hpo_trial_0' target=\"_blank\">https://wandb.ai/caspar-christiaan-utrecht-university/celloracle/runs/optuna_hpo_trial_0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training Run ---\n",
      "Configuration: {'ORACLE_PATH': '../celloracle_data/celloracle_object/new_promoter_without_mescs_trimmed_test_own_umap/ready_oracle.pkl', 'MODEL_SAVE_PATH_BASE': '../celloracle_data/optuna_hpo_models2', 'LOG_DIR_BASE': '../celloracle_data/optuna_hpo_logs2', 'HPO_FIXED_MAX_STEPS_PER_EPISODE': 30, 'BATCH_SIZE': 128, 'USE_MASKABLE_PPO': False, 'VERBOSE': 0, 'LOG_INTERVAL': 10, 'RESET_NUM_TIMESTEPS': False, 'DEVICE': 'auto', 'USE_PROGRESS_BAR': False, 'STEP_SAVE_FREQ': 1000000000, 'PPO_N_STEPS': 256, 'PPO_N_EPOCHS': 7, 'GAMMA': 0.9934533789781249, 'GAE_LAMBDA': 0.95, 'CLIP_RANGE': 0.1116167224336399, 'ENT_COEF': 0.017323522915498706, 'VF_COEF': 0.5202230023486417, 'MAX_GRAD_NORM': 0.5, 'LEARNING_RATE': 7.106591851092232e-05, 'ALLOW_GENE_ACTIVATION': True, 'STANDARD_SD_FACTOR': 1.5, 'USE_LEARNING_RATE_SCHEDULE': False, 'USE_SIMILARITY_REWARD': True, 'USE_NEW_INPUT': True, 'USE_PREV_KNOCKOUT': True, 'DIVIDER_OF_TOTAL_STEPS_FOR_CURRICULUM_LEARNING': 20, 'TARGET_CELLS_PER_PHASE': 6, 'MAX_STEP_INCREASE_PER_PHASE': 8, 'MAX_STEPS_FIRST_PHASE': 50000, 'PHASE_STEP_INCREASE': 15000, 'MAX_STEPS_PER_EPISODE': 36, 'GENE_ACTIVITY_THRESHOLD': 0.01, 'TARGET_DISTANCE_THRESHOLD': 0.1, 'DISTANCE_GAMMA': 0.959091248360355, 'STEP_PENALTY': -0.19608894608379754, 'GOAL_BONUS': 19.548647782429917, 'FAIL_PENALTY': -3, 'SAME_CELL_PENALTY': -0.7513360387993675, 'DISTANCE_REWARD_SCALE': 16.305687346221475, 'PARAMETER_TUNING': True, 'TOTAL_TIMESTEPS_HPO': 320000, 'PI_ARCH': [512, 512], 'VF_ARCH': [512, 512], 'ACTIVATION_FN': <class 'torch.nn.modules.activation.ReLU'>, 'MODEL_SAVE_PATH': '../celloracle_data/optuna_hpo_models2/trial_0', 'LOG_DIR': '../celloracle_data/optuna_hpo_logs2/trial_0', 'WANDB_RUN_ID': 'optuna_hpo_trial_0', 'WANDB_RUN_NAME': 't0_lr7.1e-05_ent0.02', 'optuna_trial_obj': <optuna.trial._trial.Trial object at 0x72d5041ed360>, 'TOTAL_TIMESTEPS': 320000}\n",
      "TensorBoard Log Directory: ../celloracle_data/optuna_hpo_logs2/trial_0\n",
      "Initializing CellOracleCustomEnv with batch_size=128...\n",
      "CuPy is available and GPU is accessible.\n",
      "AnnData object with n_obs × n_vars = 30000 × 3000\n",
      "    obs: 'bc_idx', 'colnames', 'obs_names', 'celltype', 'celltype_general'\n",
      "    var: 'rownames', 'mean', 'std', 'symbol', 'isin_top1000_var_mean_genes', 'isin_TFdict_targets', 'isin_TFdict_regulators', 'isin_actve_regulators'\n",
      "    uns: 'celltype_colors', 'neighbors', 'pca', 'umap', 'umap_neighbors_sparse'\n",
      "    obsm: 'X_pca', 'X_umap', 'colnames_factor', 'umap_neighbors'\n",
      "    varm: 'PCs'\n",
      "    layers: 'chic', 'raw_chich_counts', 'raw_count', 'unspliced_spliced', 'normalized_count', 'imputed_count', 'simulation_input'\n",
      "    obsp: 'connectivities', 'distances', 'umap_neighbors_sparse'\n",
      "Finished calculating activation values for 108 genes.\n",
      "obs space size:  358\n",
      "get attribute called with name:  render_mode\n",
      "get attribute called with indices:  None\n",
      "Number of celltypes:  30  so without pcgs we have  27  targets\n",
      "Policy architecture: {'net_arch': {'pi': [512, 512], 'vf': [512, 512]}, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in ../celloracle_data/optuna_hpo_logs2/trial_0/PPO_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent (PPO) instantiated with architecture: {'pi': [512, 512], 'vf': [512, 512]}\n",
      "Starting training for 320000 timesteps...\n",
      "Time taken for simulation:  8.647572040557861\n",
      "average overall reward:  0.0501329  average fail penalty:  0.0  and average goal bonus:  0.45817143  and average same cell penalty:  -0.005869813 average distance reward:  -0.20607975  and average step penalty:  -0.19608894608379754\n",
      "Number of done instances:  3\n",
      "DEBUG (Env): Episode done for env 78. Reward: 20.27, Length: 1\n",
      "DEBUG (Env): Episode done for env 82. Reward: 21.13, Length: 1\n",
      "DEBUG (Env): Episode done for env 120. Reward: 19.56, Length: 1\n",
      "1\n",
      "Time taken for simulation:  7.315539598464966\n",
      "average overall reward:  0.118618816  average fail penalty:  0.0  and average goal bonus:  0.45817143  and average same cell penalty:  -0.017609438 average distance reward:  -0.12585427  and average step penalty:  -0.19608894608379754\n",
      "Number of done instances:  3\n",
      "DEBUG (Env): Episode done for env 7. Reward: 17.29, Length: 2\n",
      "DEBUG (Env): Episode done for env 9. Reward: 23.59, Length: 2\n",
      "DEBUG (Env): Episode done for env 74. Reward: 18.36, Length: 2\n",
      "2\n",
      "Time taken for simulation:  7.405333995819092\n",
      "average overall reward:  -0.21831629  average fail penalty:  0.0  and average goal bonus:  0.1527238  and average same cell penalty:  -0.04108869 average distance reward:  -0.13386247  and average step penalty:  -0.19608894608379754\n",
      "Number of done instances:  1\n",
      "DEBUG (Env): Episode done for env 65. Reward: 17.95, Length: 3\n",
      "3\n",
      "Time taken for simulation:  7.36301851272583\n",
      "average overall reward:  -0.3463946  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.023479251 average distance reward:  -0.1268264  and average step penalty:  -0.19608894608379754\n",
      "Number of done instances:  0\n",
      "4\n",
      "Time taken for simulation:  7.001420497894287\n",
      "average overall reward:  -0.40442008  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.052828312 average distance reward:  -0.15550281  and average step penalty:  -0.19608894608379754\n",
      "Number of done instances:  0\n",
      "5\n",
      "Time taken for simulation:  7.073242902755737\n",
      "average overall reward:  -0.12379885  average fail penalty:  0.0  and average goal bonus:  0.3054476  and average same cell penalty:  -0.058698125 average distance reward:  -0.17445937  and average step penalty:  -0.19608894608379754\n",
      "Number of done instances:  2\n",
      "DEBUG (Env): Episode done for env 30. Reward: 20.25, Length: 6\n",
      "DEBUG (Env): Episode done for env 93. Reward: 17.53, Length: 6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import AI as ai_module # Import the refactored script\n",
    "import ParameterTuning as tuning_module # Import the refactored script\n",
    "\n",
    "data_path_new_data = os.path.join('../celloracle_data', \"celloracle_object/new_promoter_without_mescs_trimmed_test_own_umap\")\n",
    "base_config = {\n",
    "    # Paths\n",
    "    \"ORACLE_PATH\": os.path.join(data_path_new_data, \"ready_oracle.pkl\"),\n",
    "    \"MODEL_SAVE_PATH_BASE\": os.path.join(\"../celloracle_data\", \"optuna_hpo_models2\"), # Base for HPO trial models\n",
    "    \"LOG_DIR_BASE\": os.path.join('../celloracle_data', \"optuna_hpo_logs2\"),         # Base for HPO trial logs\n",
    "\n",
    "    \"HPO_FIXED_MAX_STEPS_PER_EPISODE\": 30, \n",
    "\n",
    "\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"USE_MASKABLE_PPO\": False, \n",
    "    \"VERBOSE\": 0,              \n",
    "    \"LOG_INTERVAL\": 10,       \n",
    "    \"RESET_NUM_TIMESTEPS\": False,\n",
    "    \"DEVICE\": \"auto\",\n",
    "    \"USE_PROGRESS_BAR\": False,  \n",
    "    \"STEP_SAVE_FREQ\": 1000000000, \n",
    "    \"PPO_N_STEPS\": 512,\n",
    "    \"PPO_N_EPOCHS\": 10,\n",
    "    \"GAMMA\": 0.99,\n",
    "    \"GAE_LAMBDA\": 0.95,\n",
    "    \"CLIP_RANGE\": 0.2,\n",
    "    \"ENT_COEF\": 0.01,       \n",
    "    \"VF_COEF\": 0.5,\n",
    "    \"MAX_GRAD_NORM\": 0.5,\n",
    "    \"LEARNING_RATE\": 3e-4,  \n",
    "\n",
    "    # Environment Specific \n",
    "    \"ALLOW_GENE_ACTIVATION\": True,\n",
    "    \"STANDARD_SD_FACTOR\": 1.5,\n",
    "    \"USE_LEARNING_RATE_SCHEDULE\": False, \n",
    "    \"USE_SIMILARITY_REWARD\": True,\n",
    "    \"USE_NEW_INPUT\": True, \n",
    "    \"USE_PREV_KNOCKOUT\": True, \n",
    "\n",
    "    # ENV HYPERPARAMETERS (Some will be tuned by Optuna)\n",
    "    \"DIVIDER_OF_TOTAL_STEPS_FOR_CURRICULUM_LEARNING\": 20,\n",
    "    \"TARGET_CELLS_PER_PHASE\": 10,\n",
    "    \"MAX_STEP_INCREASE_PER_PHASE\": 8,\n",
    "    \"MAX_STEPS_FIRST_PHASE\": 50000, \n",
    "    \"PHASE_STEP_INCREASE\": 15000,\n",
    "    \"MAX_STEPS_PER_EPISODE\": 36,\n",
    "\n",
    "    # Other ENV params\n",
    "    \"GENE_ACTIVITY_THRESHOLD\": 0.01,\n",
    "    \"TARGET_DISTANCE_THRESHOLD\": 0.1,\n",
    "    \"DISTANCE_GAMMA\": 0.99,           \n",
    "    \"STEP_PENALTY\": -0.05,\n",
    "    \"GOAL_BONUS\": 10,\n",
    "    \"FAIL_PENALTY\": -3,\n",
    "    \"SAME_CELL_PENALTY\": -0.5,\n",
    "    \"DISTANCE_REWARD_SCALE\": 5,\n",
    "    \"PARAMETER_TUNING\":True,\n",
    "    \"TOTAL_TIMESTEPS_HPO\": 320000,\n",
    "\n",
    "\n",
    "    # NN Architecture (Fixed for this example, but can be tuned)\n",
    "    \"PI_ARCH\": [512, 256, 256],\n",
    "    \"VF_ARCH\": [512, 256, 256],\n",
    "    \"ACTIVATION_FN\": nn.ReLU, # Make sure nn is imported if you use this directly\n",
    "}\n",
    "\n",
    "if base_config[\"USE_SIMILARITY_REWARD\"]:\n",
    "    base_config[\"DISTANCE_REWARD_SCALE\"] = 50\n",
    "else:\n",
    "    base_config[\"DISTANCE_REWARD_SCALE\"] = 5\n",
    "\n",
    "trained_model = tuning_module.run_optuna_hpo(base_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e08c2a839f1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
