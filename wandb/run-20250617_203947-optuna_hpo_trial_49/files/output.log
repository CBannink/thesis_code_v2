
--- Starting Training Run ---
Configuration: {'ORACLE_PATH': '../celloracle_data/celloracle_object/new_promoter_without_mescs_trimmed_test_own_umap/ready_oracle.pkl', 'MODEL_SAVE_PATH_BASE': '../celloracle_data/optuna_hpo_models2', 'LOG_DIR_BASE': '../celloracle_data/optuna_hpo_logs2', 'HPO_FIXED_MAX_STEPS_PER_EPISODE': 30, 'BATCH_SIZE': 128, 'USE_MASKABLE_PPO': False, 'VERBOSE': 0, 'LOG_INTERVAL': 10, 'RESET_NUM_TIMESTEPS': False, 'DEVICE': 'auto', 'USE_PROGRESS_BAR': False, 'STEP_SAVE_FREQ': 1000000000, 'PPO_N_STEPS': 256, 'PPO_N_EPOCHS': 12, 'GAMMA': 0.9816993318027057, 'GAE_LAMBDA': 0.95, 'CLIP_RANGE': 0.24207321045586905, 'ENT_COEF': 0.01506771837430503, 'VF_COEF': 0.5911860449836062, 'MAX_GRAD_NORM': 0.5, 'LEARNING_RATE': 0.00023960899115892331, 'ALLOW_GENE_ACTIVATION': True, 'STANDARD_SD_FACTOR': 1.5, 'USE_LEARNING_RATE_SCHEDULE': False, 'USE_SIMILARITY_REWARD': True, 'USE_NEW_INPUT': True, 'USE_PREV_KNOCKOUT': True, 'DIVIDER_OF_TOTAL_STEPS_FOR_CURRICULUM_LEARNING': 20, 'TARGET_CELLS_PER_PHASE': 6, 'MAX_STEP_INCREASE_PER_PHASE': 8, 'MAX_STEPS_FIRST_PHASE': 50000, 'PHASE_STEP_INCREASE': 15000, 'MAX_STEPS_PER_EPISODE': 36, 'GENE_ACTIVITY_THRESHOLD': 0.01, 'TARGET_DISTANCE_THRESHOLD': 0.1, 'DISTANCE_GAMMA': 0.987961822183782, 'STEP_PENALTY': -0.04786053509430681, 'GOAL_BONUS': 17.327620265313794, 'FAIL_PENALTY': -3, 'SAME_CELL_PENALTY': -1.647557804056219, 'DISTANCE_REWARD_SCALE': 65.64610901864404, 'PARAMETER_TUNING': True, 'TOTAL_TIMESTEPS_HPO': 320000, 'PI_ARCH': [512, 512], 'VF_ARCH': [512, 512], 'ACTIVATION_FN': <class 'torch.nn.modules.activation.ReLU'>, 'MODEL_SAVE_PATH': '../celloracle_data/optuna_hpo_models2/trial_49', 'LOG_DIR': '../celloracle_data/optuna_hpo_logs2/trial_49', 'WANDB_RUN_ID': 'optuna_hpo_trial_49', 'WANDB_RUN_NAME': 't49_lr2.4e-04_ent0.02', 'optuna_trial_obj': <optuna.trial._trial.Trial object at 0x72d4a9682fb0>, 'TOTAL_TIMESTEPS': 320000}
TensorBoard Log Directory: ../celloracle_data/optuna_hpo_logs2/trial_49
Initializing CellOracleCustomEnv with batch_size=128...
CuPy is available and GPU is accessible.
AnnData object with n_obs Ã— n_vars = 30000 Ã— 3000
    obs: 'bc_idx', 'colnames', 'obs_names', 'celltype', 'celltype_general'
    var: 'rownames', 'mean', 'std', 'symbol', 'isin_top1000_var_mean_genes', 'isin_TFdict_targets', 'isin_TFdict_regulators', 'isin_actve_regulators'
    uns: 'celltype_colors', 'neighbors', 'pca', 'umap', 'umap_neighbors_sparse'
    obsm: 'X_pca', 'X_umap', 'colnames_factor', 'umap_neighbors'
    varm: 'PCs'
    layers: 'chic', 'raw_chich_counts', 'raw_count', 'unspliced_spliced', 'normalized_count', 'imputed_count', 'simulation_input'
    obsp: 'connectivities', 'distances', 'umap_neighbors_sparse'
Finished calculating activation values for 108 genes.
obs space size:  358
get attribute called with name:  render_mode
get attribute called with indices:  None
Number of celltypes:  30  so without pcgs we have  27  targets
Policy architecture: {'net_arch': {'pi': [512, 512], 'vf': [512, 512]}, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>}
Agent (PPO) instantiated with architecture: {'pi': [512, 512], 'vf': [512, 512]}
Starting training for 320000 timesteps...
[34m[1mwandb[0m: [33mWARNING[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[0m: [33mWARNING[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in ../celloracle_data/optuna_hpo_logs2/trial_49/PPO_0
Time taken for simulation:  7.08245062828064
average overall reward:  0.22403477  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.03861464 average distance reward:  -0.09560613  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 18. Reward: 3.30, Length: 1
DEBUG (Env): Episode done for env 30. Reward: 22.86, Length: 1
DEBUG (Env): Episode done for env 63. Reward: 13.89, Length: 1
1
Time taken for simulation:  7.306151866912842
average overall reward:  0.25125694  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.012871546 average distance reward:  0.04124501  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 17. Reward: 20.22, Length: 2
DEBUG (Env): Episode done for env 43. Reward: 17.85, Length: 2
2
Time taken for simulation:  7.332751274108887
average overall reward:  -0.31047833  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.051486183 average distance reward:  -0.21113163  and average step penalty:  -0.04786053509430681
Number of done instances:  0
3
Time taken for simulation:  7.306160926818848
average overall reward:  0.00710389  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.06435773 average distance reward:  0.11932221  and average step penalty:  -0.04786053509430681
Number of done instances:  0
4
Time taken for simulation:  7.483186483383179
average overall reward:  -0.34533602  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.09010082 average distance reward:  -0.3427467  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 125. Reward: 17.83, Length: 5
5
Time taken for simulation:  7.074295282363892
average overall reward:  -0.36547482  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.025743091 average distance reward:  -0.2918712  and average step penalty:  -0.04786053509430681
Number of done instances:  0
6
Time taken for simulation:  7.023860931396484
average overall reward:  0.22019297  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  -0.022218697  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 60. Reward: 19.63, Length: 7
DEBUG (Env): Episode done for env 71. Reward: 18.84, Length: 7
DEBUG (Env): Episode done for env 111. Reward: 16.86, Length: 7
7
Time taken for simulation:  7.006431579589844
average overall reward:  0.046531737  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  -0.17013678  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 60. Reward: 20.09, Length: 1
DEBUG (Env): Episode done for env 70. Reward: 7.89, Length: 8
DEBUG (Env): Episode done for env 78. Reward: 23.78, Length: 8
8
Time taken for simulation:  7.359266042709351
average overall reward:  -0.40525702  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  -0.20293793  and average step penalty:  -0.04786053509430681
Number of done instances:  0
9
Time taken for simulation:  7.013027191162109
average overall reward:  -0.5252733  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.115843914 average distance reward:  -0.36156884  and average step penalty:  -0.04786053509430681
Number of done instances:  0
10
Time taken for simulation:  7.0826520919799805
average overall reward:  0.0046063587  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.19919059  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: 14.45, Length: 11
DEBUG (Env): Episode done for env 106. Reward: 13.80, Length: 11
DEBUG (Env): Episode done for env 117. Reward: 20.20, Length: 11
11
Time taken for simulation:  6.930608034133911
average overall reward:  -0.23885238  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.3201489  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: 17.69, Length: 12
DEBUG (Env): Episode done for env 107. Reward: 18.06, Length: 12
12
Time taken for simulation:  7.206090927124023
average overall reward:  -0.36441463  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  -0.27172446  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 28. Reward: 13.09, Length: 13
13
Time taken for simulation:  7.194709777832031
average overall reward:  -0.1663291  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.14465326  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 94. Reward: 16.15, Length: 14
DEBUG (Env): Episode done for env 101. Reward: 8.66, Length: 14
14
Time taken for simulation:  7.2708024978637695
average overall reward:  -0.07305436  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  -0.03185038  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 27. Reward: 29.94, Length: 15
15
Time taken for simulation:  7.31772780418396
average overall reward:  -0.6403854  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.283174 average distance reward:  -0.30935085  and average step penalty:  -0.04786053509430681
Number of done instances:  0
16
Time taken for simulation:  7.359133005142212
average overall reward:  -0.02229102  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.3089171 average distance reward:  0.06374258  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 116. Reward: 49.83, Length: 17
DEBUG (Env): Episode done for env 119. Reward: 16.32, Length: 17
17
Time taken for simulation:  7.316569805145264
average overall reward:  -0.49203876  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.2963763  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 114. Reward: 18.59, Length: 18
18
Time taken for simulation:  7.326180934906006
average overall reward:  -0.3040087  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.063074976  and average step penalty:  -0.04786053509430681
Number of done instances:  0
19
Time taken for simulation:  7.047314405441284
average overall reward:  -0.25023574  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.32178867 average distance reward:  -0.015958577  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 120. Reward: 21.34, Length: 20
20
Time taken for simulation:  7.021743297576904
average overall reward:  -0.26840687  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.19524477  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 14. Reward: 12.63, Length: 21
DEBUG (Env): Episode done for env 99. Reward: 24.67, Length: 21
21
Time taken for simulation:  7.051437616348267
average overall reward:  -0.24682602  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.06403501  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 63. Reward: 15.37, Length: 21
22
Time taken for simulation:  7.019405841827393
average overall reward:  -0.23983563  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.095659316  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 41. Reward: 21.61, Length: 23
23
Time taken for simulation:  7.680558919906616
average overall reward:  -0.29625404  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.26170662  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 1. Reward: 18.34, Length: 24
DEBUG (Env): Episode done for env 66. Reward: 17.83, Length: 24
24
Time taken for simulation:  7.232386112213135
average overall reward:  -0.4762836  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.283174 average distance reward:  -0.14524905  and average step penalty:  -0.04786053509430681
Number of done instances:  0
25
Time taken for simulation:  7.01485800743103
average overall reward:  -0.2945922  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.08605813  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 7. Reward: 9.62, Length: 26
26
Time taken for simulation:  7.389974117279053
average overall reward:  -0.38978997  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  -0.0973701  and average step penalty:  -0.04786053509430681
Number of done instances:  0
27
Time taken for simulation:  7.066622257232666
average overall reward:  -0.25339034  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.3604033 average distance reward:  -0.11587061  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 71. Reward: 22.38, Length: 21
DEBUG (Env): Episode done for env 127. Reward: 1.27, Length: 28
28
Time taken for simulation:  7.1348114013671875
average overall reward:  -0.25490978  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.28317398 average distance reward:  -0.059247255  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 119. Reward: 11.96, Length: 12
29
Time taken for simulation:  7.346628427505493
average overall reward:  -0.30389202  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3732748 average distance reward:  -0.018128708  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 36. Reward: 17.77, Length: 30
30
Time taken for simulation:  7.028371334075928
average overall reward:  -0.49249917  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.3089171 average distance reward:  -0.13572153  and average step penalty:  -0.04786053509430681
Number of done instances:  0
31
Time taken for simulation:  7.074199199676514
average overall reward:  -0.12962222  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.39901793 average distance reward:  -0.22423187  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 27. Reward: 32.03, Length: 17
DEBUG (Env): Episode done for env 70. Reward: 22.38, Length: 24
DEBUG (Env): Episode done for env 76. Reward: 6.16, Length: 32
DEBUG (Env): Episode done for env 124. Reward: 8.17, Length: 32
32
Time taken for simulation:  6.977273225784302
average overall reward:  -0.44909155  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.34753174 average distance reward:  -0.05369933  and average step penalty:  -0.04786053509430681
Number of done instances:  0
33
Time taken for simulation:  7.164965629577637
average overall reward:  -0.72461116  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.54060495 average distance reward:  -0.13614574  and average step penalty:  -0.04786053509430681
Number of done instances:  0
34
Time taken for simulation:  7.255321741104126
average overall reward:  -0.3881353  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3089171 average distance reward:  -0.1667297  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 121. Reward: 7.35, Length: 35
35
Time taken for simulation:  7.168604850769043
average overall reward:  -2.5404708  average fail penalty:  -2.1796875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3604033 average distance reward:  -0.08789168  and average step penalty:  -0.04786053509430681
Number of done instances:  94
DEBUG (Env): Episode done for env 0. Reward: -21.08, Length: 36
DEBUG (Env): Episode done for env 3. Reward: -11.05, Length: 36
DEBUG (Env): Episode done for env 4. Reward: -23.57, Length: 36
DEBUG (Env): Episode done for env 5. Reward: -27.76, Length: 36
DEBUG (Env): Episode done for env 6. Reward: -29.22, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -16.91, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -26.53, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -26.78, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 13. Reward: -21.19, Length: 36
DEBUG (Env): Episode done for env 15. Reward: -14.79, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -18.55, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -20.88, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -20.96, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -33.93, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -12.95, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -25.08, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -26.02, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -11.42, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -16.16, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -14.03, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -18.88, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -24.91, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -23.13, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -16.67, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -15.93, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -23.07, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -34.15, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -13.99, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -20.15, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -22.90, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -20.08, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -21.68, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -19.47, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -9.59, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -8.58, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -29.40, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -27.98, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -22.61, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -24.21, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -28.57, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -16.65, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -20.99, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -26.89, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -28.13, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -18.07, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -22.84, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -22.49, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -28.24, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -16.61, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -27.08, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -20.82, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -18.68, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -19.43, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -15.26, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -19.44, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -20.03, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -27.67, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -16.95, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -23.46, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -21.48, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -25.18, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -28.68, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -25.10, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -19.93, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -16.34, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -25.64, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -17.22, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -29.12, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -21.06, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -19.23, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -18.27, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -16.20, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -23.14, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 13.53, Length: 22
DEBUG (Env): Episode done for env 95. Reward: -20.88, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -25.16, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -16.14, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -18.52, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -24.15, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -25.31, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -19.84, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -16.11, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -22.27, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -24.23, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -17.05, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -10.63, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -19.46, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -19.62, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -25.16, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -27.11, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -23.48, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -12.48, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -23.05, Length: 36
36
Time taken for simulation:  7.155354022979736
average overall reward:  -0.42291674  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.06435773 average distance reward:  -0.26382348  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 18. Reward: -23.68, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -19.43, Length: 36
37
Time taken for simulation:  7.529869079589844
average overall reward:  0.48097086  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.025743091 average distance reward:  0.05996144  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: 18.66, Length: 2
DEBUG (Env): Episode done for env 17. Reward: -11.04, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 25.09, Length: 2
DEBUG (Env): Episode done for env 43. Reward: -12.81, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 24.73, Length: 2
DEBUG (Env): Episode done for env 126. Reward: 31.47, Length: 2
38
Time taken for simulation:  7.4474756717681885
average overall reward:  0.24711537  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.06435773 average distance reward:  -0.18215443  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 15. Reward: 16.74, Length: 3
DEBUG (Env): Episode done for env 36. Reward: 25.78, Length: 9
DEBUG (Env): Episode done for env 49. Reward: 15.86, Length: 3
DEBUG (Env): Episode done for env 103. Reward: 17.39, Length: 3
39
Time taken for simulation:  7.143113851547241
average overall reward:  0.11207217  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.18848222  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 24. Reward: 21.04, Length: 4
DEBUG (Env): Episode done for env 50. Reward: 21.67, Length: 4
DEBUG (Env): Episode done for env 63. Reward: 12.82, Length: 18
DEBUG (Env): Episode done for env 90. Reward: 17.88, Length: 4
40
Time taken for simulation:  7.2548582553863525
average overall reward:  -0.20113489  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.090100825 average distance reward:  -0.039736047  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 125. Reward: -22.00, Length: 36
41
Time taken for simulation:  7.088313341140747
average overall reward:  0.16518912  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.115843914 average distance reward:  -0.07722248  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 47. Reward: 12.11, Length: 6
DEBUG (Env): Episode done for env 60. Reward: 20.39, Length: 34
DEBUG (Env): Episode done for env 88. Reward: 30.62, Length: 6
42
Time taken for simulation:  8.04461121559143
average overall reward:  -0.46379155  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.102972366 average distance reward:  -0.28952113  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 111. Reward: -23.17, Length: 36
43
Time taken for simulation:  7.2134222984313965
average overall reward:  0.04100838  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.06435773 average distance reward:  0.041292116  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 78. Reward: -15.18, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 9.92, Length: 23
44
Time taken for simulation:  7.014387130737305
average overall reward:  -0.41709042  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.31152868  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 52. Reward: 26.13, Length: 9
45
Time taken for simulation:  7.145227432250977
average overall reward:  -0.38511598  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.141587 average distance reward:  -0.19566846  and average step penalty:  -0.04786053509430681
Number of done instances:  0
46
Time taken for simulation:  7.420135259628296
average overall reward:  -0.36533746  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  -0.041219693  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: -18.41, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -15.36, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -19.49, Length: 36
47
Time taken for simulation:  7.201322793960571
average overall reward:  0.13280442  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594475 average distance reward:  0.027368635  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: -18.56, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 22.04, Length: 12
DEBUG (Env): Episode done for env 36. Reward: 21.18, Length: 9
DEBUG (Env): Episode done for env 107. Reward: -21.65, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 29.33, Length: 12
48
Time taken for simulation:  7.091036558151245
average overall reward:  -0.36378288  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.073668554  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 28. Reward: -18.55, Length: 36
49
Time taken for simulation:  7.084849834442139
average overall reward:  -0.08029057  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.1576777  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 91. Reward: 17.74, Length: 14
DEBUG (Env): Episode done for env 101. Reward: -22.62, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 26.36, Length: 2
DEBUG (Env): Episode done for env 119. Reward: 6.91, Length: 21
50
Time taken for simulation:  7.005764722824097
average overall reward:  -0.30292475  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  -0.3970928  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 29. Reward: 19.69, Length: 15
DEBUG (Env): Episode done for env 33. Reward: 11.76, Length: 15
51
Time taken for simulation:  6.996502161026001
average overall reward:  -0.2681866  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  0.037104838  and average step penalty:  -0.04786053509430681
Number of done instances:  0
52
Time taken for simulation:  7.061786890029907
average overall reward:  -0.037284046  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594475 average distance reward:  -0.16615736  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 47. Reward: 18.48, Length: 11
DEBUG (Env): Episode done for env 95. Reward: 22.35, Length: 17
DEBUG (Env): Episode done for env 104. Reward: 18.65, Length: 17
DEBUG (Env): Episode done for env 116. Reward: -18.64, Length: 36
53
Time taken for simulation:  7.653146505355835
average overall reward:  -0.12287775  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.045364767  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 32. Reward: 13.70, Length: 18
DEBUG (Env): Episode done for env 114. Reward: -14.27, Length: 36
54
Time taken for simulation:  7.05925178527832
average overall reward:  -0.21841273  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  -0.20960847  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 84. Reward: 22.92, Length: 19
DEBUG (Env): Episode done for env 125. Reward: 4.84, Length: 14
55
Time taken for simulation:  7.574851989746094
average overall reward:  -0.47549266  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.10814905  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 120. Reward: -14.27, Length: 36
56
Time taken for simulation:  7.218075513839722
average overall reward:  -0.38972196  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.15775035  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 14. Reward: -21.14, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 10.37, Length: 21
57
Time taken for simulation:  7.1624321937561035
average overall reward:  -0.6373101  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  -0.35776168  and average step penalty:  -0.04786053509430681
Number of done instances:  0
58
Time taken for simulation:  6.9113874435424805
average overall reward:  -0.6882802  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.34667963  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 41. Reward: -18.73, Length: 36
59
Time taken for simulation:  7.394189834594727
average overall reward:  -0.17630659  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  0.02761628  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 1. Reward: -22.29, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 9.04, Length: 24
DEBUG (Env): Episode done for env 66. Reward: -20.53, Length: 36
60
Time taken for simulation:  7.021248817443848
average overall reward:  -0.32836503  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.41188946 average distance reward:  -0.13935912  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 28. Reward: 21.01, Length: 12
DEBUG (Env): Episode done for env 47. Reward: 17.88, Length: 8
61
Time taken for simulation:  7.047739267349243
average overall reward:  -0.15479144  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.109678134  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 7. Reward: -21.68, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 23.01, Length: 3
DEBUG (Env): Episode done for env 101. Reward: -5.37, Length: 12
62
Time taken for simulation:  7.016178369522095
average overall reward:  -0.5027907  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.32178864 average distance reward:  -0.13314147  and average step penalty:  -0.04786053509430681
Number of done instances:  0
63
Time taken for simulation:  7.036928653717041
average overall reward:  -0.2243295  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.020406585  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 71. Reward: -17.02, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 21.90, Length: 2
DEBUG (Env): Episode done for env 127. Reward: -10.02, Length: 36
64
Time taken for simulation:  7.657390594482422
average overall reward:  -0.42736554  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.2703177  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 123. Reward: 7.67, Length: 29
65
Time taken for simulation:  7.330939769744873
average overall reward:  -0.41212288  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.2035888  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 2. Reward: 27.80, Length: 18
66
Time taken for simulation:  7.039947271347046
average overall reward:  -0.55922693  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.34753174 average distance reward:  -0.16383466  and average step penalty:  -0.04786053509430681
Number of done instances:  0
67
Time taken for simulation:  7.162620544433594
average overall reward:  -0.300614  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.011201464  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 27. Reward: -25.14, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -22.80, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -19.39, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 2.32, Length: 32
DEBUG (Env): Episode done for env 124. Reward: -19.71, Length: 36
68
Time taken for simulation:  7.275787830352783
average overall reward:  -0.090675965  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.38614637 average distance reward:  -0.19815716  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: 13.04, Length: 33
DEBUG (Env): Episode done for env 48. Reward: 14.42, Length: 33
DEBUG (Env): Episode done for env 70. Reward: 11.58, Length: 1
DEBUG (Env): Episode done for env 74. Reward: 31.26, Length: 33
69
Time taken for simulation:  7.958954811096191
average overall reward:  -0.49976513  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.3089171 average distance reward:  -0.14298746  and average step penalty:  -0.04786053509430681
Number of done instances:  0
70
Time taken for simulation:  7.06455135345459
average overall reward:  -0.28381404  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.37327486 average distance reward:  0.025386803  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 56. Reward: 1.21, Length: 35
DEBUG (Env): Episode done for env 121. Reward: -15.79, Length: 36
71
Time taken for simulation:  7.317760467529297
average overall reward:  -1.807186  average fail penalty:  -1.5  and average goal bonus:  0.0  and average same cell penalty:  -0.29604557 average distance reward:  0.03672003  and average step penalty:  -0.04786053509430681
Number of done instances:  64
DEBUG (Env): Episode done for env 3. Reward: -18.59, Length: 36
DEBUG (Env): Episode done for env 4. Reward: -24.97, Length: 36
DEBUG (Env): Episode done for env 5. Reward: -12.38, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -10.87, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -15.86, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -24.45, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -22.59, Length: 36
DEBUG (Env): Episode done for env 13. Reward: -16.77, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -14.35, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -21.23, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -22.04, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -19.25, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -22.27, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -15.58, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -13.99, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -24.68, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -20.31, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -21.99, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -16.69, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -19.11, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -21.57, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -23.11, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -26.37, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -14.95, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -16.00, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -20.48, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -16.42, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -22.59, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -35.00, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -28.35, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -17.28, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -21.05, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -17.13, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -15.50, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -17.87, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -17.89, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -28.78, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -19.44, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -14.88, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -21.56, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -15.23, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -28.75, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -22.12, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -30.91, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -20.71, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -25.70, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -21.56, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -30.38, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -24.54, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -30.02, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -22.40, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -31.60, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -14.13, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -24.95, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -22.46, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -24.06, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -16.47, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -23.93, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -11.74, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -24.73, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -23.92, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -11.74, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -24.33, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -16.48, Length: 36
72
Time taken for simulation:  7.438832998275757
average overall reward:  0.21672341  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.06435773 average distance reward:  0.10507267  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: 22.64, Length: 1
DEBUG (Env): Episode done for env 18. Reward: -14.02, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -22.02, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 40.32, Length: 26
73
Time taken for simulation:  7.284860134124756
average overall reward:  -0.26885274  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.18378115  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -12.67, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -19.56, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -9.24, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 17.88, Length: 2
DEBUG (Env): Episode done for env 43. Reward: -18.24, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -21.02, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -27.45, Length: 36
74
Time taken for simulation:  7.688065767288208
average overall reward:  -0.55970615  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  -0.19697377  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 15. Reward: -28.54, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -15.57, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -21.99, Length: 36
75
Time taken for simulation:  7.383455514907837
average overall reward:  -0.34583646  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.115843914 average distance reward:  -0.22375403  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: -24.28, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -8.81, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -20.54, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 24.67, Length: 4
DEBUG (Env): Episode done for env 90. Reward: -12.22, Length: 36
76
Time taken for simulation:  7.221059083938599
average overall reward:  -0.22102195  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.07722928 average distance reward:  -0.09593213  and average step penalty:  -0.04786053509430681
Number of done instances:  0
77
Time taken for simulation:  7.8807384967803955
average overall reward:  -0.32353216  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.1673301 average distance reward:  -0.061466523  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 60. Reward: -13.39, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -19.36, Length: 36
78
Time taken for simulation:  7.4773008823394775
average overall reward:  -0.07474915  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  0.028506968  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 85. Reward: 32.84, Length: 7
DEBUG (Env): Episode done for env 111. Reward: -28.69, Length: 36
79
Time taken for simulation:  7.462944030761719
average overall reward:  -0.28640765  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  -0.33370072  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 11. Reward: 20.09, Length: 8
DEBUG (Env): Episode done for env 53. Reward: 30.48, Length: 8
DEBUG (Env): Episode done for env 78. Reward: -19.39, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -11.39, Length: 36
80
Time taken for simulation:  7.454726457595825
average overall reward:  0.087049924  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.016319372  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 0. Reward: 31.67, Length: 7
DEBUG (Env): Episode done for env 12. Reward: 13.97, Length: 9
DEBUG (Env): Episode done for env 52. Reward: -24.39, Length: 36
81
Time taken for simulation:  7.403606414794922
average overall reward:  -0.54651046  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.27983364  and average step penalty:  -0.04786053509430681
Number of done instances:  0
82
Time taken for simulation:  7.466212511062622
average overall reward:  -0.06473219  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.074832976  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: -21.73, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 17.17, Length: 11
DEBUG (Env): Episode done for env 106. Reward: -12.63, Length: 36
83
Time taken for simulation:  7.317169904708862
average overall reward:  -0.5661999  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.15198128  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 20. Reward: -13.91, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -14.91, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -22.07, Length: 36
84
Time taken for simulation:  7.65384578704834
average overall reward:  -0.353567  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  -0.29327655  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 38. Reward: 16.10, Length: 13
DEBUG (Env): Episode done for env 104. Reward: 12.69, Length: 32
85
Time taken for simulation:  7.321187257766724
average overall reward:  0.096966654  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.12040367  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 16.16, Length: 17
DEBUG (Env): Episode done for env 40. Reward: 28.19, Length: 14
DEBUG (Env): Episode done for env 54. Reward: 10.48, Length: 14
DEBUG (Env): Episode done for env 79. Reward: 19.26, Length: 14
DEBUG (Env): Episode done for env 91. Reward: -27.20, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -17.66, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -17.15, Length: 36
86
Time taken for simulation:  7.444215297698975
average overall reward:  -0.47474858  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.122582145  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 29. Reward: -11.34, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -27.19, Length: 36
87
Time taken for simulation:  7.032748460769653
average overall reward:  -0.06789629  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.05909194  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 18. Reward: 22.11, Length: 15
DEBUG (Env): Episode done for env 38. Reward: 45.48, Length: 3
88
Time taken for simulation:  7.108174085617065
average overall reward:  -0.52554005  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  -0.2248598  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 95. Reward: -25.96, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -24.19, Length: 36
89
Time taken for simulation:  7.062031507492065
average overall reward:  -0.21650067  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.051192418  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 32. Reward: -23.57, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 6.63, Length: 18
DEBUG (Env): Episode done for env 114. Reward: -16.19, Length: 36
90
Time taken for simulation:  7.392957925796509
average overall reward:  -0.48593277  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.29604554 average distance reward:  -0.50126773  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 11.69, Length: 31
DEBUG (Env): Episode done for env 65. Reward: 28.75, Length: 19
DEBUG (Env): Episode done for env 84. Reward: -20.28, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 17.85, Length: 11
DEBUG (Env): Episode done for env 125. Reward: -18.30, Length: 36
91
Time taken for simulation:  7.417083501815796
average overall reward:  0.19275108  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  -0.11010893  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: 9.78, Length: 20
DEBUG (Env): Episode done for env 37. Reward: 8.72, Length: 32
DEBUG (Env): Episode done for env 85. Reward: 4.50, Length: 13
DEBUG (Env): Episode done for env 90. Reward: 6.61, Length: 16
DEBUG (Env): Episode done for env 120. Reward: -21.68, Length: 36
92
Time taken for simulation:  8.011346340179443
average overall reward:  -0.38301754  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  -0.2691955  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 14. Reward: -18.91, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -26.91, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 12.96, Length: 21
93
Time taken for simulation:  7.258122682571411
average overall reward:  -0.039218843  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  0.04059974  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 40. Reward: 17.57, Length: 8
94
Time taken for simulation:  7.382547855377197
average overall reward:  -0.11473787  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  -0.30566332  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 36. Reward: 11.24, Length: 11
DEBUG (Env): Episode done for env 63. Reward: 22.56, Length: 19
DEBUG (Env): Episode done for env 69. Reward: 12.21, Length: 23
95
Time taken for simulation:  7.400200128555298
average overall reward:  -0.26880392  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.3604033 average distance reward:  -0.10784666  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 48. Reward: 9.55, Length: 27
DEBUG (Env): Episode done for env 66. Reward: -27.03, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 27.88, Length: 4
96
Time taken for simulation:  7.334208965301514
average overall reward:  -0.3963008  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.16663483  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 28. Reward: -21.11, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -19.62, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 11.24, Length: 23
97
Time taken for simulation:  7.0545494556427
average overall reward:  -0.53452176  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.14374067  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 7. Reward: -19.90, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -16.33, Length: 36
98
Time taken for simulation:  7.428075313568115
average overall reward:  -0.2214674  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.03867637  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 7. Reward: 17.39, Length: 1
99
Time taken for simulation:  7.1314191818237305
average overall reward:  0.0070279688  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.32178867 average distance reward:  0.040873557  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 1.09, Length: 28
DEBUG (Env): Episode done for env 71. Reward: -17.89, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 19.52, Length: 28
DEBUG (Env): Episode done for env 95. Reward: 23.66, Length: 11
DEBUG (Env): Episode done for env 101. Reward: -22.43, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -22.05, Length: 36
100
Time taken for simulation:  7.004705905914307
average overall reward:  -0.3817243  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.32178864 average distance reward:  -0.12400961  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 89. Reward: 19.43, Length: 1
DEBUG (Env): Episode done for env 123. Reward: -39.65, Length: 36
101
Time taken for simulation:  7.7385478019714355
average overall reward:  -0.25975806  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.09214423  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: -18.95, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 25.94, Length: 6
102
Time taken for simulation:  7.717801332473755
average overall reward:  -0.48728725  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.24635355  and average step penalty:  -0.04786053509430681
Number of done instances:  0
103
Time taken for simulation:  7.462204933166504
average overall reward:  -0.25265175  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  0.1077751  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 27. Reward: -14.96, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -28.89, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -17.33, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -23.37, Length: 36
104
Time taken for simulation:  7.300470352172852
average overall reward:  -0.5137628  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.12298169  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 70. Reward: -31.42, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -25.14, Length: 36
105
Time taken for simulation:  7.443859100341797
average overall reward:  -0.21277331  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.0042392313  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 36. Reward: 36.02, Length: 11
106
Time taken for simulation:  7.3383097648620605
average overall reward:  -0.16589049  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.32178867 average distance reward:  -0.020110361  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: 3.62, Length: 33
DEBUG (Env): Episode done for env 56. Reward: -13.97, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 33.21, Length: 12
DEBUG (Env): Episode done for env 121. Reward: -17.19, Length: 36
107
Time taken for simulation:  7.112499952316284
average overall reward:  -1.0438306  average fail penalty:  -1.0546875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.07709627  and average step penalty:  -0.04786053509430681
Number of done instances:  47
DEBUG (Env): Episode done for env 4. Reward: 11.17, Length: 36
DEBUG (Env): Episode done for env 5. Reward: -19.41, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -27.66, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -24.73, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 1.19, Length: 28
DEBUG (Env): Episode done for env 16. Reward: -16.47, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -21.20, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -16.51, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -13.38, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -10.52, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -18.44, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -25.13, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -20.13, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -16.74, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -26.10, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -17.08, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -19.77, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -25.67, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -18.26, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -20.25, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -19.79, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -23.03, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -20.52, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -16.83, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -15.27, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -29.70, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -13.92, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -37.19, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -20.34, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -18.83, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -24.90, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -8.23, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -15.76, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -24.02, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -13.54, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -11.49, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -11.48, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -18.15, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 21.74, Length: 23
DEBUG (Env): Episode done for env 105. Reward: -25.67, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -12.54, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -13.23, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -15.89, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -23.12, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -18.74, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -12.83, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -29.89, Length: 36
108
Time taken for simulation:  7.123980760574341
average overall reward:  -0.3056722  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.25229847  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: -22.88, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -18.23, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 8.49, Length: 34
DEBUG (Env): Episode done for env 113. Reward: 19.90, Length: 1
DEBUG (Env): Episode done for env 117. Reward: -31.06, Length: 36
109
Time taken for simulation:  8.278518915176392
average overall reward:  -0.46514875  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.24009395  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: -23.70, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -20.96, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -33.47, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 13.56, Length: 2
DEBUG (Env): Episode done for env 126. Reward: -17.13, Length: 36
110
Time taken for simulation:  7.2016236782073975
average overall reward:  -0.28377196  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  -0.15707836  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 15. Reward: -15.20, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -34.58, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 21.54, Length: 4
111
Time taken for simulation:  7.1522417068481445
average overall reward:  -0.07034193  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  -0.19095488  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: -25.89, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 9.93, Length: 15
DEBUG (Env): Episode done for env 50. Reward: 10.70, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -20.93, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 2.59, Length: 33
112
Time taken for simulation:  7.153101444244385
average overall reward:  -0.391323  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.3372475  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 55. Reward: 15.89, Length: 5
113
Time taken for simulation:  7.174939155578613
average overall reward:  -0.44519675  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.141587 average distance reward:  -0.20887421  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 60. Reward: -20.17, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -16.83, Length: 36
114
Time taken for simulation:  7.29336142539978
average overall reward:  0.017787836  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.02659212  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 8. Reward: 24.52, Length: 7
DEBUG (Env): Episode done for env 68. Reward: 45.74, Length: 7
115
Time taken for simulation:  7.100526809692383
average overall reward:  -0.4667446  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.15319276  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 53. Reward: -22.89, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -21.69, Length: 36
116
Time taken for simulation:  7.226305246353149
average overall reward:  -0.31756786  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  -0.16743676  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: -20.18, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -14.72, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -17.96, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 21.16, Length: 5
117
Time taken for simulation:  7.156063795089722
average overall reward:  -0.13420981  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  -0.054391205  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 47. Reward: 29.99, Length: 6
118
Time taken for simulation:  7.383422136306763
average overall reward:  -0.42174998  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.20726115  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 9. Reward: -19.53, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -21.11, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 11.83, Length: 1
DEBUG (Env): Episode done for env 106. Reward: -19.82, Length: 36
119
Time taken for simulation:  7.1519775390625
average overall reward:  -0.30858684  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.10466396  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 20. Reward: -23.89, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 23.89, Length: 12
DEBUG (Env): Episode done for env 122. Reward: -12.61, Length: 36
120
Time taken for simulation:  7.35388708114624
average overall reward:  -0.4423201  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  -0.18851481  and average step penalty:  -0.04786053509430681
Number of done instances:  0
121
Time taken for simulation:  8.034259796142578
average overall reward:  -0.35235643  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.16431248  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 6. Reward: -16.82, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 13.99, Length: 34
DEBUG (Env): Episode done for env 47. Reward: 24.16, Length: 3
DEBUG (Env): Episode done for env 54. Reward: -20.52, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -31.62, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -28.71, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -2.03, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -22.86, Length: 36
122
Time taken for simulation:  7.268720388412476
average overall reward:  0.12982926  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.15976551  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 29. Reward: -25.58, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -28.03, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 20.96, Length: 1
DEBUG (Env): Episode done for env 82. Reward: 33.92, Length: 15
123
Time taken for simulation:  7.117807626724243
average overall reward:  -0.0604143  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.055713344  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 14. Reward: 2.74, Length: 31
DEBUG (Env): Episode done for env 18. Reward: -20.70, Length: 36
124
Time taken for simulation:  7.236904144287109
average overall reward:  -0.42725328  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.23389634  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 116. Reward: -10.05, Length: 36
125
Time taken for simulation:  7.42289400100708
average overall reward:  -0.28271645  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.02852976  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 32. Reward: -28.78, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -13.41, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -12.32, Length: 36
126
Time taken for simulation:  7.171218156814575
average overall reward:  -0.06570086  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594472 average distance reward:  0.16991991  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -17.25, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -21.31, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -21.18, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -16.00, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 30.32, Length: 23
DEBUG (Env): Episode done for env 125. Reward: -16.62, Length: 36
127
Time taken for simulation:  7.378168344497681
average overall reward:  -0.29196328  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.12871546 average distance reward:  -0.021637246  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 13. Reward: -15.93, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -21.99, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -22.85, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -21.48, Length: 36
128
Time taken for simulation:  7.3600053787231445
average overall reward:  -0.5448982  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.39901793 average distance reward:  -0.18651679  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 19. Reward: 15.86, Length: 21
DEBUG (Env): Episode done for env 45. Reward: -17.01, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -20.13, Length: 36
129
Time taken for simulation:  7.38973331451416
average overall reward:  -0.58485705  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.29474273  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 40. Reward: -20.36, Length: 36
130
Time taken for simulation:  7.163279294967651
average overall reward:  -0.6116722  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  -0.38591558  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 63. Reward: -13.40, Length: 36
131
Time taken for simulation:  7.0387303829193115
average overall reward:  -0.14720221  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.29604554 average distance reward:  -0.29790923  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: 27.07, Length: 15
DEBUG (Env): Episode done for env 27. Reward: 10.58, Length: 28
DEBUG (Env): Episode done for env 29. Reward: 19.11, Length: 9
DEBUG (Env): Episode done for env 48. Reward: -22.38, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -27.03, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 0.09, Length: 24
132
Time taken for simulation:  7.964174032211304
average overall reward:  -0.028277218  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  0.07888827  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: -20.23, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -22.79, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 28.31, Length: 2
DEBUG (Env): Episode done for env 65. Reward: 14.81, Length: 6
133
Time taken for simulation:  7.248384237289429
average overall reward:  -0.4496407  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.333513  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 6. Reward: 17.11, Length: 12
DEBUG (Env): Episode done for env 41. Reward: -19.55, Length: 36
134
Time taken for simulation:  7.301194906234741
average overall reward:  -0.202289  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3089171 average distance reward:  0.04255412  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 7. Reward: -24.40, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 46.22, Length: 13
135
Time taken for simulation:  6.9940361976623535
average overall reward:  -0.5511117  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.37327483 average distance reward:  -0.14816087  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 25. Reward: -2.26, Length: 28
DEBUG (Env): Episode done for env 31. Reward: -16.24, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -20.23, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -22.38, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -20.74, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -19.36, Length: 36
136
Time taken for simulation:  6.943478584289551
average overall reward:  -0.21483451  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.1720267  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 30. Reward: 6.04, Length: 28
DEBUG (Env): Episode done for env 89. Reward: -15.35, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 6.68, Length: 9
DEBUG (Env): Episode done for env 123. Reward: -17.61, Length: 36
137
Time taken for simulation:  7.241124629974365
average overall reward:  -0.5469524  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.23340057  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: -23.42, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -26.20, Length: 36
138
Time taken for simulation:  7.0674214363098145
average overall reward:  -0.16874796  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.024571627  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 41. Reward: 17.53, Length: 5
139
Time taken for simulation:  7.041917324066162
average overall reward:  0.11990407  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.29604554 average distance reward:  -0.030802969  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 27. Reward: 35.87, Length: 8
DEBUG (Env): Episode done for env 76. Reward: -18.26, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 9.47, Length: 24
DEBUG (Env): Episode done for env 81. Reward: -0.68, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 19.76, Length: 8
140
Time taken for simulation:  7.400428056716919
average overall reward:  -0.34285578  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.055047095  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 70. Reward: -20.45, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -20.77, Length: 36
141
Time taken for simulation:  7.298714876174927
average overall reward:  -0.30335099  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.25823766  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 18. Reward: 19.42, Length: 18
DEBUG (Env): Episode done for env 36. Reward: -27.95, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 16.54, Length: 5
142
Time taken for simulation:  7.3363518714904785
average overall reward:  -0.5103216  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.33466017 average distance reward:  -0.19286044  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: -22.02, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -28.36, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 30.11, Length: 2
DEBUG (Env): Episode done for env 121. Reward: -22.30, Length: 36
143
Time taken for simulation:  7.534222602844238
average overall reward:  -1.3623548  average fail penalty:  -0.8671875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.3381193  and average step penalty:  -0.04786053509430681
Number of done instances:  37
DEBUG (Env): Episode done for env 4. Reward: -24.90, Length: 36
DEBUG (Env): Episode done for env 5. Reward: -22.38, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -19.99, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -26.36, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -23.27, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -16.45, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -28.04, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -31.30, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -19.34, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -21.50, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -9.75, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -21.32, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -21.80, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -23.54, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -20.33, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -20.01, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -12.45, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -22.17, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -22.25, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -13.93, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -14.82, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -22.12, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -14.16, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -17.74, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -20.06, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -18.35, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -38.55, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -15.61, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -17.42, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -11.98, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -18.22, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -22.49, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -26.48, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -16.35, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -5.64, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -15.97, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -18.06, Length: 36
144
Time taken for simulation:  7.200437784194946
average overall reward:  -0.4827804  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.102972366 average distance reward:  -0.3735695  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: -14.79, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 19.52, Length: 1
DEBUG (Env): Episode done for env 103. Reward: -21.99, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -20.38, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -17.35, Length: 36
145
Time taken for simulation:  7.2806174755096436
average overall reward:  -0.34170115  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.016420081  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: -19.11, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -17.62, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -22.65, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -21.66, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -16.04, Length: 36
146
Time taken for simulation:  7.395265817642212
average overall reward:  -0.55623865  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  -0.20637776  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 15. Reward: -14.31, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -16.59, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -17.49, Length: 36
147
Time taken for simulation:  7.151086330413818
average overall reward:  -0.3537733  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.16733009 average distance reward:  -0.06827015  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 24. Reward: -21.45, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -21.39, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -21.01, Length: 36
148
Time taken for simulation:  7.202600002288818
average overall reward:  0.019413233  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.12233162  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 55. Reward: -14.25, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -0.61, Length: 34
DEBUG (Env): Episode done for env 103. Reward: 33.39, Length: 4
DEBUG (Env): Episode done for env 126. Reward: 16.48, Length: 3
149
Time taken for simulation:  7.007652997970581
average overall reward:  -0.29432878  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.29013562  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 35. Reward: 16.12, Length: 4
DEBUG (Env): Episode done for env 60. Reward: -12.09, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 19.50, Length: 10
DEBUG (Env): Episode done for env 88. Reward: -23.50, Length: 36
150
Time taken for simulation:  7.32313084602356
average overall reward:  -0.0677838  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.035542008  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 8. Reward: -16.83, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 25.29, Length: 7
DEBUG (Env): Episode done for env 99. Reward: 14.73, Length: 24
151
Time taken for simulation:  7.485432863235474
average overall reward:  -0.1266378  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.115843914 average distance reward:  -0.07486789  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 53. Reward: -21.05, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 28.31, Length: 16
152
Time taken for simulation:  7.018995761871338
average overall reward:  0.082642026  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.00064374506  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: -10.32, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 12.75, Length: 25
DEBUG (Env): Episode done for env 52. Reward: -20.93, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 14.63, Length: 1
DEBUG (Env): Episode done for env 111. Reward: -16.79, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 20.00, Length: 1
153
Time taken for simulation:  7.2806055545806885
average overall reward:  -0.29337114  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.08483711  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 46. Reward: 21.40, Length: 9
154
Time taken for simulation:  7.253893852233887
average overall reward:  -0.4984669  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  -0.13573451  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: -27.29, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -23.08, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -25.79, Length: 36
155
Time taken for simulation:  7.2688658237457275
average overall reward:  -0.42988637  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.17678288  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 20. Reward: -27.39, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 15.46, Length: 8
DEBUG (Env): Episode done for env 42. Reward: -21.61, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -18.94, Length: 36
156
Time taken for simulation:  7.03766393661499
average overall reward:  0.025889196  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.13929316  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 14. Reward: 2.45, Length: 33
DEBUG (Env): Episode done for env 24. Reward: 11.84, Length: 1
DEBUG (Env): Episode done for env 74. Reward: 20.59, Length: 16
157
Time taken for simulation:  7.555149793624878
average overall reward:  -0.17140222  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168783 average distance reward:  0.0899616  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 38. Reward: -20.27, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -13.44, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -23.80, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 9.74, Length: 14
DEBUG (Env): Episode done for env 91. Reward: -21.94, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -24.82, Length: 36
158
Time taken for simulation:  7.044914484024048
average overall reward:  -0.6719154  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  -0.56039894  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 33. Reward: -23.30, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 13.49, Length: 33
DEBUG (Env): Episode done for env 79. Reward: -11.27, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -17.45, Length: 36
159
Time taken for simulation:  7.510631561279297
average overall reward:  -0.23483893  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.14214881  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 39. Reward: 18.97, Length: 9
160
Time taken for simulation:  6.922383785247803
average overall reward:  -0.27964061  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.04766903  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 16. Reward: 12.34, Length: 17
DEBUG (Env): Episode done for env 116. Reward: -18.14, Length: 36
161
Time taken for simulation:  7.210268497467041
average overall reward:  -0.48615694  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.3089171 average distance reward:  -0.08250433  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 32. Reward: -14.86, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -12.54, Length: 36
162
Time taken for simulation:  7.310712099075317
average overall reward:  -0.05920627  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.0047333986  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -21.35, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 21.23, Length: 14
DEBUG (Env): Episode done for env 81. Reward: 25.41, Length: 13
DEBUG (Env): Episode done for env 84. Reward: -20.99, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -21.75, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -18.95, Length: 36
163
Time taken for simulation:  7.740900039672852
average overall reward:  -0.6930283  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.34753174 average distance reward:  -0.250761  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 13. Reward: -24.05, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -16.70, Length: 36
164
Time taken for simulation:  7.816790580749512
average overall reward:  0.19814804  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.019222293  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 19. Reward: -21.31, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 25.79, Length: 9
DEBUG (Env): Episode done for env 45. Reward: 13.65, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -17.06, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 31.49, Length: 7
DEBUG (Env): Episode done for env 119. Reward: 9.21, Length: 30
165
Time taken for simulation:  7.200668096542358
average overall reward:  0.086603925  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.04226937  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: 28.73, Length: 3
DEBUG (Env): Episode done for env 26. Reward: 30.63, Length: 11
DEBUG (Env): Episode done for env 40. Reward: -17.74, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 12.32, Length: 13
166
Time taken for simulation:  7.486864328384399
average overall reward:  -0.12288892  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  0.047030494  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 75. Reward: 14.29, Length: 23
167
Time taken for simulation:  7.244126319885254
average overall reward:  -0.7034749  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.30443347  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: -16.25, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -27.68, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -26.63, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -29.41, Length: 36
168
Time taken for simulation:  7.099797248840332
average overall reward:  -0.24688932  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.25396395  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 28. Reward: -29.02, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -12.58, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -11.49, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -24.00, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 14.37, Length: 10
DEBUG (Env): Episode done for env 82. Reward: 17.40, Length: 10
DEBUG (Env): Episode done for env 101. Reward: -0.94, Length: 33
169
Time taken for simulation:  7.004490613937378
average overall reward:  -0.43887252  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.14875817  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 6. Reward: -23.33, Length: 36
170
Time taken for simulation:  7.025960922241211
average overall reward:  -0.20809974  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.37327483 average distance reward:  -0.034270875  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 0. Reward: 24.05, Length: 3
DEBUG (Env): Episode done for env 7. Reward: -19.39, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 12.72, Length: 34
171
Time taken for simulation:  7.054434061050415
average overall reward:  -0.34044093  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.08964305  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: -14.51, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -20.83, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 17.13, Length: 28
DEBUG (Env): Episode done for env 71. Reward: -21.16, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -15.87, Length: 36
172
Time taken for simulation:  7.233985185623169
average overall reward:  -0.09472114  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  0.01244434  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: 13.49, Length: 3
DEBUG (Env): Episode done for env 30. Reward: -4.35, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 26.32, Length: 20
DEBUG (Env): Episode done for env 123. Reward: -21.29, Length: 36
173
Time taken for simulation:  7.1688597202301025
average overall reward:  -0.65020573  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.32178867 average distance reward:  -0.23368153  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: -20.05, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -15.96, Length: 36
174
Time taken for simulation:  7.755302906036377
average overall reward:  -0.22322676  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.055612944  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 7. Reward: 30.43, Length: 4
DEBUG (Env): Episode done for env 41. Reward: -17.43, Length: 36
175
Time taken for simulation:  7.450658321380615
average overall reward:  -0.3384183  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594475 average distance reward:  -0.39697915  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 29.76, Length: 5
DEBUG (Env): Episode done for env 25. Reward: 14.93, Length: 4
DEBUG (Env): Episode done for env 27. Reward: -21.56, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 17.82, Length: 17
DEBUG (Env): Episode done for env 76. Reward: -24.83, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -12.64, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -21.27, Length: 36
176
Time taken for simulation:  7.007102966308594
average overall reward:  -0.43156818  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.0876621  and average step penalty:  -0.04786053509430681
Number of done instances:  0
177
Time taken for simulation:  6.913599729537964
average overall reward:  -0.26057673  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.18145993  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: -21.50, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 19.66, Length: 12
DEBUG (Env): Episode done for env 36. Reward: -1.36, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -26.47, Length: 36
178
Time taken for simulation:  6.971837759017944
average overall reward:  -0.07147827  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.34753174 average distance reward:  0.1469199  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 23. Reward: -18.12, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 23.12, Length: 22
DEBUG (Env): Episode done for env 46. Reward: 19.94, Length: 25
DEBUG (Env): Episode done for env 69. Reward: -21.30, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -14.32, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -7.83, Length: 36
179
Time taken for simulation:  7.097078800201416
average overall reward:  -1.0722978  average fail penalty:  -0.7265625  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.027572356  and average step penalty:  -0.04786053509430681
Number of done instances:  31
DEBUG (Env): Episode done for env 4. Reward: -37.96, Length: 36
DEBUG (Env): Episode done for env 5. Reward: -38.17, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -13.17, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -17.22, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -22.91, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -25.60, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -19.88, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -24.60, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -31.92, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -16.28, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -18.57, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -16.17, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -21.01, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -18.19, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -23.71, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -12.29, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -18.98, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -18.14, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -20.00, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -19.21, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -26.43, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -29.23, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -18.44, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -27.12, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -29.54, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -23.29, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -23.04, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -30.64, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -17.42, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -15.75, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -19.78, Length: 36
180
Time taken for simulation:  7.1418046951293945
average overall reward:  -0.52612203  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.32450473  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: -29.23, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 20.26, Length: 9
DEBUG (Env): Episode done for env 113. Reward: -25.33, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -19.37, Length: 36
181
Time taken for simulation:  7.529661417007446
average overall reward:  -0.30254355  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.07518315  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 17. Reward: -19.41, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -16.88, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -17.87, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 14.75, Length: 2
182
Time taken for simulation:  7.073323726654053
average overall reward:  -0.4289166  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.24017093  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 15. Reward: -16.74, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -12.92, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -17.35, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 18.88, Length: 3
183
Time taken for simulation:  7.019808053970337
average overall reward:  -0.5595329  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.141587 average distance reward:  -0.32321033  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 50. Reward: -28.32, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -30.82, Length: 36
184
Time taken for simulation:  7.42734694480896
average overall reward:  0.0047703534  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.032400973  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 19. Reward: 17.41, Length: 20
DEBUG (Env): Episode done for env 55. Reward: -13.35, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -21.64, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -6.72, Length: 36
185
Time taken for simulation:  7.67871356010437
average overall reward:  -0.42382127  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  -0.061088845  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 35. Reward: -18.21, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -18.84, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -24.36, Length: 36
186
Time taken for simulation:  7.029011249542236
average overall reward:  -0.29893512  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.12075535  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 8. Reward: -24.82, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 14.86, Length: 15
DEBUG (Env): Episode done for env 99. Reward: -19.12, Length: 36
187
Time taken for simulation:  6.944478273391724
average overall reward:  -0.3595147  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.054223247  and average step penalty:  -0.04786053509430681
Number of done instances:  0
188
Time taken for simulation:  7.0648276805877686
average overall reward:  0.009550855  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  -0.023266807  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: -14.25, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 12.17, Length: 9
DEBUG (Env): Episode done for env 53. Reward: -16.33, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 28.14, Length: 9
DEBUG (Env): Episode done for env 91. Reward: 26.31, Length: 31
DEBUG (Env): Episode done for env 111. Reward: -22.97, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -20.81, Length: 36
189
Time taken for simulation:  7.1932220458984375
average overall reward:  0.08816718  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.07701516  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 12. Reward: 20.73, Length: 1
DEBUG (Env): Episode done for env 18. Reward: 20.68, Length: 12
DEBUG (Env): Episode done for env 58. Reward: 36.74, Length: 14
190
Time taken for simulation:  7.108529806137085
average overall reward:  -0.43562037  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.3413264  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 9. Reward: -23.82, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 18.17, Length: 9
DEBUG (Env): Episode done for env 86. Reward: 27.81, Length: 11
DEBUG (Env): Episode done for env 106. Reward: -23.29, Length: 36
191
Time taken for simulation:  7.302324533462524
average overall reward:  -0.10153456  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.32178864 average distance reward:  0.04424556  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 42. Reward: -38.30, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 22.77, Length: 12
DEBUG (Env): Episode done for env 122. Reward: -23.20, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 5.67, Length: 29
192
Time taken for simulation:  7.016562223434448
average overall reward:  -0.5123545  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  -0.17305951  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 14. Reward: -18.22, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -22.71, Length: 36
193
Time taken for simulation:  6.979236602783203
average overall reward:  -0.5472761  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.27030244 average distance reward:  -0.13536303  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 38. Reward: -20.71, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -15.73, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -24.46, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -27.92, Length: 36
194
Time taken for simulation:  7.614226579666138
average overall reward:  -0.23688652  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168783 average distance reward:  -0.0692727  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 33. Reward: -22.92, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 13.98, Length: 9
195
Time taken for simulation:  6.9808433055877686
average overall reward:  -0.10173473  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  -0.018006753  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 32. Reward: 4.74, Length: 34
DEBUG (Env): Episode done for env 39. Reward: -15.02, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 16.40, Length: 18
196
Time taken for simulation:  7.49993371963501
average overall reward:  -0.25680923  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594472 average distance reward:  -0.091501  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 16. Reward: -24.18, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -20.41, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -5.23, Length: 32
197
Time taken for simulation:  7.2706849575042725
average overall reward:  -0.49557182  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.24455936 average distance reward:  -0.1797144  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 114. Reward: -21.79, Length: 36
198
Time taken for simulation:  6.9849183559417725
average overall reward:  -0.4417952  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.27488315  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 56. Reward: 7.06, Length: 16
DEBUG (Env): Episode done for env 68. Reward: -10.81, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -27.04, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -17.74, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 13.90, Length: 19
DEBUG (Env): Episode done for env 125. Reward: -28.14, Length: 36
199
Time taken for simulation:  7.069268226623535
average overall reward:  -0.5204791  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3604033 average distance reward:  -0.20071232  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 13. Reward: -25.96, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 20.53, Length: 33
DEBUG (Env): Episode done for env 85. Reward: -26.22, Length: 36
200
Time taken for simulation:  7.235880136489868
average overall reward:  -0.5558599  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.26644737  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 20. Reward: -14.03, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -16.18, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 19.04, Length: 2
DEBUG (Env): Episode done for env 77. Reward: -23.42, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -39.80, Length: 36
201
Time taken for simulation:  7.124916315078735
average overall reward:  -0.043434136  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.061074734  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -25.25, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 22.77, Length: 12
DEBUG (Env): Episode done for env 40. Reward: -22.38, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -19.20, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 14.69, Length: 22
DEBUG (Env): Episode done for env 102. Reward: 22.67, Length: 22
202
Time taken for simulation:  7.2941436767578125
average overall reward:  -0.39489168  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.22497226  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 96. Reward: 20.59, Length: 23
203
Time taken for simulation:  7.036361217498779
average overall reward:  -0.26757607  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  0.069413215  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 29. Reward: -16.02, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -25.65, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -19.22, Length: 36
204
Time taken for simulation:  7.3465001583099365
average overall reward:  -0.017147213  average fail penalty:  -0.1640625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.14076754  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 28. Reward: -29.29, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -22.04, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -15.48, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -20.28, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -24.18, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -16.87, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 7.61, Length: 25
DEBUG (Env): Episode done for env 101. Reward: -26.61, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 14.92, Length: 3
DEBUG (Env): Episode done for env 106. Reward: 20.55, Length: 14
DEBUG (Env): Episode done for env 123. Reward: 11.62, Length: 32
205
Time taken for simulation:  7.607839822769165
average overall reward:  -0.24057718  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.33466017 average distance reward:  -0.12880051  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 20. Reward: 18.24, Length: 5
DEBUG (Env): Episode done for env 80. Reward: 37.47, Length: 5
206
Time taken for simulation:  7.121646881103516
average overall reward:  -0.55937517  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.3089171 average distance reward:  -0.17916003  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 90. Reward: -22.00, Length: 36
207
Time taken for simulation:  7.2255823612213135
average overall reward:  -0.23256388  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  -0.028641015  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 31. Reward: -18.34, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 9.84, Length: 22
DEBUG (Env): Episode done for env 95. Reward: -25.04, Length: 36
208
Time taken for simulation:  7.02929949760437
average overall reward:  -0.2188634  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.16548967  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: -24.79, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 9.77, Length: 29
DEBUG (Env): Episode done for env 30. Reward: -22.72, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -16.44, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 11.10, Length: 7
209
Time taken for simulation:  6.980262279510498
average overall reward:  -0.117197156  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.1711468  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: -22.70, Length: 36
DEBUG (Env): Episode done for env 6. Reward: 12.20, Length: 1
DEBUG (Env): Episode done for env 35. Reward: 20.53, Length: 2
DEBUG (Env): Episode done for env 38. Reward: 12.50, Length: 16
DEBUG (Env): Episode done for env 120. Reward: -17.89, Length: 36
210
Time taken for simulation:  7.146741628646851
average overall reward:  -0.51457256  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.2849066  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 7. Reward: -31.31, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -21.10, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 20.36, Length: 17
211
Time taken for simulation:  7.632020473480225
average overall reward:  -0.17974678  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.17856103  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: -19.94, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -20.45, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -27.50, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 13.97, Length: 33
DEBUG (Env): Episode done for env 76. Reward: -23.07, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 12.75, Length: 11
DEBUG (Env): Episode done for env 78. Reward: -29.69, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -18.24, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 18.48, Length: 9
212
Time taken for simulation:  7.149099349975586
average overall reward:  -0.15083414  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.3089171 average distance reward:  0.2059435  and average step penalty:  -0.04786053509430681
Number of done instances:  0
213
Time taken for simulation:  7.0317223072052
average overall reward:  -0.6686753  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.31650886  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 26. Reward: -15.50, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -14.22, Length: 36
214
Time taken for simulation:  7.215624094009399
average overall reward:  0.08976287  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  0.13186884  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: 5.55, Length: 15
DEBUG (Env): Episode done for env 23. Reward: -25.48, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -23.28, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 18.12, Length: 1
DEBUG (Env): Episode done for env 46. Reward: -28.36, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -25.27, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 22.47, Length: 35
DEBUG (Env): Episode done for env 121. Reward: -17.98, Length: 36
215
Time taken for simulation:  7.036670923233032
average overall reward:  -0.3041383  average fail penalty:  -0.421875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.1522841  and average step penalty:  -0.04786053509430681
Number of done instances:  20
DEBUG (Env): Episode done for env 4. Reward: -31.89, Length: 36
DEBUG (Env): Episode done for env 5. Reward: -15.51, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -13.16, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 21.76, Length: 7
DEBUG (Env): Episode done for env 22. Reward: -23.63, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -27.25, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -18.76, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 19.88, Length: 12
DEBUG (Env): Episode done for env 59. Reward: -15.21, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -20.58, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -20.13, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -24.58, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -24.12, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -16.36, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -18.99, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -61.37, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -25.96, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -24.29, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -17.82, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -17.79, Length: 36
216
Time taken for simulation:  7.451833009719849
average overall reward:  0.0775004  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.11569695  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: -26.25, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 17.18, Length: 2
DEBUG (Env): Episode done for env 71. Reward: -18.02, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 27.00, Length: 5
DEBUG (Env): Episode done for env 113. Reward: -7.87, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -20.96, Length: 36
217
Time taken for simulation:  7.0467329025268555
average overall reward:  -0.055854633  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.283174 average distance reward:  -0.19599572  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 39. Reward: 20.78, Length: 22
DEBUG (Env): Episode done for env 41. Reward: 26.72, Length: 7
DEBUG (Env): Episode done for env 43. Reward: -7.58, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 17.92, Length: 13
DEBUG (Env): Episode done for env 67. Reward: -22.46, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -17.11, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 17.14, Length: 20
218
Time taken for simulation:  7.172602891921997
average overall reward:  -0.13304342  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.0042161234  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: 25.75, Length: 3
DEBUG (Env): Episode done for env 15. Reward: -20.10, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -14.45, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -17.96, Length: 36
219
Time taken for simulation:  7.082690000534058
average overall reward:  -0.18770751  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.19638598  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 15. Reward: 24.71, Length: 1
DEBUG (Env): Episode done for env 38. Reward: 42.62, Length: 10
DEBUG (Env): Episode done for env 50. Reward: -22.08, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -11.88, Length: 36
220
Time taken for simulation:  7.262774229049683
average overall reward:  -0.6561681  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.36675552  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: -22.55, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 11.52, Length: 32
DEBUG (Env): Episode done for env 55. Reward: -20.11, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -31.23, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -24.13, Length: 36
221
Time taken for simulation:  7.261545419692993
average overall reward:  -0.21841902  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.16043413  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 88. Reward: -29.16, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 15.16, Length: 17
DEBUG (Env): Episode done for env 98. Reward: 39.36, Length: 6
222
Time taken for simulation:  7.162249803543091
average overall reward:  -0.43389624  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.32178864 average distance reward:  -0.2646786  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: -17.30, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 19.73, Length: 29
DEBUG (Env): Episode done for env 57. Reward: -23.61, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 14.80, Length: 1
DEBUG (Env): Episode done for env 99. Reward: -15.51, Length: 36
223
Time taken for simulation:  7.064516305923462
average overall reward:  -0.13070069  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.07662517  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 99. Reward: 24.59, Length: 1
224
Time taken for simulation:  7.923485517501831
average overall reward:  -0.08076841  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  0.18059543  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 15.98, Length: 5
DEBUG (Env): Episode done for env 21. Reward: -19.08, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -15.67, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -18.42, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -14.82, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -24.66, Length: 36
225
Time taken for simulation:  7.131576776504517
average overall reward:  -0.5319307  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.37949398  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 12. Reward: -14.11, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -30.41, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 15.99, Length: 11
226
Time taken for simulation:  7.152515649795532
average overall reward:  -0.35530198  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3089171 average distance reward:  -0.063583866  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 9. Reward: -17.73, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -22.53, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 15.34, Length: 15
DEBUG (Env): Episode done for env 86. Reward: -27.66, Length: 36
227
Time taken for simulation:  7.103089809417725
average overall reward:  -0.493872  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.20445949  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 42. Reward: -18.66, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 25.92, Length: 3
DEBUG (Env): Episode done for env 110. Reward: -15.47, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -25.02, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -26.41, Length: 36
228
Time taken for simulation:  7.281632423400879
average overall reward:  -0.19757582  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  -0.10949686  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 14. Reward: -15.39, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 13.64, Length: 25
DEBUG (Env): Episode done for env 74. Reward: -26.77, Length: 36
229
Time taken for simulation:  7.228145599365234
average overall reward:  -0.23669817  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.3655715  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 54. Reward: 2.19, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 28.00, Length: 25
DEBUG (Env): Episode done for env 103. Reward: 28.82, Length: 9
230
Time taken for simulation:  7.092289209365845
average overall reward:  -0.1451385  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.26344585  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 5.44, Length: 29
DEBUG (Env): Episode done for env 33. Reward: -18.91, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 15.93, Length: 15
DEBUG (Env): Episode done for env 60. Reward: -22.77, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 16.77, Length: 15
231
Time taken for simulation:  7.123275995254517
average overall reward:  0.07066882  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  -0.07338162  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 14.88, Length: 5
DEBUG (Env): Episode done for env 32. Reward: -25.24, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 5.19, Length: 14
DEBUG (Env): Episode done for env 89. Reward: -23.66, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 11.13, Length: 14
232
Time taken for simulation:  7.081039905548096
average overall reward:  -0.3724938  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.061247606  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 16. Reward: -20.80, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -13.47, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -16.43, Length: 36
233
Time taken for simulation:  7.0982866287231445
average overall reward:  0.039872125  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.0028097108  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 91. Reward: 20.31, Length: 6
DEBUG (Env): Episode done for env 102. Reward: 13.74, Length: 29
234
Time taken for simulation:  7.556121826171875
average overall reward:  -0.15653014  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.3089171 average distance reward:  0.04669091  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 32. Reward: 18.40, Length: 3
DEBUG (Env): Episode done for env 35. Reward: 24.07, Length: 25
DEBUG (Env): Episode done for env 56. Reward: -15.13, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -19.17, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -32.06, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -12.50, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -13.80, Length: 36
235
Time taken for simulation:  7.494170188903809
average overall reward:  -0.031750858  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.014686134  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 35. Reward: 26.09, Length: 1
DEBUG (Env): Episode done for env 75. Reward: -22.02, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -21.17, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 22.27, Length: 21
236
Time taken for simulation:  7.485657215118408
average overall reward:  0.32092646  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.17687596  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 24.86, Length: 14
DEBUG (Env): Episode done for env 45. Reward: -25.50, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -15.42, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 3.72, Length: 31
DEBUG (Env): Episode done for env 87. Reward: 15.49, Length: 12
237
Time taken for simulation:  7.078028917312622
average overall reward:  0.09129382  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  -0.074590325  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: -16.31, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 29.69, Length: 7
DEBUG (Env): Episode done for env 40. Reward: -18.78, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 14.56, Length: 21
DEBUG (Env): Episode done for env 89. Reward: 28.02, Length: 6
DEBUG (Env): Episode done for env 93. Reward: -27.77, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 16.05, Length: 14
238
Time taken for simulation:  7.150355815887451
average overall reward:  -0.3647915  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.18200053  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 93. Reward: 17.94, Length: 1
239
Time taken for simulation:  7.725388288497925
average overall reward:  -0.13909943  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.33466017 average distance reward:  -0.0038852748  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 22. Reward: 4.75, Length: 24
DEBUG (Env): Episode done for env 45. Reward: 19.57, Length: 3
DEBUG (Env): Episode done for env 66. Reward: -11.20, Length: 36
240
Time taken for simulation:  6.964956045150757
average overall reward:  0.020868476  average fail penalty:  -0.1640625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.12849498  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 3. Reward: 16.62, Length: 24
DEBUG (Env): Episode done for env 22. Reward: 19.67, Length: 1
DEBUG (Env): Episode done for env 28. Reward: -21.40, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 49.59, Length: 6
DEBUG (Env): Episode done for env 63. Reward: -18.61, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -8.90, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -22.07, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -23.70, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -28.44, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 22.53, Length: 25
DEBUG (Env): Episode done for env 123. Reward: -13.62, Length: 36
241
Time taken for simulation:  7.366527795791626
average overall reward:  -0.38574505  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  -0.10850228  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 20. Reward: -24.30, Length: 36
242
Time taken for simulation:  7.326272249221802
average overall reward:  -0.51193094  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  -0.2346882  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 90. Reward: -20.56, Length: 36
243
Time taken for simulation:  7.2164788246154785
average overall reward:  -0.29677373  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.283174 average distance reward:  0.081135854  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 31. Reward: -17.11, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -27.45, Length: 36
244
Time taken for simulation:  7.988884925842285
average overall reward:  -0.37398648  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.10801148  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: 9.10, Length: 34
DEBUG (Env): Episode done for env 30. Reward: -24.75, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -21.37, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -27.64, Length: 36
245
Time taken for simulation:  7.306376934051514
average overall reward:  -0.33749145  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.13587411  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: -22.59, Length: 36
DEBUG (Env): Episode done for env 6. Reward: -12.15, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 31.51, Length: 10
DEBUG (Env): Episode done for env 120. Reward: -13.91, Length: 36
246
Time taken for simulation:  7.8979620933532715
average overall reward:  -0.12575702  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  -0.042029046  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 19. Reward: 11.09, Length: 26
DEBUG (Env): Episode done for env 106. Reward: 29.21, Length: 6
DEBUG (Env): Episode done for env 107. Reward: -29.51, Length: 36
247
Time taken for simulation:  7.487837076187134
average overall reward:  -0.76496774  average fail penalty:  -0.1640625  and average goal bonus:  0.0  and average same cell penalty:  -0.3732748 average distance reward:  -0.17976989  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -21.03, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -29.56, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -21.78, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -19.93, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -22.53, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -25.34, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -15.62, Length: 36
248
Time taken for simulation:  7.011160373687744
average overall reward:  -0.31727123  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.14735177  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 96. Reward: 16.36, Length: 1
249
Time taken for simulation:  7.262997627258301
average overall reward:  -0.50935674  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3089171 average distance reward:  -0.5352577  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 26. Reward: -13.47, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 4.39, Length: 30
DEBUG (Env): Episode done for env 78. Reward: 15.87, Length: 2
DEBUG (Env): Episode done for env 110. Reward: 6.85, Length: 22
250
Time taken for simulation:  6.979849100112915
average overall reward:  -0.3854249  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.08544645  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: -13.30, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -22.05, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -10.32, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -22.10, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 10.81, Length: 20
DEBUG (Env): Episode done for env 112. Reward: -30.68, Length: 36
251
Time taken for simulation:  6.9671630859375
average overall reward:  -0.85989255  average fail penalty:  -0.328125  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  -0.23934767  and average step penalty:  -0.04786053509430681
Number of done instances:  14
DEBUG (Env): Episode done for env 4. Reward: -20.50, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -15.28, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -17.03, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -26.99, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -15.57, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -18.12, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -16.13, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -24.45, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -25.82, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -29.96, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -14.50, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -13.77, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -23.94, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -25.49, Length: 36
252
Time taken for simulation:  7.127200365066528
average overall reward:  -0.11049649  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.13044271  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 15. Reward: 6.39, Length: 28
DEBUG (Env): Episode done for env 23. Reward: 28.04, Length: 2
DEBUG (Env): Episode done for env 24. Reward: -18.44, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -25.81, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 17.31, Length: 6
DEBUG (Env): Episode done for env 113. Reward: -11.86, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -18.90, Length: 36
253
Time taken for simulation:  7.22223424911499
average overall reward:  -0.48148483  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.097620554  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 41. Reward: -26.83, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -16.32, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -30.22, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -12.97, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -26.19, Length: 36
254
Time taken for simulation:  7.100804805755615
average overall reward:  -0.27442336  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.098549165  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: -19.18, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 29.29, Length: 4
DEBUG (Env): Episode done for env 49. Reward: -11.41, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -18.94, Length: 36
255
Time taken for simulation:  7.039544582366943
average overall reward:  -0.62689495  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3861464 average distance reward:  -0.28138506  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 38. Reward: -25.68, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 17.62, Length: 2
DEBUG (Env): Episode done for env 50. Reward: -14.70, Length: 36
256
Time taken for simulation:  7.452894926071167
average overall reward:  -0.5079993  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.11952382  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 53. Reward: -14.69, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -15.57, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -25.95, Length: 36
257
Time taken for simulation:  7.410593748092651
average overall reward:  -0.59236866  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.23168783 average distance reward:  -0.26594526  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 92. Reward: -27.51, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -15.51, Length: 36
258
Time taken for simulation:  7.139716386795044
average overall reward:  0.1516484  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.29604554 average distance reward:  0.024378896  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 20. Reward: 22.31, Length: 17
DEBUG (Env): Episode done for env 47. Reward: -13.17, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -22.58, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 20.86, Length: 5
DEBUG (Env): Episode done for env 88. Reward: -19.32, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 18.39, Length: 1
DEBUG (Env): Episode done for env 115. Reward: 20.38, Length: 7
259
Time taken for simulation:  7.581728935241699
average overall reward:  -0.10848191  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.16403534  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 29. Reward: 15.72, Length: 31
DEBUG (Env): Episode done for env 45. Reward: 22.17, Length: 20
260
Time taken for simulation:  7.83248496055603
average overall reward:  -0.31371334  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.12496762  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 21. Reward: -19.36, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 23.16, Length: 23
DEBUG (Env): Episode done for env 111. Reward: -25.93, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -35.22, Length: 36
261
Time taken for simulation:  7.223160028457642
average overall reward:  -0.53188777  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.14341223  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 12. Reward: -17.17, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -9.49, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -19.14, Length: 36
262
Time taken for simulation:  7.371190786361694
average overall reward:  -0.2772695  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604557 average distance reward:  -0.13379493  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: -19.71, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 22.20, Length: 8
DEBUG (Env): Episode done for env 27. Reward: -11.71, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 27.10, Length: 6
DEBUG (Env): Episode done for env 86. Reward: -13.57, Length: 36
263
Time taken for simulation:  7.101121664047241
average overall reward:  -0.4007386  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.13476357  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 42. Reward: -19.59, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 19.41, Length: 5
DEBUG (Env): Episode done for env 122. Reward: -16.14, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -23.68, Length: 36
264
Time taken for simulation:  7.574199914932251
average overall reward:  -0.33982322  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  -0.03914295  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 14. Reward: -33.81, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -19.80, Length: 36
265
Time taken for simulation:  7.351687669754028
average overall reward:  -0.23331586  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.30244258  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 22. Reward: 5.61, Length: 25
DEBUG (Env): Episode done for env 31. Reward: 15.89, Length: 22
DEBUG (Env): Episode done for env 54. Reward: -10.64, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -21.93, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 11.32, Length: 25
DEBUG (Env): Episode done for env 103. Reward: -28.57, Length: 36
266
Time taken for simulation:  7.075716257095337
average overall reward:  -0.1415514  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.18493503  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -15.95, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -19.07, Length: 29
DEBUG (Env): Episode done for env 33. Reward: -12.81, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 10.41, Length: 22
DEBUG (Env): Episode done for env 60. Reward: -22.05, Length: 36
267
Time taken for simulation:  7.222700119018555
average overall reward:  -0.076981105  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  -0.18472245  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: -27.08, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -28.99, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 26.11, Length: 1
DEBUG (Env): Episode done for env 55. Reward: 19.18, Length: 5
DEBUG (Env): Episode done for env 112. Reward: 7.32, Length: 17
DEBUG (Env): Episode done for env 114. Reward: -21.68, Length: 36
268
Time taken for simulation:  7.405214548110962
average overall reward:  -0.7049675  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.32936358  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 16. Reward: -12.40, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -18.17, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -21.23, Length: 36
269
Time taken for simulation:  7.138672590255737
average overall reward:  0.19774203  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.07943469  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 27. Reward: 25.68, Length: 7
DEBUG (Env): Episode done for env 74. Reward: 17.19, Length: 5
DEBUG (Env): Episode done for env 77. Reward: 23.89, Length: 17
DEBUG (Env): Episode done for env 91. Reward: -20.32, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -22.54, Length: 36
270
Time taken for simulation:  7.341392517089844
average overall reward:  -0.23269287  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.041542523  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 56. Reward: -20.50, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -16.12, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -24.31, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 41.69, Length: 24
DEBUG (Env): Episode done for env 109. Reward: -22.90, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -23.50, Length: 36
271
Time taken for simulation:  7.174057722091675
average overall reward:  0.18712074  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  -0.0045065135  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 17.56, Length: 20
DEBUG (Env): Episode done for env 14. Reward: 34.86, Length: 7
DEBUG (Env): Episode done for env 32. Reward: 12.32, Length: 31
DEBUG (Env): Episode done for env 75. Reward: -27.99, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -19.96, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 21.64, Length: 4
DEBUG (Env): Episode done for env 121. Reward: -23.80, Length: 36
272
Time taken for simulation:  7.572937726974487
average overall reward:  -0.5176003  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  -0.14430192  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 8. Reward: -28.75, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -20.26, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -22.60, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -29.30, Length: 36
273
Time taken for simulation:  7.486851215362549
average overall reward:  -0.33545858  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168783 average distance reward:  -0.09753224  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: -23.81, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -20.98, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -27.72, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -18.26, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 21.45, Length: 3
274
Time taken for simulation:  7.059026479721069
average overall reward:  -0.33885145  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.18410908  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 93. Reward: -27.17, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 19.60, Length: 5
275
Time taken for simulation:  7.064171314239502
average overall reward:  0.18593211  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168781 average distance reward:  -0.3233142  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: 19.16, Length: 13
DEBUG (Env): Episode done for env 66. Reward: -17.24, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 9.10, Length: 3
DEBUG (Env): Episode done for env 79. Reward: 10.35, Length: 35
DEBUG (Env): Episode done for env 98. Reward: 14.43, Length: 17
DEBUG (Env): Episode done for env 109. Reward: 24.68, Length: 5
DEBUG (Env): Episode done for env 123. Reward: -5.26, Length: 35
276
Time taken for simulation:  6.902346134185791
average overall reward:  -0.5253889  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.238282  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: -30.11, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -21.83, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -32.95, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -15.80, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -24.39, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 10.87, Length: 24
277
Time taken for simulation:  7.054214954376221
average overall reward:  -0.54810715  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  -0.25568724  and average step penalty:  -0.04786053509430681
Number of done instances:  0
278
Time taken for simulation:  7.303487300872803
average overall reward:  -0.28732318  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.13258088  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 88. Reward: 23.71, Length: 20
DEBUG (Env): Episode done for env 90. Reward: -21.85, Length: 36
279
Time taken for simulation:  7.491316556930542
average overall reward:  -0.268253  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.07489605  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 95. Reward: -18.11, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 10.51, Length: 25
280
Time taken for simulation:  7.8983635902404785
average overall reward:  -0.474231  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.283174 average distance reward:  -0.07288396  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 7. Reward: -26.51, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -29.21, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -21.00, Length: 36
281
Time taken for simulation:  7.2156641483306885
average overall reward:  -0.4062309  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.14256148  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: -32.19, Length: 36
DEBUG (Env): Episode done for env 6. Reward: -21.08, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -13.94, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 8.21, Length: 27
DEBUG (Env): Episode done for env 120. Reward: -15.57, Length: 36
282
Time taken for simulation:  7.092329263687134
average overall reward:  -0.14401904  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.13752028  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 19. Reward: -16.86, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 10.21, Length: 26
DEBUG (Env): Episode done for env 121. Reward: 18.21, Length: 11
283
Time taken for simulation:  7.342594861984253
average overall reward:  -0.41531906  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.031454727  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -29.21, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -8.73, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -20.59, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -14.94, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -24.12, Length: 36
284
Time taken for simulation:  7.3388917446136475
average overall reward:  -0.09063448  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  -0.006906472  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 35. Reward: 14.23, Length: 3
DEBUG (Env): Episode done for env 84. Reward: 18.46, Length: 14
DEBUG (Env): Episode done for env 96. Reward: -33.19, Length: 36
285
Time taken for simulation:  7.147120952606201
average overall reward:  -0.4559784  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.24379519  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 26. Reward: -18.39, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -26.92, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -14.60, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -29.49, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 26.20, Length: 4
286
Time taken for simulation:  7.354759931564331
average overall reward:  0.41206875  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.22044149  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 36. Reward: -13.97, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -20.19, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 5.13, Length: 19
DEBUG (Env): Episode done for env 62. Reward: -21.95, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 32.53, Length: 7
DEBUG (Env): Episode done for env 120. Reward: 15.40, Length: 1
DEBUG (Env): Episode done for env 127. Reward: 12.28, Length: 26
287
Time taken for simulation:  7.096060514450073
average overall reward:  -0.29331976  average fail penalty:  -0.28125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.016137  and average step penalty:  -0.04786053509430681
Number of done instances:  14
DEBUG (Env): Episode done for env 4. Reward: -22.94, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -16.15, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -9.26, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -27.96, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -18.52, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -14.57, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -22.19, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -15.43, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 31.74, Length: 12
DEBUG (Env): Episode done for env 94. Reward: -28.32, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 17.95, Length: 14
DEBUG (Env): Episode done for env 105. Reward: -14.47, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -19.52, Length: 36
288
Time taken for simulation:  7.352438688278198
average overall reward:  -0.06336262  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.024014574  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 15. Reward: -15.31, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -21.16, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -14.93, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 6.48, Length: 27
DEBUG (Env): Episode done for env 97. Reward: 14.90, Length: 1
DEBUG (Env): Episode done for env 107. Reward: -19.34, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -14.22, Length: 36
289
Time taken for simulation:  8.042976140975952
average overall reward:  -0.30915624  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.09466741  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 19. Reward: 24.03, Length: 7
DEBUG (Env): Episode done for env 41. Reward: -22.71, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -11.32, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -19.87, Length: 36
290
Time taken for simulation:  7.297631740570068
average overall reward:  -0.30342788  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.3355438  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 5. Reward: -29.82, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 27.17, Length: 14
DEBUG (Env): Episode done for env 52. Reward: 44.44, Length: 4
291
Time taken for simulation:  7.309730052947998
average overall reward:  -0.10811965  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.17724639  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 19. Reward: 11.61, Length: 2
DEBUG (Env): Episode done for env 38. Reward: -20.88, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -27.71, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -24.29, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 4.31, Length: 17
DEBUG (Env): Episode done for env 116. Reward: 7.57, Length: 23
292
Time taken for simulation:  7.722149848937988
average overall reward:  -0.014481731  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.12738903  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 63. Reward: 25.49, Length: 16
DEBUG (Env): Episode done for env 126. Reward: -19.99, Length: 36
293
Time taken for simulation:  7.745921611785889
average overall reward:  0.0554976  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.0733757  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 64. Reward: 32.72, Length: 6
DEBUG (Env): Episode done for env 82. Reward: 5.20, Length: 28
DEBUG (Env): Episode done for env 92. Reward: -17.08, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 38.17, Length: 11
294
Time taken for simulation:  7.10706639289856
average overall reward:  -0.32303873  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.23335597  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 7.75, Length: 33
DEBUG (Env): Episode done for env 20. Reward: -16.54, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -15.38, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 22.73, Length: 28
DEBUG (Env): Episode done for env 67. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -25.39, Length: 36
295
Time taken for simulation:  7.507343769073486
average overall reward:  -0.19593479  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.262756  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 11.37, Length: 29
DEBUG (Env): Episode done for env 29. Reward: -19.14, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 13.53, Length: 24
DEBUG (Env): Episode done for env 45. Reward: -59.30, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 18.65, Length: 6
296
Time taken for simulation:  6.907655239105225
average overall reward:  -0.3238473  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.045000784  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 21. Reward: -20.69, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -14.36, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 40.74, Length: 24
DEBUG (Env): Episode done for env 111. Reward: -25.60, Length: 36
297
Time taken for simulation:  7.04826021194458
average overall reward:  0.34529954  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.13254037  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 46. Reward: 21.02, Length: 11
DEBUG (Env): Episode done for env 58. Reward: -17.21, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 24.64, Length: 22
DEBUG (Env): Episode done for env 71. Reward: 18.04, Length: 1
DEBUG (Env): Episode done for env 124. Reward: 4.34, Length: 34
298
Time taken for simulation:  7.08636474609375
average overall reward:  -0.3280986  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.09843263  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 13. Reward: -20.80, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 16.75, Length: 2
DEBUG (Env): Episode done for env 86. Reward: -18.12, Length: 36
299
Time taken for simulation:  7.634834289550781
average overall reward:  -0.45052758  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.26178184  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 42. Reward: -18.11, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 18.59, Length: 18
DEBUG (Env): Episode done for env 57. Reward: -7.06, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -31.76, Length: 36
300
Time taken for simulation:  7.147093296051025
average overall reward:  -0.1267104  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.102972366 average distance reward:  -0.11124952  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 59. Reward: 18.65, Length: 13
301
Time taken for simulation:  7.859604120254517
average overall reward:  -0.31267503  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.12232552  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 22. Reward: -16.70, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -24.68, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 48.67, Length: 6
DEBUG (Env): Episode done for env 54. Reward: -14.48, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -17.99, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -20.42, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 16.59, Length: 15
302
Time taken for simulation:  7.448496341705322
average overall reward:  -0.076202385  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.11062391  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: -20.37, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -17.18, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 10.98, Length: 4
DEBUG (Env): Episode done for env 84. Reward: 8.94, Length: 18
303
Time taken for simulation:  7.0828516483306885
average overall reward:  -0.44251686  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.1078331  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 17. Reward: -44.87, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -56.79, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -20.63, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -24.30, Length: 36
304
Time taken for simulation:  7.231483697891235
average overall reward:  -0.044864476  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.079285994  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: 2.21, Length: 33
DEBUG (Env): Episode done for env 16. Reward: -40.62, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 12.76, Length: 17
DEBUG (Env): Episode done for env 119. Reward: -7.88, Length: 36
305
Time taken for simulation:  7.041118860244751
average overall reward:  -0.27681798  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  0.025466088  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 17.76, Length: 15
DEBUG (Env): Episode done for env 27. Reward: -13.77, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -17.30, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -26.82, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -16.63, Length: 36
306
Time taken for simulation:  7.021155834197998
average overall reward:  -0.44285017  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  -0.17021862  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 56. Reward: -21.20, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -11.87, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -24.84, Length: 36
307
Time taken for simulation:  7.602323532104492
average overall reward:  -0.4499117  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.12871546 average distance reward:  -0.17958573  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 14. Reward: -20.85, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -10.81, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -35.99, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -33.21, Length: 36
308
Time taken for simulation:  7.063382625579834
average overall reward:  0.47751015  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.15947312  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: -16.51, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 18.80, Length: 8
DEBUG (Env): Episode done for env 68. Reward: 18.61, Length: 11
DEBUG (Env): Episode done for env 70. Reward: 7.19, Length: 25
DEBUG (Env): Episode done for env 73. Reward: 13.21, Length: 23
DEBUG (Env): Episode done for env 87. Reward: -19.93, Length: 36
309
Time taken for simulation:  7.401264190673828
average overall reward:  -0.26287705  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.063565336  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: -24.88, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -6.60, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -13.61, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 11.54, Length: 33
DEBUG (Env): Episode done for env 106. Reward: -30.88, Length: 36
310
Time taken for simulation:  7.171247243881226
average overall reward:  0.039896548  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.005090922  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 48. Reward: 20.44, Length: 6
DEBUG (Env): Episode done for env 101. Reward: 21.05, Length: 1
DEBUG (Env): Episode done for env 102. Reward: -21.42, Length: 36
311
Time taken for simulation:  7.85342001914978
average overall reward:  0.045899734  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.283174 average distance reward:  -0.04736629  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: -21.57, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 14.58, Length: 20
DEBUG (Env): Episode done for env 66. Reward: -12.06, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 5.48, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 13.94, Length: 24
DEBUG (Env): Episode done for env 102. Reward: 15.72, Length: 1
DEBUG (Env): Episode done for env 109. Reward: 0.72, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -19.04, Length: 36
312
Time taken for simulation:  7.69427752494812
average overall reward:  -0.23209128  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.114359826  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: -22.54, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 16.20, Length: 8
DEBUG (Env): Episode done for env 75. Reward: 32.34, Length: 5
DEBUG (Env): Episode done for env 108. Reward: -18.33, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -22.41, Length: 36
313
Time taken for simulation:  7.471037149429321
average overall reward:  -0.25156868  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.081649244  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 25. Reward: 5.46, Length: 30
314
Time taken for simulation:  7.232342481613159
average overall reward:  -0.4478339  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  -0.12141053  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 88. Reward: -17.78, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -16.50, Length: 36
315
Time taken for simulation:  7.85352897644043
average overall reward:  -0.532323  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.39045224  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 67. Reward: 4.31, Length: 21
DEBUG (Env): Episode done for env 95. Reward: -7.61, Length: 36
316
Time taken for simulation:  7.0945212841033936
average overall reward:  -0.39369994  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.28884003  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -22.78, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -15.21, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -16.95, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 23.71, Length: 22
DEBUG (Env): Episode done for env 58. Reward: 26.69, Length: 19
317
Time taken for simulation:  7.034857988357544
average overall reward:  -0.3407876  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.283174 average distance reward:  0.037121937  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: -15.18, Length: 36
DEBUG (Env): Episode done for env 6. Reward: -25.09, Length: 36
318
Time taken for simulation:  7.406335115432739
average overall reward:  -0.8296209  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.283174 average distance reward:  -0.4751488  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 53. Reward: -16.74, Length: 36
319
Time taken for simulation:  7.464813232421875
average overall reward:  -0.16590618  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.022431659  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -16.88, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 1.59, Length: 32
DEBUG (Env): Episode done for env 76. Reward: -18.79, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -16.76, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 24.44, Length: 17
320
Time taken for simulation:  6.985010862350464
average overall reward:  -0.25792223  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594472 average distance reward:  -0.09261398  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 35. Reward: -12.15, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 9.44, Length: 28
DEBUG (Env): Episode done for env 96. Reward: -26.52, Length: 36
321
Time taken for simulation:  7.8575358390808105
average overall reward:  -0.25685787  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  0.009117186  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: 32.74, Length: 19
DEBUG (Env): Episode done for env 26. Reward: -18.29, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -35.60, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -19.79, Length: 36
322
Time taken for simulation:  7.042359352111816
average overall reward:  -0.28265718  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3604033 average distance reward:  0.083984606  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 30. Reward: 18.26, Length: 6
DEBUG (Env): Episode done for env 36. Reward: -47.67, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -8.21, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -28.28, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -19.42, Length: 36
323
Time taken for simulation:  7.27105712890625
average overall reward:  -0.5565446  average fail penalty:  -0.1875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.18625367  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 4. Reward: -29.51, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -22.72, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 20.82, Length: 7
DEBUG (Env): Episode done for env 61. Reward: -23.88, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -7.68, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -13.73, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -21.14, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -13.35, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -15.80, Length: 36
324
Time taken for simulation:  7.6341211795806885
average overall reward:  -0.54509467  average fail penalty:  -0.1640625  and average goal bonus:  0.0  and average same cell penalty:  -0.11584391 average distance reward:  -0.2173277  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 15. Reward: -20.19, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -35.25, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -21.80, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -16.11, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -13.24, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -5.72, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -22.68, Length: 36
325
Time taken for simulation:  7.608198165893555
average overall reward:  -0.576483  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.22431654  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 41. Reward: -18.13, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -15.78, Length: 36
326
Time taken for simulation:  7.375913858413696
average overall reward:  -0.13493942  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.105003186  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 24. Reward: 20.90, Length: 2
DEBUG (Env): Episode done for env 28. Reward: -22.37, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -18.73, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 31.74, Length: 2
327
Time taken for simulation:  7.290126800537109
average overall reward:  -0.38484287  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  -0.06533626  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: -22.05, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -24.71, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -16.53, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -19.51, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -18.09, Length: 36
328
Time taken for simulation:  7.315455675125122
average overall reward:  -0.12510854  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.28317398 average distance reward:  -0.041380554  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 85. Reward: 17.22, Length: 21
DEBUG (Env): Episode done for env 97. Reward: 15.77, Length: 2
DEBUG (Env): Episode done for env 126. Reward: -24.81, Length: 36
329
Time taken for simulation:  7.360781669616699
average overall reward:  0.010582663  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.100265406  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 64. Reward: -23.64, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -12.87, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -16.46, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 9.99, Length: 18
DEBUG (Env): Episode done for env 106. Reward: 12.05, Length: 20
DEBUG (Env): Episode done for env 121. Reward: -10.27, Length: 36
330
Time taken for simulation:  7.2390053272247314
average overall reward:  -0.2728148  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.29276103  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: -18.68, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -19.35, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -19.56, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 30.86, Length: 10
DEBUG (Env): Episode done for env 114. Reward: 18.26, Length: 27
DEBUG (Env): Episode done for env 115. Reward: -23.29, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 23.92, Length: 2
331
Time taken for simulation:  7.256440162658691
average overall reward:  -0.23500565  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.106708266  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -31.58, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -22.32, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -15.81, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 4.49, Length: 21
DEBUG (Env): Episode done for env 104. Reward: -18.74, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 3.63, Length: 30
332
Time taken for simulation:  7.013984203338623
average overall reward:  0.1391709  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.1691071  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: 26.52, Length: 15
DEBUG (Env): Episode done for env 21. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -18.51, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 5.07, Length: 28
333
Time taken for simulation:  7.13049578666687
average overall reward:  -0.4038501  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  -0.17648971  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 46. Reward: -17.24, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -25.78, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 18.27, Length: 1
DEBUG (Env): Episode done for env 124. Reward: -29.11, Length: 36
334
Time taken for simulation:  7.181331157684326
average overall reward:  -0.3475597  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.3433665  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: 19.87, Length: 18
DEBUG (Env): Episode done for env 13. Reward: -14.34, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -24.27, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 6.36, Length: 11
335
Time taken for simulation:  7.39519476890564
average overall reward:  -0.071310535  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1930732 average distance reward:  -0.007370867  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: 7.32, Length: 30
DEBUG (Env): Episode done for env 42. Reward: -29.19, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -20.06, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -27.48, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 22.97, Length: 4
DEBUG (Env): Episode done for env 122. Reward: -28.48, Length: 36
336
Time taken for simulation:  7.062048435211182
average overall reward:  -0.18500872  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.16333285  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 5. Reward: 15.16, Length: 1
DEBUG (Env): Episode done for env 19. Reward: 14.79, Length: 9
337
Time taken for simulation:  7.4876933097839355
average overall reward:  -0.17103481  average fail penalty:  -0.140625  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594475 average distance reward:  0.08802346  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 22. Reward: -19.25, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -11.58, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -21.15, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -19.41, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -17.00, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 19.97, Length: 9
DEBUG (Env): Episode done for env 103. Reward: -24.90, Length: 36
338
Time taken for simulation:  7.4255897998809814
average overall reward:  -0.2331111  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.22891799  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 33. Reward: -16.07, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 19.23, Length: 14
DEBUG (Env): Episode done for env 80. Reward: -18.21, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 19.97, Length: 16
339
Time taken for simulation:  7.238659143447876
average overall reward:  0.21487224  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.0024980698  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 16.82, Length: 7
DEBUG (Env): Episode done for env 17. Reward: -17.94, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -14.06, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -21.35, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 12.35, Length: 1
DEBUG (Env): Episode done for env 94. Reward: 25.00, Length: 16
DEBUG (Env): Episode done for env 122. Reward: 14.54, Length: 4
340
Time taken for simulation:  7.005951881408691
average overall reward:  0.13314289  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.055755768  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: -10.68, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 19.21, Length: 11
DEBUG (Env): Episode done for env 116. Reward: 22.25, Length: 13
DEBUG (Env): Episode done for env 119. Reward: 19.98, Length: 7
341
Time taken for simulation:  7.309414625167847
average overall reward:  -0.23179908  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594472 average distance reward:  -0.15498787  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: -23.51, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 14.29, Length: 2
DEBUG (Env): Episode done for env 72. Reward: 8.49, Length: 18
DEBUG (Env): Episode done for env 74. Reward: -20.68, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -22.24, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -14.93, Length: 36
342
Time taken for simulation:  7.205098390579224
average overall reward:  -0.4326558  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.12140954  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 56. Reward: -24.89, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -20.38, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -27.73, Length: 36
343
Time taken for simulation:  8.042794704437256
average overall reward:  -0.07266129  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  0.03450419  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 14. Reward: -25.73, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 30.99, Length: 8
DEBUG (Env): Episode done for env 74. Reward: 22.39, Length: 2
DEBUG (Env): Episode done for env 112. Reward: -19.99, Length: 36
344
Time taken for simulation:  7.294138193130493
average overall reward:  -0.4270199  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  -0.22610442  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: -19.55, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 0.92, Length: 24
DEBUG (Env): Episode done for env 59. Reward: -17.19, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 1.57, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -31.66, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 13.64, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -14.68, Length: 36
345
Time taken for simulation:  7.117102146148682
average overall reward:  -0.43808687  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.15924032  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 13. Reward: 25.26, Length: 11
DEBUG (Env): Episode done for env 34. Reward: -24.39, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -17.40, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -33.04, Length: 36
346
Time taken for simulation:  7.153833627700806
average overall reward:  -0.112442  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  -0.08020017  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 38. Reward: 22.95, Length: 19
DEBUG (Env): Episode done for env 92. Reward: 40.74, Length: 17
DEBUG (Env): Episode done for env 101. Reward: -16.55, Length: 36
347
Time taken for simulation:  7.179965496063232
average overall reward:  -0.13730492  average fail penalty:  -0.1640625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881627 average distance reward:  0.022690386  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 9. Reward: -27.39, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -14.81, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -29.86, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 8.54, Length: 35
DEBUG (Env): Episode done for env 99. Reward: -9.22, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -11.06, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 0.71, Length: 35
DEBUG (Env): Episode done for env 109. Reward: -14.81, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -1.39, Length: 36
348
Time taken for simulation:  7.615820646286011
average overall reward:  0.13800198  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030244 average distance reward:  -0.015010618  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: -28.21, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -22.02, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 20.08, Length: 1
DEBUG (Env): Episode done for env 61. Reward: 34.00, Length: 25
DEBUG (Env): Episode done for env 108. Reward: 17.61, Length: 1
DEBUG (Env): Episode done for env 117. Reward: -16.83, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 26.86, Length: 15
349
Time taken for simulation:  7.551227331161499
average overall reward:  -0.0805881  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.022603206  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 25. Reward: -16.90, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 17.41, Length: 6
DEBUG (Env): Episode done for env 52. Reward: 4.35, Length: 23
350
Time taken for simulation:  7.053541421890259
average overall reward:  0.3755809  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.102972366 average distance reward:  0.16717276  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 71. Reward: 22.61, Length: 17
DEBUG (Env): Episode done for env 79. Reward: 28.14, Length: 27
DEBUG (Env): Episode done for env 88. Reward: -27.45, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -15.09, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 16.87, Length: 7
351
Time taken for simulation:  7.027293682098389
average overall reward:  0.16283336  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.044526055  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 67. Reward: -20.30, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 17.17, Length: 4
DEBUG (Env): Episode done for env 87. Reward: 25.46, Length: 7
DEBUG (Env): Episode done for env 95. Reward: -33.63, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 38.39, Length: 11
352
Time taken for simulation:  7.062898874282837
average overall reward:  -0.5548222  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  -0.35089928  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: -49.28, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -17.92, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 2.86, Length: 12
353
Time taken for simulation:  7.009551525115967
average overall reward:  -0.111151725  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.0789099  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 2. Reward: -14.45, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 13.95, Length: 24
DEBUG (Env): Episode done for env 121. Reward: 17.87, Length: 24
354
Time taken for simulation:  7.258980751037598
average overall reward:  -0.20269966  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.048799977  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 53. Reward: -26.28, Length: 36
355
Time taken for simulation:  7.11229681968689
average overall reward:  -0.02513586  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  -0.15701652  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: -10.56, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -40.61, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 22.51, Length: 17
DEBUG (Env): Episode done for env 59. Reward: 29.06, Length: 11
DEBUG (Env): Episode done for env 76. Reward: -12.16, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -12.76, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -22.57, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 20.07, Length: 23
DEBUG (Env): Episode done for env 117. Reward: 21.60, Length: 7
356
Time taken for simulation:  7.044358968734741
average overall reward:  -0.18402639  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.11316997  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 8. Reward: 11.58, Length: 12
DEBUG (Env): Episode done for env 96. Reward: -23.28, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 22.35, Length: 1
357
Time taken for simulation:  7.1851606369018555
average overall reward:  -0.24672571  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.087958  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: -17.08, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -16.61, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -23.92, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -24.16, Length: 36
358
Time taken for simulation:  7.732752323150635
average overall reward:  0.29201624  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  -0.011545569  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 11. Reward: 18.15, Length: 3
DEBUG (Env): Episode done for env 30. Reward: -28.27, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -23.44, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 31.54, Length: 6
DEBUG (Env): Episode done for env 62. Reward: 14.82, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 34.17, Length: 8
DEBUG (Env): Episode done for env 97. Reward: 3.25, Length: 30
DEBUG (Env): Episode done for env 100. Reward: -21.27, Length: 36
359
Time taken for simulation:  7.224846601486206
average overall reward:  -0.13470757  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  -0.057896357  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: -30.46, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 9.25, Length: 25
DEBUG (Env): Episode done for env 44. Reward: -22.32, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -15.83, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 20.05, Length: 21
DEBUG (Env): Episode done for env 118. Reward: -17.08, Length: 36
360
Time taken for simulation:  7.149855852127075
average overall reward:  -0.28533888  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.19565609  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: -18.14, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -10.91, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 20.64, Length: 2
DEBUG (Env): Episode done for env 99. Reward: 24.81, Length: 13
DEBUG (Env): Episode done for env 107. Reward: -18.88, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -21.10, Length: 36
361
Time taken for simulation:  7.450339078903198
average overall reward:  -0.260715  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.027093692  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 41. Reward: -20.00, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -16.08, Length: 36
362
Time taken for simulation:  7.183722972869873
average overall reward:  -0.35730785  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  -0.108113766  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 24. Reward: -16.96, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -19.11, Length: 36
363
Time taken for simulation:  7.949151515960693
average overall reward:  -0.21524966  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  -0.01132682  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 43. Reward: -19.56, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -22.55, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 16.80, Length: 33
364
Time taken for simulation:  7.079915523529053
average overall reward:  0.020472787  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.003533993  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 24. Reward: 22.94, Length: 2
DEBUG (Env): Episode done for env 93. Reward: 17.76, Length: 1
365
Time taken for simulation:  7.077737331390381
average overall reward:  -0.37220928  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  -0.5420028  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 28. Reward: 5.95, Length: 3
DEBUG (Env): Episode done for env 34. Reward: 13.66, Length: 20
DEBUG (Env): Episode done for env 56. Reward: 6.10, Length: 23
DEBUG (Env): Episode done for env 64. Reward: -13.18, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -22.04, Length: 36
366
Time taken for simulation:  7.075566291809082
average overall reward:  -0.57467604  average fail penalty:  -0.140625  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.34136093  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: -15.44, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -18.13, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 13.25, Length: 25
DEBUG (Env): Episode done for env 60. Reward: -20.36, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -18.58, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -17.67, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -17.92, Length: 36
367
Time taken for simulation:  7.034149646759033
average overall reward:  -0.18380223  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.13503969  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -25.70, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -13.68, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -15.82, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -17.38, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -0.97, Length: 26
DEBUG (Env): Episode done for env 104. Reward: -23.27, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 23.73, Length: 14
368
Time taken for simulation:  7.1201183795928955
average overall reward:  0.5027297  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.2642275  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: 11.04, Length: 23
DEBUG (Env): Episode done for env 21. Reward: -16.16, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 21.72, Length: 2
DEBUG (Env): Episode done for env 43. Reward: 21.85, Length: 5
DEBUG (Env): Episode done for env 118. Reward: 38.56, Length: 9
369
Time taken for simulation:  7.27872109413147
average overall reward:  -0.24423502  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.03800654  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 28. Reward: 34.32, Length: 4
DEBUG (Env): Episode done for env 46. Reward: -17.75, Length: 36
370
Time taken for simulation:  7.3764941692352295
average overall reward:  -0.034705788  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.0467166  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 86. Reward: -20.57, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 15.50, Length: 20
DEBUG (Env): Episode done for env 105. Reward: -14.57, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 41.49, Length: 7
371
Time taken for simulation:  7.428889274597168
average overall reward:  -0.013277292  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.027224839  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: 17.14, Length: 12
DEBUG (Env): Episode done for env 42. Reward: -20.66, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -38.87, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 41.36, Length: 4
DEBUG (Env): Episode done for env 120. Reward: -18.68, Length: 36
372
Time taken for simulation:  7.3040220737457275
average overall reward:  -0.35367692  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.2012402  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 5. Reward: -15.65, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 16.70, Length: 24
DEBUG (Env): Episode done for env 19. Reward: -19.72, Length: 36
373
Time taken for simulation:  7.120080471038818
average overall reward:  0.006504912  average fail penalty:  -0.1640625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.043999705  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 22. Reward: -11.55, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -18.64, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -14.61, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 22.70, Length: 18
DEBUG (Env): Episode done for env 53. Reward: 24.75, Length: 19
DEBUG (Env): Episode done for env 54. Reward: -18.31, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 4.49, Length: 34
DEBUG (Env): Episode done for env 65. Reward: -19.77, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -10.69, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -12.42, Length: 36
374
Time taken for simulation:  7.680188894271851
average overall reward:  0.25338593  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.06015487  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 54. Reward: 17.18, Length: 1
DEBUG (Env): Episode done for env 92. Reward: 12.20, Length: 28
DEBUG (Env): Episode done for env 97. Reward: 12.47, Length: 16
DEBUG (Env): Episode done for env 127. Reward: -30.80, Length: 36
375
Time taken for simulation:  7.289510726928711
average overall reward:  -0.5171226  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.23001571  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: -31.92, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -27.56, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 34.78, Length: 7
DEBUG (Env): Episode done for env 39. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -22.13, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -17.63, Length: 36
376
Time taken for simulation:  7.18119215965271
average overall reward:  -0.4042747  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.283174 average distance reward:  -0.026365193  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 10. Reward: -5.74, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -24.72, Length: 36
377
Time taken for simulation:  7.129984140396118
average overall reward:  -0.37843794  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.35080725  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: 6.02, Length: 22
DEBUG (Env): Episode done for env 69. Reward: -18.13, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -24.06, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -20.15, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 9.59, Length: 13
378
Time taken for simulation:  7.268129348754883
average overall reward:  -0.3033451  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  0.010206733  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 81. Reward: -13.13, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -14.24, Length: 36
379
Time taken for simulation:  7.523763179779053
average overall reward:  -0.32879192  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.040983204  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 14. Reward: -20.39, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -15.97, Length: 36
380
Time taken for simulation:  7.294609308242798
average overall reward:  -0.1880711  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.18020163 average distance reward:  0.13374108  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 35. Reward: -13.62, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -18.53, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -14.30, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -20.45, Length: 36
381
Time taken for simulation:  7.32181978225708
average overall reward:  -0.103587285  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.07365113  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: 34.57, Length: 5
DEBUG (Env): Episode done for env 40. Reward: -22.15, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 19.11, Length: 2
DEBUG (Env): Episode done for env 89. Reward: -23.02, Length: 36
382
Time taken for simulation:  7.072341442108154
average overall reward:  -0.059703335  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455936 average distance reward:  -0.12652451  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 35.74, Length: 10
DEBUG (Env): Episode done for env 25. Reward: 5.93, Length: 33
DEBUG (Env): Episode done for env 36. Reward: 21.17, Length: 22
DEBUG (Env): Episode done for env 38. Reward: -13.38, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -28.44, Length: 36
383
Time taken for simulation:  7.141595125198364
average overall reward:  -0.48462558  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030244 average distance reward:  -0.18464711  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: -21.51, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 17.22, Length: 12
DEBUG (Env): Episode done for env 66. Reward: -16.55, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -21.33, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -21.16, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -17.75, Length: 36
384
Time taken for simulation:  7.294661045074463
average overall reward:  -0.17053837  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.10369703  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: -18.76, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -27.20, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -19.78, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 29.23, Length: 4
DEBUG (Env): Episode done for env 108. Reward: -24.71, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -21.61, Length: 36
385
Time taken for simulation:  6.999645709991455
average overall reward:  -0.3676927  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.18951294  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 49. Reward: -24.75, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -31.22, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 6.33, Length: 32
386
Time taken for simulation:  7.570320129394531
average overall reward:  -0.3207311  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  -0.1706  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 79. Reward: -7.59, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -21.97, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 20.44, Length: 3
DEBUG (Env): Episode done for env 112. Reward: -22.15, Length: 36
387
Time taken for simulation:  6.989095211029053
average overall reward:  -0.5244204  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.14055604  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 67. Reward: -16.38, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -17.33, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -13.61, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -20.47, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -4.68, Length: 36
388
Time taken for simulation:  7.057429313659668
average overall reward:  -0.4869699  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.3345332  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 58. Reward: -11.54, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 2.45, Length: 22
DEBUG (Env): Episode done for env 119. Reward: -26.53, Length: 36
389
Time taken for simulation:  7.806607246398926
average overall reward:  -0.17533022  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.020587936  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: -7.07, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 10.22, Length: 20
390
Time taken for simulation:  7.063858270645142
average overall reward:  -0.19329348  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168783 average distance reward:  -0.049117133  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 126. Reward: 22.16, Length: 24
391
Time taken for simulation:  7.3547585010528564
average overall reward:  -0.16853175  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.11976918  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 52. Reward: 19.69, Length: 6
DEBUG (Env): Episode done for env 59. Reward: -17.48, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -14.26, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -16.72, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -27.17, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -16.67, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 19.37, Length: 1
392
Time taken for simulation:  7.128357172012329
average overall reward:  -0.29138207  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.08976476  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 8. Reward: -14.65, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -29.46, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 14.12, Length: 32
DEBUG (Env): Episode done for env 117. Reward: -24.04, Length: 36
393
Time taken for simulation:  7.090591192245483
average overall reward:  0.025626153  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.29604554 average distance reward:  -0.07820585  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: 21.21, Length: 14
DEBUG (Env): Episode done for env 18. Reward: -14.81, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -23.97, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 25.52, Length: 26
DEBUG (Env): Episode done for env 78. Reward: -22.03, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 5.31, Length: 34
DEBUG (Env): Episode done for env 106. Reward: 13.16, Length: 28
DEBUG (Env): Episode done for env 110. Reward: -39.19, Length: 36
394
Time taken for simulation:  7.042035341262817
average overall reward:  -0.26295376  average fail penalty:  -0.140625  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.11860497  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: -24.79, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -17.62, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -21.81, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -24.14, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -21.18, Length: 36
395
Time taken for simulation:  7.08345103263855
average overall reward:  0.118280925  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.13304  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: -20.44, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 11.36, Length: 22
DEBUG (Env): Episode done for env 44. Reward: -16.78, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -14.53, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 35.27, Length: 11
396
Time taken for simulation:  7.133597373962402
average overall reward:  -0.097013414  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.03307373  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: -17.69, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -12.76, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 19.51, Length: 10
DEBUG (Env): Episode done for env 99. Reward: -8.67, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -22.35, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 23.82, Length: 8
397
Time taken for simulation:  7.2917938232421875
average overall reward:  -0.17580505  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594475 average distance reward:  -0.010496773  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 41. Reward: -12.68, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -19.85, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 25.12, Length: 14
398
Time taken for simulation:  7.323432922363281
average overall reward:  -0.6234212  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  -0.395359  and average step penalty:  -0.04786053509430681
Number of done instances:  0
399
Time taken for simulation:  7.744001865386963
average overall reward:  -0.3151439  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  0.0030191056  and average step penalty:  -0.04786053509430681
Number of done instances:  0
400
Time taken for simulation:  7.479176998138428
average overall reward:  -0.41181648  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168783 average distance reward:  -0.24420261  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 9. Reward: 13.23, Length: 17
DEBUG (Env): Episode done for env 24. Reward: -18.56, Length: 36
401
Time taken for simulation:  7.411555051803589
average overall reward:  -0.21710944  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  -0.22187847  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: 18.84, Length: 19
DEBUG (Env): Episode done for env 25. Reward: 19.53, Length: 19
DEBUG (Env): Episode done for env 34. Reward: -10.27, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -19.47, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -27.62, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 18.28, Length: 14
402
Time taken for simulation:  7.0463035106658936
average overall reward:  -0.37242907  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.09588808  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: -19.79, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -15.69, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 31.55, Length: 27
DEBUG (Env): Episode done for env 60. Reward: -12.24, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -22.74, Length: 36
403
Time taken for simulation:  7.388197660446167
average overall reward:  -0.2093826  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.026238145  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -23.33, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -22.22, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -11.04, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 12.63, Length: 33
DEBUG (Env): Episode done for env 104. Reward: -20.08, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -8.44, Length: 36
404
Time taken for simulation:  7.295351505279541
average overall reward:  -0.19872102  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.109038256  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: -14.59, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -19.82, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 8.10, Length: 22
DEBUG (Env): Episode done for env 43. Reward: -8.93, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 10.95, Length: 31
DEBUG (Env): Episode done for env 118. Reward: -21.50, Length: 36
405
Time taken for simulation:  7.022549390792847
average overall reward:  0.4049789  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.043976232  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 42.35, Length: 13
DEBUG (Env): Episode done for env 23. Reward: 13.69, Length: 9
DEBUG (Env): Episode done for env 24. Reward: 15.29, Length: 5
DEBUG (Env): Episode done for env 28. Reward: -17.20, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 27.31, Length: 10
DEBUG (Env): Episode done for env 96. Reward: 24.12, Length: 13
406
Time taken for simulation:  7.38930606842041
average overall reward:  -0.38370502  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.046715714  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 86. Reward: -24.21, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -24.06, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -10.32, Length: 36
407
Time taken for simulation:  7.3591296672821045
average overall reward:  -0.27932268  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.055361025  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: -18.49, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -23.44, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -13.90, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -11.07, Length: 36
408
Time taken for simulation:  7.3927998542785645
average overall reward:  0.24795406  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.07150392  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 41.67, Length: 12
DEBUG (Env): Episode done for env 16. Reward: -16.89, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -9.85, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 13.62, Length: 4
DEBUG (Env): Episode done for env 75. Reward: 20.27, Length: 7
DEBUG (Env): Episode done for env 76. Reward: 26.72, Length: 17
409
Time taken for simulation:  7.188771724700928
average overall reward:  0.032383062  average fail penalty:  -0.1640625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  -0.052622616  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 22. Reward: -14.53, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 34.14, Length: 6
DEBUG (Env): Episode done for env 32. Reward: -15.48, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 14.86, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -21.05, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -16.23, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 7.79, Length: 28
DEBUG (Env): Episode done for env 85. Reward: -6.76, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 25.96, Length: 6
DEBUG (Env): Episode done for env 103. Reward: -17.51, Length: 36
410
Time taken for simulation:  7.033121109008789
average overall reward:  0.23192358  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.2572486  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 44. Reward: 28.56, Length: 15
DEBUG (Env): Episode done for env 54. Reward: -19.39, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 19.49, Length: 1
DEBUG (Env): Episode done for env 92. Reward: -20.94, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -10.11, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -24.57, Length: 36
411
Time taken for simulation:  7.0470969676971436
average overall reward:  -0.38453805  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.11030272  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: -24.10, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -19.64, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -17.48, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 16.49, Length: 2
DEBUG (Env): Episode done for env 94. Reward: -13.02, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -18.40, Length: 36
412
Time taken for simulation:  7.229501247406006
average overall reward:  0.27167845  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.12993363  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 54. Reward: 18.12, Length: 2
DEBUG (Env): Episode done for env 57. Reward: 6.62, Length: 15
DEBUG (Env): Episode done for env 94. Reward: 24.74, Length: 1
DEBUG (Env): Episode done for env 98. Reward: -17.52, Length: 36
413
Time taken for simulation:  7.128998279571533
average overall reward:  -0.02109319  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.0019263178  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -25.99, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 25.01, Length: 20
DEBUG (Env): Episode done for env 66. Reward: -10.92, Length: 30
DEBUG (Env): Episode done for env 69. Reward: -25.49, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -21.75, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -17.39, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -17.43, Length: 36
414
Time taken for simulation:  7.341883897781372
average overall reward:  0.19200075  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.11584391 average distance reward:  -0.1389079  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 19. Reward: 13.21, Length: 6
DEBUG (Env): Episode done for env 81. Reward: -16.62, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 20.33, Length: 23
DEBUG (Env): Episode done for env 114. Reward: 11.43, Length: 26
DEBUG (Env): Episode done for env 123. Reward: 7.73, Length: 31
DEBUG (Env): Episode done for env 125. Reward: -19.07, Length: 36
415
Time taken for simulation:  7.022538661956787
average overall reward:  -0.10583276  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.20665735  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 54. Reward: 17.39, Length: 3
DEBUG (Env): Episode done for env 62. Reward: 24.46, Length: 21
DEBUG (Env): Episode done for env 66. Reward: 16.21, Length: 2
416
Time taken for simulation:  7.01260232925415
average overall reward:  -0.5034159  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.2503124  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: 20.71, Length: 5
DEBUG (Env): Episode done for env 35. Reward: -21.00, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -15.15, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -22.95, Length: 36
417
Time taken for simulation:  7.21501898765564
average overall reward:  -0.2578845  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  0.014747102  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 10. Reward: -24.93, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -26.54, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -17.20, Length: 36
418
Time taken for simulation:  7.034754276275635
average overall reward:  -0.44070715  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.18529806  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 36. Reward: 5.90, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -28.17, Length: 36
419
Time taken for simulation:  7.031036853790283
average overall reward:  0.03646799  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  -0.015176084  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: 19.04, Length: 14
DEBUG (Env): Episode done for env 60. Reward: 17.65, Length: 17
DEBUG (Env): Episode done for env 109. Reward: -10.79, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 18.95, Length: 13
420
Time taken for simulation:  7.346072196960449
average overall reward:  -0.22579092  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.29604554 average distance reward:  -0.17081344  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 3. Reward: -19.63, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 22.21, Length: 29
DEBUG (Env): Episode done for env 61. Reward: -24.62, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -18.14, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 10.94, Length: 34
DEBUG (Env): Episode done for env 85. Reward: 25.19, Length: 9
DEBUG (Env): Episode done for env 108. Reward: -14.06, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -18.45, Length: 36
421
Time taken for simulation:  7.251834392547607
average overall reward:  -0.39915478  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  -0.124217585  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 49. Reward: -15.01, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -23.39, Length: 36
422
Time taken for simulation:  6.9979729652404785
average overall reward:  -0.017207295  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030244 average distance reward:  -0.058285374  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: 11.25, Length: 29
DEBUG (Env): Episode done for env 49. Reward: 15.80, Length: 1
DEBUG (Env): Episode done for env 101. Reward: 15.31, Length: 4
DEBUG (Env): Episode done for env 102. Reward: -17.33, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -19.20, Length: 36
423
Time taken for simulation:  7.0040366649627686
average overall reward:  -0.6397092  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.23168783 average distance reward:  -0.26641077  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 67. Reward: -20.06, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -4.12, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -23.66, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -14.00, Length: 36
424
Time taken for simulation:  6.994520425796509
average overall reward:  -0.012552505  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.0068177655  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 58. Reward: -20.82, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 16.91, Length: 23
DEBUG (Env): Episode done for env 126. Reward: 13.17, Length: 33
425
Time taken for simulation:  7.146634101867676
average overall reward:  -0.10425221  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.0481845  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 2. Reward: -18.97, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 10.60, Length: 14
DEBUG (Env): Episode done for env 46. Reward: -25.32, Length: 36
426
Time taken for simulation:  6.991570711135864
average overall reward:  -0.2529562  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.39239547  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: 6.41, Length: 32
DEBUG (Env): Episode done for env 59. Reward: 19.91, Length: 6
DEBUG (Env): Episode done for env 98. Reward: 27.11, Length: 14
427
Time taken for simulation:  7.629139184951782
average overall reward:  -0.60669297  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.16733009 average distance reward:  -0.32118988  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 52. Reward: -23.01, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -17.52, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -15.68, Length: 36
428
Time taken for simulation:  7.14948844909668
average overall reward:  0.21798603  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.17069305  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 25. Reward: 19.10, Length: 27
DEBUG (Env): Episode done for env 37. Reward: 27.55, Length: 2
DEBUG (Env): Episode done for env 113. Reward: -11.52, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -27.33, Length: 36
429
Time taken for simulation:  7.1759724617004395
average overall reward:  -0.32689017  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.33466017 average distance reward:  -0.074488476  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: -15.88, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -19.50, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -19.42, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -26.33, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 6.65, Length: 33
DEBUG (Env): Episode done for env 106. Reward: -19.15, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 29.92, Length: 9
DEBUG (Env): Episode done for env 110. Reward: -19.99, Length: 36
430
Time taken for simulation:  7.257780313491821
average overall reward:  -0.026185103  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.03325969  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: 8.74, Length: 30
DEBUG (Env): Episode done for env 11. Reward: -29.85, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -10.16, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 20.63, Length: 5
DEBUG (Env): Episode done for env 71. Reward: -6.31, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -22.38, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 35.15, Length: 8
431
Time taken for simulation:  7.295386552810669
average overall reward:  -0.12552056  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.15603267  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 7.96, Length: 11
DEBUG (Env): Episode done for env 4. Reward: -25.61, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -23.08, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -25.47, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 15.33, Length: 26
DEBUG (Env): Episode done for env 124. Reward: 22.31, Length: 11
432
Time taken for simulation:  7.329860210418701
average overall reward:  0.031659037  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.17283973  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 14.91, Length: 3
DEBUG (Env): Episode done for env 31. Reward: 18.66, Length: 1
DEBUG (Env): Episode done for env 49. Reward: 21.42, Length: 10
DEBUG (Env): Episode done for env 99. Reward: -22.80, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -15.23, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 8.30, Length: 18
DEBUG (Env): Episode done for env 119. Reward: -25.57, Length: 36
433
Time taken for simulation:  7.5313804149627686
average overall reward:  0.17447582  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.081911534  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: 28.81, Length: 8
DEBUG (Env): Episode done for env 30. Reward: 31.81, Length: 3
DEBUG (Env): Episode done for env 41. Reward: -18.77, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -20.42, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 3.20, Length: 19
434
Time taken for simulation:  7.097539901733398
average overall reward:  -0.5282582  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  -0.300196  and average step penalty:  -0.04786053509430681
Number of done instances:  0
435
Time taken for simulation:  7.3308024406433105
average overall reward:  -0.28044122  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.23302229  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 1. Reward: 14.47, Length: 32
DEBUG (Env): Episode done for env 50. Reward: 17.36, Length: 4
436
Time taken for simulation:  7.196726560592651
average overall reward:  -0.2855885  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.14141214  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 112. Reward: 17.38, Length: 6
437
Time taken for simulation:  7.30067777633667
average overall reward:  -0.61249226  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.19827369  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 5. Reward: -15.91, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -16.59, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -24.97, Length: 36
438
Time taken for simulation:  7.038459539413452
average overall reward:  -0.3554889  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.28317404 average distance reward:  -0.20144847  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 24.33, Length: 5
DEBUG (Env): Episode done for env 12. Reward: -16.55, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -24.12, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -16.30, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -16.02, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 8.83, Length: 29
439
Time taken for simulation:  7.2109575271606445
average overall reward:  -0.2669648  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.07821907  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 45. Reward: -12.80, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 26.74, Length: 12
DEBUG (Env): Episode done for env 104. Reward: -25.04, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -14.59, Length: 36
440
Time taken for simulation:  7.278417348861694
average overall reward:  -0.23512699  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.10913519  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: -22.34, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -24.94, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -19.83, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 7.15, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 18.92, Length: 21
DEBUG (Env): Episode done for env 118. Reward: -25.69, Length: 36
441
Time taken for simulation:  7.034425973892212
average overall reward:  -0.42106408  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3089171 average distance reward:  -0.105908476  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: -16.70, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -20.69, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -14.83, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -13.79, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 15.18, Length: 8
442
Time taken for simulation:  7.172831058502197
average overall reward:  -0.20903546  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.23058544  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 25. Reward: 6.89, Length: 14
DEBUG (Env): Episode done for env 65. Reward: 14.95, Length: 2
DEBUG (Env): Episode done for env 86. Reward: -30.11, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -18.76, Length: 36
443
Time taken for simulation:  7.171634912490845
average overall reward:  -0.20283003  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.19703312  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: -20.01, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 9.82, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -26.73, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 14.87, Length: 17
DEBUG (Env): Episode done for env 120. Reward: -15.02, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 18.56, Length: 2
444
Time taken for simulation:  7.265277624130249
average overall reward:  -0.5251459  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.102666974  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: -28.70, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -17.93, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -22.70, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -35.90, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -13.48, Length: 36
445
Time taken for simulation:  7.200510501861572
average overall reward:  -0.81066066  average fail penalty:  -0.1640625  and average goal bonus:  0.0  and average same cell penalty:  -0.27030244 average distance reward:  -0.32843524  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 22. Reward: -13.80, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -23.91, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -30.66, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -18.02, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -21.54, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -10.51, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -25.18, Length: 36
446
Time taken for simulation:  8.028571128845215
average overall reward:  -0.46495897  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.20359513  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 44. Reward: -18.60, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -15.81, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 15.97, Length: 1
DEBUG (Env): Episode done for env 92. Reward: -17.61, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -12.32, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -24.41, Length: 36
447
Time taken for simulation:  7.400511264801025
average overall reward:  -0.24061272  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.049561396  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: -17.47, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 28.18, Length: 10
DEBUG (Env): Episode done for env 122. Reward: -17.78, Length: 36
448
Time taken for simulation:  7.106435060501099
average overall reward:  -0.053995  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.08841645  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 48. Reward: 10.56, Length: 19
DEBUG (Env): Episode done for env 53. Reward: 24.90, Length: 3
DEBUG (Env): Episode done for env 57. Reward: -16.51, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -22.76, Length: 36
449
Time taken for simulation:  7.1006927490234375
average overall reward:  -0.33746797  average fail penalty:  -0.140625  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.04409074  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: -37.13, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -6.28, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -15.55, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -31.87, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -29.19, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -24.02, Length: 36
450
Time taken for simulation:  7.094592094421387
average overall reward:  -0.2566069  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  -0.08303825  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: -21.51, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 16.10, Length: 7
DEBUG (Env): Episode done for env 81. Reward: -28.98, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -23.68, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -20.50, Length: 36
451
Time taken for simulation:  7.060823202133179
average overall reward:  -0.19692871  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.26605546  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 19.93, Length: 19
DEBUG (Env): Episode done for env 38. Reward: 17.85, Length: 11
DEBUG (Env): Episode done for env 52. Reward: 11.31, Length: 24
DEBUG (Env): Episode done for env 54. Reward: -13.59, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -16.31, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -28.86, Length: 36
452
Time taken for simulation:  7.2739646434783936
average overall reward:  -0.39818695  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  -0.10211787  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: -16.37, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -11.62, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -23.05, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -26.18, Length: 36
453
Time taken for simulation:  7.2622902393341064
average overall reward:  -0.17001413  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.07802577  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 10. Reward: -31.05, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 15.28, Length: 8
DEBUG (Env): Episode done for env 40. Reward: -11.20, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -28.30, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 17.28, Length: 10
454
Time taken for simulation:  7.38945460319519
average overall reward:  -0.009054165  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.048930727  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 13. Reward: 20.18, Length: 14
DEBUG (Env): Episode done for env 36. Reward: -31.95, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 13.97, Length: 26
455
Time taken for simulation:  7.243752956390381
average overall reward:  -0.33840504  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.08530156  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: -19.51, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 19.17, Length: 7
DEBUG (Env): Episode done for env 60. Reward: -12.44, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -22.23, Length: 36
456
Time taken for simulation:  7.150943756103516
average overall reward:  -0.2901551  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.09084339  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 61. Reward: -21.02, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 26.95, Length: 5
DEBUG (Env): Episode done for env 70. Reward: -23.48, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -25.56, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -21.61, Length: 36
457
Time taken for simulation:  7.266059160232544
average overall reward:  0.13012591  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.09801001  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 22. Reward: 13.62, Length: 4
DEBUG (Env): Episode done for env 55. Reward: 41.75, Length: 12
DEBUG (Env): Episode done for env 82. Reward: -20.66, Length: 36
458
Time taken for simulation:  7.477573871612549
average overall reward:  -0.19647714  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.10448885  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: -13.55, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 11.77, Length: 8
DEBUG (Env): Episode done for env 42. Reward: 31.16, Length: 15
DEBUG (Env): Episode done for env 101. Reward: -7.80, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -10.68, Length: 36
459
Time taken for simulation:  6.984111785888672
average overall reward:  -0.27228066  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.29222688  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 23. Reward: 23.02, Length: 18
DEBUG (Env): Episode done for env 28. Reward: 26.30, Length: 4
DEBUG (Env): Episode done for env 67. Reward: -14.70, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -20.38, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -22.07, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -21.05, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 10.38, Length: 28
460
Time taken for simulation:  7.2193427085876465
average overall reward:  -0.64854306  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.26006755  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 58. Reward: -18.96, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -16.76, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -24.55, Length: 36
461
Time taken for simulation:  7.287854194641113
average overall reward:  -0.09535414  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  -0.030712627  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 46. Reward: -24.43, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 9.79, Length: 29
462
Time taken for simulation:  7.059977769851685
average overall reward:  0.07632285  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.09569311  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 59. Reward: -19.50, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 12.76, Length: 11
DEBUG (Env): Episode done for env 72. Reward: 21.57, Length: 12
463
Time taken for simulation:  7.1675333976745605
average overall reward:  -0.1029945  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.038876235  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 46. Reward: 32.94, Length: 2
DEBUG (Env): Episode done for env 111. Reward: -16.54, Length: 36
464
Time taken for simulation:  7.6949756145477295
average overall reward:  0.07493671  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  0.16301566  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: -19.61, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 10.21, Length: 29
DEBUG (Env): Episode done for env 113. Reward: -21.06, Length: 36
465
Time taken for simulation:  7.188384532928467
average overall reward:  0.24343419  average fail penalty:  -0.140625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.10924789  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 45. Reward: 20.45, Length: 26
DEBUG (Env): Episode done for env 59. Reward: 31.48, Length: 3
DEBUG (Env): Episode done for env 64. Reward: 8.26, Length: 5
DEBUG (Env): Episode done for env 78. Reward: -7.06, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 17.20, Length: 9
DEBUG (Env): Episode done for env 80. Reward: -38.94, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -25.63, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -25.34, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -13.95, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -20.56, Length: 36
466
Time taken for simulation:  7.308424234390259
average overall reward:  -0.31223178  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  -0.18624002  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: -11.58, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -19.25, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 34.40, Length: 15
DEBUG (Env): Episode done for env 39. Reward: -9.11, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -19.27, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 14.46, Length: 20
DEBUG (Env): Episode done for env 100. Reward: -15.09, Length: 36
467
Time taken for simulation:  7.417325973510742
average overall reward:  -0.36768368  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.11458019  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: -14.50, Length: 36
DEBUG (Env): Episode done for env 4. Reward: -25.04, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 22.00, Length: 5
DEBUG (Env): Episode done for env 96. Reward: -19.14, Length: 36
468
Time taken for simulation:  7.301558017730713
average overall reward:  -0.255354  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.019733246  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: 12.67, Length: 14
DEBUG (Env): Episode done for env 18. Reward: -18.96, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -31.59, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -17.29, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -22.29, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -15.53, Length: 36
469
Time taken for simulation:  7.137331008911133
average overall reward:  -0.19825932  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.10627096  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 28.36, Length: 22
DEBUG (Env): Episode done for env 30. Reward: -20.35, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -10.03, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 24.93, Length: 1
DEBUG (Env): Episode done for env 51. Reward: -25.95, Length: 36
470
Time taken for simulation:  7.339579105377197
average overall reward:  -0.3738771  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.20395769  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 51. Reward: 18.81, Length: 1
471
Time taken for simulation:  7.085791826248169
average overall reward:  -0.23922664  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.058741257  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 1. Reward: -25.27, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 24.43, Length: 30
472
Time taken for simulation:  7.596144676208496
average overall reward:  0.04075809  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  -0.15247297  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 25. Reward: 10.06, Length: 30
DEBUG (Env): Episode done for env 26. Reward: 1.51, Length: 23
DEBUG (Env): Episode done for env 112. Reward: -10.59, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 10.08, Length: 22
473
Time taken for simulation:  7.3899805545806885
average overall reward:  0.00907214  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.090494536  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: 10.46, Length: 35
DEBUG (Env): Episode done for env 5. Reward: -15.51, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -24.50, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 25.82, Length: 10
474
Time taken for simulation:  7.150477647781372
average overall reward:  -0.39471883  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.14622654  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: -15.31, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -19.61, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -23.64, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 8.98, Length: 26
DEBUG (Env): Episode done for env 63. Reward: -15.94, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -17.23, Length: 36
475
Time taken for simulation:  7.3616015911102295
average overall reward:  0.04551144  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.047398936  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 83. Reward: -14.05, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 4.25, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 33.91, Length: 2
DEBUG (Env): Episode done for env 121. Reward: -32.14, Length: 36
476
Time taken for simulation:  7.028958797454834
average overall reward:  -0.5598136  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.3195817  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 27. Reward: -19.29, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -23.45, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -19.49, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 8.84, Length: 33
477
Time taken for simulation:  7.082048416137695
average overall reward:  -0.09179037  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.19722615  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: -19.59, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 15.33, Length: 33
DEBUG (Env): Episode done for env 24. Reward: -36.27, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 14.87, Length: 26
DEBUG (Env): Episode done for env 96. Reward: 21.83, Length: 10
478
Time taken for simulation:  7.273382186889648
average overall reward:  -0.3646139  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168783 average distance reward:  -0.15012503  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 13. Reward: 16.66, Length: 10
DEBUG (Env): Episode done for env 65. Reward: -21.94, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -23.96, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -22.26, Length: 36
479
Time taken for simulation:  7.241645574569702
average overall reward:  -0.1831545  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.017846256  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 2. Reward: 12.39, Length: 6
DEBUG (Env): Episode done for env 7. Reward: -20.76, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -20.93, Length: 36
480
Time taken for simulation:  7.004705429077148
average overall reward:  -0.15101013  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.09994203  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 9.34, Length: 22
DEBUG (Env): Episode done for env 16. Reward: -15.15, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 31.61, Length: 3
DEBUG (Env): Episode done for env 43. Reward: -39.92, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -19.04, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -19.39, Length: 36
481
Time taken for simulation:  7.5644989013671875
average overall reward:  -0.53712195  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.12290339  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 29. Reward: -12.61, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -19.51, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -18.10, Length: 36
482
Time taken for simulation:  7.096195936203003
average overall reward:  -0.6252607  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.18991025  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 44. Reward: -26.99, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -29.18, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -18.42, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -15.80, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -16.26, Length: 36
483
Time taken for simulation:  7.06564998626709
average overall reward:  -0.3246383  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.20594472 average distance reward:  -0.023958031  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 56. Reward: -19.10, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -17.44, Length: 36
484
Time taken for simulation:  7.207837343215942
average overall reward:  -0.13457772  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.030730516  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 57. Reward: -20.02, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 19.01, Length: 18
DEBUG (Env): Episode done for env 94. Reward: -16.10, Length: 36
485
Time taken for simulation:  7.13890814781189
average overall reward:  -0.4441502  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.30528685  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -25.60, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 14.06, Length: 13
DEBUG (Env): Episode done for env 69. Reward: -19.67, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -16.78, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -12.02, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -20.25, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 15.31, Length: 27
486
Time taken for simulation:  7.190119981765747
average overall reward:  -0.78699434  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.18020163 average distance reward:  -0.5120572  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 81. Reward: -20.25, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -41.05, Length: 36
487
Time taken for simulation:  7.090832948684692
average overall reward:  0.07176995  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.22420663  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 38. Reward: -19.59, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -14.08, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 13.54, Length: 35
488
Time taken for simulation:  7.140086650848389
average overall reward:  -0.3940068  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.19238949  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: -17.84, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 17.51, Length: 15
DEBUG (Env): Episode done for env 35. Reward: -18.89, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -11.68, Length: 36
489
Time taken for simulation:  7.015502691268921
average overall reward:  -0.5124602  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  -0.13916181  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: -15.31, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -16.52, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -16.06, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -22.62, Length: 36
490
Time taken for simulation:  7.656955003738403
average overall reward:  0.16906649  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.102245316  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 35. Reward: 15.65, Length: 2
DEBUG (Env): Episode done for env 36. Reward: -15.63, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -8.56, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 13.80, Length: 15
DEBUG (Env): Episode done for env 125. Reward: 24.27, Length: 1
491
Time taken for simulation:  7.05526065826416
average overall reward:  0.32626617  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.1732535  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 42. Reward: 20.26, Length: 33
DEBUG (Env): Episode done for env 44. Reward: 26.68, Length: 9
DEBUG (Env): Episode done for env 48. Reward: -25.69, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -4.20, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -19.68, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -8.08, Length: 19
DEBUG (Env): Episode done for env 121. Reward: 18.89, Length: 1
492
Time taken for simulation:  7.359120607376099
average overall reward:  -0.38217127  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  -0.22147419  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 61. Reward: -11.35, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -10.69, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -5.45, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 20.76, Length: 27
DEBUG (Env): Episode done for env 85. Reward: -10.01, Length: 36
493
Time taken for simulation:  7.170003414154053
average overall reward:  -0.363736  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.24600454  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: 11.82, Length: 13
DEBUG (Env): Episode done for env 22. Reward: -11.90, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -24.45, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 20.91, Length: 15
DEBUG (Env): Episode done for env 82. Reward: -10.24, Length: 36
494
Time taken for simulation:  7.5920774936676025
average overall reward:  -0.008078996  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  0.08621496  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 19. Reward: -27.81, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 25.67, Length: 2
DEBUG (Env): Episode done for env 102. Reward: -30.32, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 25.42, Length: 3
495
Time taken for simulation:  7.633389949798584
average overall reward:  -0.10584259  average fail penalty:  -0.1640625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.06702417  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 11. Reward: 9.05, Length: 29
DEBUG (Env): Episode done for env 23. Reward: -16.34, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -24.57, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 17.57, Length: 5
DEBUG (Env): Episode done for env 67. Reward: -14.72, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -19.33, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -26.46, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -18.92, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -11.75, Length: 36
496
Time taken for simulation:  7.223813056945801
average overall reward:  0.36668146  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.0033731833  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: 34.93, Length: 18
DEBUG (Env): Episode done for env 20. Reward: 24.94, Length: 22
DEBUG (Env): Episode done for env 29. Reward: 38.03, Length: 15
DEBUG (Env): Episode done for env 58. Reward: -13.20, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 25.08, Length: 3
DEBUG (Env): Episode done for env 104. Reward: 4.66, Length: 21
DEBUG (Env): Episode done for env 126. Reward: -18.76, Length: 36
497
Time taken for simulation:  7.093414306640625
average overall reward:  -0.13640657  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  -0.20713714  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 42. Reward: 21.80, Length: 6
DEBUG (Env): Episode done for env 119. Reward: -18.57, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 18.25, Length: 21
498
Time taken for simulation:  7.359648704528809
average overall reward:  -0.07325363  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.07962644  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 12. Reward: 11.13, Length: 24
DEBUG (Env): Episode done for env 36. Reward: 31.63, Length: 8
DEBUG (Env): Episode done for env 72. Reward: -20.16, Length: 36
499
Time taken for simulation:  7.090953350067139
average overall reward:  -0.12603831  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.0029608477  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 46. Reward: -15.08, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 26.83, Length: 9
500
Time taken for simulation:  7.7620556354522705
average overall reward:  -0.5677531  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.17927758  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: -21.93, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -26.91, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -13.62, Length: 36
501
Time taken for simulation:  7.2714972496032715
average overall reward:  -0.37939024  average fail penalty:  -0.2109375  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.059609443  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 45. Reward: -19.25, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -17.11, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -51.93, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -15.56, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -15.35, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -21.93, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -20.82, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -22.86, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -24.89, Length: 36
502
Time taken for simulation:  7.3519415855407715
average overall reward:  -0.31927738  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.2705149  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: -18.81, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 20.58, Length: 25
DEBUG (Env): Episode done for env 28. Reward: 16.39, Length: 7
DEBUG (Env): Episode done for env 31. Reward: -13.34, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -26.92, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -17.76, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -27.86, Length: 36
503
Time taken for simulation:  7.23866081237793
average overall reward:  0.4974474  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.34443486  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: -21.96, Length: 36
DEBUG (Env): Episode done for env 4. Reward: -17.35, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 16.76, Length: 8
DEBUG (Env): Episode done for env 42. Reward: 21.61, Length: 6
DEBUG (Env): Episode done for env 66. Reward: -18.88, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 21.98, Length: 1
DEBUG (Env): Episode done for env 124. Reward: 30.82, Length: 8
504
Time taken for simulation:  7.405679702758789
average overall reward:  -0.2175172  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  -0.3018211  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 18.82, Length: 1
DEBUG (Env): Episode done for env 18. Reward: -13.86, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 21.60, Length: 2
DEBUG (Env): Episode done for env 46. Reward: 35.58, Length: 5
DEBUG (Env): Episode done for env 99. Reward: -10.31, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -20.92, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -23.20, Length: 36
505
Time taken for simulation:  7.121776819229126
average overall reward:  -0.017618313  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.046321373  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: -18.54, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 20.03, Length: 1
DEBUG (Env): Episode done for env 30. Reward: -16.15, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -0.15, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -19.57, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 6.31, Length: 31
506
Time taken for simulation:  7.133568048477173
average overall reward:  -0.2971784  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  -0.23253696  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 51. Reward: -9.02, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 22.19, Length: 16
507
Time taken for simulation:  7.302520990371704
average overall reward:  -0.12671582  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  -0.13539423  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: -22.72, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 4.45, Length: 7
DEBUG (Env): Episode done for env 47. Reward: -6.13, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 16.83, Length: 1
508
Time taken for simulation:  7.2504799365997314
average overall reward:  -0.14479521  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.23735951  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: 5.30, Length: 29
DEBUG (Env): Episode done for env 26. Reward: -16.81, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 21.36, Length: 3
DEBUG (Env): Episode done for env 92. Reward: 18.61, Length: 5
DEBUG (Env): Episode done for env 123. Reward: -14.75, Length: 36
509
Time taken for simulation:  7.047571182250977
average overall reward:  0.0067490414  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.026119322  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 5. Reward: -26.53, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 20.59, Length: 5
DEBUG (Env): Episode done for env 69. Reward: 16.56, Length: 24
510
Time taken for simulation:  7.784404516220093
average overall reward:  0.23070791  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.29695314  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: -11.28, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -20.63, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -24.89, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 4.05, Length: 28
DEBUG (Env): Episode done for env 110. Reward: 14.14, Length: 9
511
Time taken for simulation:  7.517884969711304
average overall reward:  -0.34586507  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.058056325  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 83. Reward: -9.02, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -21.60, Length: 36
512
Time taken for simulation:  7.612638235092163
average overall reward:  -0.1295763  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.059169453  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 27. Reward: -18.02, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 15.48, Length: 32
DEBUG (Env): Episode done for env 115. Reward: -27.80, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -30.93, Length: 36
513
Time taken for simulation:  7.085110902786255
average overall reward:  -0.65199953  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.2763956  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 8. Reward: -20.36, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -14.06, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -19.86, Length: 36
514
Time taken for simulation:  7.29332709312439
average overall reward:  -0.29974005  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.45666203  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 16.44, Length: 11
DEBUG (Env): Episode done for env 15. Reward: 8.36, Length: 12
DEBUG (Env): Episode done for env 86. Reward: -19.73, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 15.97, Length: 12
DEBUG (Env): Episode done for env 105. Reward: -14.88, Length: 36
515
Time taken for simulation:  7.0271337032318115
average overall reward:  -0.26849002  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.025952518  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 7. Reward: -23.67, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -11.82, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 29.69, Length: 15
516
Time taken for simulation:  7.76938796043396
average overall reward:  -0.13183415  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  0.093220666  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 16. Reward: -25.38, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -23.21, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 51.81, Length: 7
DEBUG (Env): Episode done for env 75. Reward: -22.73, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -16.88, Length: 36
517
Time taken for simulation:  7.437243223190308
average overall reward:  -0.31469384  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.22039992  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 32. Reward: -24.88, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -19.46, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 30.62, Length: 19
DEBUG (Env): Episode done for env 114. Reward: 28.66, Length: 13
518
Time taken for simulation:  7.133216381072998
average overall reward:  -0.591254  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.283174 average distance reward:  -0.18990695  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 90. Reward: -18.67, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -20.08, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -24.15, Length: 36
519
Time taken for simulation:  7.102941274642944
average overall reward:  -0.27663326  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.12419657  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: 8.39, Length: 12
DEBUG (Env): Episode done for env 56. Reward: -20.26, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -10.69, Length: 36
520
Time taken for simulation:  7.1337971687316895
average overall reward:  0.039209023  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  0.37619838  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 57. Reward: -16.46, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -17.00, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -19.45, Length: 36
521
Time taken for simulation:  7.4073166847229
average overall reward:  -0.11649695  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.32178864 average distance reward:  -0.012338903  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: -28.02, Length: 36
DEBUG (Env): Episode done for env 2. Reward: 38.13, Length: 13
DEBUG (Env): Episode done for env 25. Reward: -20.81, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 22.04, Length: 5
DEBUG (Env): Episode done for env 77. Reward: -10.11, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -18.81, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -12.90, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -14.42, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 13.59, Length: 11
522
Time taken for simulation:  7.353243589401245
average overall reward:  0.06567249  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.09124951  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 56. Reward: 17.13, Length: 3
DEBUG (Env): Episode done for env 64. Reward: 29.26, Length: 21
DEBUG (Env): Episode done for env 81. Reward: -21.28, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -26.63, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 19.72, Length: 1
523
Time taken for simulation:  7.07242226600647
average overall reward:  -0.5919529  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.17773435  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 38. Reward: -16.37, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -21.42, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -18.44, Length: 36
524
Time taken for simulation:  7.6239564418792725
average overall reward:  0.07924367  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594475 average distance reward:  -0.0027546287  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: 18.68, Length: 10
DEBUG (Env): Episode done for env 6. Reward: -22.63, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -11.59, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -27.85, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 12.94, Length: 3
DEBUG (Env): Episode done for env 85. Reward: 9.66, Length: 32
525
Time taken for simulation:  7.169437885284424
average overall reward:  0.29958123  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.37869802  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 10. Reward: -18.18, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -20.76, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -17.47, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 19.06, Length: 5
DEBUG (Env): Episode done for env 108. Reward: 13.58, Length: 24
526
Time taken for simulation:  7.863276720046997
average overall reward:  -0.18779907  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.06936582  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 2. Reward: 34.58, Length: 5
527
Time taken for simulation:  7.325998306274414
average overall reward:  -0.3662772  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.19501412  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 44. Reward: -14.55, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -22.96, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -5.91, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 9.98, Length: 26
DEBUG (Env): Episode done for env 109. Reward: -19.03, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -22.12, Length: 36
528
Time taken for simulation:  7.055645227432251
average overall reward:  -0.2008964  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.1603942  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 62. Reward: -12.07, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -17.95, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 0.05, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 34.55, Length: 25
529
Time taken for simulation:  7.4657697677612305
average overall reward:  -0.068968326  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.13034339  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: -15.36, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -15.24, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -24.12, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -15.51, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 32.40, Length: 34
530
Time taken for simulation:  7.207215785980225
average overall reward:  0.07194377  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455936 average distance reward:  0.18736959  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 19. Reward: -16.66, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 8.79, Length: 26
DEBUG (Env): Episode done for env 61. Reward: -7.42, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -25.83, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -22.35, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 29.47, Length: 11
531
Time taken for simulation:  7.332831382751465
average overall reward:  -0.10000864  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020163 average distance reward:  -0.16087501  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: 33.24, Length: 24
DEBUG (Env): Episode done for env 8. Reward: 17.88, Length: 18
DEBUG (Env): Episode done for env 11. Reward: -18.89, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 9.84, Length: 35
DEBUG (Env): Episode done for env 35. Reward: -20.80, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -10.48, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -11.75, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -14.03, Length: 36
532
Time taken for simulation:  7.240018129348755
average overall reward:  0.22018349  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.35674125  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 20. Reward: -26.54, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 9.33, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 6.63, Length: 27
DEBUG (Env): Episode done for env 58. Reward: -20.56, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -10.48, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -22.48, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -25.35, Length: 36
533
Time taken for simulation:  7.379685640335083
average overall reward:  -0.36519733  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.05164548  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 119. Reward: -22.37, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -19.75, Length: 36
534
Time taken for simulation:  7.103942394256592
average overall reward:  -0.3002677  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.12208789  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 12. Reward: -21.14, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -24.94, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 27.11, Length: 12
535
Time taken for simulation:  7.018980503082275
average overall reward:  -0.06501649  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  0.14121197  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 57. Reward: 25.81, Length: 15
DEBUG (Env): Episode done for env 117. Reward: -22.81, Length: 36
536
Time taken for simulation:  7.333802938461304
average overall reward:  -0.0682708  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.24863032  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 50. Reward: -9.03, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 20.06, Length: 5
DEBUG (Env): Episode done for env 115. Reward: 19.86, Length: 24
DEBUG (Env): Episode done for env 121. Reward: 25.72, Length: 9
537
Time taken for simulation:  7.218430280685425
average overall reward:  0.15817086  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.0123244375  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 40. Reward: 14.35, Length: 12
DEBUG (Env): Episode done for env 45. Reward: -11.34, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -30.22, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 26.67, Length: 16
DEBUG (Env): Episode done for env 80. Reward: -10.84, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -22.85, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -14.36, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 22.00, Length: 4
DEBUG (Env): Episode done for env 124. Reward: 16.34, Length: 9
538
Time taken for simulation:  7.14612340927124
average overall reward:  -0.22648013  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.21172106  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: -13.80, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -14.70, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 3.18, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 30.54, Length: 8
DEBUG (Env): Episode done for env 126. Reward: 26.65, Length: 6
539
Time taken for simulation:  7.4306769371032715
average overall reward:  -0.24138379  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.123652324  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: -23.38, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -24.31, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 10.28, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 17.71, Length: 14
540
Time taken for simulation:  7.320161819458008
average overall reward:  -0.3502196  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  -0.2000885  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: -15.30, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 9.77, Length: 13
DEBUG (Env): Episode done for env 99. Reward: -21.03, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -17.34, Length: 36
541
Time taken for simulation:  7.241863250732422
average overall reward:  -0.056250885  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  -0.056668982  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: -23.67, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -14.04, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -18.27, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 20.57, Length: 13
DEBUG (Env): Episode done for env 103. Reward: -11.18, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 11.26, Length: 20
542
Time taken for simulation:  7.044531583786011
average overall reward:  -0.11401328  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  -0.010757109  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 13. Reward: 11.78, Length: 11
DEBUG (Env): Episode done for env 125. Reward: -16.55, Length: 36
543
Time taken for simulation:  7.163371801376343
average overall reward:  0.059635893  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  0.0509575  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 44. Reward: 27.76, Length: 16
DEBUG (Env): Episode done for env 47. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -12.49, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 21.78, Length: 3
544
Time taken for simulation:  7.124528646469116
average overall reward:  -0.41205594  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.12264344  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 24.85, Length: 13
DEBUG (Env): Episode done for env 26. Reward: -24.98, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -27.11, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -11.46, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -23.61, Length: 36
545
Time taken for simulation:  7.07072639465332
average overall reward:  0.14354151  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  0.23162052  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 5. Reward: -15.75, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -31.54, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 42.87, Length: 23
546
Time taken for simulation:  7.091663360595703
average overall reward:  0.09288803  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.072941855  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 22.50, Length: 6
DEBUG (Env): Episode done for env 16. Reward: 1.30, Length: 30
DEBUG (Env): Episode done for env 17. Reward: 17.10, Length: 5
DEBUG (Env): Episode done for env 21. Reward: -9.55, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -14.40, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -21.46, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -18.92, Length: 36
547
Time taken for simulation:  7.013332366943359
average overall reward:  0.17155401  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.20149018  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 80. Reward: 41.95, Length: 10
DEBUG (Env): Episode done for env 83. Reward: -17.56, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -18.64, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 14.09, Length: 11
548
Time taken for simulation:  7.1876044273376465
average overall reward:  -0.2864477  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594472 average distance reward:  -0.097701944  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 27. Reward: -15.69, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -15.75, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 21.64, Length: 4
DEBUG (Env): Episode done for env 118. Reward: -18.62, Length: 36
549
Time taken for simulation:  7.43209433555603
average overall reward:  0.16233417  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.08264141  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 42. Reward: 9.59, Length: 10
DEBUG (Env): Episode done for env 47. Reward: 21.94, Length: 6
DEBUG (Env): Episode done for env 52. Reward: -20.16, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 7.20, Length: 27
DEBUG (Env): Episode done for env 96. Reward: -9.38, Length: 36
550
Time taken for simulation:  7.254165172576904
average overall reward:  -0.42617303  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.1625036  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: 2.86, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 14.42, Length: 3
DEBUG (Env): Episode done for env 86. Reward: -9.83, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -16.73, Length: 36
551
Time taken for simulation:  7.17259669303894
average overall reward:  -0.062723264  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.1575931  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: -19.52, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -2.83, Length: 35
DEBUG (Env): Episode done for env 98. Reward: -19.66, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 14.69, Length: 1
DEBUG (Env): Episode done for env 113. Reward: -8.91, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 23.18, Length: 7
552
Time taken for simulation:  7.1942994594573975
average overall reward:  0.14321482  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.012035936  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: 28.00, Length: 14
DEBUG (Env): Episode done for env 24. Reward: -18.27, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -16.35, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 21.68, Length: 20
DEBUG (Env): Episode done for env 79. Reward: -1.15, Length: 25
553
Time taken for simulation:  7.367162466049194
average overall reward:  -0.1940473  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.11723613  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 32. Reward: -17.35, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -19.37, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -3.23, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 21.43, Length: 15
DEBUG (Env): Episode done for env 47. Reward: 31.86, Length: 4
DEBUG (Env): Episode done for env 114. Reward: -13.09, Length: 36
554
Time taken for simulation:  7.319237232208252
average overall reward:  -0.49261233  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.22663733  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 33. Reward: 23.21, Length: 1
DEBUG (Env): Episode done for env 90. Reward: -14.49, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -15.22, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -23.47, Length: 36
555
Time taken for simulation:  7.283339023590088
average overall reward:  0.45314464  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.1374131  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: 4.72, Length: 24
DEBUG (Env): Episode done for env 18. Reward: 19.15, Length: 14
DEBUG (Env): Episode done for env 37. Reward: -11.84, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 33.20, Length: 15
DEBUG (Env): Episode done for env 116. Reward: 17.15, Length: 26
556
Time taken for simulation:  7.189136505126953
average overall reward:  -0.09919022  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.081295155  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 69. Reward: 33.96, Length: 11
DEBUG (Env): Episode done for env 71. Reward: -29.95, Length: 36
557
Time taken for simulation:  7.478702068328857
average overall reward:  -0.1386927  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.010395311  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: -17.86, Length: 36
DEBUG (Env): Episode done for env 10. Reward: 11.80, Length: 32
DEBUG (Env): Episode done for env 25. Reward: -13.20, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 46.37, Length: 7
DEBUG (Env): Episode done for env 93. Reward: -29.64, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -19.87, Length: 36
558
Time taken for simulation:  7.290168285369873
average overall reward:  0.006648302  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.014901668  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 50. Reward: 26.36, Length: 22
DEBUG (Env): Episode done for env 64. Reward: -11.51, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -34.66, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 8.11, Length: 21
559
Time taken for simulation:  7.043260097503662
average overall reward:  -0.31320357  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.18881556  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 25. Reward: 13.51, Length: 2
DEBUG (Env): Episode done for env 38. Reward: -16.53, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -20.77, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -11.91, Length: 36
560
Time taken for simulation:  7.467857599258423
average overall reward:  -0.3252461  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.22730294  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: -25.67, Length: 36
DEBUG (Env): Episode done for env 6. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 17.58, Length: 5
DEBUG (Env): Episode done for env 34. Reward: -10.66, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 15.19, Length: 1
DEBUG (Env): Episode done for env 68. Reward: -21.06, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -16.38, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -18.59, Length: 36
561
Time taken for simulation:  7.131341218948364
average overall reward:  -0.31040955  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.102972366 average distance reward:  -0.112701654  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 94. Reward: -18.33, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -13.03, Length: 36
562
Time taken for simulation:  7.50512957572937
average overall reward:  -0.1597867  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030244 average distance reward:  0.046441764  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: -23.07, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 18.89, Length: 6
563
Time taken for simulation:  7.004497289657593
average overall reward:  -0.018841248  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  -0.20816286  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 15.89, Length: 12
DEBUG (Env): Episode done for env 29. Reward: 14.42, Length: 31
DEBUG (Env): Episode done for env 48. Reward: -17.14, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -26.32, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -4.83, Length: 33
DEBUG (Env): Episode done for env 115. Reward: 6.38, Length: 27
564
Time taken for simulation:  7.130936861038208
average overall reward:  -0.07224383  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.32178867 average distance reward:  -0.061835743  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: 19.09, Length: 4
DEBUG (Env): Episode done for env 62. Reward: -29.22, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -18.94, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 33.82, Length: 13
DEBUG (Env): Episode done for env 124. Reward: 11.80, Length: 27
565
Time taken for simulation:  7.100179195404053
average overall reward:  0.1512639  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.115843914 average distance reward:  0.13797435  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: -21.21, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 5.63, Length: 33
DEBUG (Env): Episode done for env 22. Reward: -21.34, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -22.86, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -13.55, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 31.63, Length: 18
566
Time taken for simulation:  6.987081050872803
average overall reward:  0.13666812  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.18773624  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 19. Reward: -26.59, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -21.70, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -15.40, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 19.60, Length: 25
DEBUG (Env): Episode done for env 112. Reward: 27.48, Length: 3
DEBUG (Env): Episode done for env 122. Reward: -22.81, Length: 36
567
Time taken for simulation:  7.569356679916382
average overall reward:  -0.08077447  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.30045044  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: -14.59, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 17.62, Length: 15
DEBUG (Env): Episode done for env 35. Reward: -17.51, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 38.43, Length: 4
DEBUG (Env): Episode done for env 67. Reward: -20.49, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -13.87, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 23.00, Length: 10
DEBUG (Env): Episode done for env 117. Reward: 11.17, Length: 32
568
Time taken for simulation:  7.840092182159424
average overall reward:  0.35682404  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  -0.008789808  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 20. Reward: 14.37, Length: 3
DEBUG (Env): Episode done for env 37. Reward: 11.97, Length: 13
DEBUG (Env): Episode done for env 58. Reward: -15.87, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 19.44, Length: 12
DEBUG (Env): Episode done for env 74. Reward: 16.37, Length: 22
DEBUG (Env): Episode done for env 82. Reward: -8.83, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -24.80, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 10.65, Length: 27
569
Time taken for simulation:  7.097429037094116
average overall reward:  0.4007121  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.013966281  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: 25.91, Length: 12
DEBUG (Env): Episode done for env 18. Reward: 30.78, Length: 9
DEBUG (Env): Episode done for env 25. Reward: 24.04, Length: 10
DEBUG (Env): Episode done for env 35. Reward: 22.88, Length: 2
DEBUG (Env): Episode done for env 66. Reward: 22.91, Length: 30
DEBUG (Env): Episode done for env 120. Reward: -13.80, Length: 36
570
Time taken for simulation:  7.13153076171875
average overall reward:  0.34454888  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.14005014  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: -24.59, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 8.64, Length: 32
DEBUG (Env): Episode done for env 42. Reward: 30.24, Length: 21
DEBUG (Env): Episode done for env 72. Reward: -19.75, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -21.56, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 23.07, Length: 7
DEBUG (Env): Episode done for env 114. Reward: 7.97, Length: 17
571
Time taken for simulation:  7.263895034790039
average overall reward:  0.07505372  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  0.08155243  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 57. Reward: -16.86, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 18.72, Length: 2
DEBUG (Env): Episode done for env 115. Reward: 16.84, Length: 8
572
Time taken for simulation:  7.472729921340942
average overall reward:  0.10687685  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.13911867  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 1. Reward: 3.66, Length: 28
DEBUG (Env): Episode done for env 3. Reward: 21.17, Length: 26
DEBUG (Env): Episode done for env 95. Reward: -21.96, Length: 36
573
Time taken for simulation:  7.339638948440552
average overall reward:  0.08387322  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.19468789  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 31. Reward: 21.40, Length: 3
DEBUG (Env): Episode done for env 40. Reward: -13.95, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -21.61, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -23.47, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 22.81, Length: 3
DEBUG (Env): Episode done for env 77. Reward: -16.36, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -20.91, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -7.07, Length: 36
574
Time taken for simulation:  7.235688924789429
average overall reward:  0.6812993  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.21881628 average distance reward:  0.047246918  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 24. Reward: 22.56, Length: 7
DEBUG (Env): Episode done for env 28. Reward: -16.03, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 17.50, Length: 1
DEBUG (Env): Episode done for env 63. Reward: 5.36, Length: 28
DEBUG (Env): Episode done for env 90. Reward: 7.14, Length: 20
DEBUG (Env): Episode done for env 92. Reward: 5.54, Length: 26
DEBUG (Env): Episode done for env 94. Reward: 18.07, Length: 13
DEBUG (Env): Episode done for env 102. Reward: 18.96, Length: 8
DEBUG (Env): Episode done for env 126. Reward: -27.16, Length: 36
575
Time taken for simulation:  7.301788806915283
average overall reward:  0.7091609  average fail penalty:  -0.046875  and average goal bonus:  0.8122322  and average same cell penalty:  -0.18020165 average distance reward:  0.17186598  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: 24.78, Length: 12
DEBUG (Env): Episode done for env 10. Reward: 31.39, Length: 18
DEBUG (Env): Episode done for env 23. Reward: -19.45, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 38.12, Length: 7
DEBUG (Env): Episode done for env 74. Reward: 32.04, Length: 7
DEBUG (Env): Episode done for env 89. Reward: -20.82, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 13.11, Length: 1
DEBUG (Env): Episode done for env 97. Reward: 20.85, Length: 21
576
Time taken for simulation:  7.4250946044921875
average overall reward:  -0.022788439  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  -0.054904357  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 41. Reward: -3.08, Length: 35
DEBUG (Env): Episode done for env 107. Reward: -15.10, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 14.31, Length: 6
577
Time taken for simulation:  7.5617852210998535
average overall reward:  0.06770924  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.022549435  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: 11.31, Length: 2
DEBUG (Env): Episode done for env 28. Reward: 18.34, Length: 3
DEBUG (Env): Episode done for env 67. Reward: 36.19, Length: 10
DEBUG (Env): Episode done for env 78. Reward: -20.10, Length: 36
578
Time taken for simulation:  7.394910097122192
average overall reward:  0.30610126  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.03955038  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: -17.86, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 17.91, Length: 1
DEBUG (Env): Episode done for env 28. Reward: 21.64, Length: 1
DEBUG (Env): Episode done for env 29. Reward: 18.21, Length: 15
DEBUG (Env): Episode done for env 44. Reward: 11.79, Length: 35
DEBUG (Env): Episode done for env 125. Reward: -18.02, Length: 36
579
Time taken for simulation:  7.247396945953369
average overall reward:  -0.020944446  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.08776565  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 43. Reward: 26.67, Length: 31
DEBUG (Env): Episode done for env 51. Reward: -18.14, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -1.40, Length: 33
DEBUG (Env): Episode done for env 60. Reward: -14.55, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 20.59, Length: 1
580
Time taken for simulation:  7.597565412521362
average overall reward:  -0.2899409  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  -0.08601802  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 26. Reward: -15.52, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -20.51, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 16.31, Length: 16
581
Time taken for simulation:  7.162760257720947
average overall reward:  -0.23808548  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.15666303  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: -15.80, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 29.04, Length: 29
DEBUG (Env): Episode done for env 84. Reward: -26.61, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 7.08, Length: 14
582
Time taken for simulation:  6.985285520553589
average overall reward:  -0.24482822  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.043210898  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 16. Reward: -14.13, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -23.46, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -16.00, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 37.17, Length: 17
583
Time taken for simulation:  7.067954778671265
average overall reward:  -0.13199866  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.17307675  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 14.44, Length: 17
DEBUG (Env): Episode done for env 45. Reward: 4.99, Length: 10
DEBUG (Env): Episode done for env 80. Reward: -15.63, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 17.95, Length: 25
DEBUG (Env): Episode done for env 121. Reward: -16.37, Length: 36
584
Time taken for simulation:  6.976716995239258
average overall reward:  0.1745876  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.066220224  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: -29.20, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 20.33, Length: 4
DEBUG (Env): Episode done for env 85. Reward: 7.81, Length: 24
DEBUG (Env): Episode done for env 102. Reward: 10.06, Length: 10
DEBUG (Env): Episode done for env 118. Reward: -13.28, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 15.70, Length: 30
585
Time taken for simulation:  7.259779930114746
average overall reward:  -0.0910182  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.13440187  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: -2.09, Length: 35
DEBUG (Env): Episode done for env 52. Reward: -18.72, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -22.96, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -16.29, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 21.04, Length: 17
DEBUG (Env): Episode done for env 127. Reward: 9.93, Length: 1
586
Time taken for simulation:  7.054416179656982
average overall reward:  0.038812056  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  -0.15050958  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 38. Reward: 12.84, Length: 27
DEBUG (Env): Episode done for env 66. Reward: 13.02, Length: 15
DEBUG (Env): Episode done for env 83. Reward: -10.94, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 18.89, Length: 2
DEBUG (Env): Episode done for env 86. Reward: 2.50, Length: 29
DEBUG (Env): Episode done for env 105. Reward: -24.69, Length: 36
587
Time taken for simulation:  7.560701370239258
average overall reward:  -0.076138034  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.013544738  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 51. Reward: 16.43, Length: 8
DEBUG (Env): Episode done for env 62. Reward: 17.54, Length: 23
DEBUG (Env): Episode done for env 75. Reward: -12.93, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -16.42, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -17.27, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -18.69, Length: 36
588
Time taken for simulation:  6.979396820068359
average overall reward:  -0.1465963  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  -0.15136531  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: 13.73, Length: 28
DEBUG (Env): Episode done for env 9. Reward: -22.47, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 17.68, Length: 19
DEBUG (Env): Episode done for env 46. Reward: -13.91, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 16.51, Length: 13
DEBUG (Env): Episode done for env 79. Reward: -16.35, Length: 36
589
Time taken for simulation:  7.340576648712158
average overall reward:  -0.33196354  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.20366612  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 32. Reward: -10.55, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 28.68, Length: 20
DEBUG (Env): Episode done for env 36. Reward: -13.43, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -21.92, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -20.47, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 21.40, Length: 3
590
Time taken for simulation:  7.049014329910278
average overall reward:  0.3457  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  -0.06678893  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: 23.69, Length: 9
DEBUG (Env): Episode done for env 6. Reward: 9.35, Length: 30
DEBUG (Env): Episode done for env 17. Reward: 36.09, Length: 8
DEBUG (Env): Episode done for env 33. Reward: -20.74, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 15.39, Length: 5
DEBUG (Env): Episode done for env 113. Reward: 19.14, Length: 3
591
Time taken for simulation:  7.467455863952637
average overall reward:  -0.16245994  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.14770089  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: -20.13, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 26.00, Length: 4
DEBUG (Env): Episode done for env 99. Reward: -13.37, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 15.25, Length: 5
DEBUG (Env): Episode done for env 116. Reward: -15.95, Length: 36
592
Time taken for simulation:  7.301644802093506
average overall reward:  -0.10474411  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.18604064  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 11. Reward: 22.87, Length: 1
DEBUG (Env): Episode done for env 121. Reward: 15.32, Length: 9
593
Time taken for simulation:  7.362216472625732
average overall reward:  0.086728975  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  -0.06788741  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 25. Reward: 8.04, Length: 24
DEBUG (Env): Episode done for env 65. Reward: 14.22, Length: 28
DEBUG (Env): Episode done for env 85. Reward: 21.39, Length: 7
DEBUG (Env): Episode done for env 93. Reward: -15.31, Length: 36
594
Time taken for simulation:  7.19136381149292
average overall reward:  -0.16708376  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  -0.036480762  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 43. Reward: 8.12, Length: 15
DEBUG (Env): Episode done for env 50. Reward: -56.69, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -9.34, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -22.00, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 13.91, Length: 25
595
Time taken for simulation:  7.087112665176392
average overall reward:  0.48468828  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.1946998  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: 20.75, Length: 2
DEBUG (Env): Episode done for env 37. Reward: 8.79, Length: 27
DEBUG (Env): Episode done for env 53. Reward: 25.61, Length: 16
DEBUG (Env): Episode done for env 73. Reward: -4.26, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 16.42, Length: 21
596
Time taken for simulation:  7.012827157974243
average overall reward:  -0.17891032  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.03543579  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 17.69, Length: 6
DEBUG (Env): Episode done for env 54. Reward: -26.47, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -22.58, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -8.31, Length: 34
DEBUG (Env): Episode done for env 76. Reward: -5.02, Length: 36
597
Time taken for simulation:  7.2109105587005615
average overall reward:  -0.13826102  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  0.08083898  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 38. Reward: 23.57, Length: 11
DEBUG (Env): Episode done for env 108. Reward: -16.81, Length: 36
598
Time taken for simulation:  7.042253494262695
average overall reward:  -0.27388668  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.21590176  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 2. Reward: -26.37, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -3.46, Length: 30
DEBUG (Env): Episode done for env 86. Reward: 24.85, Length: 9
599
Time taken for simulation:  7.108771562576294
average overall reward:  0.06717697  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  0.024495102  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 22. Reward: 38.74, Length: 17
DEBUG (Env): Episode done for env 78. Reward: 7.08, Length: 22
600
Time taken for simulation:  7.252298831939697
average overall reward:  -0.21649314  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.08188155  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 70. Reward: -13.34, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -23.75, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -20.80, Length: 36
601
Time taken for simulation:  6.986361503601074
average overall reward:  -0.012976989  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  -0.19173265  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 14. Reward: -18.87, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 13.78, Length: 5
DEBUG (Env): Episode done for env 44. Reward: 14.65, Length: 23
DEBUG (Env): Episode done for env 55. Reward: -17.31, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 16.18, Length: 13
DEBUG (Env): Episode done for env 100. Reward: 17.65, Length: 1
DEBUG (Env): Episode done for env 111. Reward: -16.98, Length: 36
602
Time taken for simulation:  7.136438369750977
average overall reward:  0.31009918  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  -0.1417062  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 44. Reward: 17.78, Length: 1
DEBUG (Env): Episode done for env 45. Reward: 12.71, Length: 19
DEBUG (Env): Episode done for env 55. Reward: 17.70, Length: 1
DEBUG (Env): Episode done for env 61. Reward: -12.12, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 11.59, Length: 15
DEBUG (Env): Episode done for env 76. Reward: 13.36, Length: 6
DEBUG (Env): Episode done for env 92. Reward: -0.25, Length: 28
DEBUG (Env): Episode done for env 103. Reward: -16.28, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -27.58, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -21.74, Length: 36
603
Time taken for simulation:  7.113921880722046
average overall reward:  -0.1610331  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.08422188  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: -5.64, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -15.90, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 38.39, Length: 8
DEBUG (Env): Episode done for env 101. Reward: -17.49, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -15.17, Length: 36
604
Time taken for simulation:  7.534105062484741
average overall reward:  0.060979024  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  -0.046762403  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: 13.13, Length: 16
DEBUG (Env): Episode done for env 25. Reward: 12.52, Length: 9
DEBUG (Env): Episode done for env 71. Reward: -30.63, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -13.67, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 4.05, Length: 21
DEBUG (Env): Episode done for env 110. Reward: -17.31, Length: 36
605
Time taken for simulation:  7.611759185791016
average overall reward:  -0.05311285  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  0.01774364  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 0. Reward: -23.83, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 19.75, Length: 18
DEBUG (Env): Episode done for env 108. Reward: 30.22, Length: 8
606
Time taken for simulation:  7.134835481643677
average overall reward:  -0.3454501  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.010766391  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 12. Reward: -23.57, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -18.94, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -23.27, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -20.87, Length: 36
607
Time taken for simulation:  7.21708345413208
average overall reward:  0.16405046  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.08435775  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 43. Reward: 26.65, Length: 13
DEBUG (Env): Episode done for env 53. Reward: 18.17, Length: 12
DEBUG (Env): Episode done for env 57. Reward: -15.21, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 30.64, Length: 11
DEBUG (Env): Episode done for env 115. Reward: -26.70, Length: 36
608
Time taken for simulation:  6.9997031688690186
average overall reward:  0.11526708  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.3089171 average distance reward:  0.00086915866  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -23.93, Length: 36
DEBUG (Env): Episode done for env 3. Reward: -11.62, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 24.38, Length: 9
DEBUG (Env): Episode done for env 26. Reward: 24.29, Length: 28
DEBUG (Env): Episode done for env 55. Reward: 17.39, Length: 6
DEBUG (Env): Episode done for env 72. Reward: 10.24, Length: 35
DEBUG (Env): Episode done for env 95. Reward: -40.70, Length: 36
609
Time taken for simulation:  7.034305095672607
average overall reward:  0.009764008  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  -0.06397393  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 31. Reward: -20.74, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 15.42, Length: 7
DEBUG (Env): Episode done for env 46. Reward: 5.19, Length: 21
DEBUG (Env): Episode done for env 59. Reward: -14.17, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -21.28, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 20.58, Length: 26
DEBUG (Env): Episode done for env 88. Reward: -7.54, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -15.34, Length: 36
610
Time taken for simulation:  7.5375542640686035
average overall reward:  -0.14935945  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.03393361  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 24. Reward: -20.84, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -17.19, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -31.38, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 20.64, Length: 4
DEBUG (Env): Episode done for env 114. Reward: 32.29, Length: 4
DEBUG (Env): Episode done for env 126. Reward: -9.60, Length: 36
611
Time taken for simulation:  7.2586829662323
average overall reward:  -0.19805832  average fail penalty:  -0.140625  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  0.11248611  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 7. Reward: -12.76, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -25.46, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -19.38, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 37.71, Length: 9
DEBUG (Env): Episode done for env 89. Reward: -27.55, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -18.65, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -13.47, Length: 36
612
Time taken for simulation:  7.058065414428711
average overall reward:  0.15731232  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.283174 average distance reward:  0.017171249  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 23. Reward: 31.13, Length: 34
DEBUG (Env): Episode done for env 39. Reward: 36.04, Length: 23
DEBUG (Env): Episode done for env 41. Reward: -19.85, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 1.78, Length: 27
DEBUG (Env): Episode done for env 99. Reward: 2.67, Length: 21
DEBUG (Env): Episode done for env 107. Reward: -20.40, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -24.16, Length: 36
613
Time taken for simulation:  7.200945138931274
average overall reward:  0.47416162  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.15843016  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 5.37, Length: 30
DEBUG (Env): Episode done for env 20. Reward: 16.06, Length: 15
DEBUG (Env): Episode done for env 22. Reward: 13.76, Length: 5
DEBUG (Env): Episode done for env 39. Reward: 17.83, Length: 1
DEBUG (Env): Episode done for env 67. Reward: -4.66, Length: 36
614
Time taken for simulation:  7.434652328491211
average overall reward:  -0.08253218  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.10621355  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 13. Reward: -18.25, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -23.57, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -28.49, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 33.56, Length: 10
615
Time taken for simulation:  7.114152193069458
average overall reward:  -0.03563089  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  0.06531961  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 5. Reward: 16.16, Length: 25
DEBUG (Env): Episode done for env 60. Reward: -15.05, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -17.75, Length: 36
616
Time taken for simulation:  7.046240329742432
average overall reward:  0.4612616  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.22275938  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 30. Reward: -30.05, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 16.85, Length: 26
DEBUG (Env): Episode done for env 73. Reward: 10.66, Length: 21
DEBUG (Env): Episode done for env 74. Reward: 15.23, Length: 28
DEBUG (Env): Episode done for env 88. Reward: 25.71, Length: 7
617
Time taken for simulation:  7.496507406234741
average overall reward:  -0.15217139  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  -0.07305458  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 49. Reward: -17.43, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 21.23, Length: 4
DEBUG (Env): Episode done for env 84. Reward: -14.08, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -22.64, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 15.24, Length: 12
618
Time taken for simulation:  7.600969076156616
average overall reward:  -0.18526003  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.01995176  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 16. Reward: -18.22, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -28.55, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 16.62, Length: 29
619
Time taken for simulation:  7.24636697769165
average overall reward:  0.24690898  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.107469715  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 40. Reward: 24.36, Length: 9
DEBUG (Env): Episode done for env 44. Reward: 37.47, Length: 17
DEBUG (Env): Episode done for env 55. Reward: 45.17, Length: 11
620
Time taken for simulation:  7.1378679275512695
average overall reward:  0.072153494  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455936 average distance reward:  0.18757942  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: -21.83, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -23.00, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 22.90, Length: 11
DEBUG (Env): Episode done for env 53. Reward: 20.09, Length: 13
DEBUG (Env): Episode done for env 102. Reward: -20.20, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -11.29, Length: 36
621
Time taken for simulation:  7.128583669662476
average overall reward:  0.34718272  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.16612142  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 15. Reward: 23.61, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 1.20, Length: 25
DEBUG (Env): Episode done for env 87. Reward: 16.83, Length: 4
DEBUG (Env): Episode done for env 89. Reward: 42.29, Length: 10
DEBUG (Env): Episode done for env 96. Reward: -24.85, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -17.54, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -21.23, Length: 36
622
Time taken for simulation:  7.20369291305542
average overall reward:  0.08286904  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.016047895  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 16.20, Length: 7
DEBUG (Env): Episode done for env 56. Reward: 24.78, Length: 6
DEBUG (Env): Episode done for env 65. Reward: 19.73, Length: 29
DEBUG (Env): Episode done for env 66. Reward: -23.72, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -21.33, Length: 36
623
Time taken for simulation:  7.229782342910767
average overall reward:  0.15083304  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.0067825913  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 69. Reward: 15.15, Length: 16
DEBUG (Env): Episode done for env 73. Reward: 35.44, Length: 7
DEBUG (Env): Episode done for env 98. Reward: -15.94, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 25.12, Length: 2
DEBUG (Env): Episode done for env 123. Reward: -9.67, Length: 36
624
Time taken for simulation:  7.164458513259888
average overall reward:  0.030707851  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.087599486  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: -11.13, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -17.80, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 12.36, Length: 20
DEBUG (Env): Episode done for env 65. Reward: 18.17, Length: 2
DEBUG (Env): Episode done for env 114. Reward: 17.87, Length: 14
625
Time taken for simulation:  7.545973777770996
average overall reward:  0.24525332  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.040754553  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: 30.95, Length: 17
DEBUG (Env): Episode done for env 32. Reward: -17.34, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -17.03, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -33.39, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 31.30, Length: 16
DEBUG (Env): Episode done for env 100. Reward: 12.24, Length: 24
DEBUG (Env): Episode done for env 104. Reward: 17.67, Length: 2
626
Time taken for simulation:  7.432905435562134
average overall reward:  0.035036862  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.16946192  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: -14.27, Length: 36
DEBUG (Env): Episode done for env 10. Reward: 20.58, Length: 15
DEBUG (Env): Episode done for env 27. Reward: 25.09, Length: 6
DEBUG (Env): Episode done for env 33. Reward: -14.33, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 27.38, Length: 1
DEBUG (Env): Episode done for env 83. Reward: 31.72, Length: 4
DEBUG (Env): Episode done for env 113. Reward: -19.97, Length: 36
627
Time taken for simulation:  7.082793951034546
average overall reward:  0.012080684  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.0570461  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 58. Reward: 12.12, Length: 16
DEBUG (Env): Episode done for env 75. Reward: -18.86, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 16.55, Length: 10
DEBUG (Env): Episode done for env 91. Reward: 8.13, Length: 33
DEBUG (Env): Episode done for env 105. Reward: -23.63, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -19.35, Length: 36
628
Time taken for simulation:  7.2853405475616455
average overall reward:  -0.066780776  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.023972992  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 11. Reward: -22.45, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 1.76, Length: 31
DEBUG (Env): Episode done for env 121. Reward: -20.05, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 26.62, Length: 13
629
Time taken for simulation:  6.949520111083984
average overall reward:  0.1884456  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.13449594  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: 7.95, Length: 25
DEBUG (Env): Episode done for env 39. Reward: 32.13, Length: 16
DEBUG (Env): Episode done for env 85. Reward: -16.13, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -21.29, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 31.63, Length: 27
630
Time taken for simulation:  7.245284080505371
average overall reward:  0.55660236  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.055616476  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 50. Reward: -17.16, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -5.38, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 28.64, Length: 6
DEBUG (Env): Episode done for env 79. Reward: -5.39, Length: 29
DEBUG (Env): Episode done for env 83. Reward: 17.64, Length: 4
DEBUG (Env): Episode done for env 97. Reward: 2.59, Length: 19
DEBUG (Env): Episode done for env 106. Reward: 16.31, Length: 26
DEBUG (Env): Episode done for env 120. Reward: -22.03, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 30.09, Length: 2
631
Time taken for simulation:  7.044602155685425
average overall reward:  -0.16700327  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  -0.19911921  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: -23.01, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 21.29, Length: 1
DEBUG (Env): Episode done for env 121. Reward: 11.16, Length: 1
632
Time taken for simulation:  7.475804328918457
average overall reward:  -0.16718869  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.090100825 average distance reward:  -0.005789861  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 68. Reward: -21.88, Length: 36
633
Time taken for simulation:  7.270597457885742
average overall reward:  -0.10731235  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.120749824  and average step penalty:  -0.04786053509430681
Number of done instances:  0
634
Time taken for simulation:  7.264639616012573
average overall reward:  0.025840543  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  0.22976339  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 2. Reward: -10.02, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -11.96, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 30.93, Length: 3
635
Time taken for simulation:  7.838350057601929
average overall reward:  0.3711545  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.09403758  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: 22.83, Length: 27
DEBUG (Env): Episode done for env 50. Reward: 27.65, Length: 5
DEBUG (Env): Episode done for env 65. Reward: 17.22, Length: 5
DEBUG (Env): Episode done for env 78. Reward: -20.09, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 24.54, Length: 23
636
Time taken for simulation:  7.3543901443481445
average overall reward:  0.1361218  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.13042913  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 58. Reward: 27.90, Length: 9
DEBUG (Env): Episode done for env 59. Reward: 22.40, Length: 27
DEBUG (Env): Episode done for env 70. Reward: 2.70, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -29.48, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 25.67, Length: 15
637
Time taken for simulation:  7.0277605056762695
average overall reward:  0.21432662  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.11945675  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: -24.34, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -22.16, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 17.78, Length: 21
DEBUG (Env): Episode done for env 93. Reward: 14.13, Length: 8
DEBUG (Env): Episode done for env 111. Reward: -23.18, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 30.98, Length: 17
638
Time taken for simulation:  7.323401927947998
average overall reward:  -0.32443166  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.19843984  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 38. Reward: 20.07, Length: 10
DEBUG (Env): Episode done for env 62. Reward: -17.90, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -17.05, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -7.30, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -14.86, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -24.91, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 12.38, Length: 29
639
Time taken for simulation:  7.48210883140564
average overall reward:  -0.14368951  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  -0.120670095  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: -11.85, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 25.23, Length: 14
DEBUG (Env): Episode done for env 48. Reward: -24.90, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -4.48, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -15.49, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 13.47, Length: 15
DEBUG (Env): Episode done for env 117. Reward: -21.43, Length: 36
640
Time taken for simulation:  7.3178229331970215
average overall reward:  0.19138001  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.06229934  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: 20.74, Length: 22
DEBUG (Env): Episode done for env 20. Reward: 13.03, Length: 27
DEBUG (Env): Episode done for env 56. Reward: 14.78, Length: 18
DEBUG (Env): Episode done for env 71. Reward: -20.21, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -18.76, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 22.29, Length: 10
641
Time taken for simulation:  7.056054353713989
average overall reward:  0.4253463  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  -0.0023197755  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -10.30, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 18.61, Length: 15
DEBUG (Env): Episode done for env 38. Reward: 13.21, Length: 3
DEBUG (Env): Episode done for env 51. Reward: -29.93, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 36.11, Length: 5
DEBUG (Env): Episode done for env 97. Reward: 16.97, Length: 11
DEBUG (Env): Episode done for env 110. Reward: 37.22, Length: 27
642
Time taken for simulation:  7.376816749572754
average overall reward:  -0.022284038  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.10197675  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: -15.44, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 25.61, Length: 1
DEBUG (Env): Episode done for env 42. Reward: -20.01, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 21.44, Length: 12
DEBUG (Env): Episode done for env 122. Reward: 17.15, Length: 13
643
Time taken for simulation:  7.495915174484253
average overall reward:  -0.040347256  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.07085936  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: 21.81, Length: 3
DEBUG (Env): Episode done for env 43. Reward: -25.41, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -17.71, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 23.62, Length: 6
DEBUG (Env): Episode done for env 102. Reward: 21.67, Length: 23
DEBUG (Env): Episode done for env 115. Reward: -22.23, Length: 36
644
Time taken for simulation:  7.29846453666687
average overall reward:  0.3770997  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.29604554 average distance reward:  0.11445815  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: 14.96, Length: 19
DEBUG (Env): Episode done for env 26. Reward: -12.37, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 16.09, Length: 35
DEBUG (Env): Episode done for env 62. Reward: 16.53, Length: 6
DEBUG (Env): Episode done for env 72. Reward: -26.92, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 25.11, Length: 5
DEBUG (Env): Episode done for env 95. Reward: -32.83, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 19.74, Length: 6
645
Time taken for simulation:  8.060823917388916
average overall reward:  0.46897095  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.115843914 average distance reward:  0.13806228  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: 29.57, Length: 21
DEBUG (Env): Episode done for env 8. Reward: 20.04, Length: 6
DEBUG (Env): Episode done for env 31. Reward: -22.91, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 18.03, Length: 2
DEBUG (Env): Episode done for env 80. Reward: -30.97, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 19.57, Length: 17
646
Time taken for simulation:  7.239175319671631
average overall reward:  -0.21569379  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.13888258  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 21. Reward: 6.84, Length: 28
DEBUG (Env): Episode done for env 24. Reward: -12.68, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -12.44, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -12.47, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 30.52, Length: 7
DEBUG (Env): Episode done for env 126. Reward: -17.67, Length: 36
647
Time taken for simulation:  7.940588474273682
average overall reward:  0.38385838  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.11500187  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 16.78, Length: 6
DEBUG (Env): Episode done for env 7. Reward: -10.86, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 15.14, Length: 27
DEBUG (Env): Episode done for env 61. Reward: -15.31, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -15.17, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 18.93, Length: 1
DEBUG (Env): Episode done for env 122. Reward: 22.33, Length: 5
648
Time taken for simulation:  7.195678949356079
average overall reward:  -0.19655049  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  0.00045561045  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 23. Reward: -22.79, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -20.49, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -16.13, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 29.21, Length: 5
DEBUG (Env): Episode done for env 107. Reward: -18.30, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -20.89, Length: 36
649
Time taken for simulation:  7.179044485092163
average overall reward:  -0.064839005  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594475 average distance reward:  0.100469284  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 19. Reward: -22.07, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -23.49, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 12.32, Length: 19
650
Time taken for simulation:  7.62858247756958
average overall reward:  -0.45532465  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.102972366 average distance reward:  -0.2341792  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 13. Reward: -10.66, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -9.90, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -7.00, Length: 36
651
Time taken for simulation:  6.952686786651611
average overall reward:  -0.17661408  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.12871546 average distance reward:  0.02339944  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 60. Reward: -15.77, Length: 36
652
Time taken for simulation:  7.07882833480835
average overall reward:  -0.14388674  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.13969365  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 14. Reward: 11.30, Length: 15
DEBUG (Env): Episode done for env 23. Reward: 30.36, Length: 4
DEBUG (Env): Episode done for env 30. Reward: -20.51, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -0.09, Length: 36
653
Time taken for simulation:  7.0899200439453125
average overall reward:  -0.56367916  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.43929118  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 49. Reward: -11.44, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -16.33, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -23.24, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 17.05, Length: 19
654
Time taken for simulation:  7.397179126739502
average overall reward:  -0.17287877  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  0.020478174  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 47. Reward: -19.36, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 31.67, Length: 10
655
Time taken for simulation:  7.625887393951416
average overall reward:  0.122830965  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.20194778  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 18.32, Length: 18
DEBUG (Env): Episode done for env 21. Reward: 30.47, Length: 9
DEBUG (Env): Episode done for env 40. Reward: -23.20, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -18.52, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -10.34, Length: 36
656
Time taken for simulation:  7.045573472976685
average overall reward:  -0.08135308  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.051416848  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 34. Reward: -22.37, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -26.52, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 16.87, Length: 29
DEBUG (Env): Episode done for env 109. Reward: 29.29, Length: 8
657
Time taken for simulation:  7.424010515213013
average overall reward:  -0.46171904  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.29045594  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: -12.64, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -19.03, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 8.64, Length: 25
DEBUG (Env): Episode done for env 87. Reward: -22.54, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -13.02, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -17.65, Length: 36
658
Time taken for simulation:  7.2214035987854
average overall reward:  0.23876524  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.0020425916  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: -12.40, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 9.49, Length: 30
DEBUG (Env): Episode done for env 32. Reward: -2.15, Length: 33
DEBUG (Env): Episode done for env 66. Reward: -24.12, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 21.77, Length: 18
DEBUG (Env): Episode done for env 107. Reward: 27.95, Length: 10
659
Time taken for simulation:  6.97405481338501
average overall reward:  0.10251929  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.007527707  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 55. Reward: 18.92, Length: 4
DEBUG (Env): Episode done for env 69. Reward: -21.02, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -17.68, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 16.01, Length: 19
DEBUG (Env): Episode done for env 83. Reward: 18.93, Length: 1
DEBUG (Env): Episode done for env 98. Reward: -20.61, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -14.58, Length: 36
660
Time taken for simulation:  7.247463226318359
average overall reward:  -0.21021229  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.1931476  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 18. Reward: 2.65, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -24.15, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 27.97, Length: 15
661
Time taken for simulation:  7.03368353843689
average overall reward:  -0.12015699  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.10539795  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 67. Reward: 25.70, Length: 8
DEBUG (Env): Episode done for env 77. Reward: -9.95, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 30.25, Length: 14
DEBUG (Env): Episode done for env 100. Reward: -16.10, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -20.23, Length: 36
662
Time taken for simulation:  7.146163702011108
average overall reward:  -0.3487739  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.18020163 average distance reward:  -0.0035241842  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: -8.35, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -18.28, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -17.09, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -19.34, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -12.88, Length: 36
663
Time taken for simulation:  7.267696142196655
average overall reward:  -0.29000896  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.09069727  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 57. Reward: 17.08, Length: 18
DEBUG (Env): Episode done for env 75. Reward: -15.58, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -15.79, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -17.62, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -18.20, Length: 36
664
Time taken for simulation:  7.3181211948394775
average overall reward:  0.16353703  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.14659822  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 34. Reward: 32.35, Length: 8
DEBUG (Env): Episode done for env 106. Reward: 12.31, Length: 34
665
Time taken for simulation:  7.024993658065796
average overall reward:  -0.25149477  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.32178864 average distance reward:  -0.082277104  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: -19.53, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 10.49, Length: 5
DEBUG (Env): Episode done for env 39. Reward: -52.41, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 24.77, Length: 6
DEBUG (Env): Episode done for env 85. Reward: -19.54, Length: 36
666
Time taken for simulation:  7.179098844528198
average overall reward:  0.010260314  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.12869354  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 18. Reward: 26.05, Length: 6
667
Time taken for simulation:  7.214253902435303
average overall reward:  0.3780123  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020163 average distance reward:  0.1114613  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 37. Reward: -18.03, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 10.59, Length: 28
DEBUG (Env): Episode done for env 109. Reward: 11.31, Length: 11
DEBUG (Env): Episode done for env 113. Reward: 31.64, Length: 5
DEBUG (Env): Episode done for env 117. Reward: 25.68, Length: 20
DEBUG (Env): Episode done for env 120. Reward: -17.93, Length: 36
668
Time taken for simulation:  7.190064191818237
average overall reward:  -0.15221837  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.088715374  and average step penalty:  -0.04786053509430681
Number of done instances:  0
669
Time taken for simulation:  7.340987205505371
average overall reward:  0.44311348  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.115843914 average distance reward:  0.20070188  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 86. Reward: 4.19, Length: 35
DEBUG (Env): Episode done for env 90. Reward: 23.42, Length: 8
DEBUG (Env): Episode done for env 98. Reward: 13.93, Length: 10
670
Time taken for simulation:  7.159704685211182
average overall reward:  -0.4503802  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  -0.17313744  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 2. Reward: -46.59, Length: 36
671
Time taken for simulation:  7.162875413894653
average overall reward:  -0.0378031  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.034311756  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 3. Reward: -16.42, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 31.66, Length: 7
DEBUG (Env): Episode done for env 50. Reward: -37.05, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 22.61, Length: 35
DEBUG (Env): Episode done for env 65. Reward: -17.01, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -16.05, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -22.06, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 17.75, Length: 8
672
Time taken for simulation:  7.481312036514282
average overall reward:  -0.049173027  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  0.11382957  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 58. Reward: -25.10, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 47.14, Length: 11
DEBUG (Env): Episode done for env 124. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -11.23, Length: 36
673
Time taken for simulation:  7.249921560287476
average overall reward:  0.21335173  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  -0.08124784  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 74. Reward: -6.25, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 24.84, Length: 4
DEBUG (Env): Episode done for env 91. Reward: 24.37, Length: 10
DEBUG (Env): Episode done for env 111. Reward: -16.91, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 22.91, Length: 2
DEBUG (Env): Episode done for env 118. Reward: -27.41, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 16.81, Length: 6
674
Time taken for simulation:  7.26924467086792
average overall reward:  0.11224528  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.20192805  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 21.59, Length: 3
DEBUG (Env): Episode done for env 76. Reward: -13.82, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 37.78, Length: 17
DEBUG (Env): Episode done for env 92. Reward: -20.25, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -19.10, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -22.00, Length: 36
675
Time taken for simulation:  7.161449670791626
average overall reward:  0.02544802  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  -0.14043611  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 8.31, Length: 5
DEBUG (Env): Episode done for env 31. Reward: 18.00, Length: 30
DEBUG (Env): Episode done for env 36. Reward: -11.30, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 22.47, Length: 10
DEBUG (Env): Episode done for env 101. Reward: -21.27, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 10.65, Length: 8
DEBUG (Env): Episode done for env 114. Reward: -12.11, Length: 36
676
Time taken for simulation:  7.510002374649048
average overall reward:  -0.3482619  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  0.0015990175  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 20. Reward: -17.93, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -16.49, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -9.32, Length: 36
677
Time taken for simulation:  6.932706832885742
average overall reward:  -0.077424236  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  0.09383879  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 38. Reward: -25.14, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -27.28, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -19.24, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -12.19, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 19.36, Length: 29
DEBUG (Env): Episode done for env 110. Reward: -12.05, Length: 36
678
Time taken for simulation:  7.12903094291687
average overall reward:  0.17159703  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  -0.12530816  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 11. Reward: 17.26, Length: 20
DEBUG (Env): Episode done for env 12. Reward: -9.08, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -18.55, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 5.93, Length: 16
DEBUG (Env): Episode done for env 42. Reward: -11.75, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 9.97, Length: 19
DEBUG (Env): Episode done for env 79. Reward: -7.52, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 19.96, Length: 1
679
Time taken for simulation:  7.533462047576904
average overall reward:  -0.12775166  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  0.23267515  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 16. Reward: -11.34, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -17.66, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -9.38, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -5.65, Length: 36
680
Time taken for simulation:  7.1865973472595215
average overall reward:  -0.16286162  average fail penalty:  -0.1640625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.16398148  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 1. Reward: -13.51, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 34.82, Length: 28
DEBUG (Env): Episode done for env 26. Reward: -24.26, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -13.89, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -5.34, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -0.44, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 23.80, Length: 9
DEBUG (Env): Episode done for env 95. Reward: -9.28, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 12.56, Length: 16
DEBUG (Env): Episode done for env 119. Reward: -8.95, Length: 36
681
Time taken for simulation:  7.136023044586182
average overall reward:  -0.40156314  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.45781833  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: -8.33, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 11.15, Length: 34
DEBUG (Env): Episode done for env 8. Reward: -10.09, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 15.77, Length: 3
DEBUG (Env): Episode done for env 58. Reward: 23.25, Length: 9
DEBUG (Env): Episode done for env 80. Reward: -17.10, Length: 36
682
Time taken for simulation:  7.206900596618652
average overall reward:  0.06577955  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  -0.23778221  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 17. Reward: 23.89, Length: 27
DEBUG (Env): Episode done for env 24. Reward: -14.39, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 1.69, Length: 27
DEBUG (Env): Episode done for env 52. Reward: 2.90, Length: 34
DEBUG (Env): Episode done for env 63. Reward: -12.91, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 14.87, Length: 5
DEBUG (Env): Episode done for env 71. Reward: 16.88, Length: 6
DEBUG (Env): Episode done for env 81. Reward: -1.36, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -17.86, Length: 36
683
Time taken for simulation:  7.136987686157227
average overall reward:  0.21373883  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.11656331  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -20.80, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 28.30, Length: 2
DEBUG (Env): Episode done for env 53. Reward: -11.43, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -10.54, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 22.07, Length: 1
DEBUG (Env): Episode done for env 92. Reward: 19.55, Length: 9
DEBUG (Env): Episode done for env 122. Reward: -20.80, Length: 36
684
Time taken for simulation:  7.0928590297698975
average overall reward:  -0.033379585  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.102972366 average distance reward:  0.0055187866  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 41. Reward: -16.41, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 12.08, Length: 23
685
Time taken for simulation:  7.716420888900757
average overall reward:  -0.16550523  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.022030726  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: 34.91, Length: 23
DEBUG (Env): Episode done for env 19. Reward: -20.69, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -19.69, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -12.76, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 18.55, Length: 24
686
Time taken for simulation:  7.100693941116333
average overall reward:  0.025122926  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.031132279  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: -13.72, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -24.21, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 15.35, Length: 28
DEBUG (Env): Episode done for env 80. Reward: 19.13, Length: 5
DEBUG (Env): Episode done for env 97. Reward: 18.49, Length: 9
687
Time taken for simulation:  7.512473821640015
average overall reward:  -0.034643948  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.09435525  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 60. Reward: -23.87, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 14.94, Length: 1
688
Time taken for simulation:  7.24939227104187
average overall reward:  0.34662855  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  -0.018985359  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: -24.70, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -23.98, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 32.46, Length: 5
DEBUG (Env): Episode done for env 67. Reward: 21.60, Length: 3
DEBUG (Env): Episode done for env 74. Reward: 21.59, Length: 15
DEBUG (Env): Episode done for env 88. Reward: -19.83, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 28.59, Length: 11
DEBUG (Env): Episode done for env 120. Reward: 18.40, Length: 15
689
Time taken for simulation:  7.524813890457153
average overall reward:  -0.21941191  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.3014102  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: 26.57, Length: 9
DEBUG (Env): Episode done for env 11. Reward: 18.62, Length: 11
DEBUG (Env): Episode done for env 12. Reward: 32.48, Length: 8
DEBUG (Env): Episode done for env 49. Reward: -25.11, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -20.15, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -17.11, Length: 36
690
Time taken for simulation:  7.115376234054565
average overall reward:  0.326854  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.11178923  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 26. Reward: 23.55, Length: 10
DEBUG (Env): Episode done for env 47. Reward: -24.45, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 22.82, Length: 33
DEBUG (Env): Episode done for env 93. Reward: 21.43, Length: 11
DEBUG (Env): Episode done for env 94. Reward: -14.98, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 18.01, Length: 1
691
Time taken for simulation:  7.043833255767822
average overall reward:  -0.1444401  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.04348956  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 21. Reward: -14.83, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -23.76, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 21.93, Length: 10
692
Time taken for simulation:  7.299190521240234
average overall reward:  0.031625576  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.23554845  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 45. Reward: -20.21, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -9.01, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 28.94, Length: 9
693
Time taken for simulation:  7.20333194732666
average overall reward:  0.7710618  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.141587 average distance reward:  0.106655166  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 13. Reward: 23.35, Length: 7
DEBUG (Env): Episode done for env 15. Reward: -15.86, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 16.76, Length: 13
DEBUG (Env): Episode done for env 54. Reward: -32.30, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -21.00, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 20.62, Length: 30
DEBUG (Env): Episode done for env 77. Reward: 21.80, Length: 9
DEBUG (Env): Episode done for env 90. Reward: 14.32, Length: 24
DEBUG (Env): Episode done for env 96. Reward: -24.06, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 43.42, Length: 20
DEBUG (Env): Episode done for env 124. Reward: 17.61, Length: 21
694
Time taken for simulation:  6.979826927185059
average overall reward:  0.27419338  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594475 average distance reward:  0.05682303  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 5. Reward: -28.95, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 19.25, Length: 6
DEBUG (Env): Episode done for env 49. Reward: 17.82, Length: 5
DEBUG (Env): Episode done for env 66. Reward: -19.41, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 17.38, Length: 16
DEBUG (Env): Episode done for env 82. Reward: 28.57, Length: 29
DEBUG (Env): Episode done for env 107. Reward: -24.40, Length: 36
695
Time taken for simulation:  7.513588905334473
average overall reward:  -0.1267145  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  0.1112118  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 55. Reward: -10.90, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -13.57, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -18.56, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -16.31, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 8.04, Length: 35
696
Time taken for simulation:  7.264453172683716
average overall reward:  0.22683956  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.11232952  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: 20.33, Length: 30
DEBUG (Env): Episode done for env 46. Reward: 19.86, Length: 3
DEBUG (Env): Episode done for env 82. Reward: 25.33, Length: 2
DEBUG (Env): Episode done for env 118. Reward: 5.53, Length: 23
697
Time taken for simulation:  7.372776985168457
average overall reward:  -0.20737188  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.07837261  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 54. Reward: 32.22, Length: 4
DEBUG (Env): Episode done for env 100. Reward: -14.07, Length: 36
698
Time taken for simulation:  7.1873602867126465
average overall reward:  -0.17099455  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3089171 average distance reward:  0.09728606  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 10. Reward: -22.64, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -19.25, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 0.05, Length: 35
699
Time taken for simulation:  7.2478578090667725
average overall reward:  -0.20115224  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  -0.19465351  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 52. Reward: 9.44, Length: 17
DEBUG (Env): Episode done for env 84. Reward: -19.38, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 18.88, Length: 7
700
Time taken for simulation:  7.070343732833862
average overall reward:  -0.044595495  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.12871546 average distance reward:  0.13198054  and average step penalty:  -0.04786053509430681
Number of done instances:  0
701
Time taken for simulation:  7.237715721130371
average overall reward:  0.2757359  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.019750938  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: -16.81, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 8.16, Length: 25
DEBUG (Env): Episode done for env 25. Reward: -13.43, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 34.30, Length: 15
DEBUG (Env): Episode done for env 39. Reward: -29.61, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 11.17, Length: 30
DEBUG (Env): Episode done for env 111. Reward: 9.81, Length: 28
702
Time taken for simulation:  7.1287806034088135
average overall reward:  -0.2025679  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.18089207  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 52. Reward: 20.95, Length: 3
DEBUG (Env): Episode done for env 120. Reward: 7.31, Length: 14
703
Time taken for simulation:  7.520742893218994
average overall reward:  0.20817831  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.16248903  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 23.74, Length: 7
DEBUG (Env): Episode done for env 25. Reward: 23.21, Length: 2
DEBUG (Env): Episode done for env 37. Reward: -26.64, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -22.40, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 15.39, Length: 17
DEBUG (Env): Episode done for env 109. Reward: -21.34, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -23.76, Length: 36
704
Time taken for simulation:  8.078975200653076
average overall reward:  -0.14104907  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.17085946  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 14. Reward: 14.56, Length: 16
DEBUG (Env): Episode done for env 25. Reward: 16.33, Length: 1
705
Time taken for simulation:  7.665434837341309
average overall reward:  -0.51508605  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  -0.21210016  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 98. Reward: -29.13, Length: 36
706
Time taken for simulation:  7.377826452255249
average overall reward:  0.38396206  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.15442199  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 0. Reward: 19.77, Length: 23
DEBUG (Env): Episode done for env 37. Reward: 23.96, Length: 3
DEBUG (Env): Episode done for env 117. Reward: 21.21, Length: 3
707
Time taken for simulation:  7.153261661529541
average overall reward:  -0.38492668  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  -0.1984865  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: -15.70, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -20.14, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -20.86, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -25.12, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 17.04, Length: 25
708
Time taken for simulation:  6.991634368896484
average overall reward:  0.14658791  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  0.2732815  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: 23.42, Length: 7
DEBUG (Env): Episode done for env 104. Reward: -21.57, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -9.53, Length: 36
709
Time taken for simulation:  7.176930665969849
average overall reward:  0.055648126  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3604033 average distance reward:  0.10467091  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: 29.75, Length: 3
DEBUG (Env): Episode done for env 27. Reward: 20.06, Length: 11
DEBUG (Env): Episode done for env 86. Reward: -22.89, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 15.43, Length: 35
DEBUG (Env): Episode done for env 91. Reward: -21.70, Length: 36
710
Time taken for simulation:  7.110489130020142
average overall reward:  -0.3920836  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.10267107  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: -23.68, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -19.97, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 22.69, Length: 3
DEBUG (Env): Episode done for env 103. Reward: -24.31, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -24.60, Length: 36
711
Time taken for simulation:  7.35630202293396
average overall reward:  -0.015822753  average fail penalty:  -0.1640625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594475 average distance reward:  -0.0040711164  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: -15.93, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -31.36, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -26.63, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 21.22, Length: 14
DEBUG (Env): Episode done for env 85. Reward: -22.70, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 28.08, Length: 2
DEBUG (Env): Episode done for env 101. Reward: -16.69, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -14.65, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 5.43, Length: 36
712
Time taken for simulation:  7.617852687835693
average overall reward:  0.30829102  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.20516072  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 22. Reward: 4.14, Length: 27
DEBUG (Env): Episode done for env 47. Reward: 36.30, Length: 22
DEBUG (Env): Episode done for env 56. Reward: -17.54, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 6.84, Length: 32
713
Time taken for simulation:  7.531634569168091
average overall reward:  0.71050626  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.29571173  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 15. Reward: 21.60, Length: 20
DEBUG (Env): Episode done for env 23. Reward: 10.14, Length: 33
DEBUG (Env): Episode done for env 33. Reward: 16.50, Length: 35
DEBUG (Env): Episode done for env 38. Reward: -8.95, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -22.99, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 26.23, Length: 30
DEBUG (Env): Episode done for env 88. Reward: 15.44, Length: 25
714
Time taken for simulation:  7.169467210769653
average overall reward:  0.6004902  average fail penalty:  -0.09375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.12871546 average distance reward:  0.19395602  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 15. Reward: 25.34, Length: 1
DEBUG (Env): Episode done for env 35. Reward: -25.77, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -16.45, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 39.88, Length: 12
DEBUG (Env): Episode done for env 77. Reward: 23.06, Length: 21
DEBUG (Env): Episode done for env 79. Reward: -7.71, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 13.74, Length: 3
DEBUG (Env): Episode done for env 93. Reward: 40.24, Length: 24
DEBUG (Env): Episode done for env 110. Reward: -11.67, Length: 36
715
Time taken for simulation:  7.321749687194824
average overall reward:  -0.586727  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.24973765  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 16. Reward: -18.58, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -18.23, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -25.97, Length: 36
716
Time taken for simulation:  7.199697732925415
average overall reward:  -0.4977705  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.22353509  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 17.34, Length: 2
DEBUG (Env): Episode done for env 62. Reward: -23.36, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -23.68, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -9.69, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -14.73, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -19.29, Length: 36
717
Time taken for simulation:  7.3227858543396
average overall reward:  0.2080714  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.051149383  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: -12.32, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -20.77, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 27.13, Length: 8
DEBUG (Env): Episode done for env 70. Reward: 13.15, Length: 35
DEBUG (Env): Episode done for env 106. Reward: 21.30, Length: 1
718
Time taken for simulation:  7.011156320571899
average overall reward:  0.010984305  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.16271919  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 17. Reward: -16.32, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -11.68, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -21.21, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 37.48, Length: 6
DEBUG (Env): Episode done for env 71. Reward: -18.83, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -13.07, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -3.23, Length: 35
719
Time taken for simulation:  7.056001663208008
average overall reward:  0.26882747  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.028019592  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: -7.07, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 20.35, Length: 8
DEBUG (Env): Episode done for env 53. Reward: -19.57, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 15.27, Length: 21
DEBUG (Env): Episode done for env 110. Reward: 29.80, Length: 5
DEBUG (Env): Episode done for env 114. Reward: 18.09, Length: 8
720
Time taken for simulation:  7.3249194622039795
average overall reward:  -0.20810002  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  -0.02761466  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 41. Reward: -14.30, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 19.17, Length: 11
721
Time taken for simulation:  7.372989654541016
average overall reward:  0.36739987  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.29604554 average distance reward:  0.37550238  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: 0.40, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 8.47, Length: 2
DEBUG (Env): Episode done for env 19. Reward: -11.89, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 33.38, Length: 8
DEBUG (Env): Episode done for env 64. Reward: -4.92, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 19.84, Length: 27
722
Time taken for simulation:  6.977872848510742
average overall reward:  0.037220772  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  -0.13257274  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 22. Reward: 21.26, Length: 10
DEBUG (Env): Episode done for env 28. Reward: -16.28, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -10.71, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 9.75, Length: 35
DEBUG (Env): Episode done for env 96. Reward: -3.56, Length: 29
723
Time taken for simulation:  7.690868139266968
average overall reward:  -0.18159324  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.123608395  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 52. Reward: 36.71, Length: 9
DEBUG (Env): Episode done for env 59. Reward: 29.53, Length: 16
DEBUG (Env): Episode done for env 80. Reward: -19.34, Length: 36
724
Time taken for simulation:  7.341346502304077
average overall reward:  -0.15351343  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.06383069  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: 20.47, Length: 9
DEBUG (Env): Episode done for env 22. Reward: 19.04, Length: 2
DEBUG (Env): Episode done for env 63. Reward: -17.90, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -14.57, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -18.17, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -16.40, Length: 36
725
Time taken for simulation:  7.0654377937316895
average overall reward:  -0.3287543  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.11657102  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -4.22, Length: 36
DEBUG (Env): Episode done for env 6. Reward: 11.30, Length: 4
DEBUG (Env): Episode done for env 11. Reward: -19.17, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -17.49, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -26.09, Length: 36
726
Time taken for simulation:  7.097931146621704
average overall reward:  -0.119119674  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  -0.11953772  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 26. Reward: -26.06, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 6.56, Length: 35
DEBUG (Env): Episode done for env 86. Reward: 13.49, Length: 15
DEBUG (Env): Episode done for env 89. Reward: -26.76, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -14.79, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -25.35, Length: 36
727
Time taken for simulation:  7.200551271438599
average overall reward:  0.3175392  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168783 average distance reward:  -0.03289763  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 21. Reward: -11.57, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -22.04, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 27.23, Length: 8
DEBUG (Env): Episode done for env 88. Reward: 20.55, Length: 14
DEBUG (Env): Episode done for env 92. Reward: 32.88, Length: 9
DEBUG (Env): Episode done for env 93. Reward: 29.62, Length: 13
DEBUG (Env): Episode done for env 98. Reward: 21.04, Length: 22
728
Time taken for simulation:  7.193363666534424
average overall reward:  -0.1823257  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  -0.055632077  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: 25.18, Length: 10
DEBUG (Env): Episode done for env 45. Reward: -21.93, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -17.07, Length: 36
729
Time taken for simulation:  7.060340166091919
average overall reward:  0.15487769  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.091705695  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 13. Reward: -16.35, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 18.48, Length: 1
DEBUG (Env): Episode done for env 57. Reward: 9.69, Length: 10
DEBUG (Env): Episode done for env 62. Reward: 24.60, Length: 13
DEBUG (Env): Episode done for env 68. Reward: -22.53, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -22.89, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -20.56, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -12.92, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -16.03, Length: 36
730
Time taken for simulation:  7.458108425140381
average overall reward:  -0.1829021  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.16653924  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 3. Reward: 36.48, Length: 20
DEBUG (Env): Episode done for env 5. Reward: -18.64, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -17.29, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -25.62, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -14.56, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 1.91, Length: 31
DEBUG (Env): Episode done for env 90. Reward: 21.11, Length: 1
DEBUG (Env): Episode done for env 107. Reward: -18.89, Length: 36
731
Time taken for simulation:  7.355203151702881
average overall reward:  0.21556385  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.11608284  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 21. Reward: 27.54, Length: 4
DEBUG (Env): Episode done for env 53. Reward: 34.50, Length: 4
DEBUG (Env): Episode done for env 55. Reward: -31.39, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -24.79, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 13.69, Length: 21
DEBUG (Env): Episode done for env 83. Reward: -14.96, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -22.92, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -16.12, Length: 36
732
Time taken for simulation:  7.625863552093506
average overall reward:  0.47856277  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.10007738  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: 33.81, Length: 7
DEBUG (Env): Episode done for env 25. Reward: 30.97, Length: 28
DEBUG (Env): Episode done for env 46. Reward: -17.62, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 12.18, Length: 14
DEBUG (Env): Episode done for env 82. Reward: -20.48, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 4.70, Length: 35
DEBUG (Env): Episode done for env 111. Reward: 5.74, Length: 31
DEBUG (Env): Episode done for env 118. Reward: -23.25, Length: 36
733
Time taken for simulation:  7.016823053359985
average overall reward:  -0.26389262  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  -0.035830423  and average step penalty:  -0.04786053509430681
Number of done instances:  0
734
Time taken for simulation:  7.105375289916992
average overall reward:  0.09458987  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.02141188  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: -16.18, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 25.07, Length: 3
DEBUG (Env): Episode done for env 83. Reward: 10.78, Length: 3
DEBUG (Env): Episode done for env 113. Reward: 0.78, Length: 23
735
Time taken for simulation:  7.021715402603149
average overall reward:  -0.04659833  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.08240086  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 37. Reward: 19.61, Length: 29
DEBUG (Env): Episode done for env 122. Reward: -17.73, Length: 36
736
Time taken for simulation:  7.186158180236816
average overall reward:  -0.025952473  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  -0.25549254  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 64. Reward: 36.44, Length: 15
DEBUG (Env): Episode done for env 72. Reward: 17.91, Length: 20
DEBUG (Env): Episode done for env 81. Reward: 14.31, Length: 18
737
Time taken for simulation:  7.26621675491333
average overall reward:  -0.05560454  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  0.02120671  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 20. Reward: -17.77, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -5.91, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -13.60, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -17.40, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 18.94, Length: 11
DEBUG (Env): Episode done for env 113. Reward: 20.16, Length: 3
738
Time taken for simulation:  7.157393217086792
average overall reward:  0.59551287  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020163 average distance reward:  0.30552444  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 28. Reward: 46.66, Length: 16
DEBUG (Env): Episode done for env 117. Reward: 8.93, Length: 32
DEBUG (Env): Episode done for env 119. Reward: 31.22, Length: 22
DEBUG (Env): Episode done for env 120. Reward: -21.18, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 1.93, Length: 30
739
Time taken for simulation:  7.156998157501221
average overall reward:  -0.08549234  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.034424245  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 18. Reward: -14.45, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -13.52, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 33.64, Length: 5
DEBUG (Env): Episode done for env 60. Reward: 14.97, Length: 17
DEBUG (Env): Episode done for env 97. Reward: -16.83, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -19.39, Length: 36
740
Time taken for simulation:  7.764057874679565
average overall reward:  0.031101078  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.011856727  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 14. Reward: -14.39, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 27.41, Length: 4
DEBUG (Env): Episode done for env 74. Reward: 6.00, Length: 16
741
Time taken for simulation:  7.387201547622681
average overall reward:  0.098689884  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  0.043136463  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 3. Reward: 14.09, Length: 11
DEBUG (Env): Episode done for env 6. Reward: 16.32, Length: 16
742
Time taken for simulation:  7.038607358932495
average overall reward:  -0.3114112  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.12862024  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 109. Reward: 18.09, Length: 3
743
Time taken for simulation:  7.107243299484253
average overall reward:  -0.035342366  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.06585456  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 34. Reward: -22.28, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 11.07, Length: 31
DEBUG (Env): Episode done for env 60. Reward: 14.52, Length: 4
DEBUG (Env): Episode done for env 65. Reward: -21.07, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -28.81, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 24.21, Length: 5
744
Time taken for simulation:  7.082056999206543
average overall reward:  0.43206275  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  -0.092360705  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: 21.44, Length: 12
DEBUG (Env): Episode done for env 9. Reward: -24.03, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 18.72, Length: 17
DEBUG (Env): Episode done for env 50. Reward: 13.53, Length: 7
DEBUG (Env): Episode done for env 67. Reward: 21.30, Length: 20
DEBUG (Env): Episode done for env 94. Reward: 27.75, Length: 18
DEBUG (Env): Episode done for env 104. Reward: -18.34, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 15.57, Length: 6
745
Time taken for simulation:  7.2539544105529785
average overall reward:  -0.22477098  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.141587 average distance reward:  0.011551563  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 0. Reward: -13.54, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -18.03, Length: 36
746
Time taken for simulation:  7.433553218841553
average overall reward:  -0.29406673  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  -0.2664361  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 58. Reward: 20.17, Length: 20
DEBUG (Env): Episode done for env 97. Reward: 7.79, Length: 7
DEBUG (Env): Episode done for env 99. Reward: -21.86, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -29.34, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -15.10, Length: 36
747
Time taken for simulation:  7.104132413864136
average overall reward:  -0.06970343  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.1424798  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: -19.59, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -17.18, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -18.20, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 15.28, Length: 24
DEBUG (Env): Episode done for env 101. Reward: -22.54, Length: 36
748
Time taken for simulation:  7.074641227722168
average overall reward:  0.30849338  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.007238224  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: 17.68, Length: 5
DEBUG (Env): Episode done for env 51. Reward: 11.55, Length: 35
DEBUG (Env): Episode done for env 67. Reward: 28.62, Length: 4
DEBUG (Env): Episode done for env 79. Reward: 15.77, Length: 34
DEBUG (Env): Episode done for env 95. Reward: -13.93, Length: 36
749
Time taken for simulation:  7.171201705932617
average overall reward:  -0.26877603  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.14438802  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: -13.88, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -12.44, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -18.32, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 21.71, Length: 22
750
Time taken for simulation:  7.329747438430786
average overall reward:  -0.15307024  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.037644375  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 35. Reward: 0.47, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -7.21, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -20.85, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -31.29, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 22.38, Length: 2
751
Time taken for simulation:  7.116912364959717
average overall reward:  -0.35205388  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.06424515  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 43. Reward: -12.77, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -11.89, Length: 36
752
Time taken for simulation:  7.046599626541138
average overall reward:  -0.5365247  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  -0.21010137  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 15. Reward: -18.40, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -11.94, Length: 36
753
Time taken for simulation:  7.0095131397247314
average overall reward:  0.039700687  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  -0.05978035  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: -14.11, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -16.37, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 5.45, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 28.66, Length: 10
DEBUG (Env): Episode done for env 53. Reward: 35.63, Length: 14
DEBUG (Env): Episode done for env 70. Reward: -19.27, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -19.75, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 28.06, Length: 9
754
Time taken for simulation:  7.110908031463623
average overall reward:  -0.3789746  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.16448574  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 24. Reward: -28.35, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -17.26, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -21.02, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 21.51, Length: 8
755
Time taken for simulation:  7.051693439483643
average overall reward:  -0.8138772  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.29604554 average distance reward:  -0.3996586  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 36. Reward: -16.24, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -18.07, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -14.58, Length: 36
756
Time taken for simulation:  7.181763172149658
average overall reward:  -0.3891481  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  -0.11421095  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 41. Reward: -25.37, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -19.07, Length: 36
757
Time taken for simulation:  7.107054710388184
average overall reward:  -0.5944537  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.3089171 average distance reward:  -0.27929807  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -18.22, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -18.87, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 13.92, Length: 20
DEBUG (Env): Episode done for env 61. Reward: -15.44, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -22.01, Length: 36
758
Time taken for simulation:  7.427361726760864
average overall reward:  0.21061331  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.021291655  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 28. Reward: 15.03, Length: 20
DEBUG (Env): Episode done for env 29. Reward: -17.23, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 21.61, Length: 5
DEBUG (Env): Episode done for env 55. Reward: 16.32, Length: 27
DEBUG (Env): Episode done for env 96. Reward: -11.32, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 21.31, Length: 12
759
Time taken for simulation:  7.21026611328125
average overall reward:  -0.28017142  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.063377015  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 8. Reward: 17.55, Length: 6
DEBUG (Env): Episode done for env 52. Reward: -16.05, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -16.86, Length: 36
760
Time taken for simulation:  7.036572217941284
average overall reward:  -0.03194037  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  0.019127794  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: -19.58, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -24.92, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 17.37, Length: 25
DEBUG (Env): Episode done for env 63. Reward: -22.08, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -22.80, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 34.49, Length: 17
761
Time taken for simulation:  7.430763244628906
average overall reward:  -0.14175907  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.10125689  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: -20.89, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -12.93, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 21.98, Length: 31
DEBUG (Env): Episode done for env 108. Reward: 15.10, Length: 24
DEBUG (Env): Episode done for env 121. Reward: -22.81, Length: 36
762
Time taken for simulation:  7.266491413116455
average overall reward:  -0.013995767  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.05224955  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: 11.30, Length: 31
DEBUG (Env): Episode done for env 26. Reward: -19.60, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 18.49, Length: 4
DEBUG (Env): Episode done for env 86. Reward: -18.99, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -17.87, Length: 36
763
Time taken for simulation:  7.464550733566284
average overall reward:  -0.06533985  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.08298042  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 43. Reward: 6.93, Length: 12
DEBUG (Env): Episode done for env 52. Reward: 17.92, Length: 4
DEBUG (Env): Episode done for env 91. Reward: 20.10, Length: 7
DEBUG (Env): Episode done for env 92. Reward: -13.10, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -17.26, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -16.44, Length: 36
764
Time taken for simulation:  7.218781232833862
average overall reward:  -0.12313628  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.1518009  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 45. Reward: -25.28, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -22.99, Length: 36
765
Time taken for simulation:  7.088571310043335
average overall reward:  0.14062305  average fail penalty:  -0.1875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.053311773  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 13. Reward: -21.05, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -19.90, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 1.13, Length: 35
DEBUG (Env): Episode done for env 57. Reward: -15.47, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -0.08, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -30.03, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -20.24, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 14.89, Length: 2
DEBUG (Env): Episode done for env 116. Reward: -18.54, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 16.98, Length: 30
DEBUG (Env): Episode done for env 124. Reward: -11.57, Length: 36
766
Time taken for simulation:  7.18063759803772
average overall reward:  -0.61597383  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.50285363  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 5. Reward: -21.56, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -1.86, Length: 16
DEBUG (Env): Episode done for env 49. Reward: -8.39, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -24.47, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 19.51, Length: 13
DEBUG (Env): Episode done for env 84. Reward: -6.43, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -12.89, Length: 36
767
Time taken for simulation:  7.079532861709595
average overall reward:  0.13381302  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  -0.014848642  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 14. Reward: 22.56, Length: 27
DEBUG (Env): Episode done for env 21. Reward: 22.63, Length: 5
DEBUG (Env): Episode done for env 43. Reward: 20.56, Length: 4
DEBUG (Env): Episode done for env 69. Reward: -20.03, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -14.97, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -15.62, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -20.36, Length: 36
768
Time taken for simulation:  7.450850248336792
average overall reward:  0.11773789  average fail penalty:  -0.1640625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.07800339  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 25. Reward: -18.44, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -18.67, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -22.06, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -20.89, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 8.42, Length: 19
DEBUG (Env): Episode done for env 94. Reward: 20.42, Length: 24
DEBUG (Env): Episode done for env 100. Reward: -12.75, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 18.83, Length: 4
DEBUG (Env): Episode done for env 111. Reward: -20.51, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -21.40, Length: 36
769
Time taken for simulation:  7.111358880996704
average overall reward:  0.696008  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  0.22146688  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 64. Reward: 8.93, Length: 29
DEBUG (Env): Episode done for env 82. Reward: 14.00, Length: 1
DEBUG (Env): Episode done for env 89. Reward: 19.74, Length: 7
DEBUG (Env): Episode done for env 95. Reward: 26.99, Length: 19
DEBUG (Env): Episode done for env 107. Reward: 31.66, Length: 3
770
Time taken for simulation:  7.096592426300049
average overall reward:  0.09346666  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.09765978  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: -25.39, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 34.72, Length: 12
DEBUG (Env): Episode done for env 83. Reward: -11.73, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 12.13, Length: 5
771
Time taken for simulation:  7.524118661880493
average overall reward:  0.027421758  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.0023885332  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 3. Reward: 3.80, Length: 30
DEBUG (Env): Episode done for env 107. Reward: 19.29, Length: 2
772
Time taken for simulation:  7.394099950790405
average overall reward:  0.21030721  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.18875729  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 72. Reward: -19.95, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -20.08, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 19.70, Length: 7
DEBUG (Env): Episode done for env 124. Reward: 23.28, Length: 7
773
Time taken for simulation:  7.030956268310547
average overall reward:  0.22917837  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.1673301 average distance reward:  -0.16217871  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 20. Reward: -24.95, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -20.96, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 23.82, Length: 5
DEBUG (Env): Episode done for env 81. Reward: 16.12, Length: 1
DEBUG (Env): Episode done for env 109. Reward: -3.24, Length: 31
DEBUG (Env): Episode done for env 110. Reward: 23.09, Length: 18
DEBUG (Env): Episode done for env 113. Reward: -7.53, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 15.60, Length: 13
774
Time taken for simulation:  7.082428693771362
average overall reward:  0.15794979  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.23937213  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 4. Reward: 25.28, Length: 21
DEBUG (Env): Episode done for env 117. Reward: -19.80, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -21.82, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 43.74, Length: 7
775
Time taken for simulation:  7.558448076248169
average overall reward:  -0.045026675  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.120281555  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 18. Reward: -17.25, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -19.88, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 13.95, Length: 7
776
Time taken for simulation:  7.140287399291992
average overall reward:  0.18468992  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.16733009 average distance reward:  -0.25354213  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 20. Reward: 25.20, Length: 3
DEBUG (Env): Episode done for env 66. Reward: 16.76, Length: 10
DEBUG (Env): Episode done for env 74. Reward: -23.29, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 25.43, Length: 3
DEBUG (Env): Episode done for env 112. Reward: -0.53, Length: 30
DEBUG (Env): Episode done for env 118. Reward: 26.13, Length: 8
777
Time taken for simulation:  7.025610446929932
average overall reward:  0.85337806  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.38940293  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: -21.33, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 17.87, Length: 20
DEBUG (Env): Episode done for env 67. Reward: 7.40, Length: 29
DEBUG (Env): Episode done for env 90. Reward: 11.73, Length: 16
DEBUG (Env): Episode done for env 92. Reward: 15.62, Length: 14
DEBUG (Env): Episode done for env 115. Reward: 10.27, Length: 26
778
Time taken for simulation:  7.1855363845825195
average overall reward:  -0.2173993  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.2729527  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 16. Reward: 10.99, Length: 18
DEBUG (Env): Episode done for env 65. Reward: 5.83, Length: 35
779
Time taken for simulation:  7.126827239990234
average overall reward:  0.4631772  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.24811248  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 24. Reward: 17.55, Length: 25
DEBUG (Env): Episode done for env 42. Reward: 19.38, Length: 13
DEBUG (Env): Episode done for env 51. Reward: 44.64, Length: 31
DEBUG (Env): Episode done for env 60. Reward: -22.66, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 13.61, Length: 10
DEBUG (Env): Episode done for env 127. Reward: -12.96, Length: 36
780
Time taken for simulation:  7.167265176773071
average overall reward:  0.085509226  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.17288643  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -15.19, Length: 36
DEBUG (Env): Episode done for env 9. Reward: -18.59, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -20.39, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 28.75, Length: 7
DEBUG (Env): Episode done for env 103. Reward: 0.41, Length: 34
DEBUG (Env): Episode done for env 104. Reward: -26.03, Length: 36
781
Time taken for simulation:  8.035677909851074
average overall reward:  -0.0048344135  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.045912497  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -8.24, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 20.50, Length: 3
DEBUG (Env): Episode done for env 20. Reward: 38.62, Length: 5
DEBUG (Env): Episode done for env 49. Reward: 26.42, Length: 15
DEBUG (Env): Episode done for env 87. Reward: -6.09, Length: 36
782
Time taken for simulation:  7.392805337905884
average overall reward:  0.03161417  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.08438757  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 26. Reward: 9.08, Length: 20
DEBUG (Env): Episode done for env 34. Reward: 20.40, Length: 34
DEBUG (Env): Episode done for env 97. Reward: -18.84, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 23.58, Length: 9
783
Time taken for simulation:  7.465286731719971
average overall reward:  0.1040764  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.115843914 average distance reward:  -0.02114772  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: -19.10, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 11.67, Length: 3
DEBUG (Env): Episode done for env 31. Reward: -22.62, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -20.51, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -16.48, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 40.74, Length: 5
DEBUG (Env): Episode done for env 66. Reward: 22.49, Length: 7
DEBUG (Env): Episode done for env 101. Reward: -18.11, Length: 36
784
Time taken for simulation:  7.181023836135864
average overall reward:  0.016400311  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.04864216  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 56. Reward: 7.76, Length: 30
DEBUG (Env): Episode done for env 79. Reward: -21.06, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 28.19, Length: 18
785
Time taken for simulation:  6.998295783996582
average overall reward:  0.41019514  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.27671066  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: 11.83, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -21.36, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 13.07, Length: 3
DEBUG (Env): Episode done for env 38. Reward: -22.74, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 21.87, Length: 20
786
Time taken for simulation:  7.276130199432373
average overall reward:  0.8256092  average fail penalty:  -0.0703125  and average goal bonus:  1.0829761  and average same cell penalty:  -0.2574309 average distance reward:  0.11823691  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 6. Reward: 28.04, Length: 9
DEBUG (Env): Episode done for env 12. Reward: 24.74, Length: 25
DEBUG (Env): Episode done for env 35. Reward: -23.78, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 10.51, Length: 30
DEBUG (Env): Episode done for env 64. Reward: 26.74, Length: 7
DEBUG (Env): Episode done for env 77. Reward: -15.13, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -20.29, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 17.14, Length: 28
DEBUG (Env): Episode done for env 109. Reward: 24.75, Length: 4
DEBUG (Env): Episode done for env 110. Reward: 23.68, Length: 10
DEBUG (Env): Episode done for env 124. Reward: 22.31, Length: 14
787
Time taken for simulation:  7.143608093261719
average overall reward:  0.61046803  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.22602779  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: 28.15, Length: 8
DEBUG (Env): Episode done for env 31. Reward: 16.12, Length: 4
DEBUG (Env): Episode done for env 75. Reward: 22.12, Length: 22
DEBUG (Env): Episode done for env 77. Reward: 18.06, Length: 1
DEBUG (Env): Episode done for env 105. Reward: 20.85, Length: 19
788
Time taken for simulation:  7.476861476898193
average overall reward:  -0.061973758  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.21889581  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: -8.57, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -12.40, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 10.34, Length: 20
DEBUG (Env): Episode done for env 104. Reward: 18.36, Length: 8
DEBUG (Env): Episode done for env 107. Reward: 27.95, Length: 17
789
Time taken for simulation:  7.433715581893921
average overall reward:  0.45216465  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.115843914 average distance reward:  0.16813096  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 16. Reward: 14.09, Length: 8
DEBUG (Env): Episode done for env 27. Reward: -22.27, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -21.04, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 17.75, Length: 6
DEBUG (Env): Episode done for env 66. Reward: 20.62, Length: 6
DEBUG (Env): Episode done for env 86. Reward: 22.18, Length: 27
DEBUG (Env): Episode done for env 106. Reward: -14.55, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -17.89, Length: 36
790
Time taken for simulation:  7.047571897506714
average overall reward:  0.46872565  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.20217472  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 40. Reward: -25.07, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -24.98, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 30.64, Length: 18
DEBUG (Env): Episode done for env 97. Reward: 30.89, Length: 8
DEBUG (Env): Episode done for env 110. Reward: 40.34, Length: 4
DEBUG (Env): Episode done for env 118. Reward: 39.91, Length: 14
791
Time taken for simulation:  7.102843284606934
average overall reward:  -0.5213315  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.15629348  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 36. Reward: -22.21, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -18.51, Length: 36
792
Time taken for simulation:  7.277127027511597
average overall reward:  0.48798484  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.052058447  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 32. Reward: 12.74, Length: 19
DEBUG (Env): Episode done for env 64. Reward: 19.32, Length: 6
DEBUG (Env): Episode done for env 79. Reward: 26.37, Length: 8
DEBUG (Env): Episode done for env 93. Reward: 30.35, Length: 2
DEBUG (Env): Episode done for env 109. Reward: 15.75, Length: 6
793
Time taken for simulation:  7.180678129196167
average overall reward:  -0.44615772  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.3693465  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: -13.75, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -24.84, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -21.51, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 4.32, Length: 25
DEBUG (Env): Episode done for env 73. Reward: -12.86, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 10.82, Length: 23
794
Time taken for simulation:  7.98529577255249
average overall reward:  0.6286179  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.398376  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 28. Reward: -37.68, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -14.39, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 40.42, Length: 17
DEBUG (Env): Episode done for env 97. Reward: 24.91, Length: 4
DEBUG (Env): Episode done for env 99. Reward: -18.61, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 16.50, Length: 19
DEBUG (Env): Episode done for env 106. Reward: 25.96, Length: 5
795
Time taken for simulation:  7.228679180145264
average overall reward:  -0.03864798  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.07517412  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 8. Reward: -20.01, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 21.18, Length: 16
DEBUG (Env): Episode done for env 80. Reward: -20.31, Length: 36
796
Time taken for simulation:  7.192957639694214
average overall reward:  0.2737301  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020163 average distance reward:  0.05405417  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: 27.39, Length: 13
DEBUG (Env): Episode done for env 22. Reward: -19.10, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 10.72, Length: 14
DEBUG (Env): Episode done for env 35. Reward: 35.20, Length: 10
DEBUG (Env): Episode done for env 37. Reward: -21.58, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -20.60, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 29.32, Length: 13
DEBUG (Env): Episode done for env 102. Reward: -22.84, Length: 36
797
Time taken for simulation:  7.537760972976685
average overall reward:  -0.33235323  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.02110701  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 11. Reward: -17.79, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -15.09, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -10.80, Length: 36
798
Time taken for simulation:  7.6358654499053955
average overall reward:  0.33919102  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  -0.008940183  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 46. Reward: 17.38, Length: 25
DEBUG (Env): Episode done for env 55. Reward: -24.60, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 25.37, Length: 9
DEBUG (Env): Episode done for env 106. Reward: 22.64, Length: 4
DEBUG (Env): Episode done for env 115. Reward: 17.81, Length: 21
DEBUG (Env): Episode done for env 125. Reward: 15.21, Length: 24
799
Time taken for simulation:  7.402875185012817
average overall reward:  0.012600362  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.29604554 average distance reward:  -0.114669144  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 23. Reward: 10.34, Length: 14
DEBUG (Env): Episode done for env 36. Reward: 17.53, Length: 8
DEBUG (Env): Episode done for env 52. Reward: -17.37, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 13.59, Length: 10
DEBUG (Env): Episode done for env 73. Reward: 22.81, Length: 6
DEBUG (Env): Episode done for env 91. Reward: -17.08, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -19.34, Length: 36
800
Time taken for simulation:  7.314819812774658
average overall reward:  0.14738223  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.14100939  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 15. Reward: 28.92, Length: 12
DEBUG (Env): Episode done for env 45. Reward: -23.53, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 26.27, Length: 32
801
Time taken for simulation:  7.177172660827637
average overall reward:  0.08936457  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3089171 average distance reward:  0.18065108  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 13. Reward: -31.30, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -20.88, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -13.61, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -23.62, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -18.83, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 11.90, Length: 7
DEBUG (Env): Episode done for env 68. Reward: -16.86, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 18.37, Length: 7
DEBUG (Env): Episode done for env 113. Reward: 8.64, Length: 28
802
Time taken for simulation:  7.291550874710083
average overall reward:  -0.12917283  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.112108134  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: -4.01, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 23.68, Length: 9
DEBUG (Env): Episode done for env 70. Reward: -23.69, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 17.92, Length: 12
803
Time taken for simulation:  7.446458578109741
average overall reward:  -0.5219962  average fail penalty:  -0.140625  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.262938  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: -11.58, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -22.66, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 7.31, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -16.29, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -24.02, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -21.36, Length: 36
804
Time taken for simulation:  7.384589433670044
average overall reward:  -0.21639001  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.11584391 average distance reward:  -0.0058105737  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 25. Reward: -14.56, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -18.60, Length: 36
805
Time taken for simulation:  7.2614240646362305
average overall reward:  -0.17317542  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.010172769  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 82. Reward: -19.08, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -17.83, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -18.29, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 9.27, Length: 17
806
Time taken for simulation:  7.09885311126709
average overall reward:  0.07509923  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.15514264  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: -18.27, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 12.80, Length: 7
DEBUG (Env): Episode done for env 29. Reward: -26.17, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 23.50, Length: 8
DEBUG (Env): Episode done for env 76. Reward: 23.94, Length: 3
DEBUG (Env): Episode done for env 80. Reward: 20.20, Length: 11
DEBUG (Env): Episode done for env 122. Reward: -21.31, Length: 36
807
Time taken for simulation:  6.983138561248779
average overall reward:  0.60811013  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.15700658  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: -7.28, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 20.45, Length: 1
DEBUG (Env): Episode done for env 32. Reward: 21.85, Length: 15
DEBUG (Env): Episode done for env 86. Reward: 23.74, Length: 18
DEBUG (Env): Episode done for env 115. Reward: 28.31, Length: 9
DEBUG (Env): Episode done for env 126. Reward: 1.83, Length: 34
808
Time taken for simulation:  7.383282899856567
average overall reward:  0.094996415  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  -0.07249148  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 14. Reward: 13.74, Length: 5
DEBUG (Env): Episode done for env 72. Reward: -25.78, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 18.90, Length: 27
DEBUG (Env): Episode done for env 113. Reward: 31.56, Length: 7
809
Time taken for simulation:  7.015346050262451
average overall reward:  0.31686375  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.054924004  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 51. Reward: 12.96, Length: 14
DEBUG (Env): Episode done for env 54. Reward: 20.86, Length: 26
DEBUG (Env): Episode done for env 65. Reward: 26.77, Length: 3
DEBUG (Env): Episode done for env 69. Reward: 22.14, Length: 6
810
Time taken for simulation:  7.070084571838379
average overall reward:  -0.011295766  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.10616558  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: -23.47, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 11.12, Length: 14
DEBUG (Env): Episode done for env 39. Reward: 27.15, Length: 8
DEBUG (Env): Episode done for env 43. Reward: 18.02, Length: 7
DEBUG (Env): Episode done for env 117. Reward: -16.45, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -17.53, Length: 36
811
Time taken for simulation:  7.971972942352295
average overall reward:  -0.0062364973  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.283174 average distance reward:  -0.16981502  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 18. Reward: -19.40, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 24.30, Length: 5
DEBUG (Env): Episode done for env 32. Reward: 29.29, Length: 4
DEBUG (Env): Episode done for env 48. Reward: -9.30, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 15.42, Length: 19
DEBUG (Env): Episode done for env 87. Reward: 18.38, Length: 3
812
Time taken for simulation:  7.19773006439209
average overall reward:  -0.0076543875  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.029204354  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 51. Reward: 19.75, Length: 3
DEBUG (Env): Episode done for env 71. Reward: 25.46, Length: 19
DEBUG (Env): Episode done for env 74. Reward: -23.76, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -18.06, Length: 36
813
Time taken for simulation:  7.572444677352905
average overall reward:  -0.39795917  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  -0.2478281  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 61. Reward: -22.69, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 19.74, Length: 12
DEBUG (Env): Episode done for env 90. Reward: -7.17, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -11.45, Length: 36
814
Time taken for simulation:  7.241612911224365
average overall reward:  0.13043948  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594472 average distance reward:  -0.021871317  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 36. Reward: 21.05, Length: 15
DEBUG (Env): Episode done for env 92. Reward: 32.03, Length: 1
DEBUG (Env): Episode done for env 122. Reward: 21.55, Length: 8
815
Time taken for simulation:  7.100550174713135
average overall reward:  0.28560308  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.20360479  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 21.58, Length: 7
DEBUG (Env): Episode done for env 42. Reward: -11.89, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -16.94, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 19.20, Length: 8
DEBUG (Env): Episode done for env 101. Reward: 25.35, Length: 19
DEBUG (Env): Episode done for env 127. Reward: -17.19, Length: 36
816
Time taken for simulation:  7.1192498207092285
average overall reward:  -0.3891521  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.32178867 average distance reward:  -0.03768741  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -23.71, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -20.19, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -17.84, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 2.05, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -19.43, Length: 36
817
Time taken for simulation:  7.038440942764282
average overall reward:  0.19498774  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.112989455  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: -16.62, Length: 36
DEBUG (Env): Episode done for env 8. Reward: 24.32, Length: 22
DEBUG (Env): Episode done for env 20. Reward: -11.54, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -14.11, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 14.41, Length: 33
DEBUG (Env): Episode done for env 112. Reward: 21.14, Length: 5
818
Time taken for simulation:  7.72501540184021
average overall reward:  0.40370458  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.05166396  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 26. Reward: 20.22, Length: 8
DEBUG (Env): Episode done for env 47. Reward: 13.69, Length: 24
DEBUG (Env): Episode done for env 85. Reward: 12.62, Length: 32
DEBUG (Env): Episode done for env 98. Reward: 19.54, Length: 19
819
Time taken for simulation:  7.99015212059021
average overall reward:  0.74809027  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.3719104  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: -20.19, Length: 36
DEBUG (Env): Episode done for env 8. Reward: 41.51, Length: 2
DEBUG (Env): Episode done for env 28. Reward: 11.08, Length: 25
DEBUG (Env): Episode done for env 59. Reward: -19.09, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 16.37, Length: 3
DEBUG (Env): Episode done for env 86. Reward: 25.96, Length: 4
DEBUG (Env): Episode done for env 112. Reward: 18.81, Length: 2
820
Time taken for simulation:  7.190282344818115
average overall reward:  -0.1863626  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  -0.23800665  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 55. Reward: 14.26, Length: 22
DEBUG (Env): Episode done for env 67. Reward: 22.05, Length: 19
DEBUG (Env): Episode done for env 84. Reward: -21.29, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 20.27, Length: 30
821
Time taken for simulation:  7.257495403289795
average overall reward:  -0.34381965  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.13163637  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 10.42, Length: 28
DEBUG (Env): Episode done for env 33. Reward: -23.37, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -19.75, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -20.03, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -16.19, Length: 36
822
Time taken for simulation:  7.189304828643799
average overall reward:  -0.30647516  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  0.06451758  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: -18.82, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -17.21, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -19.36, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -24.16, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -25.32, Length: 36
823
Time taken for simulation:  7.82368016242981
average overall reward:  -0.046363004  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.041014105  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 8.93, Length: 12
DEBUG (Env): Episode done for env 24. Reward: -19.09, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -24.11, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -21.65, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 20.73, Length: 17
DEBUG (Env): Episode done for env 77. Reward: -20.02, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -28.12, Length: 36
824
Time taken for simulation:  7.395342588424683
average overall reward:  -0.032764792  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594475 average distance reward:  -0.11476308  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 19.13, Length: 17
DEBUG (Env): Episode done for env 37. Reward: 6.57, Length: 28
DEBUG (Env): Episode done for env 78. Reward: -11.09, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 26.02, Length: 4
DEBUG (Env): Episode done for env 88. Reward: -11.78, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -19.43, Length: 36
825
Time taken for simulation:  7.259843587875366
average overall reward:  0.026784182  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020163 average distance reward:  -0.05751969  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 17.67, Length: 3
DEBUG (Env): Episode done for env 16. Reward: -13.04, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -18.06, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -20.34, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 17.32, Length: 13
DEBUG (Env): Episode done for env 101. Reward: 8.65, Length: 10
DEBUG (Env): Episode done for env 119. Reward: -12.56, Length: 36
826
Time taken for simulation:  7.12148118019104
average overall reward:  -0.27954137  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.13997622  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 40. Reward: -24.67, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -15.81, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 17.14, Length: 2
827
Time taken for simulation:  7.459583282470703
average overall reward:  -0.19805115  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.16580932  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 6. Reward: 22.13, Length: 2
DEBUG (Env): Episode done for env 47. Reward: 20.80, Length: 9
DEBUG (Env): Episode done for env 114. Reward: -11.97, Length: 36
828
Time taken for simulation:  7.971612215042114
average overall reward:  0.5721863  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  -0.06417164  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 25. Reward: 7.97, Length: 24
DEBUG (Env): Episode done for env 27. Reward: 22.56, Length: 3
DEBUG (Env): Episode done for env 47. Reward: 17.26, Length: 1
DEBUG (Env): Episode done for env 79. Reward: -19.01, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 25.86, Length: 2
DEBUG (Env): Episode done for env 93. Reward: -23.21, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 16.45, Length: 30
DEBUG (Env): Episode done for env 109. Reward: -21.73, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 13.60, Length: 18
DEBUG (Env): Episode done for env 124. Reward: 16.40, Length: 6
829
Time taken for simulation:  7.113515138626099
average overall reward:  0.29332054  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.065384224  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: -19.43, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 26.88, Length: 11
DEBUG (Env): Episode done for env 74. Reward: 17.96, Length: 4
DEBUG (Env): Episode done for env 83. Reward: -18.81, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 28.27, Length: 6
DEBUG (Env): Episode done for env 120. Reward: 26.38, Length: 1
830
Time taken for simulation:  7.200963735580444
average overall reward:  0.38573945  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  0.18354622  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 50. Reward: 19.10, Length: 14
DEBUG (Env): Episode done for env 52. Reward: 15.57, Length: 31
DEBUG (Env): Episode done for env 97. Reward: -26.80, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -20.25, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 22.75, Length: 2
DEBUG (Env): Episode done for env 117. Reward: 14.62, Length: 20
831
Time taken for simulation:  7.093226432800293
average overall reward:  -0.04623428  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.07604461  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 80. Reward: 10.04, Length: 25
DEBUG (Env): Episode done for env 100. Reward: 26.75, Length: 1
832
Time taken for simulation:  7.414865016937256
average overall reward:  -0.22341293  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  -0.026406825  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: -16.16, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -25.86, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -18.51, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -24.42, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 29.42, Length: 9
DEBUG (Env): Episode done for env 102. Reward: -16.86, Length: 36
833
Time taken for simulation:  7.193050861358643
average overall reward:  -0.02839841  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.026510902  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: -12.63, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 22.18, Length: 18
DEBUG (Env): Episode done for env 108. Reward: -19.51, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 38.97, Length: 12
DEBUG (Env): Episode done for env 121. Reward: -16.81, Length: 36
834
Time taken for simulation:  7.221553325653076
average overall reward:  -0.055828862  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.21275085  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 10.21, Length: 15
DEBUG (Env): Episode done for env 46. Reward: -22.68, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 12.30, Length: 25
DEBUG (Env): Episode done for env 108. Reward: 16.75, Length: 1
DEBUG (Env): Episode done for env 125. Reward: -6.92, Length: 36
835
Time taken for simulation:  7.247544288635254
average overall reward:  -0.059876777  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.283174 average distance reward:  -0.33538988  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 53. Reward: -9.61, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 11.86, Length: 1
DEBUG (Env): Episode done for env 55. Reward: 26.01, Length: 15
DEBUG (Env): Episode done for env 71. Reward: 22.04, Length: 23
DEBUG (Env): Episode done for env 73. Reward: -15.12, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -19.27, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 15.11, Length: 5
DEBUG (Env): Episode done for env 107. Reward: 6.71, Length: 30
836
Time taken for simulation:  7.318732976913452
average overall reward:  0.685058  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.1325859  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: 8.86, Length: 2
DEBUG (Env): Episode done for env 15. Reward: -0.20, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 5.77, Length: 29
DEBUG (Env): Episode done for env 45. Reward: -19.59, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 9.89, Length: 24
DEBUG (Env): Episode done for env 66. Reward: 10.07, Length: 11
DEBUG (Env): Episode done for env 94. Reward: -38.96, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 27.88, Length: 8
837
Time taken for simulation:  7.197871923446655
average overall reward:  -0.20243019  average fail penalty:  -0.140625  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  0.018013388  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: -14.85, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -22.54, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -14.45, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 20.78, Length: 23
DEBUG (Env): Episode done for env 57. Reward: -15.82, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -7.42, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -22.85, Length: 36
838
Time taken for simulation:  7.498213291168213
average overall reward:  0.009902656  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.0010813791  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: -18.41, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -9.30, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 31.72, Length: 15
DEBUG (Env): Episode done for env 118. Reward: -22.71, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 17.75, Length: 4
839
Time taken for simulation:  7.439398765563965
average overall reward:  -0.08484199  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.16453478  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: -24.35, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 13.81, Length: 18
DEBUG (Env): Episode done for env 66. Reward: 18.23, Length: 3
DEBUG (Env): Episode done for env 82. Reward: 2.70, Length: 34
DEBUG (Env): Episode done for env 123. Reward: -17.65, Length: 36
840
Time taken for simulation:  7.033334255218506
average overall reward:  0.55941254  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.037294626  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 34.07, Length: 11
DEBUG (Env): Episode done for env 44. Reward: 13.72, Length: 24
DEBUG (Env): Episode done for env 63. Reward: 25.65, Length: 8
DEBUG (Env): Episode done for env 73. Reward: 22.09, Length: 5
DEBUG (Env): Episode done for env 80. Reward: 16.15, Length: 9
DEBUG (Env): Episode done for env 111. Reward: 15.06, Length: 36
841
Time taken for simulation:  7.299140691757202
average overall reward:  0.43611944  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.034196407  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 5. Reward: 35.36, Length: 3
DEBUG (Env): Episode done for env 31. Reward: 16.42, Length: 18
DEBUG (Env): Episode done for env 39. Reward: 15.15, Length: 31
DEBUG (Env): Episode done for env 63. Reward: 23.08, Length: 1
DEBUG (Env): Episode done for env 89. Reward: -14.58, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -23.46, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 21.71, Length: 3
842
Time taken for simulation:  7.021843671798706
average overall reward:  0.16525345  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  -0.060377203  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 10. Reward: -20.42, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 14.86, Length: 3
DEBUG (Env): Episode done for env 52. Reward: 21.84, Length: 12
DEBUG (Env): Episode done for env 66. Reward: 16.15, Length: 3
DEBUG (Env): Episode done for env 93. Reward: 19.08, Length: 14
843
Time taken for simulation:  7.286478519439697
average overall reward:  0.4931843  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.23950487  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 29. Reward: 10.04, Length: 32
DEBUG (Env): Episode done for env 60. Reward: 29.98, Length: 10
DEBUG (Env): Episode done for env 105. Reward: 11.80, Length: 14
DEBUG (Env): Episode done for env 107. Reward: 16.89, Length: 8
DEBUG (Env): Episode done for env 115. Reward: -12.52, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -16.73, Length: 36
844
Time taken for simulation:  7.172858476638794
average overall reward:  0.37306845  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.14513215  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 57. Reward: 34.00, Length: 7
DEBUG (Env): Episode done for env 60. Reward: 17.73, Length: 1
DEBUG (Env): Episode done for env 72. Reward: -20.78, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 11.35, Length: 12
DEBUG (Env): Episode done for env 113. Reward: -22.42, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 32.50, Length: 3
845
Time taken for simulation:  7.28471040725708
average overall reward:  -0.2021968  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.02401701  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 65. Reward: -22.08, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -14.70, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 22.56, Length: 6
846
Time taken for simulation:  7.108374834060669
average overall reward:  -0.070852846  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.06665973  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 4. Reward: -14.85, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 16.62, Length: 18
DEBUG (Env): Episode done for env 37. Reward: 12.56, Length: 22
DEBUG (Env): Episode done for env 43. Reward: -12.64, Length: 36
847
Time taken for simulation:  7.196955680847168
average overall reward:  -0.1694698  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.05404392  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 32. Reward: -6.58, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -22.13, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -21.18, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -25.93, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 21.91, Length: 12
DEBUG (Env): Episode done for env 111. Reward: 34.16, Length: 7
848
Time taken for simulation:  7.308744668960571
average overall reward:  0.18892494  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.13337152  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: 7.23, Length: 29
DEBUG (Env): Episode done for env 72. Reward: 23.14, Length: 4
849
Time taken for simulation:  7.3166823387146
average overall reward:  0.10095593  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.0060860813  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 43. Reward: 21.70, Length: 3
DEBUG (Env): Episode done for env 61. Reward: -19.58, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -17.50, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 23.17, Length: 8
DEBUG (Env): Episode done for env 90. Reward: -23.16, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 15.28, Length: 21
850
Time taken for simulation:  7.15276575088501
average overall reward:  0.33651304  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.2825635  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 39. Reward: 44.21, Length: 9
DEBUG (Env): Episode done for env 65. Reward: 24.14, Length: 5
DEBUG (Env): Episode done for env 91. Reward: 15.37, Length: 3
DEBUG (Env): Episode done for env 92. Reward: -14.42, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -21.42, Length: 36
851
Time taken for simulation:  7.1256303787231445
average overall reward:  -0.04259263  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  -0.066448174  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: -19.07, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 19.64, Length: 8
DEBUG (Env): Episode done for env 106. Reward: 26.26, Length: 21
DEBUG (Env): Episode done for env 127. Reward: -14.67, Length: 36
852
Time taken for simulation:  7.1024415493011475
average overall reward:  0.34459358  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455938 average distance reward:  -0.12834372  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: -15.40, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 20.30, Length: 15
DEBUG (Env): Episode done for env 20. Reward: 20.32, Length: 35
DEBUG (Env): Episode done for env 37. Reward: 34.94, Length: 6
DEBUG (Env): Episode done for env 48. Reward: 31.82, Length: 5
DEBUG (Env): Episode done for env 71. Reward: 4.33, Length: 17
DEBUG (Env): Episode done for env 103. Reward: -34.01, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 18.22, Length: 23
853
Time taken for simulation:  7.464197397232056
average overall reward:  -0.04454638  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.008827347  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -29.13, Length: 36
DEBUG (Env): Episode done for env 5. Reward: 22.06, Length: 12
DEBUG (Env): Episode done for env 32. Reward: 15.62, Length: 6
DEBUG (Env): Episode done for env 49. Reward: -6.58, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -6.40, Length: 36
854
Time taken for simulation:  7.136112689971924
average overall reward:  0.045164004  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  -0.08601491  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: 21.08, Length: 8
DEBUG (Env): Episode done for env 56. Reward: 23.30, Length: 1
DEBUG (Env): Episode done for env 85. Reward: -12.66, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 8.08, Length: 12
DEBUG (Env): Episode done for env 98. Reward: -22.68, Length: 36
855
Time taken for simulation:  7.883484601974487
average overall reward:  0.0218599  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.12210861  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 28. Reward: -21.25, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -19.30, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 21.55, Length: 18
DEBUG (Env): Episode done for env 81. Reward: -29.11, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 23.60, Length: 26
DEBUG (Env): Episode done for env 86. Reward: -25.02, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -13.25, Length: 36
856
Time taken for simulation:  7.068647623062134
average overall reward:  -0.23158643  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.18877867  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 38. Reward: 2.24, Length: 35
DEBUG (Env): Episode done for env 67. Reward: -21.03, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 25.92, Length: 5
DEBUG (Env): Episode done for env 110. Reward: -23.16, Length: 36
857
Time taken for simulation:  7.435654640197754
average overall reward:  0.016677305  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.017744198  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 19. Reward: -18.67, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -21.98, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 30.08, Length: 15
DEBUG (Env): Episode done for env 116. Reward: 6.36, Length: 24
858
Time taken for simulation:  7.121209383010864
average overall reward:  0.08559392  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.15183918  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: -16.82, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 21.16, Length: 4
DEBUG (Env): Episode done for env 32. Reward: 16.41, Length: 5
DEBUG (Env): Episode done for env 41. Reward: -29.28, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -11.27, Length: 36
859
Time taken for simulation:  7.219674825668335
average overall reward:  0.2946003  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  -0.071013525  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: 19.28, Length: 7
DEBUG (Env): Episode done for env 18. Reward: -17.08, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -11.33, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 28.27, Length: 7
DEBUG (Env): Episode done for env 49. Reward: 31.92, Length: 6
DEBUG (Env): Episode done for env 55. Reward: 7.06, Length: 24
DEBUG (Env): Episode done for env 77. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 17.36, Length: 2
860
Time taken for simulation:  7.025854110717773
average overall reward:  -0.063061535  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  0.084763974  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: -15.79, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -22.33, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -15.03, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -33.09, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 22.60, Length: 15
861
Time taken for simulation:  7.571594476699829
average overall reward:  -0.106050424  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.1623057  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: -12.56, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 20.17, Length: 22
DEBUG (Env): Episode done for env 66. Reward: 18.34, Length: 19
DEBUG (Env): Episode done for env 79. Reward: 7.22, Length: 33
DEBUG (Env): Episode done for env 101. Reward: -12.48, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -17.08, Length: 36
862
Time taken for simulation:  7.30543065071106
average overall reward:  -0.28690258  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.14733742  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 40. Reward: -17.65, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 11.09, Length: 20
DEBUG (Env): Episode done for env 58. Reward: -20.59, Length: 36
863
Time taken for simulation:  7.310147523880005
average overall reward:  0.8035677  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.12871546 average distance reward:  0.35015854  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: -15.41, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 24.00, Length: 5
DEBUG (Env): Episode done for env 40. Reward: 18.21, Length: 1
DEBUG (Env): Episode done for env 79. Reward: 24.29, Length: 2
DEBUG (Env): Episode done for env 93. Reward: 15.52, Length: 9
DEBUG (Env): Episode done for env 114. Reward: -14.89, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 25.51, Length: 2
864
Time taken for simulation:  7.378978729248047
average overall reward:  0.1839661  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.17298207  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 27. Reward: 2.83, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -19.25, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -16.68, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 38.38, Length: 9
865
Time taken for simulation:  7.209206819534302
average overall reward:  0.1520828  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.059518576  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 50.61, Length: 13
DEBUG (Env): Episode done for env 26. Reward: -15.85, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 8.96, Length: 33
DEBUG (Env): Episode done for env 74. Reward: -8.40, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 28.83, Length: 14
866
Time taken for simulation:  7.021301031112671
average overall reward:  -0.048883915  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.006795425  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 35. Reward: 23.84, Length: 1
DEBUG (Env): Episode done for env 50. Reward: -14.66, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 25.14, Length: 17
DEBUG (Env): Episode done for env 117. Reward: -27.25, Length: 36
867
Time taken for simulation:  7.090818166732788
average overall reward:  0.34527564  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.081030324  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 22.93, Length: 14
DEBUG (Env): Episode done for env 19. Reward: 26.18, Length: 10
DEBUG (Env): Episode done for env 82. Reward: 16.21, Length: 28
DEBUG (Env): Episode done for env 100. Reward: -20.31, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 29.50, Length: 15
868
Time taken for simulation:  7.648222923278809
average overall reward:  -0.13694544  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.096443206  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 21.76, Length: 22
DEBUG (Env): Episode done for env 9. Reward: -16.88, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 24.69, Length: 9
DEBUG (Env): Episode done for env 22. Reward: -17.77, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -16.65, Length: 36
869
Time taken for simulation:  7.07059383392334
average overall reward:  -0.000991404  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.01607328  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 11. Reward: -10.48, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 17.41, Length: 11
DEBUG (Env): Episode done for env 67. Reward: 14.39, Length: 13
DEBUG (Env): Episode done for env 121. Reward: -16.72, Length: 36
870
Time taken for simulation:  7.131787538528442
average overall reward:  -0.03267221  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  -0.24773696  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 18.42, Length: 10
DEBUG (Env): Episode done for env 27. Reward: 22.32, Length: 6
DEBUG (Env): Episode done for env 46. Reward: -22.79, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 16.87, Length: 32
DEBUG (Env): Episode done for env 75. Reward: 19.42, Length: 2
DEBUG (Env): Episode done for env 108. Reward: -19.93, Length: 36
871
Time taken for simulation:  7.502923250198364
average overall reward:  0.2553208  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.17332248  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: 16.19, Length: 2
DEBUG (Env): Episode done for env 20. Reward: -21.00, Length: 19
DEBUG (Env): Episode done for env 53. Reward: -25.08, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -13.88, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -19.83, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 10.87, Length: 33
872
Time taken for simulation:  7.554112672805786
average overall reward:  0.22809382  average fail penalty:  -0.1640625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.40096068  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 8. Reward: -24.59, Length: 36
DEBUG (Env): Episode done for env 15. Reward: -12.14, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -25.22, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 34.43, Length: 6
DEBUG (Env): Episode done for env 45. Reward: -21.60, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -9.67, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -20.97, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 34.74, Length: 5
DEBUG (Env): Episode done for env 124. Reward: -17.70, Length: 36
873
Time taken for simulation:  7.254281282424927
average overall reward:  0.0054864436  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.3346602 average distance reward:  -0.19510296  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 15. Reward: 29.75, Length: 1
DEBUG (Env): Episode done for env 17. Reward: -20.92, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 23.77, Length: 14
DEBUG (Env): Episode done for env 30. Reward: -51.69, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -14.67, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 16.96, Length: 32
DEBUG (Env): Episode done for env 74. Reward: 10.60, Length: 8
DEBUG (Env): Episode done for env 81. Reward: 17.50, Length: 18
DEBUG (Env): Episode done for env 99. Reward: -22.28, Length: 36
874
Time taken for simulation:  7.0801100730896
average overall reward:  0.11070903  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  0.26545134  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 1. Reward: 28.80, Length: 9
DEBUG (Env): Episode done for env 76. Reward: -16.63, Length: 36
875
Time taken for simulation:  7.314818620681763
average overall reward:  -0.08572525  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.10266405  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 26. Reward: 16.67, Length: 10
DEBUG (Env): Episode done for env 99. Reward: 18.84, Length: 2
876
Time taken for simulation:  7.484551429748535
average overall reward:  -0.32483438  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  -0.15126576  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -10.53, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 11.86, Length: 9
DEBUG (Env): Episode done for env 44. Reward: -7.85, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -18.17, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -18.70, Length: 36
877
Time taken for simulation:  7.3021416664123535
average overall reward:  0.41637588  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  0.04019604  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 7. Reward: 18.49, Length: 1
DEBUG (Env): Episode done for env 31. Reward: -13.10, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 11.15, Length: 27
DEBUG (Env): Episode done for env 95. Reward: -12.50, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 28.58, Length: 16
DEBUG (Env): Episode done for env 102. Reward: 12.65, Length: 33
DEBUG (Env): Episode done for env 115. Reward: -1.24, Length: 34
878
Time taken for simulation:  7.529078722000122
average overall reward:  0.09738943  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  0.18111745  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 10. Reward: -13.99, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 12.36, Length: 22
DEBUG (Env): Episode done for env 58. Reward: 27.80, Length: 16
879
Time taken for simulation:  7.045905590057373
average overall reward:  -0.50625217  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030244 average distance reward:  -0.25314867  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 29. Reward: -12.48, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 25.26, Length: 20
DEBUG (Env): Episode done for env 107. Reward: -17.09, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -20.59, Length: 36
880
Time taken for simulation:  7.011651039123535
average overall reward:  -0.05539474  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.047159582  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 57. Reward: -27.59, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -15.59, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 24.88, Length: 5
DEBUG (Env): Episode done for env 113. Reward: -5.14, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 18.49, Length: 11
DEBUG (Env): Episode done for env 125. Reward: -9.22, Length: 36
881
Time taken for simulation:  7.378775358200073
average overall reward:  -0.009588748  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.04839617  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 26. Reward: 26.50, Length: 6
DEBUG (Env): Episode done for env 69. Reward: -18.18, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 12.52, Length: 2
882
Time taken for simulation:  7.155999660491943
average overall reward:  0.5253993  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.11521599  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 26.75, Length: 14
DEBUG (Env): Episode done for env 90. Reward: 26.04, Length: 33
DEBUG (Env): Episode done for env 94. Reward: 18.62, Length: 10
DEBUG (Env): Episode done for env 115. Reward: 14.23, Length: 5
DEBUG (Env): Episode done for env 120. Reward: 29.45, Length: 15
883
Time taken for simulation:  7.213546514511108
average overall reward:  0.22592688  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020163 average distance reward:  0.11818549  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 16. Reward: 19.12, Length: 22
DEBUG (Env): Episode done for env 23. Reward: 44.98, Length: 11
DEBUG (Env): Episode done for env 64. Reward: -21.45, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 6.13, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -13.05, Length: 36
884
Time taken for simulation:  7.161752700805664
average overall reward:  0.098885395  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  0.21892245  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: -8.52, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 28.18, Length: 26
DEBUG (Env): Episode done for env 72. Reward: -17.04, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 27.42, Length: 7
885
Time taken for simulation:  7.411634683609009
average overall reward:  -0.32688296  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.21145707  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: 24.20, Length: 15
DEBUG (Env): Episode done for env 43. Reward: -18.02, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -12.85, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -22.05, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -22.54, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 21.23, Length: 8
886
Time taken for simulation:  7.242585897445679
average overall reward:  -0.16828257  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.130086  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 65. Reward: -16.73, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -29.32, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 24.75, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 12.17, Length: 15
DEBUG (Env): Episode done for env 122. Reward: -15.59, Length: 36
887
Time taken for simulation:  7.4195098876953125
average overall reward:  0.26321802  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.102972366 average distance reward:  -0.19249673  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: -16.26, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 16.10, Length: 18
DEBUG (Env): Episode done for env 34. Reward: 18.51, Length: 30
DEBUG (Env): Episode done for env 41. Reward: 13.07, Length: 3
DEBUG (Env): Episode done for env 42. Reward: -28.06, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 12.67, Length: 20
DEBUG (Env): Episode done for env 109. Reward: 11.82, Length: 21
DEBUG (Env): Episode done for env 127. Reward: -13.01, Length: 36
888
Time taken for simulation:  7.127326011657715
average overall reward:  0.4919314  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.28743267  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: 15.13, Length: 14
DEBUG (Env): Episode done for env 48. Reward: -27.31, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -18.40, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -5.63, Length: 34
DEBUG (Env): Episode done for env 102. Reward: 31.13, Length: 3
DEBUG (Env): Episode done for env 103. Reward: -22.81, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 10.73, Length: 32
889
Time taken for simulation:  7.741995096206665
average overall reward:  0.30443218  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.0015722513  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -23.37, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 17.00, Length: 12
DEBUG (Env): Episode done for env 53. Reward: 34.06, Length: 18
DEBUG (Env): Episode done for env 109. Reward: 18.58, Length: 2
DEBUG (Env): Episode done for env 112. Reward: 8.65, Length: 25
890
Time taken for simulation:  7.6074137687683105
average overall reward:  0.3069502  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.102972366 average distance reward:  -0.172202  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 42. Reward: 23.12, Length: 3
DEBUG (Env): Episode done for env 55. Reward: 38.12, Length: 31
DEBUG (Env): Episode done for env 56. Reward: -14.68, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 7.67, Length: 30
DEBUG (Env): Episode done for env 85. Reward: -15.61, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 15.67, Length: 1
DEBUG (Env): Episode done for env 123. Reward: 18.48, Length: 30
891
Time taken for simulation:  7.413950204849243
average overall reward:  -0.29217523  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.2176696  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 28. Reward: -17.26, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -25.06, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -15.70, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 14.10, Length: 21
DEBUG (Env): Episode done for env 83. Reward: -25.78, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -24.72, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 15.11, Length: 1
892
Time taken for simulation:  7.071688175201416
average overall reward:  -0.19204547  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.12871546 average distance reward:  0.007968005  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 106. Reward: -19.24, Length: 36
893
Time taken for simulation:  7.393558502197266
average overall reward:  -0.25776607  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.12876683  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 33. Reward: -23.43, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 16.96, Length: 2
894
Time taken for simulation:  7.214008331298828
average overall reward:  0.017497465  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.23618191  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 23. Reward: 24.32, Length: 11
DEBUG (Env): Episode done for env 32. Reward: -17.42, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 15.31, Length: 31
DEBUG (Env): Episode done for env 87. Reward: 11.32, Length: 11
DEBUG (Env): Episode done for env 96. Reward: -23.25, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 9.65, Length: 17
895
Time taken for simulation:  7.774040699005127
average overall reward:  -0.09952897  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.07722928 average distance reward:  -0.016061183  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: -20.46, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -25.54, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 29.07, Length: 7
DEBUG (Env): Episode done for env 116. Reward: -12.33, Length: 36
896
Time taken for simulation:  8.025014638900757
average overall reward:  -0.34040934  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.026857525  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 88. Reward: -27.62, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -19.21, Length: 36
897
Time taken for simulation:  7.280326843261719
average overall reward:  0.1640957  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  0.16828884  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 21. Reward: -24.77, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 43.81, Length: 6
DEBUG (Env): Episode done for env 66. Reward: -15.04, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 20.19, Length: 17
898
Time taken for simulation:  7.167866945266724
average overall reward:  -0.005011201  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  0.1754742  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 52. Reward: -15.33, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 46.39, Length: 2
899
Time taken for simulation:  7.629434823989868
average overall reward:  0.0003848374  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.0015706047  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 6. Reward: -16.14, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -24.12, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 24.90, Length: 4
DEBUG (Env): Episode done for env 63. Reward: 22.36, Length: 26
DEBUG (Env): Episode done for env 79. Reward: -14.95, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -15.18, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -17.70, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -16.85, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 34.52, Length: 2
900
Time taken for simulation:  7.179395914077759
average overall reward:  0.3876203  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.08245474  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 14.56, Length: 1
DEBUG (Env): Episode done for env 45. Reward: 9.38, Length: 28
DEBUG (Env): Episode done for env 47. Reward: -28.19, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 19.19, Length: 10
DEBUG (Env): Episode done for env 84. Reward: -20.72, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 16.37, Length: 15
901
Time taken for simulation:  7.110715627670288
average overall reward:  -0.3053901  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.17639089  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 79. Reward: 33.35, Length: 2
DEBUG (Env): Episode done for env 105. Reward: -17.10, Length: 36
902
Time taken for simulation:  7.1362059116363525
average overall reward:  -0.047420718  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.08849879  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 16. Reward: 10.95, Length: 19
DEBUG (Env): Episode done for env 50. Reward: -13.47, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 24.42, Length: 16
DEBUG (Env): Episode done for env 116. Reward: 17.53, Length: 7
DEBUG (Env): Episode done for env 117. Reward: -29.36, Length: 36
903
Time taken for simulation:  7.6295576095581055
average overall reward:  0.36491048  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.1135367  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: -17.37, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 8.09, Length: 26
DEBUG (Env): Episode done for env 58. Reward: 35.99, Length: 25
DEBUG (Env): Episode done for env 104. Reward: 20.39, Length: 5
DEBUG (Env): Episode done for env 123. Reward: 18.11, Length: 13
904
Time taken for simulation:  7.519144773483276
average overall reward:  0.55038595  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.141587 average distance reward:  0.13328579  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: -17.00, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -2.64, Length: 33
DEBUG (Env): Episode done for env 13. Reward: -19.02, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 15.32, Length: 2
DEBUG (Env): Episode done for env 71. Reward: 24.42, Length: 16
DEBUG (Env): Episode done for env 75. Reward: 32.93, Length: 13
DEBUG (Env): Episode done for env 97. Reward: 24.62, Length: 18
905
Time taken for simulation:  7.122596263885498
average overall reward:  0.20273373  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.03524579  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: 21.39, Length: 16
DEBUG (Env): Episode done for env 12. Reward: 23.87, Length: 5
DEBUG (Env): Episode done for env 67. Reward: -16.49, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 4.41, Length: 19
906
Time taken for simulation:  7.022197484970093
average overall reward:  0.028680407  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.029880442  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: -11.77, Length: 36
DEBUG (Env): Episode done for env 4. Reward: 9.95, Length: 24
DEBUG (Env): Episode done for env 23. Reward: 12.73, Length: 12
DEBUG (Env): Episode done for env 46. Reward: -12.68, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 8.33, Length: 20
DEBUG (Env): Episode done for env 70. Reward: -14.39, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -15.85, Length: 36
907
Time taken for simulation:  7.590916156768799
average overall reward:  0.7447009  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.11584391 average distance reward:  0.031113662  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 20. Reward: -9.29, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 26.62, Length: 1
DEBUG (Env): Episode done for env 49. Reward: 15.14, Length: 8
DEBUG (Env): Episode done for env 54. Reward: -26.71, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 15.23, Length: 7
DEBUG (Env): Episode done for env 71. Reward: 24.03, Length: 3
DEBUG (Env): Episode done for env 91. Reward: 17.80, Length: 5
DEBUG (Env): Episode done for env 116. Reward: 29.06, Length: 5
DEBUG (Env): Episode done for env 118. Reward: -23.33, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 16.95, Length: 20
908
Time taken for simulation:  7.046681880950928
average overall reward:  -0.079498686  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.10175045  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: -9.41, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -12.56, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -17.74, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 6.89, Length: 35
DEBUG (Env): Episode done for env 100. Reward: -14.87, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 4.61, Length: 25
DEBUG (Env): Episode done for env 123. Reward: 19.80, Length: 5
DEBUG (Env): Episode done for env 124. Reward: -7.87, Length: 36
909
Time taken for simulation:  7.44507098197937
average overall reward:  0.44674072  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.38356873  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 15. Reward: -14.30, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -19.22, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -15.27, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -19.77, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -16.15, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -6.55, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 18.13, Length: 27
DEBUG (Env): Episode done for env 101. Reward: 15.96, Length: 15
DEBUG (Env): Episode done for env 109. Reward: 23.32, Length: 20
910
Time taken for simulation:  7.074662685394287
average overall reward:  0.68269604  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.31547847  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 74. Reward: 22.68, Length: 1
DEBUG (Env): Episode done for env 76. Reward: -19.32, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 39.78, Length: 2
DEBUG (Env): Episode done for env 112. Reward: 16.60, Length: 19
DEBUG (Env): Episode done for env 119. Reward: 26.52, Length: 11
911
Time taken for simulation:  7.111624002456665
average overall reward:  0.38448626  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.032445736  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 54. Reward: 32.67, Length: 4
DEBUG (Env): Episode done for env 57. Reward: -0.34, Length: 31
DEBUG (Env): Episode done for env 59. Reward: 19.05, Length: 14
DEBUG (Env): Episode done for env 94. Reward: 5.51, Length: 29
912
Time taken for simulation:  7.162714004516602
average overall reward:  0.3869946  average fail penalty:  -0.09375  and average goal bonus:  0.8122322  and average same cell penalty:  -0.20594473 average distance reward:  -0.07768245  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 13. Reward: 22.82, Length: 8
DEBUG (Env): Episode done for env 18. Reward: 12.79, Length: 17
DEBUG (Env): Episode done for env 19. Reward: -14.14, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -24.23, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 11.02, Length: 13
DEBUG (Env): Episode done for env 71. Reward: 29.28, Length: 5
DEBUG (Env): Episode done for env 73. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -14.81, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 25.75, Length: 18
DEBUG (Env): Episode done for env 94. Reward: 18.30, Length: 1
913
Time taken for simulation:  7.25221061706543
average overall reward:  -0.064583346  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.19345668  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 31. Reward: -21.02, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 37.93, Length: 6
DEBUG (Env): Episode done for env 94. Reward: 14.40, Length: 1
DEBUG (Env): Episode done for env 121. Reward: 23.74, Length: 14
914
Time taken for simulation:  7.096474885940552
average overall reward:  0.06855854  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  -0.1269781  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 10. Reward: -15.42, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 21.52, Length: 7
DEBUG (Env): Episode done for env 38. Reward: -6.70, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 20.19, Length: 8
DEBUG (Env): Episode done for env 114. Reward: 19.91, Length: 15
915
Time taken for simulation:  7.243728160858154
average overall reward:  0.13426825  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.115843914 average distance reward:  0.09754112  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 21. Reward: 10.75, Length: 18
DEBUG (Env): Episode done for env 29. Reward: -19.79, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -7.10, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -16.94, Length: 36
916
Time taken for simulation:  7.2346155643463135
average overall reward:  -0.18024758  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.1873222  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: 21.00, Length: 11
DEBUG (Env): Episode done for env 60. Reward: -18.45, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 14.86, Length: 4
DEBUG (Env): Episode done for env 79. Reward: 23.39, Length: 15
DEBUG (Env): Episode done for env 99. Reward: -12.03, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -21.54, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -21.03, Length: 36
917
Time taken for simulation:  7.1675848960876465
average overall reward:  -0.033533603  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.16701812  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 20. Reward: 24.65, Length: 10
DEBUG (Env): Episode done for env 26. Reward: -26.42, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -18.01, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 20.61, Length: 3
DEBUG (Env): Episode done for env 100. Reward: 21.32, Length: 9
DEBUG (Env): Episode done for env 126. Reward: -11.78, Length: 36
918
Time taken for simulation:  7.455196857452393
average overall reward:  0.081364244  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  -0.06268621  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 14.26, Length: 12
DEBUG (Env): Episode done for env 59. Reward: 36.11, Length: 7
DEBUG (Env): Episode done for env 83. Reward: 22.68, Length: 27
DEBUG (Env): Episode done for env 115. Reward: -17.01, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -26.59, Length: 36
919
Time taken for simulation:  7.315191030502319
average overall reward:  0.4033804  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.2873786  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 64. Reward: -16.65, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 33.60, Length: 3
DEBUG (Env): Episode done for env 91. Reward: 30.92, Length: 12
DEBUG (Env): Episode done for env 101. Reward: 19.40, Length: 10
920
Time taken for simulation:  7.492713212966919
average overall reward:  -0.23483357  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.3168319  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: -16.54, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 18.30, Length: 11
DEBUG (Env): Episode done for env 71. Reward: 11.26, Length: 1
DEBUG (Env): Episode done for env 72. Reward: -16.86, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -26.62, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 23.83, Length: 12
921
Time taken for simulation:  7.1174163818359375
average overall reward:  -0.14423853  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.06742734  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: -16.33, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -17.85, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 23.29, Length: 17
DEBUG (Env): Episode done for env 61. Reward: -18.39, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -12.32, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 5.71, Length: 29
922
Time taken for simulation:  7.123774766921997
average overall reward:  -0.029618606  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  0.19613801  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 92. Reward: -18.36, Length: 36
923
Time taken for simulation:  7.1468422412872314
average overall reward:  0.059909254  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.13632914  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 14. Reward: -19.19, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -12.34, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -17.49, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -19.03, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 17.37, Length: 2
DEBUG (Env): Episode done for env 82. Reward: -16.64, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 10.83, Length: 35
DEBUG (Env): Episode done for env 118. Reward: 1.41, Length: 16
DEBUG (Env): Episode done for env 126. Reward: 18.78, Length: 6
924
Time taken for simulation:  7.1975390911102295
average overall reward:  -0.25290072  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.06646059  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -14.24, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -12.65, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 24.44, Length: 7
DEBUG (Env): Episode done for env 98. Reward: -23.92, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -16.63, Length: 36
925
Time taken for simulation:  7.027712821960449
average overall reward:  0.7133585  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.21467812  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 0. Reward: -14.86, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 42.22, Length: 20
DEBUG (Env): Episode done for env 10. Reward: 22.69, Length: 11
DEBUG (Env): Episode done for env 12. Reward: 17.04, Length: 9
DEBUG (Env): Episode done for env 53. Reward: -19.48, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 16.73, Length: 20
DEBUG (Env): Episode done for env 104. Reward: 23.46, Length: 22
DEBUG (Env): Episode done for env 107. Reward: 35.93, Length: 10
926
Time taken for simulation:  7.350207328796387
average overall reward:  0.023058102  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3089171 average distance reward:  0.067469634  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: 28.13, Length: 1
DEBUG (Env): Episode done for env 23. Reward: 13.06, Length: 12
DEBUG (Env): Episode done for env 42. Reward: -15.36, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -19.50, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 9.95, Length: 2
DEBUG (Env): Episode done for env 78. Reward: -15.75, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -21.39, Length: 36
927
Time taken for simulation:  7.062046051025391
average overall reward:  0.07216106  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.19438991  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 20.83, Length: 7
DEBUG (Env): Episode done for env 28. Reward: -20.89, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 33.25, Length: 18
DEBUG (Env): Episode done for env 35. Reward: 17.69, Length: 19
DEBUG (Env): Episode done for env 78. Reward: 16.42, Length: 1
DEBUG (Env): Episode done for env 86. Reward: -25.52, Length: 36
928
Time taken for simulation:  7.10641884803772
average overall reward:  0.374798  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  -0.09974305  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 20.67, Length: 10
DEBUG (Env): Episode done for env 10. Reward: 31.55, Length: 3
DEBUG (Env): Episode done for env 18. Reward: 4.52, Length: 16
DEBUG (Env): Episode done for env 58. Reward: 8.59, Length: 25
DEBUG (Env): Episode done for env 126. Reward: 21.31, Length: 5
929
Time taken for simulation:  7.10927939414978
average overall reward:  0.040937632  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.058002364  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: 26.43, Length: 4
DEBUG (Env): Episode done for env 33. Reward: -15.06, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -18.23, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 25.75, Length: 12
930
Time taken for simulation:  7.220157623291016
average overall reward:  -0.20874292  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.032868702  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 32. Reward: -26.96, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -12.58, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 30.84, Length: 9
DEBUG (Env): Episode done for env 96. Reward: -15.37, Length: 36
931
Time taken for simulation:  7.222076654434204
average overall reward:  0.119182765  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.1619906  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 32. Reward: 24.70, Length: 1
DEBUG (Env): Episode done for env 37. Reward: -24.19, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -15.40, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 12.11, Length: 24
932
Time taken for simulation:  7.207841157913208
average overall reward:  0.43000826  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.043262422  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 34. Reward: 17.20, Length: 9
DEBUG (Env): Episode done for env 38. Reward: 13.80, Length: 18
DEBUG (Env): Episode done for env 77. Reward: 22.39, Length: 17
DEBUG (Env): Episode done for env 88. Reward: -19.01, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 15.62, Length: 33
DEBUG (Env): Episode done for env 105. Reward: 17.54, Length: 31
933
Time taken for simulation:  7.156831502914429
average overall reward:  0.22830944  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.060821474  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 20. Reward: 37.19, Length: 16
DEBUG (Env): Episode done for env 58. Reward: 39.38, Length: 5
DEBUG (Env): Episode done for env 66. Reward: -22.54, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 17.96, Length: 21
934
Time taken for simulation:  7.537771463394165
average overall reward:  0.26795146  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.11333507  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: 38.29, Length: 10
DEBUG (Env): Episode done for env 33. Reward: 17.58, Length: 5
DEBUG (Env): Episode done for env 52. Reward: -16.05, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 10.07, Length: 34
935
Time taken for simulation:  7.187591314315796
average overall reward:  0.23016876  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.02120506  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: -13.32, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 19.02, Length: 6
DEBUG (Env): Episode done for env 23. Reward: 21.40, Length: 9
DEBUG (Env): Episode done for env 48. Reward: 22.65, Length: 11
DEBUG (Env): Episode done for env 97. Reward: 4.76, Length: 31
936
Time taken for simulation:  7.429020881652832
average overall reward:  -0.5061026  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.23168783 average distance reward:  -0.1562418  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 45. Reward: -31.11, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -19.92, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -16.46, Length: 36
937
Time taken for simulation:  7.346067190170288
average overall reward:  0.062331766  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.05136437  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 43. Reward: 31.86, Length: 16
DEBUG (Env): Episode done for env 61. Reward: 14.27, Length: 7
DEBUG (Env): Episode done for env 66. Reward: 26.44, Length: 4
938
Time taken for simulation:  7.126722812652588
average overall reward:  0.38304192  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.102972366 average distance reward:  0.31000578  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 16. Reward: -24.32, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 24.51, Length: 4
DEBUG (Env): Episode done for env 117. Reward: -17.05, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -1.81, Length: 33
939
Time taken for simulation:  7.205962896347046
average overall reward:  -0.24862756  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  -0.39267796  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: -14.92, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 6.84, Length: 30
DEBUG (Env): Episode done for env 34. Reward: 15.96, Length: 7
DEBUG (Env): Episode done for env 39. Reward: -17.63, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 27.93, Length: 14
940
Time taken for simulation:  7.642756223678589
average overall reward:  0.071159296  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  -0.24527398  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 9. Reward: -16.79, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -29.84, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 20.89, Length: 12
DEBUG (Env): Episode done for env 22. Reward: -19.74, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 15.48, Length: 22
DEBUG (Env): Episode done for env 75. Reward: -17.99, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 27.77, Length: 8
DEBUG (Env): Episode done for env 85. Reward: 16.27, Length: 14
DEBUG (Env): Episode done for env 104. Reward: 16.33, Length: 1
941
Time taken for simulation:  7.113766431808472
average overall reward:  0.43364114  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  0.062072426  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: 17.22, Length: 29
DEBUG (Env): Episode done for env 40. Reward: 32.03, Length: 11
DEBUG (Env): Episode done for env 70. Reward: 12.98, Length: 15
DEBUG (Env): Episode done for env 88. Reward: 23.55, Length: 9
DEBUG (Env): Episode done for env 114. Reward: 10.20, Length: 27
942
Time taken for simulation:  7.074735403060913
average overall reward:  -0.3703593  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  -0.068075195  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: -17.38, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 14.21, Length: 7
DEBUG (Env): Episode done for env 46. Reward: -13.21, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -26.60, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -21.96, Length: 36
943
Time taken for simulation:  7.645108222961426
average overall reward:  0.58421177  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.1565457  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 16.20, Length: 3
DEBUG (Env): Episode done for env 34. Reward: 19.71, Length: 4
DEBUG (Env): Episode done for env 56. Reward: -15.89, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 16.85, Length: 6
DEBUG (Env): Episode done for env 87. Reward: 8.60, Length: 31
DEBUG (Env): Episode done for env 102. Reward: 16.25, Length: 12
DEBUG (Env): Episode done for env 116. Reward: -18.04, Length: 36
944
Time taken for simulation:  7.307260036468506
average overall reward:  0.28232044  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  -0.034112815  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: 30.54, Length: 2
DEBUG (Env): Episode done for env 8. Reward: -5.73, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 19.90, Length: 4
DEBUG (Env): Episode done for env 28. Reward: 28.82, Length: 17
DEBUG (Env): Episode done for env 51. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 12.87, Length: 1
DEBUG (Env): Episode done for env 58. Reward: 28.16, Length: 11
DEBUG (Env): Episode done for env 111. Reward: -19.20, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -17.62, Length: 36
945
Time taken for simulation:  7.481149196624756
average overall reward:  0.0138994455  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.077839114  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: -21.75, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 30.59, Length: 12
DEBUG (Env): Episode done for env 36. Reward: -16.05, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -14.88, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -9.40, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 18.79, Length: 1
946
Time taken for simulation:  7.022973299026489
average overall reward:  0.46067291  average fail penalty:  -0.1171875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455936 average distance reward:  0.058048118  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 10. Reward: 12.73, Length: 18
DEBUG (Env): Episode done for env 14. Reward: 28.02, Length: 23
DEBUG (Env): Episode done for env 74. Reward: -15.09, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -19.56, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -20.28, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 7.32, Length: 17
DEBUG (Env): Episode done for env 112. Reward: -21.34, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -5.19, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 3.76, Length: 28
DEBUG (Env): Episode done for env 124. Reward: 23.86, Length: 2
947
Time taken for simulation:  7.0400550365448
average overall reward:  0.23006114  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  -0.049361333  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 19. Reward: 14.27, Length: 35
DEBUG (Env): Episode done for env 50. Reward: 7.64, Length: 26
DEBUG (Env): Episode done for env 54. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -23.31, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 20.84, Length: 14
DEBUG (Env): Episode done for env 86. Reward: 25.71, Length: 20
948
Time taken for simulation:  7.161725759506226
average overall reward:  0.062393878  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.23826812  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: 24.45, Length: 13
DEBUG (Env): Episode done for env 44. Reward: -17.83, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -22.64, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -13.37, Length: 36
949
Time taken for simulation:  7.098530292510986
average overall reward:  -0.0039963126  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.021328736  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 21.37, Length: 5
DEBUG (Env): Episode done for env 31. Reward: -20.54, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -10.14, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 29.77, Length: 5
DEBUG (Env): Episode done for env 94. Reward: -12.86, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -18.08, Length: 36
950
Time taken for simulation:  7.564298391342163
average overall reward:  0.49358118  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.15441218  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: 28.04, Length: 6
DEBUG (Env): Episode done for env 38. Reward: 13.46, Length: 18
DEBUG (Env): Episode done for env 77. Reward: 19.19, Length: 10
DEBUG (Env): Episode done for env 104. Reward: 12.65, Length: 10
951
Time taken for simulation:  7.041535139083862
average overall reward:  -0.1380399  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.037089363  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 21. Reward: -18.54, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 19.15, Length: 7
DEBUG (Env): Episode done for env 29. Reward: -16.97, Length: 36
952
Time taken for simulation:  7.566509008407593
average overall reward:  0.25913107  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.115843914 average distance reward:  -0.0014650971  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 19. Reward: 15.36, Length: 5
DEBUG (Env): Episode done for env 60. Reward: -14.47, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 32.67, Length: 9
DEBUG (Env): Episode done for env 79. Reward: -17.43, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 18.98, Length: 18
DEBUG (Env): Episode done for env 99. Reward: -17.84, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 16.45, Length: 27
DEBUG (Env): Episode done for env 113. Reward: -23.17, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -28.21, Length: 36
953
Time taken for simulation:  7.433915138244629
average overall reward:  0.034796923  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  -0.1607397  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 16. Reward: 28.46, Length: 15
DEBUG (Env): Episode done for env 26. Reward: -23.26, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 30.40, Length: 18
DEBUG (Env): Episode done for env 69. Reward: -16.99, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 25.14, Length: 4
954
Time taken for simulation:  7.186304569244385
average overall reward:  0.48047468  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.16243759  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 22.90, Length: 5
DEBUG (Env): Episode done for env 58. Reward: 38.88, Length: 10
DEBUG (Env): Episode done for env 83. Reward: -22.59, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 13.56, Length: 9
DEBUG (Env): Episode done for env 115. Reward: -8.36, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 2.45, Length: 31
955
Time taken for simulation:  7.050838947296143
average overall reward:  0.4399569  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.3322155  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: 24.02, Length: 10
DEBUG (Env): Episode done for env 43. Reward: 19.81, Length: 18
DEBUG (Env): Episode done for env 64. Reward: -14.92, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 25.78, Length: 13
DEBUG (Env): Episode done for env 91. Reward: -13.68, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -24.80, Length: 36
956
Time taken for simulation:  7.226945400238037
average overall reward:  -0.4043578  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  -0.020493489  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: -19.11, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -25.50, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -13.44, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -26.66, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -33.38, Length: 36
957
Time taken for simulation:  7.253135442733765
average overall reward:  0.2534884  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.21906687  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 27. Reward: -23.35, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 20.61, Length: 31
DEBUG (Env): Episode done for env 86. Reward: 24.51, Length: 10
DEBUG (Env): Episode done for env 106. Reward: -20.77, Length: 36
958
Time taken for simulation:  7.512501955032349
average overall reward:  -0.21375123  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.020394295  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 46. Reward: 47.34, Length: 16
DEBUG (Env): Episode done for env 92. Reward: -13.56, Length: 36
959
Time taken for simulation:  7.5516908168792725
average overall reward:  -0.39497682  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.20462725  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 24. Reward: 14.98, Length: 3
DEBUG (Env): Episode done for env 25. Reward: -13.45, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -10.78, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -17.93, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 25.11, Length: 6
DEBUG (Env): Episode done for env 82. Reward: -16.48, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -25.05, Length: 36
960
Time taken for simulation:  7.227696418762207
average overall reward:  0.3982766  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.2413546  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: 29.43, Length: 10
DEBUG (Env): Episode done for env 14. Reward: 25.50, Length: 14
DEBUG (Env): Episode done for env 69. Reward: 16.41, Length: 1
DEBUG (Env): Episode done for env 98. Reward: -24.50, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -10.93, Length: 36
961
Time taken for simulation:  7.35543966293335
average overall reward:  0.36726797  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.32178864 average distance reward:  0.13036951  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 0. Reward: -12.08, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 19.66, Length: 2
DEBUG (Env): Episode done for env 53. Reward: -28.58, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -31.77, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 22.68, Length: 13
DEBUG (Env): Episode done for env 98. Reward: 16.58, Length: 1
DEBUG (Env): Episode done for env 109. Reward: 26.11, Length: 7
DEBUG (Env): Episode done for env 127. Reward: 14.64, Length: 30
962
Time taken for simulation:  7.072347164154053
average overall reward:  -0.097483546  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.08041888  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 12. Reward: -18.48, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 14.70, Length: 9
DEBUG (Env): Episode done for env 55. Reward: -17.96, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 23.93, Length: 3
963
Time taken for simulation:  7.042886734008789
average overall reward:  -0.07105939  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  -0.20684949  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: -25.45, Length: 36
DEBUG (Env): Episode done for env 3. Reward: 17.04, Length: 3
DEBUG (Env): Episode done for env 30. Reward: -17.19, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -26.49, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 18.58, Length: 22
DEBUG (Env): Episode done for env 63. Reward: 19.26, Length: 15
DEBUG (Env): Episode done for env 78. Reward: -20.38, Length: 36
964
Time taken for simulation:  7.093982458114624
average overall reward:  0.65653414  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168783 average distance reward:  0.17072532  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: 18.96, Length: 1
DEBUG (Env): Episode done for env 4. Reward: -19.82, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 21.27, Length: 9
DEBUG (Env): Episode done for env 30. Reward: 24.20, Length: 1
DEBUG (Env): Episode done for env 56. Reward: 33.80, Length: 15
DEBUG (Env): Episode done for env 77. Reward: 13.93, Length: 14
DEBUG (Env): Episode done for env 92. Reward: 24.85, Length: 6
DEBUG (Env): Episode done for env 126. Reward: -19.56, Length: 36
965
Time taken for simulation:  7.121262550354004
average overall reward:  0.42142844  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.27968356  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 45. Reward: 13.19, Length: 29
DEBUG (Env): Episode done for env 53. Reward: 29.22, Length: 4
DEBUG (Env): Episode done for env 66. Reward: 40.52, Length: 13
DEBUG (Env): Episode done for env 68. Reward: -10.66, Length: 36
966
Time taken for simulation:  7.206662654876709
average overall reward:  0.4569425  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.1283394  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: 50.30, Length: 18
DEBUG (Env): Episode done for env 18. Reward: 14.36, Length: 23
DEBUG (Env): Episode done for env 58. Reward: 31.27, Length: 12
DEBUG (Env): Episode done for env 69. Reward: 14.27, Length: 6
DEBUG (Env): Episode done for env 96. Reward: -18.07, Length: 36
967
Time taken for simulation:  7.20734429359436
average overall reward:  0.29819041  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.08312568  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 21. Reward: 13.63, Length: 16
DEBUG (Env): Episode done for env 32. Reward: -13.78, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -14.49, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 16.76, Length: 20
DEBUG (Env): Episode done for env 65. Reward: 10.59, Length: 12
DEBUG (Env): Episode done for env 87. Reward: 6.32, Length: 24
968
Time taken for simulation:  7.386645078659058
average overall reward:  0.5266374  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  0.13758594  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 21. Reward: 22.20, Length: 1
DEBUG (Env): Episode done for env 22. Reward: 11.29, Length: 24
DEBUG (Env): Episode done for env 24. Reward: 14.23, Length: 7
DEBUG (Env): Episode done for env 69. Reward: 35.39, Length: 2
DEBUG (Env): Episode done for env 85. Reward: 3.64, Length: 28
DEBUG (Env): Episode done for env 93. Reward: -22.37, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -13.74, Length: 36
969
Time taken for simulation:  7.641391038894653
average overall reward:  0.2488803  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.03221173  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 14. Reward: 30.96, Length: 9
DEBUG (Env): Episode done for env 61. Reward: 23.55, Length: 32
DEBUG (Env): Episode done for env 79. Reward: 19.46, Length: 17
970
Time taken for simulation:  7.327817916870117
average overall reward:  0.15717885  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.0131284  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -9.56, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -13.15, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 21.88, Length: 4
DEBUG (Env): Episode done for env 98. Reward: 25.43, Length: 9
DEBUG (Env): Episode done for env 109. Reward: 13.23, Length: 9
971
Time taken for simulation:  7.3117945194244385
average overall reward:  -0.26464045  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  -0.015446357  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 23. Reward: -18.81, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -16.58, Length: 36
972
Time taken for simulation:  7.32111930847168
average overall reward:  -0.2546717  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.11584391 average distance reward:  -0.17946425  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 47. Reward: -12.87, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 16.90, Length: 4
DEBUG (Env): Episode done for env 89. Reward: -20.15, Length: 36
973
Time taken for simulation:  7.243756532669067
average overall reward:  -0.3921432  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.28658146  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 35. Reward: 26.01, Length: 10
974
Time taken for simulation:  7.01598334312439
average overall reward:  -0.07564095  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.10615311  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: 13.68, Length: 10
DEBUG (Env): Episode done for env 33. Reward: -17.24, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 13.40, Length: 4
DEBUG (Env): Episode done for env 117. Reward: -17.55, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 0.78, Length: 28
DEBUG (Env): Episode done for env 122. Reward: -19.78, Length: 36
975
Time taken for simulation:  7.229377746582031
average overall reward:  0.18543139  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.283174 average distance reward:  0.045290433  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: -22.33, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 0.15, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -12.89, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 14.14, Length: 3
DEBUG (Env): Episode done for env 80. Reward: 26.27, Length: 28
DEBUG (Env): Episode done for env 107. Reward: 15.28, Length: 23
976
Time taken for simulation:  7.343448162078857
average overall reward:  0.26612467  average fail penalty:  -0.09375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.23168781 average distance reward:  -0.03743709  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: -18.27, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -16.10, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 11.05, Length: 28
DEBUG (Env): Episode done for env 52. Reward: 21.20, Length: 2
DEBUG (Env): Episode done for env 53. Reward: 29.16, Length: 11
DEBUG (Env): Episode done for env 59. Reward: -14.02, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 16.83, Length: 8
DEBUG (Env): Episode done for env 75. Reward: 4.68, Length: 36
977
Time taken for simulation:  7.214393615722656
average overall reward:  0.012267031  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.089078255  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: -20.15, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 14.56, Length: 12
DEBUG (Env): Episode done for env 70. Reward: -13.02, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -18.50, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -23.51, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 23.83, Length: 3
978
Time taken for simulation:  7.597868204116821
average overall reward:  -0.09108692  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.14503653  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: 18.09, Length: 12
DEBUG (Env): Episode done for env 7. Reward: -22.60, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 11.26, Length: 23
DEBUG (Env): Episode done for env 103. Reward: 42.93, Length: 16
DEBUG (Env): Episode done for env 108. Reward: -28.57, Length: 36
979
Time taken for simulation:  7.267686128616333
average overall reward:  0.7346302  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.44003057  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 8.60, Length: 15
DEBUG (Env): Episode done for env 7. Reward: 17.12, Length: 1
DEBUG (Env): Episode done for env 34. Reward: -19.30, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 15.74, Length: 6
DEBUG (Env): Episode done for env 39. Reward: 24.82, Length: 4
DEBUG (Env): Episode done for env 102. Reward: -25.00, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -16.04, Length: 36
980
Time taken for simulation:  7.455569744110107
average overall reward:  -0.052528292  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.03315802  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 51. Reward: -7.70, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 27.36, Length: 4
DEBUG (Env): Episode done for env 68. Reward: 32.55, Length: 15
981
Time taken for simulation:  7.09504508972168
average overall reward:  0.3290345  average fail penalty:  -0.09375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  -0.05175654  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 20. Reward: 12.57, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 30.76, Length: 30
DEBUG (Env): Episode done for env 36. Reward: -17.19, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 20.04, Length: 24
DEBUG (Env): Episode done for env 45. Reward: 11.01, Length: 16
DEBUG (Env): Episode done for env 70. Reward: 21.91, Length: 4
DEBUG (Env): Episode done for env 90. Reward: -21.21, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -15.28, Length: 36
982
Time taken for simulation:  7.028931617736816
average overall reward:  -0.6034297  average fail penalty:  -0.1875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.28462493  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 10. Reward: -1.54, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -9.62, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -14.21, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 13.22, Length: 19
DEBUG (Env): Episode done for env 81. Reward: -11.40, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -20.20, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -19.39, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -28.51, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -21.61, Length: 36
983
Time taken for simulation:  7.2393598556518555
average overall reward:  -0.20194934  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.062384203  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 54. Reward: -19.21, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -12.87, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 17.72, Length: 6
984
Time taken for simulation:  7.104550361633301
average overall reward:  -0.08223618  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.124918096  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 15. Reward: 22.29, Length: 9
DEBUG (Env): Episode done for env 76. Reward: 36.21, Length: 2
985
Time taken for simulation:  7.160488843917847
average overall reward:  -0.04861726  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  -0.020986632  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: -12.75, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -20.31, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 30.19, Length: 3
DEBUG (Env): Episode done for env 110. Reward: 12.93, Length: 25
DEBUG (Env): Episode done for env 121. Reward: -16.79, Length: 36
986
Time taken for simulation:  6.997385263442993
average overall reward:  -0.10083023  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.032279376  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 38. Reward: -7.04, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 43.52, Length: 3
DEBUG (Env): Episode done for env 104. Reward: -18.23, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 17.64, Length: 4
987
Time taken for simulation:  7.0977935791015625
average overall reward:  -0.21898976  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.032509908  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 28. Reward: -17.25, Length: 36
988
Time taken for simulation:  7.0987772941589355
average overall reward:  -0.15677533  average fail penalty:  -0.140625  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  0.23765492  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 19. Reward: -15.82, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -10.71, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -21.15, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -30.30, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -17.14, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -10.90, Length: 36
989
Time taken for simulation:  7.178899526596069
average overall reward:  -0.23483491  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.117103435  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: 22.87, Length: 13
DEBUG (Env): Episode done for env 16. Reward: -18.56, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -22.75, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 23.97, Length: 31
DEBUG (Env): Episode done for env 94. Reward: -15.62, Length: 36
990
Time taken for simulation:  7.32560133934021
average overall reward:  -0.117634155  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  0.12029219  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 10. Reward: 35.00, Length: 8
DEBUG (Env): Episode done for env 31. Reward: -22.49, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -24.53, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -24.43, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -20.57, Length: 36
991
Time taken for simulation:  7.173446178436279
average overall reward:  -0.105087414  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.32245773  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 18.75, Length: 12
DEBUG (Env): Episode done for env 43. Reward: -24.56, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -0.76, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 19.54, Length: 19
DEBUG (Env): Episode done for env 99. Reward: 14.04, Length: 3
DEBUG (Env): Episode done for env 101. Reward: -4.26, Length: 36
992
Time taken for simulation:  6.910241603851318
average overall reward:  -0.116564944  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  0.01838904  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 71. Reward: -10.85, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -22.01, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 21.94, Length: 25
DEBUG (Env): Episode done for env 95. Reward: -9.48, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -18.27, Length: 36
993
Time taken for simulation:  7.212537050247192
average overall reward:  -0.04583098  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.03328583  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 13.71, Length: 5
DEBUG (Env): Episode done for env 27. Reward: -15.18, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 24.11, Length: 6
DEBUG (Env): Episode done for env 86. Reward: -0.23, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -19.40, Length: 36
994
Time taken for simulation:  7.098373889923096
average overall reward:  -0.22137308  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.090068325  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 119. Reward: 14.30, Length: 12
995
Time taken for simulation:  7.103466510772705
average overall reward:  0.2357123  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  -0.10646409  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: -2.39, Length: 32
DEBUG (Env): Episode done for env 25. Reward: -20.67, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 26.58, Length: 14
DEBUG (Env): Episode done for env 41. Reward: -22.55, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 18.14, Length: 7
DEBUG (Env): Episode done for env 62. Reward: -13.46, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 8.25, Length: 34
DEBUG (Env): Episode done for env 80. Reward: 10.92, Length: 20
DEBUG (Env): Episode done for env 82. Reward: -15.39, Length: 36
996
Time taken for simulation:  6.981459379196167
average overall reward:  0.04122621  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.024287388  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 23. Reward: 6.82, Length: 25
DEBUG (Env): Episode done for env 104. Reward: 15.93, Length: 10
997
Time taken for simulation:  7.058922290802002
average overall reward:  0.17971829  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.1620777  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: -22.71, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 23.97, Length: 16
DEBUG (Env): Episode done for env 73. Reward: -10.26, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 22.91, Length: 28
DEBUG (Env): Episode done for env 95. Reward: 24.80, Length: 5
DEBUG (Env): Episode done for env 127. Reward: -21.94, Length: 36
998
Time taken for simulation:  7.5644001960754395
average overall reward:  -0.12606579  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  0.024065346  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 12. Reward: -19.54, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -19.66, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -19.34, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 17.41, Length: 3
999
Time taken for simulation:  7.080591440200806
average overall reward:  0.1807319  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  -0.09869058  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: 25.33, Length: 6
DEBUG (Env): Episode done for env 40. Reward: -12.80, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 17.73, Length: 10
DEBUG (Env): Episode done for env 62. Reward: 24.92, Length: 4
DEBUG (Env): Episode done for env 63. Reward: -18.70, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 18.93, Length: 28
1000
Time taken for simulation:  7.030986309051514
average overall reward:  -0.17077184  average fail penalty:  -0.140625  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.036800236  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: -15.90, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -20.35, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -10.40, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -2.96, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -15.01, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -22.91, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 23.30, Length: 3
1001
Time taken for simulation:  7.83951210975647
average overall reward:  -0.4244659  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.3089171 average distance reward:  -0.06768824  and average step penalty:  -0.04786053509430681
Number of done instances:  0
1002
Time taken for simulation:  7.334317922592163
average overall reward:  -0.41609478  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.063928336  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 18. Reward: -18.82, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -12.23, Length: 36
1003
Time taken for simulation:  7.096028089523315
average overall reward:  0.121294916  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.11422026  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 18.96, Length: 1
DEBUG (Env): Episode done for env 21. Reward: 3.49, Length: 35
DEBUG (Env): Episode done for env 27. Reward: 24.92, Length: 4
DEBUG (Env): Episode done for env 32. Reward: -14.85, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -25.37, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -14.71, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -19.70, Length: 36
1004
Time taken for simulation:  7.157330274581909
average overall reward:  0.33542734  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.102879934  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: 17.84, Length: 35
DEBUG (Env): Episode done for env 22. Reward: -19.11, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -14.00, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 18.26, Length: 1
DEBUG (Env): Episode done for env 80. Reward: 29.34, Length: 9
DEBUG (Env): Episode done for env 93. Reward: -19.63, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 19.15, Length: 26
DEBUG (Env): Episode done for env 105. Reward: -6.91, Length: 36
1005
Time taken for simulation:  7.758591413497925
average overall reward:  0.047291428  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594475 average distance reward:  -0.2169539  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 18.59, Length: 35
DEBUG (Env): Episode done for env 18. Reward: 22.78, Length: 2
DEBUG (Env): Episode done for env 44. Reward: 11.20, Length: 29
DEBUG (Env): Episode done for env 61. Reward: -7.82, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 11.75, Length: 24
1006
Time taken for simulation:  7.016937494277954
average overall reward:  0.20714523  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.060789205  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 22. Reward: 28.94, Length: 2
DEBUG (Env): Episode done for env 39. Reward: 3.49, Length: 27
DEBUG (Env): Episode done for env 96. Reward: -13.38, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -22.18, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -19.24, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 33.61, Length: 16
1007
Time taken for simulation:  7.0795557498931885
average overall reward:  -0.10016063  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.12997095  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 32. Reward: 23.16, Length: 4
DEBUG (Env): Episode done for env 115. Reward: 20.56, Length: 17
1008
Time taken for simulation:  7.534945726394653
average overall reward:  0.17012072  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  -0.22949663  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 23. Reward: 21.03, Length: 12
DEBUG (Env): Episode done for env 24. Reward: 18.31, Length: 4
DEBUG (Env): Episode done for env 80. Reward: 19.72, Length: 4
DEBUG (Env): Episode done for env 85. Reward: -23.89, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 19.10, Length: 16
DEBUG (Env): Episode done for env 89. Reward: 10.70, Length: 17
1009
Time taken for simulation:  7.3547937870025635
average overall reward:  -0.30316702  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.32178864 average distance reward:  -0.06888984  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 86. Reward: 14.81, Length: 16
1010
Time taken for simulation:  7.450659990310669
average overall reward:  -0.06836046  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  0.10520814  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: -18.34, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -26.67, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 45.09, Length: 11
DEBUG (Env): Episode done for env 120. Reward: -13.90, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -19.91, Length: 36
1011
Time taken for simulation:  7.453460693359375
average overall reward:  0.112567335  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.05631206  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: -29.03, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 11.45, Length: 1
DEBUG (Env): Episode done for env 39. Reward: 13.26, Length: 5
DEBUG (Env): Episode done for env 47. Reward: -18.65, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 19.50, Length: 6
DEBUG (Env): Episode done for env 107. Reward: -20.90, Length: 36
1012
Time taken for simulation:  7.5325767993927
average overall reward:  -0.21798044  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.1692179  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: -6.58, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 10.95, Length: 7
DEBUG (Env): Episode done for env 27. Reward: 24.21, Length: 9
DEBUG (Env): Episode done for env 53. Reward: -11.96, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -14.20, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -9.04, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -23.59, Length: 36
1013
Time taken for simulation:  7.150406837463379
average overall reward:  0.11160328  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  -0.024186783  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: -22.42, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 24.26, Length: 2
DEBUG (Env): Episode done for env 19. Reward: 16.73, Length: 20
DEBUG (Env): Episode done for env 31. Reward: 2.04, Length: 23
DEBUG (Env): Episode done for env 88. Reward: -27.46, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -23.60, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -11.65, Length: 36
1014
Time taken for simulation:  7.324430227279663
average overall reward:  0.03000056  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  0.04475967  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: -13.38, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 15.86, Length: 8
DEBUG (Env): Episode done for env 91. Reward: -24.42, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -12.84, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 18.83, Length: 14
1015
Time taken for simulation:  7.27717924118042
average overall reward:  -0.11030853  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.13256028  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: -18.86, Length: 36
DEBUG (Env): Episode done for env 8. Reward: 2.73, Length: 30
DEBUG (Env): Episode done for env 34. Reward: -26.95, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -9.23, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 29.07, Length: 3
DEBUG (Env): Episode done for env 102. Reward: -9.75, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -29.28, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 18.74, Length: 5
1016
Time taken for simulation:  7.400715351104736
average overall reward:  -0.2805956  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168783 average distance reward:  -0.066106774  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 49. Reward: 0.53, Length: 31
DEBUG (Env): Episode done for env 51. Reward: -12.65, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -12.59, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -11.18, Length: 36
1017
Time taken for simulation:  7.304182291030884
average overall reward:  -0.12526603  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  0.039340414  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 29. Reward: -29.34, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -19.74, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -9.58, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 12.23, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 30.99, Length: 9
DEBUG (Env): Episode done for env 111. Reward: -28.36, Length: 36
1018
Time taken for simulation:  6.939390659332275
average overall reward:  0.27883595  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.115843914 average distance reward:  0.26554638  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 17.28, Length: 14
DEBUG (Env): Episode done for env 78. Reward: -24.62, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -20.42, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -20.34, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 26.77, Length: 11
DEBUG (Env): Episode done for env 124. Reward: -20.89, Length: 36
1019
Time taken for simulation:  7.092923402786255
average overall reward:  0.44460016  average fail penalty:  -0.046875  and average goal bonus:  0.8122322  and average same cell penalty:  -0.24455938 average distance reward:  -0.028337091  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: 15.26, Length: 19
DEBUG (Env): Episode done for env 14. Reward: 17.58, Length: 1
DEBUG (Env): Episode done for env 33. Reward: 42.75, Length: 9
DEBUG (Env): Episode done for env 54. Reward: -21.47, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -25.31, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 33.93, Length: 7
DEBUG (Env): Episode done for env 109. Reward: 12.23, Length: 13
DEBUG (Env): Episode done for env 124. Reward: 26.04, Length: 1
1020
Time taken for simulation:  7.05303692817688
average overall reward:  0.05230269  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.10798206  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 15. Reward: -20.34, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 30.80, Length: 5
DEBUG (Env): Episode done for env 76. Reward: -6.21, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 23.94, Length: 10
1021
Time taken for simulation:  7.622621059417725
average overall reward:  0.22114298  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.029515743  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: 27.68, Length: 6
DEBUG (Env): Episode done for env 30. Reward: 22.62, Length: 21
DEBUG (Env): Episode done for env 44. Reward: 14.76, Length: 16
DEBUG (Env): Episode done for env 50. Reward: 25.96, Length: 17
DEBUG (Env): Episode done for env 74. Reward: -10.92, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -29.73, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -26.48, Length: 36
1022
Time taken for simulation:  7.189932346343994
average overall reward:  0.117224246  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.093368694  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 27. Reward: 23.47, Length: 10
DEBUG (Env): Episode done for env 38. Reward: -8.63, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -18.41, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -0.18, Length: 18
DEBUG (Env): Episode done for env 112. Reward: -23.27, Length: 36
1023
Time taken for simulation:  7.494830846786499
average overall reward:  -0.091902554  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.2570849  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 51. Reward: 25.25, Length: 7
DEBUG (Env): Episode done for env 65. Reward: 20.38, Length: 20
DEBUG (Env): Episode done for env 120. Reward: 27.05, Length: 8
1024
Time taken for simulation:  7.224425554275513
average overall reward:  0.03991335  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.119030096  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 29. Reward: 17.50, Length: 7
DEBUG (Env): Episode done for env 43. Reward: 8.01, Length: 33
DEBUG (Env): Episode done for env 84. Reward: -13.64, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -17.36, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -14.74, Length: 36
1025
Time taken for simulation:  7.283337831497192
average overall reward:  0.22651736  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.26471394  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: -18.95, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 15.17, Length: 6
DEBUG (Env): Episode done for env 16. Reward: -18.16, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -22.16, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 19.13, Length: 8
DEBUG (Env): Episode done for env 94. Reward: -20.12, Length: 36
1026
Time taken for simulation:  7.179172992706299
average overall reward:  -0.30384368  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.2610359  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: -15.77, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 23.22, Length: 28
DEBUG (Env): Episode done for env 22. Reward: 14.51, Length: 12
DEBUG (Env): Episode done for env 83. Reward: -25.81, Length: 36
1027
Time taken for simulation:  7.487822771072388
average overall reward:  0.33485144  average fail penalty:  -0.09375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  0.0055466406  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: -20.31, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 19.12, Length: 14
DEBUG (Env): Episode done for env 22. Reward: 11.28, Length: 1
DEBUG (Env): Episode done for env 45. Reward: 27.59, Length: 10
DEBUG (Env): Episode done for env 64. Reward: -16.65, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 22.07, Length: 7
DEBUG (Env): Episode done for env 82. Reward: 21.76, Length: 29
DEBUG (Env): Episode done for env 99. Reward: -9.37, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -13.80, Length: 36
1028
Time taken for simulation:  7.1445653438568115
average overall reward:  0.41863722  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.4076532  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 43. Reward: 33.37, Length: 4
DEBUG (Env): Episode done for env 71. Reward: -20.33, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -16.91, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 21.89, Length: 7
DEBUG (Env): Episode done for env 123. Reward: -23.23, Length: 36
1029
Time taken for simulation:  7.083908796310425
average overall reward:  -0.1717334  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.16754028  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: -22.61, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 8.54, Length: 13
DEBUG (Env): Episode done for env 55. Reward: 13.13, Length: 31
DEBUG (Env): Episode done for env 106. Reward: -13.99, Length: 36
1030
Time taken for simulation:  7.030390501022339
average overall reward:  0.19882838  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.082826644  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: 24.24, Length: 18
DEBUG (Env): Episode done for env 74. Reward: 13.97, Length: 9
DEBUG (Env): Episode done for env 119. Reward: -50.23, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 55.88, Length: 6
1031
Time taken for simulation:  7.206913232803345
average overall reward:  0.0076019764  average fail penalty:  -0.140625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.283174 average distance reward:  -0.062226593  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 2. Reward: 12.55, Length: 4
DEBUG (Env): Episode done for env 3. Reward: -21.69, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -27.27, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -18.50, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -19.17, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 21.24, Length: 3
DEBUG (Env): Episode done for env 59. Reward: 25.51, Length: 11
DEBUG (Env): Episode done for env 60. Reward: -15.74, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -12.09, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 18.00, Length: 15
1032
Time taken for simulation:  7.842975378036499
average overall reward:  -0.0123474  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  -0.031591766  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: 13.19, Length: 29
DEBUG (Env): Episode done for env 104. Reward: -14.90, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 21.21, Length: 9
1033
Time taken for simulation:  7.3952577114105225
average overall reward:  0.0020495653  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.005540848  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 0. Reward: -23.87, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 14.34, Length: 13
DEBUG (Env): Episode done for env 20. Reward: -20.90, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -13.80, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 9.19, Length: 15
DEBUG (Env): Episode done for env 79. Reward: -14.52, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -19.52, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 23.41, Length: 15
1034
Time taken for simulation:  7.6561620235443115
average overall reward:  0.41777617  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.115843914 average distance reward:  -0.07194204  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 20. Reward: 24.21, Length: 1
DEBUG (Env): Episode done for env 36. Reward: 30.49, Length: 3
DEBUG (Env): Episode done for env 48. Reward: -6.17, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 11.81, Length: 34
DEBUG (Env): Episode done for env 80. Reward: 27.29, Length: 17
DEBUG (Env): Episode done for env 125. Reward: 6.07, Length: 4
1035
Time taken for simulation:  7.305654287338257
average overall reward:  -0.2590837  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  -0.08551507  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: 10.87, Length: 27
DEBUG (Env): Episode done for env 40. Reward: -13.47, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -25.02, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -14.29, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -18.04, Length: 36
1036
Time taken for simulation:  7.519275188446045
average overall reward:  -0.05655402  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.003180325  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 64. Reward: 19.12, Length: 9
DEBUG (Env): Episode done for env 77. Reward: -17.77, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 17.63, Length: 12
DEBUG (Env): Episode done for env 92. Reward: -15.54, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -21.34, Length: 36
1037
Time taken for simulation:  7.370620965957642
average overall reward:  0.82541126  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.56347156  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: 16.44, Length: 4
DEBUG (Env): Episode done for env 43. Reward: 42.64, Length: 6
DEBUG (Env): Episode done for env 108. Reward: 33.67, Length: 23
DEBUG (Env): Episode done for env 118. Reward: 2.96, Length: 31
1038
Time taken for simulation:  7.161564111709595
average overall reward:  0.9033863  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020163 average distance reward:  0.34265375  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 40. Reward: 26.36, Length: 3
DEBUG (Env): Episode done for env 54. Reward: 17.65, Length: 19
DEBUG (Env): Episode done for env 58. Reward: -25.49, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 14.27, Length: 19
DEBUG (Env): Episode done for env 72. Reward: 15.90, Length: 10
DEBUG (Env): Episode done for env 95. Reward: 28.31, Length: 5
DEBUG (Env): Episode done for env 127. Reward: 25.72, Length: 2
1039
Time taken for simulation:  7.056487083435059
average overall reward:  0.050964803  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.04459199  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 21. Reward: -18.34, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 23.25, Length: 4
DEBUG (Env): Episode done for env 73. Reward: 24.39, Length: 6
1040
Time taken for simulation:  7.078359127044678
average overall reward:  -0.5978798  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.35534233  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 22. Reward: 13.43, Length: 13
DEBUG (Env): Episode done for env 93. Reward: -15.36, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -10.90, Length: 36
1041
Time taken for simulation:  7.663627624511719
average overall reward:  -0.016547792  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.039131492  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: -21.30, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 4.58, Length: 34
DEBUG (Env): Episode done for env 82. Reward: 29.68, Length: 14
DEBUG (Env): Episode done for env 90. Reward: -21.25, Length: 36
1042
Time taken for simulation:  7.042798042297363
average overall reward:  0.2974818  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.14055976  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: 16.26, Length: 16
DEBUG (Env): Episode done for env 13. Reward: 27.42, Length: 15
DEBUG (Env): Episode done for env 45. Reward: 36.30, Length: 15
DEBUG (Env): Episode done for env 96. Reward: -11.23, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -3.66, Length: 36
1043
Time taken for simulation:  7.171385049819946
average overall reward:  0.06419128  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.0729956  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 62. Reward: 14.53, Length: 4
DEBUG (Env): Episode done for env 85. Reward: 9.04, Length: 35
1044
Time taken for simulation:  7.2333903312683105
average overall reward:  -0.09521243  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  -0.20295385  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 30.76, Length: 29
DEBUG (Env): Episode done for env 23. Reward: -10.58, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -21.26, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -15.87, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 24.46, Length: 3
DEBUG (Env): Episode done for env 112. Reward: 11.02, Length: 22
1045
Time taken for simulation:  7.286150693893433
average overall reward:  -0.006282054  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.24521762  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 86. Reward: -5.68, Length: 36
1046
Time taken for simulation:  7.130405902862549
average overall reward:  0.4742824  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.07466513  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 51. Reward: 39.04, Length: 23
DEBUG (Env): Episode done for env 63. Reward: 24.57, Length: 11
DEBUG (Env): Episode done for env 68. Reward: 12.97, Length: 15
DEBUG (Env): Episode done for env 76. Reward: 18.45, Length: 19
DEBUG (Env): Episode done for env 97. Reward: -10.31, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 26.64, Length: 22
1047
Time taken for simulation:  7.354101657867432
average overall reward:  0.10723612  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.12359896  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: -20.31, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 34.05, Length: 13
DEBUG (Env): Episode done for env 39. Reward: -23.24, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -16.47, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -24.65, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 28.44, Length: 8
DEBUG (Env): Episode done for env 107. Reward: -22.82, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 17.04, Length: 1
1048
Time taken for simulation:  7.382389307022095
average overall reward:  -0.4106713  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.022195842  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: -13.98, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -20.82, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -17.26, Length: 36
1049
Time taken for simulation:  7.128038167953491
average overall reward:  0.8680041  average fail penalty:  -0.140625  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.38584447  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 3. Reward: 22.61, Length: 18
DEBUG (Env): Episode done for env 14. Reward: 30.14, Length: 24
DEBUG (Env): Episode done for env 17. Reward: -12.13, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -17.08, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 24.43, Length: 20
DEBUG (Env): Episode done for env 31. Reward: -16.73, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 33.67, Length: 20
DEBUG (Env): Episode done for env 88. Reward: -18.98, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 39.71, Length: 5
DEBUG (Env): Episode done for env 100. Reward: 11.68, Length: 31
DEBUG (Env): Episode done for env 114. Reward: -12.22, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -1.32, Length: 36
1050
Time taken for simulation:  7.380259990692139
average overall reward:  0.5892446  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.07538716  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: 20.04, Length: 13
DEBUG (Env): Episode done for env 6. Reward: -20.14, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 2.53, Length: 28
DEBUG (Env): Episode done for env 39. Reward: 29.09, Length: 3
DEBUG (Env): Episode done for env 86. Reward: 21.77, Length: 5
DEBUG (Env): Episode done for env 90. Reward: 20.54, Length: 6
DEBUG (Env): Episode done for env 91. Reward: -18.79, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 5.07, Length: 20
DEBUG (Env): Episode done for env 126. Reward: -21.05, Length: 36
1051
Time taken for simulation:  7.0492730140686035
average overall reward:  -0.073547356  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  0.15150748  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: -16.68, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -19.82, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 20.80, Length: 4
DEBUG (Env): Episode done for env 102. Reward: -18.02, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -19.81, Length: 36
1052
Time taken for simulation:  6.98993706703186
average overall reward:  0.3383125  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.08693876  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: 20.15, Length: 21
DEBUG (Env): Episode done for env 23. Reward: 26.33, Length: 8
DEBUG (Env): Episode done for env 44. Reward: 5.77, Length: 31
DEBUG (Env): Episode done for env 49. Reward: -13.58, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 12.04, Length: 3
1053
Time taken for simulation:  7.281418561935425
average overall reward:  -0.23533574  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.20539953  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 40. Reward: 40.86, Length: 15
DEBUG (Env): Episode done for env 42. Reward: -15.37, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 24.40, Length: 15
DEBUG (Env): Episode done for env 111. Reward: -15.25, Length: 36
1054
Time taken for simulation:  7.322657108306885
average overall reward:  -0.13629493  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  -0.16841084  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: 17.03, Length: 5
DEBUG (Env): Episode done for env 81. Reward: -16.44, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 9.99, Length: 10
1055
Time taken for simulation:  7.0826311111450195
average overall reward:  0.20194733  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.28932446  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: -19.38, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -3.12, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 25.52, Length: 4
DEBUG (Env): Episode done for env 57. Reward: -11.62, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -23.06, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 11.10, Length: 27
DEBUG (Env): Episode done for env 124. Reward: -14.01, Length: 36
1056
Time taken for simulation:  7.1839680671691895
average overall reward:  0.13634676  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.020344973  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 34. Reward: 30.33, Length: 5
DEBUG (Env): Episode done for env 68. Reward: 11.76, Length: 10
DEBUG (Env): Episode done for env 84. Reward: 8.33, Length: 20
DEBUG (Env): Episode done for env 122. Reward: -18.17, Length: 36
1057
Time taken for simulation:  7.069917440414429
average overall reward:  1.0959096  average fail penalty:  -0.09375  and average goal bonus:  1.0829761  and average same cell penalty:  -0.24455938 average distance reward:  0.39910337  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 2. Reward: 23.76, Length: 5
DEBUG (Env): Episode done for env 5. Reward: 36.36, Length: 10
DEBUG (Env): Episode done for env 8. Reward: -14.30, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 7.23, Length: 15
DEBUG (Env): Episode done for env 28. Reward: 13.25, Length: 8
DEBUG (Env): Episode done for env 30. Reward: -17.16, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 19.48, Length: 23
DEBUG (Env): Episode done for env 50. Reward: -21.69, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 22.40, Length: 23
DEBUG (Env): Episode done for env 105. Reward: 19.20, Length: 17
DEBUG (Env): Episode done for env 117. Reward: 15.56, Length: 5
DEBUG (Env): Episode done for env 121. Reward: -16.10, Length: 36
1058
Time taken for simulation:  7.453024864196777
average overall reward:  0.5595688  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.32932693  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 28.84, Length: 1
DEBUG (Env): Episode done for env 38. Reward: -14.08, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 10.54, Length: 29
DEBUG (Env): Episode done for env 66. Reward: -11.40, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 12.84, Length: 25
DEBUG (Env): Episode done for env 103. Reward: -27.60, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 25.48, Length: 5
1059
Time taken for simulation:  7.507927894592285
average overall reward:  0.17013916  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.015522783  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 27. Reward: 34.41, Length: 9
DEBUG (Env): Episode done for env 31. Reward: 15.62, Length: 10
DEBUG (Env): Episode done for env 52. Reward: 36.85, Length: 10
DEBUG (Env): Episode done for env 65. Reward: -29.24, Length: 36
1060
Time taken for simulation:  7.408819198608398
average overall reward:  -0.4234137  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.094684795  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 29. Reward: -0.10, Length: 36
1061
Time taken for simulation:  7.279041290283203
average overall reward:  -0.56662595  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.279519  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 16.36, Length: 4
DEBUG (Env): Episode done for env 11. Reward: -20.21, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -24.90, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -18.86, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -43.37, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -17.62, Length: 36
1062
Time taken for simulation:  7.3677427768707275
average overall reward:  0.44218963  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.31101075  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 10. Reward: -19.63, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -18.13, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 21.03, Length: 12
DEBUG (Env): Episode done for env 121. Reward: 24.25, Length: 5
DEBUG (Env): Episode done for env 126. Reward: 19.07, Length: 12
1063
Time taken for simulation:  7.163542032241821
average overall reward:  0.2821725  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.010121502  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 20. Reward: 31.15, Length: 16
DEBUG (Env): Episode done for env 83. Reward: 8.46, Length: 1
DEBUG (Env): Episode done for env 95. Reward: 10.68, Length: 25
DEBUG (Env): Episode done for env 99. Reward: -18.77, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -13.97, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 21.91, Length: 12
1064
Time taken for simulation:  7.002697229385376
average overall reward:  -0.05080712  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.14337136  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 26. Reward: 25.71, Length: 3
DEBUG (Env): Episode done for env 71. Reward: -15.01, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 16.15, Length: 7
DEBUG (Env): Episode done for env 109. Reward: 12.10, Length: 9
DEBUG (Env): Episode done for env 110. Reward: -20.26, Length: 36
1065
Time taken for simulation:  7.04634428024292
average overall reward:  -0.07279791  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.17870174  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 106. Reward: -12.88, Length: 36
1066
Time taken for simulation:  7.0054357051849365
average overall reward:  0.29510975  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  0.09291661  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: 7.59, Length: 16
DEBUG (Env): Episode done for env 18. Reward: -33.43, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 16.69, Length: 25
DEBUG (Env): Episode done for env 40. Reward: 48.59, Length: 13
DEBUG (Env): Episode done for env 74. Reward: -18.02, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 14.29, Length: 17
1067
Time taken for simulation:  7.050508260726929
average overall reward:  -0.27861884  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.21698478  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 25. Reward: -12.90, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 16.51, Length: 12
DEBUG (Env): Episode done for env 41. Reward: -26.36, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 9.90, Length: 21
DEBUG (Env): Episode done for env 59. Reward: -21.22, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -19.69, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -25.16, Length: 36
1068
Time taken for simulation:  7.328406095504761
average overall reward:  -0.42956048  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.22794323  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 37. Reward: -19.69, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 10.17, Length: 15
DEBUG (Env): Episode done for env 104. Reward: -3.69, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -22.53, Length: 36
1069
Time taken for simulation:  7.019535541534424
average overall reward:  -0.22984459  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594472 average distance reward:  -0.17647088  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: -18.75, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 16.23, Length: 1
DEBUG (Env): Episode done for env 78. Reward: -21.75, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 21.92, Length: 8
DEBUG (Env): Episode done for env 115. Reward: -10.94, Length: 36
1070
Time taken for simulation:  7.430038928985596
average overall reward:  0.42734128  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  0.100341976  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 44. Reward: 24.34, Length: 18
DEBUG (Env): Episode done for env 48. Reward: -20.54, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -20.12, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 21.64, Length: 3
DEBUG (Env): Episode done for env 73. Reward: 20.52, Length: 19
DEBUG (Env): Episode done for env 78. Reward: 24.84, Length: 1
DEBUG (Env): Episode done for env 79. Reward: 20.58, Length: 12
DEBUG (Env): Episode done for env 125. Reward: -21.13, Length: 36
1071
Time taken for simulation:  7.012690782546997
average overall reward:  0.21684112  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.07279067  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: 17.64, Length: 13
DEBUG (Env): Episode done for env 5. Reward: 23.38, Length: 14
DEBUG (Env): Episode done for env 24. Reward: -13.88, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 19.56, Length: 4
DEBUG (Env): Episode done for env 46. Reward: -12.97, Length: 36
1072
Time taken for simulation:  6.997797966003418
average overall reward:  -0.18796338  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168783 average distance reward:  0.026525497  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 64. Reward: -6.73, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -17.96, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -16.66, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 26.79, Length: 26
1073
Time taken for simulation:  7.075833082199097
average overall reward:  0.27716538  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.30479598  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: 18.05, Length: 25
DEBUG (Env): Episode done for env 36. Reward: 20.84, Length: 16
DEBUG (Env): Episode done for env 43. Reward: -23.06, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -7.43, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -17.95, Length: 36
1074
Time taken for simulation:  7.352781534194946
average overall reward:  -0.059858065  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.10554731  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 54. Reward: -9.72, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 26.59, Length: 4
DEBUG (Env): Episode done for env 58. Reward: -20.21, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -17.84, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 20.75, Length: 11
DEBUG (Env): Episode done for env 110. Reward: 30.41, Length: 10
DEBUG (Env): Episode done for env 127. Reward: -11.95, Length: 36
1075
Time taken for simulation:  7.437116384506226
average overall reward:  0.35783118  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594472 average distance reward:  0.09358589  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: 12.06, Length: 26
DEBUG (Env): Episode done for env 21. Reward: -14.51, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 22.94, Length: 4
DEBUG (Env): Episode done for env 52. Reward: 23.56, Length: 16
DEBUG (Env): Episode done for env 68. Reward: 24.70, Length: 19
1076
Time taken for simulation:  7.315388917922974
average overall reward:  0.17688045  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  -0.0057846387  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: 7.81, Length: 34
DEBUG (Env): Episode done for env 22. Reward: -18.63, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 14.61, Length: 24
DEBUG (Env): Episode done for env 60. Reward: 19.49, Length: 9
DEBUG (Env): Episode done for env 93. Reward: -20.17, Length: 36
1077
Time taken for simulation:  7.098986864089966
average overall reward:  0.6930088  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.117099196  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -9.49, Length: 36
DEBUG (Env): Episode done for env 2. Reward: 40.72, Length: 6
DEBUG (Env): Episode done for env 8. Reward: 11.61, Length: 16
DEBUG (Env): Episode done for env 44. Reward: 2.69, Length: 7
DEBUG (Env): Episode done for env 82. Reward: -18.78, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 16.31, Length: 27
DEBUG (Env): Episode done for env 126. Reward: 19.98, Length: 15
1078
Time taken for simulation:  7.24558687210083
average overall reward:  0.18519782  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  0.19995692  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: 14.87, Length: 7
DEBUG (Env): Episode done for env 45. Reward: -17.36, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -15.11, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -21.69, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 17.33, Length: 20
1079
Time taken for simulation:  7.259956359863281
average overall reward:  0.29117385  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  -0.08500603  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 22.25, Length: 2
DEBUG (Env): Episode done for env 16. Reward: 21.35, Length: 18
DEBUG (Env): Episode done for env 62. Reward: -27.11, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -17.76, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 25.01, Length: 17
DEBUG (Env): Episode done for env 115. Reward: 23.08, Length: 10
DEBUG (Env): Episode done for env 122. Reward: 9.85, Length: 23
1080
Time taken for simulation:  7.712445497512817
average overall reward:  0.13564414  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.0212778  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -14.67, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 21.41, Length: 23
DEBUG (Env): Episode done for env 17. Reward: 8.94, Length: 26
DEBUG (Env): Episode done for env 68. Reward: 43.96, Length: 5
DEBUG (Env): Episode done for env 87. Reward: -18.16, Length: 36
1081
Time taken for simulation:  7.458555221557617
average overall reward:  0.15856847  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  0.23838714  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 24. Reward: 28.54, Length: 10
1082
Time taken for simulation:  7.053049802780151
average overall reward:  -0.43407267  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.19153517  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 4. Reward: 33.57, Length: 27
DEBUG (Env): Episode done for env 63. Reward: -17.73, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -12.35, Length: 36
1083
Time taken for simulation:  7.077725887298584
average overall reward:  -0.11915855  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.08015312  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: 38.96, Length: 17
DEBUG (Env): Episode done for env 47. Reward: -12.62, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -21.05, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -18.10, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -18.19, Length: 36
1084
Time taken for simulation:  7.484290361404419
average overall reward:  0.30555367  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.12871546 average distance reward:  -0.14785546  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 22.46, Length: 5
DEBUG (Env): Episode done for env 53. Reward: -11.54, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 13.49, Length: 14
DEBUG (Env): Episode done for env 74. Reward: 16.67, Length: 18
DEBUG (Env): Episode done for env 75. Reward: -11.66, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 8.79, Length: 26
DEBUG (Env): Episode done for env 113. Reward: 15.59, Length: 1
1085
Time taken for simulation:  7.0911242961883545
average overall reward:  0.05502951  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.103792004  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: -23.36, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -25.92, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 37.94, Length: 4
DEBUG (Env): Episode done for env 40. Reward: 33.72, Length: 19
DEBUG (Env): Episode done for env 88. Reward: -16.45, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -21.63, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -9.56, Length: 36
1086
Time taken for simulation:  7.085099935531616
average overall reward:  0.21208724  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.31464154  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: -20.19, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -19.95, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 2.75, Length: 34
DEBUG (Env): Episode done for env 64. Reward: 13.41, Length: 14
DEBUG (Env): Episode done for env 91. Reward: -19.29, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -14.73, Length: 36
1087
Time taken for simulation:  7.831547737121582
average overall reward:  -0.12395418  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.15607008  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 15. Reward: 1.09, Length: 18
DEBUG (Env): Episode done for env 116. Reward: -12.74, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 9.55, Length: 30
1088
Time taken for simulation:  7.410313844680786
average overall reward:  0.52347684  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.15856473  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 51. Reward: 23.20, Length: 21
DEBUG (Env): Episode done for env 59. Reward: 39.11, Length: 4
DEBUG (Env): Episode done for env 76. Reward: 26.49, Length: 6
DEBUG (Env): Episode done for env 123. Reward: 6.37, Length: 33
1089
Time taken for simulation:  7.470340251922607
average overall reward:  0.36157656  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.03297353  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 26. Reward: 36.60, Length: 25
DEBUG (Env): Episode done for env 65. Reward: 14.12, Length: 30
DEBUG (Env): Episode done for env 68. Reward: 41.68, Length: 9
DEBUG (Env): Episode done for env 69. Reward: -7.28, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 19.61, Length: 15
1090
Time taken for simulation:  7.116082668304443
average overall reward:  0.22568044  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.049230322  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 27.04, Length: 6
DEBUG (Env): Episode done for env 9. Reward: 14.63, Length: 17
DEBUG (Env): Episode done for env 14. Reward: 25.04, Length: 15
DEBUG (Env): Episode done for env 60. Reward: 14.98, Length: 14
DEBUG (Env): Episode done for env 81. Reward: -3.45, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -26.17, Length: 36
1091
Time taken for simulation:  7.2530505657196045
average overall reward:  0.466793  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.10117915  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 10. Reward: 7.16, Length: 29
DEBUG (Env): Episode done for env 35. Reward: -15.64, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 26.66, Length: 3
DEBUG (Env): Episode done for env 57. Reward: -40.66, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 11.20, Length: 21
DEBUG (Env): Episode done for env 100. Reward: 13.51, Length: 6
DEBUG (Env): Episode done for env 109. Reward: 18.36, Length: 27
DEBUG (Env): Episode done for env 124. Reward: -13.48, Length: 36
1092
Time taken for simulation:  7.286812782287598
average overall reward:  0.14437944  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  -0.032070696  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 18.61, Length: 5
DEBUG (Env): Episode done for env 23. Reward: 15.07, Length: 16
DEBUG (Env): Episode done for env 27. Reward: 8.86, Length: 33
DEBUG (Env): Episode done for env 34. Reward: -19.99, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 27.52, Length: 6
DEBUG (Env): Episode done for env 84. Reward: -37.61, Length: 36
1093
Time taken for simulation:  7.409236907958984
average overall reward:  0.3058288  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.07722928 average distance reward:  -0.15219152  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 23. Reward: 19.78, Length: 1
DEBUG (Env): Episode done for env 28. Reward: -20.05, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -20.70, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 24.62, Length: 10
DEBUG (Env): Episode done for env 50. Reward: -13.84, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 23.15, Length: 2
DEBUG (Env): Episode done for env 73. Reward: 34.78, Length: 23
DEBUG (Env): Episode done for env 89. Reward: 7.51, Length: 27
DEBUG (Env): Episode done for env 105. Reward: -14.91, Length: 36
1094
Time taken for simulation:  7.492776393890381
average overall reward:  0.31219858  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.03047054  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 16.83, Length: 3
DEBUG (Env): Episode done for env 34. Reward: 16.59, Length: 2
DEBUG (Env): Episode done for env 38. Reward: -10.23, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 22.07, Length: 19
DEBUG (Env): Episode done for env 55. Reward: -17.76, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -13.45, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 12.53, Length: 14
1095
Time taken for simulation:  7.263579607009888
average overall reward:  0.31882653  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.26096755  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 7. Reward: 17.97, Length: 15
DEBUG (Env): Episode done for env 23. Reward: 22.85, Length: 2
DEBUG (Env): Episode done for env 31. Reward: -20.96, Length: 36
1096
Time taken for simulation:  7.1312525272369385
average overall reward:  0.047320377  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.11584391 average distance reward:  0.099090256  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 29. Reward: -20.68, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 14.74, Length: 2
1097
Time taken for simulation:  7.180125713348389
average overall reward:  0.786924  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.5461162  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: -12.70, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 20.95, Length: 4
DEBUG (Env): Episode done for env 70. Reward: -4.02, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 30.66, Length: 6
DEBUG (Env): Episode done for env 103. Reward: 33.68, Length: 19
DEBUG (Env): Episode done for env 104. Reward: 5.41, Length: 29
1098
Time taken for simulation:  7.243735074996948
average overall reward:  0.65184927  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.27030247 average distance reward:  0.18121758  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 18.41, Length: 8
DEBUG (Env): Episode done for env 15. Reward: 17.08, Length: 6
DEBUG (Env): Episode done for env 47. Reward: 46.52, Length: 5
DEBUG (Env): Episode done for env 61. Reward: 31.75, Length: 15
DEBUG (Env): Episode done for env 62. Reward: 11.97, Length: 19
DEBUG (Env): Episode done for env 81. Reward: 25.19, Length: 8
DEBUG (Env): Episode done for env 121. Reward: -19.02, Length: 36
1099
Time taken for simulation:  7.888197898864746
average overall reward:  0.36889946  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.037289068  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 13. Reward: 24.77, Length: 23
DEBUG (Env): Episode done for env 20. Reward: -18.09, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 16.70, Length: 3
DEBUG (Env): Episode done for env 64. Reward: 18.80, Length: 13
DEBUG (Env): Episode done for env 66. Reward: 29.63, Length: 5
DEBUG (Env): Episode done for env 95. Reward: -19.67, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -18.86, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -25.76, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -24.39, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 27.49, Length: 12
1100
Time taken for simulation:  7.1017396450042725
average overall reward:  -0.022681274  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  0.116883874  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 32. Reward: 13.56, Length: 34
DEBUG (Env): Episode done for env 71. Reward: -13.70, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -20.51, Length: 36
1101
Time taken for simulation:  7.143233776092529
average overall reward:  0.34453484  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.22853312  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 79. Reward: 22.29, Length: 4
DEBUG (Env): Episode done for env 97. Reward: 16.02, Length: 29
DEBUG (Env): Episode done for env 106. Reward: -15.53, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 24.81, Length: 15
1102
Time taken for simulation:  7.420107126235962
average overall reward:  -0.18753843  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.19391128  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 6. Reward: -18.76, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 27.86, Length: 23
DEBUG (Env): Episode done for env 109. Reward: 20.79, Length: 11
1103
Time taken for simulation:  7.2388916015625
average overall reward:  0.411169  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.16805558  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 24.84, Length: 17
DEBUG (Env): Episode done for env 33. Reward: -23.07, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 14.63, Length: 30
DEBUG (Env): Episode done for env 41. Reward: -17.25, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -16.43, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 24.55, Length: 3
DEBUG (Env): Episode done for env 92. Reward: 14.25, Length: 31
1104
Time taken for simulation:  7.554419040679932
average overall reward:  0.2166658  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.049885154  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: 21.77, Length: 7
DEBUG (Env): Episode done for env 26. Reward: 23.62, Length: 15
DEBUG (Env): Episode done for env 31. Reward: 30.55, Length: 9
DEBUG (Env): Episode done for env 37. Reward: -12.12, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 24.47, Length: 6
DEBUG (Env): Episode done for env 120. Reward: -20.49, Length: 36
1105
Time taken for simulation:  7.663779973983765
average overall reward:  -0.00014284253  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.042664863  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: 5.33, Length: 28
DEBUG (Env): Episode done for env 33. Reward: 21.82, Length: 2
DEBUG (Env): Episode done for env 42. Reward: -20.08, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -12.90, Length: 36
1106
Time taken for simulation:  7.14350152015686
average overall reward:  0.44335097  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.22598061  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 30.89, Length: 3
DEBUG (Env): Episode done for env 11. Reward: 15.44, Length: 2
DEBUG (Env): Episode done for env 48. Reward: -4.70, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -18.00, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 17.15, Length: 19
DEBUG (Env): Episode done for env 123. Reward: 28.94, Length: 18
DEBUG (Env): Episode done for env 125. Reward: -14.42, Length: 36
1107
Time taken for simulation:  7.190611839294434
average overall reward:  0.3839622  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.19073126  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: -16.32, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 43.28, Length: 2
DEBUG (Env): Episode done for env 58. Reward: 24.96, Length: 33
DEBUG (Env): Episode done for env 89. Reward: 22.11, Length: 14
1108
Time taken for simulation:  7.408199310302734
average overall reward:  0.127602  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.014142893  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 35. Reward: 12.40, Length: 17
DEBUG (Env): Episode done for env 59. Reward: 8.94, Length: 20
DEBUG (Env): Episode done for env 77. Reward: -12.93, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 19.21, Length: 30
1109
Time taken for simulation:  7.63285756111145
average overall reward:  0.9270193  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168781 average distance reward:  0.46464804  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 5. Reward: 24.33, Length: 2
DEBUG (Env): Episode done for env 22. Reward: 5.77, Length: 33
DEBUG (Env): Episode done for env 43. Reward: -5.28, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 0.94, Length: 27
DEBUG (Env): Episode done for env 81. Reward: 15.56, Length: 11
DEBUG (Env): Episode done for env 83. Reward: 16.36, Length: 35
DEBUG (Env): Episode done for env 102. Reward: 20.42, Length: 10
DEBUG (Env): Episode done for env 108. Reward: -26.21, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -22.36, Length: 36
1110
Time taken for simulation:  7.145184516906738
average overall reward:  0.15297598  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.092443004  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 45. Reward: 10.17, Length: 32
DEBUG (Env): Episode done for env 54. Reward: -13.40, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -22.13, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -15.72, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 5.62, Length: 33
DEBUG (Env): Episode done for env 99. Reward: 24.57, Length: 11
DEBUG (Env): Episode done for env 105. Reward: 22.44, Length: 17
DEBUG (Env): Episode done for env 127. Reward: -22.74, Length: 36
1111
Time taken for simulation:  7.222867488861084
average overall reward:  0.19267331  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  -0.11249227  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: 12.26, Length: 5
DEBUG (Env): Episode done for env 20. Reward: 21.59, Length: 12
DEBUG (Env): Episode done for env 21. Reward: -18.79, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 14.24, Length: 18
DEBUG (Env): Episode done for env 40. Reward: 17.65, Length: 26
DEBUG (Env): Episode done for env 46. Reward: -19.70, Length: 36
1112
Time taken for simulation:  7.766599893569946
average overall reward:  0.18669984  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.044954956  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 34. Reward: 30.02, Length: 18
DEBUG (Env): Episode done for env 48. Reward: 19.23, Length: 6
DEBUG (Env): Episode done for env 69. Reward: 11.54, Length: 23
DEBUG (Env): Episode done for env 93. Reward: -23.09, Length: 36
1113
Time taken for simulation:  7.429082155227661
average overall reward:  -0.06648809  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.028291598  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: -15.75, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 19.24, Length: 13
DEBUG (Env): Episode done for env 44. Reward: -16.70, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -18.21, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 21.17, Length: 9
DEBUG (Env): Episode done for env 126. Reward: -20.19, Length: 36
1114
Time taken for simulation:  7.24957799911499
average overall reward:  0.40563148  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.28732416  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: -11.80, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 17.32, Length: 22
DEBUG (Env): Episode done for env 75. Reward: 7.85, Length: 30
DEBUG (Env): Episode done for env 96. Reward: -20.83, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 3.32, Length: 31
1115
Time taken for simulation:  7.187477111816406
average overall reward:  0.26082063  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.26661757  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 16. Reward: -15.58, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 35.58, Length: 5
DEBUG (Env): Episode done for env 87. Reward: 22.16, Length: 21
DEBUG (Env): Episode done for env 89. Reward: 25.99, Length: 8
DEBUG (Env): Episode done for env 90. Reward: -9.96, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -10.03, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -20.80, Length: 36
1116
Time taken for simulation:  7.152373790740967
average overall reward:  0.03548652  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  -0.044206172  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: -17.78, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -19.04, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 29.46, Length: 4
DEBUG (Env): Episode done for env 108. Reward: 17.88, Length: 7
DEBUG (Env): Episode done for env 126. Reward: 19.20, Length: 3
1117
Time taken for simulation:  7.367721080780029
average overall reward:  0.27766466  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.11248235  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 48. Reward: 23.27, Length: 5
DEBUG (Env): Episode done for env 56. Reward: 15.05, Length: 2
DEBUG (Env): Episode done for env 93. Reward: 16.13, Length: 5
1118
Time taken for simulation:  7.408164024353027
average overall reward:  0.28004926  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.13830438  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: 27.23, Length: 20
DEBUG (Env): Episode done for env 4. Reward: -43.50, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 9.73, Length: 11
DEBUG (Env): Episode done for env 91. Reward: 22.12, Length: 32
1119
Time taken for simulation:  7.597898483276367
average overall reward:  -0.12589847  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  0.080330014  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 18. Reward: -13.94, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 26.12, Length: 13
1120
Time taken for simulation:  7.131005525588989
average overall reward:  -0.11654569  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.1493634  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 28. Reward: 28.61, Length: 9
DEBUG (Env): Episode done for env 30. Reward: 16.84, Length: 27
DEBUG (Env): Episode done for env 53. Reward: -18.87, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 15.51, Length: 8
DEBUG (Env): Episode done for env 74. Reward: -0.10, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -17.58, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -19.61, Length: 36
1121
Time taken for simulation:  7.4325995445251465
average overall reward:  0.5387353  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.20712483  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 3. Reward: 5.90, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -21.48, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -16.88, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 4.88, Length: 30
DEBUG (Env): Episode done for env 63. Reward: 18.68, Length: 12
DEBUG (Env): Episode done for env 73. Reward: 28.01, Length: 28
DEBUG (Env): Episode done for env 88. Reward: -23.94, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 21.42, Length: 13
DEBUG (Env): Episode done for env 109. Reward: 20.25, Length: 19
DEBUG (Env): Episode done for env 114. Reward: -13.45, Length: 36
1122
Time taken for simulation:  7.4634504318237305
average overall reward:  -0.36423117  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.141587 average distance reward:  -0.15134606  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 39. Reward: -8.97, Length: 36
1123
Time taken for simulation:  7.3066246509552
average overall reward:  -0.07135217  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.023933278  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 6. Reward: 20.66, Length: 21
DEBUG (Env): Episode done for env 95. Reward: 16.25, Length: 24
1124
Time taken for simulation:  7.230503797531128
average overall reward:  0.35988417  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.21813932  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 32. Reward: 23.98, Length: 11
DEBUG (Env): Episode done for env 76. Reward: -16.84, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 18.41, Length: 3
DEBUG (Env): Episode done for env 111. Reward: 24.09, Length: 4
1125
Time taken for simulation:  7.162168025970459
average overall reward:  0.06437297  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  -0.28836936  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 22.58, Length: 7
DEBUG (Env): Episode done for env 18. Reward: 31.30, Length: 6
DEBUG (Env): Episode done for env 65. Reward: 11.52, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -20.11, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -1.04, Length: 25
DEBUG (Env): Episode done for env 76. Reward: 16.79, Length: 1
DEBUG (Env): Episode done for env 110. Reward: -9.13, Length: 36
1126
Time taken for simulation:  7.008410930633545
average overall reward:  -0.43339512  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  -0.3308408  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: -2.69, Length: 36
DEBUG (Env): Episode done for env 14. Reward: -16.17, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -26.36, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 16.88, Length: 27
DEBUG (Env): Episode done for env 112. Reward: -11.17, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 19.82, Length: 10
1127
Time taken for simulation:  7.21751594543457
average overall reward:  0.29672927  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.102972366 average distance reward:  0.088321105  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 38. Reward: 8.24, Length: 31
DEBUG (Env): Episode done for env 79. Reward: 13.85, Length: 26
DEBUG (Env): Episode done for env 100. Reward: -13.65, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 21.83, Length: 1
DEBUG (Env): Episode done for env 124. Reward: -14.09, Length: 36
1128
Time taken for simulation:  7.258303642272949
average overall reward:  0.6937901  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.27030247 average distance reward:  0.1112238  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 17. Reward: 18.24, Length: 12
DEBUG (Env): Episode done for env 27. Reward: -14.01, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 10.04, Length: 11
DEBUG (Env): Episode done for env 53. Reward: 27.73, Length: 8
DEBUG (Env): Episode done for env 67. Reward: 6.44, Length: 25
DEBUG (Env): Episode done for env 79. Reward: 20.46, Length: 1
DEBUG (Env): Episode done for env 82. Reward: 29.84, Length: 15
DEBUG (Env): Episode done for env 84. Reward: -22.28, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 34.01, Length: 2
1129
Time taken for simulation:  7.334920883178711
average overall reward:  0.26640174  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  0.24715735  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 34. Reward: 19.83, Length: 13
DEBUG (Env): Episode done for env 57. Reward: -8.61, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 17.73, Length: 2
1130
Time taken for simulation:  7.014552116394043
average overall reward:  0.6246002  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.12361428  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 10. Reward: -16.56, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 15.62, Length: 17
DEBUG (Env): Episode done for env 45. Reward: 28.16, Length: 20
DEBUG (Env): Episode done for env 52. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -20.84, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 7.77, Length: 22
DEBUG (Env): Episode done for env 95. Reward: 17.75, Length: 7
DEBUG (Env): Episode done for env 107. Reward: 10.73, Length: 16
DEBUG (Env): Episode done for env 115. Reward: 22.57, Length: 15
1131
Time taken for simulation:  7.192627668380737
average overall reward:  0.23775548  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.14519118  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -21.90, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 30.00, Length: 17
DEBUG (Env): Episode done for env 113. Reward: 21.99, Length: 11
DEBUG (Env): Episode done for env 124. Reward: 27.16, Length: 2
1132
Time taken for simulation:  7.209586143493652
average overall reward:  -0.23429912  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  -0.141609  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 92. Reward: 30.85, Length: 29
1133
Time taken for simulation:  7.471663475036621
average overall reward:  0.60410196  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.12871546 average distance reward:  -0.07317621  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 15. Reward: 7.77, Length: 35
DEBUG (Env): Episode done for env 16. Reward: 18.38, Length: 18
DEBUG (Env): Episode done for env 21. Reward: 22.86, Length: 22
DEBUG (Env): Episode done for env 38. Reward: 22.11, Length: 6
DEBUG (Env): Episode done for env 50. Reward: -12.43, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -17.02, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 43.48, Length: 3
DEBUG (Env): Episode done for env 100. Reward: 26.13, Length: 6
DEBUG (Env): Episode done for env 103. Reward: -23.50, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -23.84, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 29.22, Length: 18
1134
Time taken for simulation:  7.552965879440308
average overall reward:  0.2288886  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  -0.07236761  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: 23.90, Length: 9
DEBUG (Env): Episode done for env 7. Reward: 29.18, Length: 3
DEBUG (Env): Episode done for env 18. Reward: 21.67, Length: 9
DEBUG (Env): Episode done for env 28. Reward: 16.87, Length: 14
DEBUG (Env): Episode done for env 47. Reward: -22.23, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 31.44, Length: 6
DEBUG (Env): Episode done for env 62. Reward: -21.88, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -19.14, Length: 36
1135
Time taken for simulation:  7.437808275222778
average overall reward:  0.3313465  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.32196632  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: -19.63, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 16.20, Length: 14
DEBUG (Env): Episode done for env 29. Reward: -7.52, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 35.44, Length: 11
DEBUG (Env): Episode done for env 34. Reward: 19.56, Length: 6
DEBUG (Env): Episode done for env 64. Reward: -16.82, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -22.44, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -6.26, Length: 36
1136
Time taken for simulation:  7.09590220451355
average overall reward:  0.33185303  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.0055555487  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 25. Reward: 18.56, Length: 5
DEBUG (Env): Episode done for env 46. Reward: 35.92, Length: 25
DEBUG (Env): Episode done for env 66. Reward: 20.73, Length: 1
DEBUG (Env): Episode done for env 119. Reward: 4.52, Length: 35
1137
Time taken for simulation:  7.240949869155884
average overall reward:  0.22941877  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.28509805  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 12. Reward: 8.61, Length: 21
DEBUG (Env): Episode done for env 97. Reward: -5.64, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -15.67, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 21.69, Length: 2
1138
Time taken for simulation:  7.01469087600708
average overall reward:  -0.07195462  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.026841309  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 85. Reward: -22.80, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 16.78, Length: 1
DEBUG (Env): Episode done for env 101. Reward: 10.86, Length: 12
1139
Time taken for simulation:  7.363969326019287
average overall reward:  0.15147908  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.04373768  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 32. Reward: 27.99, Length: 4
DEBUG (Env): Episode done for env 36. Reward: -10.18, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 20.03, Length: 17
DEBUG (Env): Episode done for env 41. Reward: -21.07, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -14.89, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 23.19, Length: 1
1140
Time taken for simulation:  7.2239367961883545
average overall reward:  0.3633073  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.18224595  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 26. Reward: -16.90, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -24.01, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -17.99, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -13.85, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 25.11, Length: 4
DEBUG (Env): Episode done for env 85. Reward: 15.62, Length: 1
DEBUG (Env): Episode done for env 86. Reward: 23.58, Length: 30
DEBUG (Env): Episode done for env 122. Reward: 41.08, Length: 7
1141
Time taken for simulation:  7.121289491653442
average overall reward:  0.67279255  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.283174 average distance reward:  0.3972795  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: -22.70, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 20.59, Length: 4
DEBUG (Env): Episode done for env 32. Reward: 20.23, Length: 2
DEBUG (Env): Episode done for env 39. Reward: 17.23, Length: 2
DEBUG (Env): Episode done for env 42. Reward: -27.76, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 27.85, Length: 8
DEBUG (Env): Episode done for env 94. Reward: -11.37, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 31.03, Length: 16
1142
Time taken for simulation:  7.245390892028809
average overall reward:  0.026880085  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.15418121  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 0. Reward: -17.05, Length: 36
DEBUG (Env): Episode done for env 10. Reward: 32.15, Length: 12
DEBUG (Env): Episode done for env 29. Reward: 15.00, Length: 7
DEBUG (Env): Episode done for env 69. Reward: 22.73, Length: 22
DEBUG (Env): Episode done for env 84. Reward: 27.38, Length: 14
DEBUG (Env): Episode done for env 116. Reward: -26.12, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -16.67, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -20.99, Length: 36
1143
Time taken for simulation:  7.704582691192627
average overall reward:  -0.14351529  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.01451613  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 16. Reward: 13.88, Length: 10
DEBUG (Env): Episode done for env 58. Reward: -21.09, Length: 36
1144
Time taken for simulation:  7.679097652435303
average overall reward:  -0.28310764  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.13067092  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 35. Reward: -21.31, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -21.40, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 24.89, Length: 2
1145
Time taken for simulation:  7.179699659347534
average overall reward:  -0.15215303  average fail penalty:  -0.1640625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.03077235  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 5. Reward: -24.28, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -19.13, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -18.74, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -17.52, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -9.17, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 17.99, Length: 24
DEBUG (Env): Episode done for env 102. Reward: -13.55, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 30.36, Length: 12
DEBUG (Env): Episode done for env 118. Reward: -17.47, Length: 36
1146
Time taken for simulation:  7.181542158126831
average overall reward:  -0.07575488  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.0980067  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 34. Reward: 18.42, Length: 11
DEBUG (Env): Episode done for env 54. Reward: -19.14, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 24.09, Length: 2
DEBUG (Env): Episode done for env 72. Reward: -21.21, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 16.92, Length: 8
DEBUG (Env): Episode done for env 99. Reward: -30.40, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -15.49, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -17.54, Length: 36
1147
Time taken for simulation:  7.197038888931274
average overall reward:  0.33295673  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  0.4444732  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 4. Reward: 26.52, Length: 13
DEBUG (Env): Episode done for env 11. Reward: -16.20, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -13.33, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -21.68, Length: 36
1148
Time taken for simulation:  7.393019676208496
average overall reward:  0.5914928  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.16733009 average distance reward:  -0.00554879  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 63. Reward: -1.86, Length: 27
DEBUG (Env): Episode done for env 66. Reward: 36.69, Length: 8
DEBUG (Env): Episode done for env 70. Reward: 19.10, Length: 15
DEBUG (Env): Episode done for env 76. Reward: 31.04, Length: 23
DEBUG (Env): Episode done for env 81. Reward: 36.68, Length: 3
DEBUG (Env): Episode done for env 103. Reward: 14.71, Length: 3
1149
Time taken for simulation:  7.418630361557007
average overall reward:  0.25984007  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.03245392  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: -43.17, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 16.34, Length: 2
DEBUG (Env): Episode done for env 24. Reward: 6.12, Length: 28
DEBUG (Env): Episode done for env 83. Reward: 32.30, Length: 4
DEBUG (Env): Episode done for env 119. Reward: 35.78, Length: 13
DEBUG (Env): Episode done for env 120. Reward: -23.65, Length: 36
1150
Time taken for simulation:  7.330205917358398
average overall reward:  0.5974353  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.36719334  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 14. Reward: 27.18, Length: 24
DEBUG (Env): Episode done for env 49. Reward: -10.42, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 13.49, Length: 4
DEBUG (Env): Episode done for env 75. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -15.52, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 17.21, Length: 16
DEBUG (Env): Episode done for env 125. Reward: 22.91, Length: 6
1151
Time taken for simulation:  7.235680818557739
average overall reward:  0.23340285  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.06435773 average distance reward:  0.14518958  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 87. Reward: -10.48, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -24.93, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -15.08, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 12.24, Length: 27
DEBUG (Env): Episode done for env 125. Reward: 14.98, Length: 1
1152
Time taken for simulation:  7.315120458602905
average overall reward:  -0.061564356  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.08080873  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 50. Reward: 35.30, Length: 11
DEBUG (Env): Episode done for env 108. Reward: -18.99, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 25.56, Length: 3
1153
Time taken for simulation:  7.066156387329102
average overall reward:  0.15791968  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.013869256  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 36. Reward: 22.42, Length: 14
DEBUG (Env): Episode done for env 56. Reward: -15.92, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 24.73, Length: 14
DEBUG (Env): Episode done for env 93. Reward: -13.64, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 26.24, Length: 13
1154
Time taken for simulation:  7.21880030632019
average overall reward:  0.3762675  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.120282516  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: -14.56, Length: 36
DEBUG (Env): Episode done for env 10. Reward: 11.63, Length: 12
DEBUG (Env): Episode done for env 33. Reward: -18.43, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -8.07, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 29.16, Length: 8
DEBUG (Env): Episode done for env 122. Reward: 20.93, Length: 1
DEBUG (Env): Episode done for env 123. Reward: 6.62, Length: 12
1155
Time taken for simulation:  7.101525068283081
average overall reward:  -0.13266882  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  0.14457394  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 78. Reward: -18.13, Length: 36
1156
Time taken for simulation:  7.376432180404663
average overall reward:  -0.17239211  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  -0.168199  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 30. Reward: -15.05, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -9.99, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 25.64, Length: 3
DEBUG (Env): Episode done for env 107. Reward: 11.65, Length: 26
1157
Time taken for simulation:  7.213312864303589
average overall reward:  0.14666852  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  0.014787817  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: -15.56, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -13.96, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 8.88, Length: 15
DEBUG (Env): Episode done for env 73. Reward: -16.93, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 23.77, Length: 2
DEBUG (Env): Episode done for env 85. Reward: 21.68, Length: 17
DEBUG (Env): Episode done for env 88. Reward: -12.68, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 23.78, Length: 6
DEBUG (Env): Episode done for env 114. Reward: -21.84, Length: 36
1158
Time taken for simulation:  7.024151802062988
average overall reward:  0.4580896  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.18327832  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: 12.85, Length: 16
DEBUG (Env): Episode done for env 1. Reward: 1.91, Length: 17
DEBUG (Env): Episode done for env 76. Reward: 24.40, Length: 10
DEBUG (Env): Episode done for env 78. Reward: 26.92, Length: 1
1159
Time taken for simulation:  7.38948130607605
average overall reward:  0.92226136  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.29604554 average distance reward:  0.20662877  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 1. Reward: 20.34, Length: 1
DEBUG (Env): Episode done for env 2. Reward: 34.43, Length: 5
DEBUG (Env): Episode done for env 6. Reward: -19.54, Length: 36
DEBUG (Env): Episode done for env 8. Reward: 17.79, Length: 10
DEBUG (Env): Episode done for env 75. Reward: 34.04, Length: 9
DEBUG (Env): Episode done for env 78. Reward: 23.21, Length: 1
DEBUG (Env): Episode done for env 93. Reward: 21.50, Length: 3
DEBUG (Env): Episode done for env 104. Reward: 27.54, Length: 26
DEBUG (Env): Episode done for env 113. Reward: 3.73, Length: 28
1160
Time taken for simulation:  7.038080453872681
average overall reward:  0.62209  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.18385805  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 35.41, Length: 10
DEBUG (Env): Episode done for env 33. Reward: 24.93, Length: 6
DEBUG (Env): Episode done for env 76. Reward: 19.85, Length: 2
DEBUG (Env): Episode done for env 99. Reward: 15.81, Length: 14
DEBUG (Env): Episode done for env 109. Reward: -22.26, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 19.31, Length: 6
1161
Time taken for simulation:  7.238015174865723
average overall reward:  -0.03499837  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.102261215  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 65. Reward: -11.55, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -12.71, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -14.70, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 17.99, Length: 1
1162
Time taken for simulation:  7.127901077270508
average overall reward:  -0.04769458  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.101644225  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: -13.68, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -24.81, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 13.18, Length: 28
DEBUG (Env): Episode done for env 88. Reward: 38.71, Length: 5
DEBUG (Env): Episode done for env 89. Reward: 36.65, Length: 11
1163
Time taken for simulation:  7.360970973968506
average overall reward:  0.6574385  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.21881628 average distance reward:  -5.1274896e-05  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 19. Reward: 14.99, Length: 28
DEBUG (Env): Episode done for env 47. Reward: 12.08, Length: 29
DEBUG (Env): Episode done for env 49. Reward: 21.87, Length: 13
DEBUG (Env): Episode done for env 53. Reward: 8.66, Length: 35
DEBUG (Env): Episode done for env 63. Reward: 37.69, Length: 15
DEBUG (Env): Episode done for env 100. Reward: 9.05, Length: 30
DEBUG (Env): Episode done for env 112. Reward: -12.48, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 28.51, Length: 11
1164
Time taken for simulation:  7.2443952560424805
average overall reward:  -0.149764  average fail penalty:  -0.140625  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  0.1607804  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 17. Reward: -31.16, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -28.14, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 17.08, Length: 35
DEBUG (Env): Episode done for env 67. Reward: -5.36, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -20.59, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -15.56, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -13.42, Length: 36
1165
Time taken for simulation:  7.021606683731079
average overall reward:  0.35870093  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.20639011  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 49. Reward: 22.47, Length: 2
DEBUG (Env): Episode done for env 63. Reward: 24.07, Length: 2
DEBUG (Env): Episode done for env 97. Reward: 17.75, Length: 11
1166
Time taken for simulation:  7.2843475341796875
average overall reward:  0.028918449  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.0342535  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 5. Reward: 17.96, Length: 21
DEBUG (Env): Episode done for env 44. Reward: -27.37, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -23.24, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -20.66, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -17.27, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 23.56, Length: 5
DEBUG (Env): Episode done for env 95. Reward: -17.59, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -14.61, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 19.59, Length: 3
1167
Time taken for simulation:  7.632964611053467
average overall reward:  0.5303298  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020163 average distance reward:  0.3991509  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: -14.11, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 27.71, Length: 7
DEBUG (Env): Episode done for env 89. Reward: 22.23, Length: 5
DEBUG (Env): Episode done for env 113. Reward: 49.83, Length: 8
DEBUG (Env): Episode done for env 124. Reward: -19.11, Length: 36
1168
Time taken for simulation:  7.12711501121521
average overall reward:  0.26459748  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.013223637  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 49. Reward: 15.57, Length: 3
DEBUG (Env): Episode done for env 69. Reward: 35.97, Length: 11
DEBUG (Env): Episode done for env 78. Reward: 28.71, Length: 9
DEBUG (Env): Episode done for env 85. Reward: 52.66, Length: 11
DEBUG (Env): Episode done for env 92. Reward: -21.24, Length: 36
1169
Time taken for simulation:  7.546957731246948
average overall reward:  -0.27514452  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  0.014267996  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: -18.20, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -13.39, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -20.06, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -23.36, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 3.92, Length: 27
1170
Time taken for simulation:  7.363669157028198
average overall reward:  -0.27890906  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  0.10726086  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: -25.54, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -18.97, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -18.84, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -21.74, Length: 36
1171
Time taken for simulation:  7.1897501945495605
average overall reward:  0.31961873  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.23992601  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: -19.02, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 5.89, Length: 28
DEBUG (Env): Episode done for env 58. Reward: 19.14, Length: 28
DEBUG (Env): Episode done for env 64. Reward: -7.50, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 32.75, Length: 12
1172
Time taken for simulation:  7.16382360458374
average overall reward:  0.7736936  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.1673301 average distance reward:  -0.04721696  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 20. Reward: 11.98, Length: 25
DEBUG (Env): Episode done for env 25. Reward: -17.99, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -23.16, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 26.56, Length: 4
DEBUG (Env): Episode done for env 50. Reward: 19.82, Length: 20
DEBUG (Env): Episode done for env 51. Reward: 20.01, Length: 15
DEBUG (Env): Episode done for env 54. Reward: 22.59, Length: 22
DEBUG (Env): Episode done for env 75. Reward: 30.48, Length: 13
DEBUG (Env): Episode done for env 84. Reward: 10.40, Length: 30
DEBUG (Env): Episode done for env 88. Reward: 39.18, Length: 10
1173
Time taken for simulation:  7.246108293533325
average overall reward:  -0.31037033  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.07722928 average distance reward:  -0.27377757  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 62. Reward: 16.32, Length: 11
DEBUG (Env): Episode done for env 106. Reward: -15.59, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -18.82, Length: 36
1174
Time taken for simulation:  7.0627524852752686
average overall reward:  0.0104925  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.115843914 average distance reward:  0.06226246  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 13. Reward: 17.03, Length: 3
DEBUG (Env): Episode done for env 101. Reward: -19.23, Length: 36
1175
Time taken for simulation:  7.145817995071411
average overall reward:  0.5506742  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.38318625  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: 33.95, Length: 9
DEBUG (Env): Episode done for env 41. Reward: -25.15, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 30.54, Length: 3
DEBUG (Env): Episode done for env 60. Reward: 21.81, Length: 13
1176
Time taken for simulation:  7.4507904052734375
average overall reward:  0.218229  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.009119049  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 7. Reward: 24.49, Length: 6
DEBUG (Env): Episode done for env 26. Reward: -24.56, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 6.13, Length: 20
DEBUG (Env): Episode done for env 31. Reward: -14.10, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -22.29, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 18.49, Length: 13
DEBUG (Env): Episode done for env 61. Reward: -14.24, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -21.14, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 21.07, Length: 16
1177
Time taken for simulation:  7.114298343658447
average overall reward:  -0.0057447404  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.030302085  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 12. Reward: -22.96, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -16.61, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -22.21, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -24.39, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 27.09, Length: 5
DEBUG (Env): Episode done for env 94. Reward: -19.17, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -3.58, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 30.45, Length: 14
DEBUG (Env): Episode done for env 123. Reward: 32.28, Length: 17
1178
Time taken for simulation:  7.27906060218811
average overall reward:  0.7172979  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.41443786  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: 20.95, Length: 9
DEBUG (Env): Episode done for env 29. Reward: -16.24, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 26.04, Length: 18
DEBUG (Env): Episode done for env 55. Reward: 43.84, Length: 12
DEBUG (Env): Episode done for env 70. Reward: 6.07, Length: 30
1179
Time taken for simulation:  7.413189172744751
average overall reward:  0.47961935  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.11584391 average distance reward:  -0.03353633  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: 22.68, Length: 30
DEBUG (Env): Episode done for env 28. Reward: 24.85, Length: 9
DEBUG (Env): Episode done for env 49. Reward: 34.90, Length: 7
DEBUG (Env): Episode done for env 95. Reward: 12.83, Length: 13
DEBUG (Env): Episode done for env 123. Reward: 29.51, Length: 2
1180
Time taken for simulation:  7.303966283798218
average overall reward:  -0.033867493  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.17561236  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 8. Reward: 29.81, Length: 21
DEBUG (Env): Episode done for env 35. Reward: -16.72, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 24.88, Length: 14
DEBUG (Env): Episode done for env 124. Reward: 26.05, Length: 13
1181
Time taken for simulation:  7.050562143325806
average overall reward:  0.011621103  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.13761297  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 22. Reward: -28.57, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -18.67, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 24.33, Length: 9
DEBUG (Env): Episode done for env 98. Reward: -17.60, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -29.76, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 30.39, Length: 4
DEBUG (Env): Episode done for env 118. Reward: -16.93, Length: 36
1182
Time taken for simulation:  7.0048606395721436
average overall reward:  0.71664363  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.35929006  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 1. Reward: 25.61, Length: 23
DEBUG (Env): Episode done for env 6. Reward: 16.25, Length: 23
DEBUG (Env): Episode done for env 34. Reward: -18.49, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 26.09, Length: 11
DEBUG (Env): Episode done for env 59. Reward: -27.30, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -16.89, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 13.72, Length: 15
DEBUG (Env): Episode done for env 105. Reward: -24.08, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 14.47, Length: 33
DEBUG (Env): Episode done for env 127. Reward: -12.68, Length: 36
1183
Time taken for simulation:  7.619429349899292
average overall reward:  0.15467608  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.13761792  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: -27.23, Length: 36
DEBUG (Env): Episode done for env 6. Reward: 28.83, Length: 1
DEBUG (Env): Episode done for env 8. Reward: 30.35, Length: 3
DEBUG (Env): Episode done for env 40. Reward: -19.86, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 18.05, Length: 1
DEBUG (Env): Episode done for env 73. Reward: 15.14, Length: 26
1184
Time taken for simulation:  7.188404321670532
average overall reward:  0.07391581  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.11584391 average distance reward:  -0.23355533  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 29. Reward: 12.09, Length: 6
DEBUG (Env): Episode done for env 66. Reward: -15.84, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -9.71, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 8.58, Length: 3
DEBUG (Env): Episode done for env 103. Reward: -12.41, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 22.61, Length: 13
DEBUG (Env): Episode done for env 120. Reward: 23.69, Length: 18
1185
Time taken for simulation:  7.399455785751343
average overall reward:  0.12765597  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.11584391 average distance reward:  0.067491375  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 24. Reward: -13.35, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 19.27, Length: 1
DEBUG (Env): Episode done for env 83. Reward: -19.76, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 22.64, Length: 4
1186
Time taken for simulation:  7.179732322692871
average overall reward:  0.01192233  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.041858595  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 4. Reward: 16.74, Length: 3
DEBUG (Env): Episode done for env 70. Reward: 27.89, Length: 8
DEBUG (Env): Episode done for env 96. Reward: -19.46, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -13.20, Length: 36
1187
Time taken for simulation:  7.199660301208496
average overall reward:  0.24673723  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.11325273  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 53. Reward: 8.15, Length: 24
DEBUG (Env): Episode done for env 87. Reward: -23.87, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -13.52, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 18.50, Length: 5
DEBUG (Env): Episode done for env 121. Reward: 14.88, Length: 1
DEBUG (Env): Episode done for env 125. Reward: -16.13, Length: 36
1188
Time taken for simulation:  7.129939794540405
average overall reward:  0.24140885  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.086792484  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: 29.75, Length: 6
DEBUG (Env): Episode done for env 57. Reward: 21.25, Length: 24
DEBUG (Env): Episode done for env 72. Reward: 22.79, Length: 6
DEBUG (Env): Episode done for env 108. Reward: -17.22, Length: 36
1189
Time taken for simulation:  7.22442364692688
average overall reward:  -0.22017406  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  -0.057171408  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 36. Reward: -12.31, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -14.64, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -15.56, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 31.02, Length: 5
1190
Time taken for simulation:  7.222068786621094
average overall reward:  -0.2061713  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  -0.12705448  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: 10.06, Length: 33
DEBUG (Env): Episode done for env 10. Reward: -17.46, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -17.75, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 16.89, Length: 9
DEBUG (Env): Episode done for env 122. Reward: -11.69, Length: 36
1191
Time taken for simulation:  7.28605842590332
average overall reward:  0.26971796  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.06592097  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 60. Reward: 21.31, Length: 16
DEBUG (Env): Episode done for env 110. Reward: 25.67, Length: 14
DEBUG (Env): Episode done for env 113. Reward: 14.92, Length: 24
1192
Time taken for simulation:  7.061262845993042
average overall reward:  0.27342558  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.4387338  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 74. Reward: -14.96, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 11.36, Length: 27
DEBUG (Env): Episode done for env 107. Reward: -28.01, Length: 36
1193
Time taken for simulation:  7.204282522201538
average overall reward:  -0.29589048  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.20159651  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 71. Reward: 4.45, Length: 32
DEBUG (Env): Episode done for env 90. Reward: -8.17, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 17.59, Length: 1
DEBUG (Env): Episode done for env 114. Reward: -22.00, Length: 36
1194
Time taken for simulation:  7.0891335010528564
average overall reward:  0.11504802  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.115843914 average distance reward:  0.03144597  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 0. Reward: -16.30, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 25.97, Length: 5
DEBUG (Env): Episode done for env 57. Reward: 27.97, Length: 6
1195
Time taken for simulation:  7.292673587799072
average overall reward:  0.17700681  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.11528722  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: -16.13, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 10.39, Length: 33
DEBUG (Env): Episode done for env 13. Reward: 30.29, Length: 21
DEBUG (Env): Episode done for env 68. Reward: 2.89, Length: 29
DEBUG (Env): Episode done for env 89. Reward: 16.17, Length: 28
DEBUG (Env): Episode done for env 93. Reward: -14.85, Length: 36
1196
Time taken for simulation:  7.478516578674316
average overall reward:  -0.0020137653  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.26625913  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: -14.55, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 31.25, Length: 20
DEBUG (Env): Episode done for env 65. Reward: -25.07, Length: 35
DEBUG (Env): Episode done for env 115. Reward: 21.51, Length: 16
DEBUG (Env): Episode done for env 116. Reward: 31.24, Length: 27
1197
Time taken for simulation:  7.1271703243255615
average overall reward:  -0.44787246  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  -0.18350118  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 109. Reward: -14.90, Length: 36
1198
Time taken for simulation:  7.452012777328491
average overall reward:  -0.16190502  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  -0.11448607  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 62. Reward: 22.32, Length: 25
DEBUG (Env): Episode done for env 123. Reward: 18.87, Length: 19
1199
Time taken for simulation:  7.272587776184082
average overall reward:  0.08631566  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  -0.057734773  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: -14.20, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 18.50, Length: 10
DEBUG (Env): Episode done for env 80. Reward: 24.27, Length: 10
DEBUG (Env): Episode done for env 95. Reward: 32.50, Length: 20
DEBUG (Env): Episode done for env 100. Reward: -18.66, Length: 36
1200
Time taken for simulation:  7.557908773422241
average overall reward:  0.3523972  average fail penalty:  -0.140625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.24395396  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 7. Reward: 14.41, Length: 24
DEBUG (Env): Episode done for env 11. Reward: 19.64, Length: 21
DEBUG (Env): Episode done for env 17. Reward: -17.51, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 9.38, Length: 31
DEBUG (Env): Episode done for env 27. Reward: -17.68, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 9.11, Length: 29
DEBUG (Env): Episode done for env 67. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -22.01, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -15.76, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -26.85, Length: 36
1201
Time taken for simulation:  7.1143763065338135
average overall reward:  0.03935688  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.071598694  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 23. Reward: 18.08, Length: 34
DEBUG (Env): Episode done for env 62. Reward: 17.77, Length: 3
DEBUG (Env): Episode done for env 63. Reward: -15.33, Length: 36
1202
Time taken for simulation:  7.47995662689209
average overall reward:  0.049667932  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.032027353  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 19.34, Length: 12
DEBUG (Env): Episode done for env 9. Reward: 35.81, Length: 7
DEBUG (Env): Episode done for env 38. Reward: 19.42, Length: 33
DEBUG (Env): Episode done for env 44. Reward: -30.56, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -15.73, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -16.70, Length: 36
1203
Time taken for simulation:  7.123636245727539
average overall reward:  0.6323853  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.283174 average distance reward:  0.15118769  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 15.88, Length: 1
DEBUG (Env): Episode done for env 8. Reward: 20.79, Length: 20
DEBUG (Env): Episode done for env 11. Reward: 32.64, Length: 3
DEBUG (Env): Episode done for env 70. Reward: 8.48, Length: 17
DEBUG (Env): Episode done for env 73. Reward: 18.26, Length: 20
DEBUG (Env): Episode done for env 80. Reward: 35.48, Length: 4
1204
Time taken for simulation:  7.054332494735718
average overall reward:  0.13893071  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.13851261  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 69. Reward: -17.89, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -15.34, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -21.39, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 12.09, Length: 9
DEBUG (Env): Episode done for env 92. Reward: -16.74, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 19.07, Length: 13
1205
Time taken for simulation:  7.111959457397461
average overall reward:  0.4719762  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.30448818  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 16. Reward: 17.78, Length: 34
DEBUG (Env): Episode done for env 30. Reward: 6.83, Length: 29
DEBUG (Env): Episode done for env 47. Reward: 4.34, Length: 29
DEBUG (Env): Episode done for env 77. Reward: -14.01, Length: 36
1206
Time taken for simulation:  7.268651008605957
average overall reward:  -0.09379977  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.050991967  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: -17.54, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 26.75, Length: 19
DEBUG (Env): Episode done for env 70. Reward: 23.54, Length: 3
1207
Time taken for simulation:  7.062829971313477
average overall reward:  -0.37598553  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.36718124  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 45. Reward: 22.84, Length: 5
DEBUG (Env): Episode done for env 70. Reward: 20.56, Length: 1
1208
Time taken for simulation:  7.777141094207764
average overall reward:  -0.058512658  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.05230195  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 20. Reward: -20.95, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -15.44, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -11.85, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -4.46, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 10.38, Length: 32
DEBUG (Env): Episode done for env 75. Reward: -20.95, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 22.43, Length: 3
DEBUG (Env): Episode done for env 84. Reward: -18.05, Length: 36
1209
Time taken for simulation:  7.224505662918091
average overall reward:  0.71623707  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594475 average distance reward:  0.06931315  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 8. Reward: 29.03, Length: 6
DEBUG (Env): Episode done for env 14. Reward: 8.24, Length: 13
DEBUG (Env): Episode done for env 15. Reward: 0.97, Length: 31
DEBUG (Env): Episode done for env 33. Reward: 18.64, Length: 31
DEBUG (Env): Episode done for env 84. Reward: 21.64, Length: 1
DEBUG (Env): Episode done for env 96. Reward: 14.93, Length: 23
DEBUG (Env): Episode done for env 106. Reward: -20.39, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 11.77, Length: 13
DEBUG (Env): Episode done for env 117. Reward: -20.79, Length: 36
1210
Time taken for simulation:  7.115652561187744
average overall reward:  0.93735313  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.12871546 average distance reward:  0.46050644  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 24.23, Length: 1
DEBUG (Env): Episode done for env 17. Reward: 32.95, Length: 10
DEBUG (Env): Episode done for env 45. Reward: 44.99, Length: 3
DEBUG (Env): Episode done for env 71. Reward: 13.23, Length: 17
DEBUG (Env): Episode done for env 101. Reward: -15.93, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 18.24, Length: 22
1211
Time taken for simulation:  7.065732479095459
average overall reward:  0.28856426  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.23168781 average distance reward:  -0.038434993  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: -19.85, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 35.63, Length: 2
DEBUG (Env): Episode done for env 41. Reward: -21.91, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 20.33, Length: 6
DEBUG (Env): Episode done for env 54. Reward: -17.50, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 18.53, Length: 1
DEBUG (Env): Episode done for env 111. Reward: 7.46, Length: 24
DEBUG (Env): Episode done for env 121. Reward: 2.41, Length: 24
1212
Time taken for simulation:  7.195997714996338
average overall reward:  0.067813314  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.06739528  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 26. Reward: -14.48, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -19.28, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 13.94, Length: 8
DEBUG (Env): Episode done for env 79. Reward: 28.15, Length: 12
DEBUG (Env): Episode done for env 86. Reward: -8.13, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -11.55, Length: 36
1213
Time taken for simulation:  7.074856519699097
average overall reward:  0.0940332  average fail penalty:  -0.140625  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  -0.18839666  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 12. Reward: -14.98, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 12.37, Length: 13
DEBUG (Env): Episode done for env 29. Reward: 8.66, Length: 28
DEBUG (Env): Episode done for env 32. Reward: -17.88, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -8.00, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -11.79, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -15.14, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 20.68, Length: 5
DEBUG (Env): Episode done for env 54. Reward: 25.75, Length: 2
DEBUG (Env): Episode done for env 85. Reward: 23.89, Length: 9
DEBUG (Env): Episode done for env 94. Reward: -27.59, Length: 36
1214
Time taken for simulation:  7.164241075515747
average overall reward:  0.17932875  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.13434127  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 55. Reward: -3.34, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 21.25, Length: 24
DEBUG (Env): Episode done for env 93. Reward: 15.43, Length: 19
1215
Time taken for simulation:  7.253117561340332
average overall reward:  -0.010847986  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  0.11584564  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 28. Reward: -22.25, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -19.94, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 17.74, Length: 13
1216
Time taken for simulation:  7.075852870941162
average overall reward:  0.17085627  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.02680584  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 35. Reward: -9.45, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 17.59, Length: 20
DEBUG (Env): Episode done for env 70. Reward: 21.90, Length: 9
DEBUG (Env): Episode done for env 79. Reward: 26.05, Length: 4
DEBUG (Env): Episode done for env 124. Reward: -23.88, Length: 36
1217
Time taken for simulation:  7.351246118545532
average overall reward:  0.22149605  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.06617787  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 22. Reward: -19.53, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 25.84, Length: 9
DEBUG (Env): Episode done for env 43. Reward: -22.64, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 27.92, Length: 15
DEBUG (Env): Episode done for env 65. Reward: 18.39, Length: 21
DEBUG (Env): Episode done for env 102. Reward: -17.78, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -11.87, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 19.45, Length: 27
1218
Time taken for simulation:  7.08414626121521
average overall reward:  0.66954494  average fail penalty:  -0.1171875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.141587 average distance reward:  0.29931986  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 19. Reward: 12.58, Length: 19
DEBUG (Env): Episode done for env 26. Reward: 26.69, Length: 6
DEBUG (Env): Episode done for env 34. Reward: -15.36, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -12.74, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -16.55, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -16.18, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 10.10, Length: 25
DEBUG (Env): Episode done for env 112. Reward: 23.83, Length: 1
DEBUG (Env): Episode done for env 126. Reward: 13.38, Length: 18
DEBUG (Env): Episode done for env 127. Reward: -10.71, Length: 36
1219
Time taken for simulation:  7.538154125213623
average overall reward:  -0.15993291  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.08081606  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: -19.73, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 20.27, Length: 7
DEBUG (Env): Episode done for env 40. Reward: -17.70, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -23.15, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 19.92, Length: 11
1220
Time taken for simulation:  7.412168264389038
average overall reward:  0.3109354  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  -0.033546582  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 57. Reward: 6.25, Length: 26
DEBUG (Env): Episode done for env 64. Reward: 29.04, Length: 20
DEBUG (Env): Episode done for env 66. Reward: -19.37, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 15.91, Length: 10
DEBUG (Env): Episode done for env 81. Reward: -19.63, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -18.06, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -20.73, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -27.23, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 24.58, Length: 2
DEBUG (Env): Episode done for env 108. Reward: 17.25, Length: 9
1221
Time taken for simulation:  7.599535226821899
average overall reward:  0.17385012  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.030648675  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: 23.98, Length: 8
DEBUG (Env): Episode done for env 24. Reward: -18.96, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 15.94, Length: 11
DEBUG (Env): Episode done for env 64. Reward: 18.18, Length: 1
DEBUG (Env): Episode done for env 83. Reward: -13.04, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -25.07, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 11.96, Length: 8
1222
Time taken for simulation:  7.086722135543823
average overall reward:  0.26383883  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.07060777  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 4. Reward: -19.34, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 24.53, Length: 5
DEBUG (Env): Episode done for env 26. Reward: 23.53, Length: 4
DEBUG (Env): Episode done for env 96. Reward: 13.53, Length: 13
1223
Time taken for simulation:  7.439702987670898
average overall reward:  0.0009505749  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.24216281  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 25.20, Length: 1
DEBUG (Env): Episode done for env 39. Reward: 13.91, Length: 10
DEBUG (Env): Episode done for env 50. Reward: 24.58, Length: 15
DEBUG (Env): Episode done for env 58. Reward: 23.90, Length: 5
DEBUG (Env): Episode done for env 87. Reward: -23.08, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -24.61, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -26.44, Length: 36
1224
Time taken for simulation:  7.34468674659729
average overall reward:  0.5321375  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.102972366 average distance reward:  0.32372922  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -26.72, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -14.80, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 42.91, Length: 7
DEBUG (Env): Episode done for env 126. Reward: 18.47, Length: 6
DEBUG (Env): Episode done for env 127. Reward: 19.25, Length: 6
1225
Time taken for simulation:  7.4754109382629395
average overall reward:  -0.23440638  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  -0.008649815  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 120. Reward: -17.16, Length: 36
1226
Time taken for simulation:  7.072368860244751
average overall reward:  -0.39388332  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.32178864 average distance reward:  -0.11273116  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 10. Reward: -21.01, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 15.52, Length: 6
DEBUG (Env): Episode done for env 122. Reward: -13.47, Length: 36
1227
Time taken for simulation:  7.400728940963745
average overall reward:  -0.272515  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.35220775  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 44. Reward: 26.53, Length: 10
DEBUG (Env): Episode done for env 47. Reward: 20.29, Length: 16
DEBUG (Env): Episode done for env 60. Reward: -22.74, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 12.98, Length: 10
DEBUG (Env): Episode done for env 113. Reward: -14.88, Length: 36
1228
Time taken for simulation:  7.196002721786499
average overall reward:  0.43107623  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.18020165 average distance reward:  0.029153243  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: 27.81, Length: 18
DEBUG (Env): Episode done for env 9. Reward: 17.91, Length: 26
DEBUG (Env): Episode done for env 33. Reward: 19.97, Length: 19
DEBUG (Env): Episode done for env 58. Reward: 19.03, Length: 5
DEBUG (Env): Episode done for env 74. Reward: -23.55, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 14.07, Length: 10
DEBUG (Env): Episode done for env 97. Reward: -14.50, Length: 36
1229
Time taken for simulation:  7.257359266281128
average overall reward:  0.5774674  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.115843914 average distance reward:  0.2465587  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 33. Reward: 15.38, Length: 1
DEBUG (Env): Episode done for env 52. Reward: 19.04, Length: 14
DEBUG (Env): Episode done for env 90. Reward: -13.42, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 33.12, Length: 17
DEBUG (Env): Episode done for env 105. Reward: 17.60, Length: 9
DEBUG (Env): Episode done for env 114. Reward: -28.26, Length: 36
1230
Time taken for simulation:  7.5206458568573
average overall reward:  0.21351494  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.053036015  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: -23.46, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 21.21, Length: 15
DEBUG (Env): Episode done for env 35. Reward: 17.43, Length: 14
DEBUG (Env): Episode done for env 36. Reward: -20.51, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 19.64, Length: 10
DEBUG (Env): Episode done for env 110. Reward: 16.35, Length: 26
1231
Time taken for simulation:  7.147075176239014
average overall reward:  0.15832824  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.07632992  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: -18.15, Length: 36
DEBUG (Env): Episode done for env 13. Reward: -17.30, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 18.81, Length: 25
DEBUG (Env): Episode done for env 68. Reward: -12.48, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 24.10, Length: 11
DEBUG (Env): Episode done for env 112. Reward: 17.75, Length: 13
1232
Time taken for simulation:  7.780958414077759
average overall reward:  0.4217354  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.08026081  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 28.43, Length: 21
DEBUG (Env): Episode done for env 94. Reward: 26.61, Length: 11
DEBUG (Env): Episode done for env 103. Reward: 16.85, Length: 12
DEBUG (Env): Episode done for env 112. Reward: 21.32, Length: 1
DEBUG (Env): Episode done for env 115. Reward: -19.87, Length: 36
1233
Time taken for simulation:  7.286001443862915
average overall reward:  -0.13598576  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.27773064  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 33. Reward: 21.83, Length: 4
DEBUG (Env): Episode done for env 46. Reward: 30.52, Length: 20
DEBUG (Env): Episode done for env 109. Reward: -17.93, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 30.66, Length: 9
1234
Time taken for simulation:  7.695470094680786
average overall reward:  0.25146466  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.012780674  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: 19.04, Length: 3
DEBUG (Env): Episode done for env 38. Reward: -3.04, Length: 32
DEBUG (Env): Episode done for env 45. Reward: 21.72, Length: 13
DEBUG (Env): Episode done for env 65. Reward: 16.56, Length: 7
DEBUG (Env): Episode done for env 123. Reward: -19.77, Length: 36
1235
Time taken for simulation:  7.067838191986084
average overall reward:  0.50272775  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.0017417967  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 19. Reward: 24.22, Length: 17
DEBUG (Env): Episode done for env 31. Reward: 14.92, Length: 16
DEBUG (Env): Episode done for env 40. Reward: 23.79, Length: 16
DEBUG (Env): Episode done for env 56. Reward: -21.24, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 4.97, Length: 34
DEBUG (Env): Episode done for env 95. Reward: -14.16, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -20.40, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 23.82, Length: 3
DEBUG (Env): Episode done for env 118. Reward: 18.24, Length: 18
1236
Time taken for simulation:  7.044756889343262
average overall reward:  0.04746433  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.29826224  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -13.90, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -25.64, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 15.98, Length: 23
DEBUG (Env): Episode done for env 67. Reward: -15.57, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -21.91, Length: 36
1237
Time taken for simulation:  7.105476140975952
average overall reward:  0.28746676  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.18203098  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: -14.07, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -9.05, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 40.67, Length: 6
DEBUG (Env): Episode done for env 113. Reward: 21.07, Length: 10
DEBUG (Env): Episode done for env 120. Reward: 23.24, Length: 12
1238
Time taken for simulation:  7.059858083724976
average overall reward:  0.41656363  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  0.17415196  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 33. Reward: 21.16, Length: 5
DEBUG (Env): Episode done for env 81. Reward: 26.11, Length: 18
DEBUG (Env): Episode done for env 86. Reward: 22.30, Length: 26
1239
Time taken for simulation:  7.496510028839111
average overall reward:  -0.032628536  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  -0.013960056  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 20.78, Length: 8
DEBUG (Env): Episode done for env 3. Reward: -20.65, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -10.46, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 15.83, Length: 22
DEBUG (Env): Episode done for env 73. Reward: -18.80, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -9.67, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 27.45, Length: 13
1240
Time taken for simulation:  7.191647529602051
average overall reward:  -0.086833626  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.07722928 average distance reward:  -0.16217536  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 78. Reward: -11.61, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -17.14, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -20.00, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 19.63, Length: 12
DEBUG (Env): Episode done for env 107. Reward: 12.72, Length: 22
1241
Time taken for simulation:  7.068233251571655
average overall reward:  -0.2073366  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.12591419  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 16. Reward: -16.69, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -21.78, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 20.48, Length: 28
DEBUG (Env): Episode done for env 102. Reward: 12.87, Length: 17
1242
Time taken for simulation:  7.0980939865112305
average overall reward:  0.29899034  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.051486183 average distance reward:  0.17446804  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 48. Reward: -23.95, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 3.17, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -0.40, Length: 34
DEBUG (Env): Episode done for env 94. Reward: 38.62, Length: 10
1243
Time taken for simulation:  7.238300561904907
average overall reward:  -0.15557167  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.159639  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 44. Reward: 36.03, Length: 16
DEBUG (Env): Episode done for env 72. Reward: 22.98, Length: 19
1244
Time taken for simulation:  7.259047746658325
average overall reward:  0.30641744  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.14949547  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 1.08, Length: 34
DEBUG (Env): Episode done for env 20. Reward: -13.40, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 26.64, Length: 33
DEBUG (Env): Episode done for env 61. Reward: -11.52, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 15.25, Length: 35
1245
Time taken for simulation:  7.320737600326538
average overall reward:  -0.7269424  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.20594475 average distance reward:  -0.3793871  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 15. Reward: -17.42, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -23.63, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -14.28, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -18.14, Length: 36
1246
Time taken for simulation:  7.139022350311279
average overall reward:  0.14628059  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.17852241  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: 22.79, Length: 30
DEBUG (Env): Episode done for env 55. Reward: 11.40, Length: 32
DEBUG (Env): Episode done for env 101. Reward: -15.49, Length: 36
1247
Time taken for simulation:  6.987987756729126
average overall reward:  -0.47691965  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  -0.30104545  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 14. Reward: -28.46, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 8.99, Length: 27
DEBUG (Env): Episode done for env 111. Reward: -8.77, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -22.08, Length: 36
1248
Time taken for simulation:  7.041869878768921
average overall reward:  0.5171828  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.053207725  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: 26.09, Length: 29
DEBUG (Env): Episode done for env 26. Reward: 8.32, Length: 26
DEBUG (Env): Episode done for env 44. Reward: 22.49, Length: 5
DEBUG (Env): Episode done for env 67. Reward: 35.75, Length: 12
DEBUG (Env): Episode done for env 69. Reward: -20.54, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 2.80, Length: 25
1249
Time taken for simulation:  7.231221675872803
average overall reward:  0.37856328  average fail penalty:  -0.1171875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  -0.12703383  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 6. Reward: 18.50, Length: 1
DEBUG (Env): Episode done for env 18. Reward: 14.33, Length: 15
DEBUG (Env): Episode done for env 29. Reward: -15.83, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -33.66, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -22.65, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 13.67, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 13.37, Length: 11
DEBUG (Env): Episode done for env 82. Reward: 18.81, Length: 13
DEBUG (Env): Episode done for env 85. Reward: -9.32, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 21.19, Length: 14
1250
Time taken for simulation:  7.449467420578003
average overall reward:  0.2061103  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  0.1974319  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: 20.37, Length: 20
DEBUG (Env): Episode done for env 41. Reward: 15.21, Length: 6
DEBUG (Env): Episode done for env 91. Reward: -10.47, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -18.65, Length: 36
1251
Time taken for simulation:  7.24326229095459
average overall reward:  0.19942692  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.0705536  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 11. Reward: 32.62, Length: 12
DEBUG (Env): Episode done for env 49. Reward: -17.55, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 12.55, Length: 12
DEBUG (Env): Episode done for env 124. Reward: 5.43, Length: 35
1252
Time taken for simulation:  7.151108741760254
average overall reward:  0.3480936  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.1783001  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 19.49, Length: 24
DEBUG (Env): Episode done for env 63. Reward: 22.97, Length: 15
DEBUG (Env): Episode done for env 70. Reward: -21.36, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -10.53, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 28.60, Length: 15
1253
Time taken for simulation:  7.255141735076904
average overall reward:  1.0340518  average fail penalty:  -0.0234375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.24455936 average distance reward:  0.131561  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 10. Reward: 38.04, Length: 27
DEBUG (Env): Episode done for env 11. Reward: 17.80, Length: 2
DEBUG (Env): Episode done for env 22. Reward: -21.26, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 34.79, Length: 4
DEBUG (Env): Episode done for env 47. Reward: 19.17, Length: 26
DEBUG (Env): Episode done for env 53. Reward: 23.19, Length: 11
DEBUG (Env): Episode done for env 76. Reward: 12.04, Length: 25
DEBUG (Env): Episode done for env 80. Reward: 13.53, Length: 14
DEBUG (Env): Episode done for env 100. Reward: 10.19, Length: 18
DEBUG (Env): Episode done for env 107. Reward: 21.06, Length: 13
1254
Time taken for simulation:  7.876269340515137
average overall reward:  0.21218395  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.14766842  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 34. Reward: -27.46, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 32.24, Length: 20
DEBUG (Env): Episode done for env 48. Reward: 14.97, Length: 12
DEBUG (Env): Episode done for env 75. Reward: 10.86, Length: 12
1255
Time taken for simulation:  7.346068859100342
average overall reward:  -0.027503818  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.0024324507  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: 31.66, Length: 18
DEBUG (Env): Episode done for env 59. Reward: -19.79, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 26.89, Length: 11
DEBUG (Env): Episode done for env 77. Reward: -18.72, Length: 36
1256
Time taken for simulation:  7.3042824268341064
average overall reward:  -0.076257974  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  0.05043566  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 57. Reward: -15.78, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -25.20, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 21.62, Length: 12
1257
Time taken for simulation:  7.306742191314697
average overall reward:  0.23051473  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.085762516  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 12. Reward: -21.18, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -10.47, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 20.95, Length: 11
DEBUG (Env): Episode done for env 64. Reward: -21.65, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -22.37, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 21.33, Length: 9
DEBUG (Env): Episode done for env 88. Reward: -8.49, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 6.25, Length: 22
DEBUG (Env): Episode done for env 99. Reward: -3.15, Length: 28
1258
Time taken for simulation:  7.076920747756958
average overall reward:  0.5691462  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.07046586  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 0. Reward: 10.97, Length: 28
DEBUG (Env): Episode done for env 25. Reward: -13.36, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 1.65, Length: 35
DEBUG (Env): Episode done for env 44. Reward: 25.95, Length: 10
DEBUG (Env): Episode done for env 54. Reward: 39.60, Length: 9
DEBUG (Env): Episode done for env 72. Reward: 13.13, Length: 15
DEBUG (Env): Episode done for env 74. Reward: 2.40, Length: 30
DEBUG (Env): Episode done for env 96. Reward: -14.05, Length: 36
1259
Time taken for simulation:  7.11506724357605
average overall reward:  -0.27380094  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.26134747  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: -17.19, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -14.17, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 19.59, Length: 6
DEBUG (Env): Episode done for env 119. Reward: 6.36, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -17.13, Length: 36
1260
Time taken for simulation:  7.1823790073394775
average overall reward:  0.34182388  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.102972366 average distance reward:  0.13341564  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -15.60, Length: 36
DEBUG (Env): Episode done for env 2. Reward: 10.65, Length: 21
DEBUG (Env): Episode done for env 53. Reward: 16.84, Length: 1
DEBUG (Env): Episode done for env 100. Reward: 16.63, Length: 7
DEBUG (Env): Episode done for env 126. Reward: -13.37, Length: 36
1261
Time taken for simulation:  7.537004232406616
average overall reward:  0.22289976  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.031974304  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 83. Reward: 25.69, Length: 4
DEBUG (Env): Episode done for env 84. Reward: 8.15, Length: 16
DEBUG (Env): Episode done for env 107. Reward: 13.58, Length: 8
1262
Time taken for simulation:  7.657726049423218
average overall reward:  -0.08871625  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.056474436  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 23. Reward: 22.00, Length: 7
DEBUG (Env): Episode done for env 71. Reward: -15.73, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 21.60, Length: 17
1263
Time taken for simulation:  7.1877031326293945
average overall reward:  0.327384  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.121281445  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 55. Reward: 15.24, Length: 17
DEBUG (Env): Episode done for env 60. Reward: -22.50, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 21.82, Length: 5
DEBUG (Env): Episode done for env 79. Reward: 17.48, Length: 11
1264
Time taken for simulation:  7.202649831771851
average overall reward:  -0.2357866  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  -0.1672357  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 9. Reward: -12.35, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 13.59, Length: 10
DEBUG (Env): Episode done for env 57. Reward: 19.26, Length: 8
DEBUG (Env): Episode done for env 58. Reward: -19.67, Length: 36
1265
Time taken for simulation:  7.203623294830322
average overall reward:  -0.12092586  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  0.052642807  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 52. Reward: -15.02, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 26.34, Length: 2
DEBUG (Env): Episode done for env 90. Reward: -15.78, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -11.33, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -24.60, Length: 36
1266
Time taken for simulation:  6.999741792678833
average overall reward:  -0.41614395  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.15247451  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: 21.77, Length: 4
DEBUG (Env): Episode done for env 35. Reward: -20.54, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -10.49, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -33.81, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -16.85, Length: 36
1267
Time taken for simulation:  7.404332876205444
average overall reward:  -0.15029216  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.10748439  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 13. Reward: -20.24, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 25.39, Length: 1
DEBUG (Env): Episode done for env 74. Reward: 15.51, Length: 9
DEBUG (Env): Episode done for env 98. Reward: -20.30, Length: 36
1268
Time taken for simulation:  7.229033470153809
average overall reward:  -0.030663025  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.12553291  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: -16.80, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 14.55, Length: 18
DEBUG (Env): Episode done for env 55. Reward: 21.13, Length: 3
DEBUG (Env): Episode done for env 71. Reward: 21.39, Length: 6
DEBUG (Env): Episode done for env 103. Reward: -19.76, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -13.09, Length: 36
1269
Time taken for simulation:  7.456881046295166
average overall reward:  -0.24394797  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  0.08016981  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 46. Reward: -15.23, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -8.24, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -17.96, Length: 36
1270
Time taken for simulation:  7.2066662311553955
average overall reward:  0.17858739  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.07084602  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 45. Reward: -14.19, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 18.59, Length: 17
DEBUG (Env): Episode done for env 55. Reward: 24.23, Length: 2
DEBUG (Env): Episode done for env 65. Reward: -18.79, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 26.98, Length: 14
DEBUG (Env): Episode done for env 123. Reward: -15.42, Length: 36
1271
Time taken for simulation:  7.234982252120972
average overall reward:  0.3455336  average fail penalty:  -0.140625  and average goal bonus:  0.6768601  and average same cell penalty:  -0.12871546 average distance reward:  -0.014125481  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 19. Reward: -21.81, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 7.40, Length: 21
DEBUG (Env): Episode done for env 31. Reward: -29.31, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -18.27, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 13.67, Length: 7
DEBUG (Env): Episode done for env 56. Reward: -13.96, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -13.33, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 13.39, Length: 14
DEBUG (Env): Episode done for env 87. Reward: 13.92, Length: 14
DEBUG (Env): Episode done for env 118. Reward: -17.92, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 8.36, Length: 19
1272
Time taken for simulation:  7.499294996261597
average overall reward:  0.45542917  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.27030247 average distance reward:  0.16704461  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: -21.38, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -12.90, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 22.53, Length: 1
DEBUG (Env): Episode done for env 50. Reward: 11.33, Length: 13
DEBUG (Env): Episode done for env 87. Reward: 23.46, Length: 1
DEBUG (Env): Episode done for env 88. Reward: 29.85, Length: 15
DEBUG (Env): Episode done for env 92. Reward: 25.23, Length: 32
1273
Time taken for simulation:  7.2704832553863525
average overall reward:  0.41365916  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  -0.014006866  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 9.26, Length: 14
DEBUG (Env): Episode done for env 68. Reward: -6.16, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 30.49, Length: 24
DEBUG (Env): Episode done for env 88. Reward: 22.24, Length: 1
DEBUG (Env): Episode done for env 91. Reward: 11.43, Length: 23
DEBUG (Env): Episode done for env 113. Reward: -16.22, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 10.30, Length: 34
1274
Time taken for simulation:  7.258018493652344
average overall reward:  0.18400025  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.07856441  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 33. Reward: -17.54, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 15.80, Length: 25
DEBUG (Env): Episode done for env 86. Reward: -19.81, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 13.42, Length: 9
DEBUG (Env): Episode done for env 114. Reward: 26.76, Length: 9
1275
Time taken for simulation:  7.233320713043213
average overall reward:  0.09831567  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.11538034  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: -16.90, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 13.35, Length: 9
DEBUG (Env): Episode done for env 43. Reward: -15.45, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 25.37, Length: 11
1276
Time taken for simulation:  7.240191459655762
average overall reward:  0.18924382  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.17825982  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 78. Reward: -20.87, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 23.44, Length: 15
DEBUG (Env): Episode done for env 89. Reward: -12.21, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -24.55, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 16.41, Length: 5
1277
Time taken for simulation:  7.28799295425415
average overall reward:  0.024664424  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.08538254  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 16. Reward: -15.66, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 26.29, Length: 2
DEBUG (Env): Episode done for env 30. Reward: -31.41, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -22.32, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 1.70, Length: 26
DEBUG (Env): Episode done for env 102. Reward: -14.82, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 29.75, Length: 7
1278
Time taken for simulation:  7.65315580368042
average overall reward:  -0.14051658  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020163 average distance reward:  -0.295133  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: 26.03, Length: 6
DEBUG (Env): Episode done for env 36. Reward: 29.64, Length: 12
DEBUG (Env): Episode done for env 49. Reward: 0.42, Length: 27
DEBUG (Env): Episode done for env 94. Reward: -26.25, Length: 36
1279
Time taken for simulation:  7.587676763534546
average overall reward:  0.5145142  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.039973117  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 26. Reward: 9.85, Length: 31
DEBUG (Env): Episode done for env 31. Reward: 31.70, Length: 8
DEBUG (Env): Episode done for env 53. Reward: 14.26, Length: 19
DEBUG (Env): Episode done for env 82. Reward: 20.01, Length: 6
DEBUG (Env): Episode done for env 119. Reward: 19.24, Length: 20
1280
Time taken for simulation:  7.095970630645752
average overall reward:  0.6079947  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.16733009 average distance reward:  0.19320023  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 17. Reward: -18.41, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -18.73, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 14.22, Length: 3
DEBUG (Env): Episode done for env 46. Reward: 30.87, Length: 11
DEBUG (Env): Episode done for env 78. Reward: 22.39, Length: 4
DEBUG (Env): Episode done for env 88. Reward: 29.66, Length: 7
DEBUG (Env): Episode done for env 99. Reward: 26.47, Length: 23
1281
Time taken for simulation:  7.147682428359985
average overall reward:  -0.537353  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.1673301 average distance reward:  -0.2752874  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 15. Reward: -16.34, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -17.04, Length: 36
1282
Time taken for simulation:  7.142007827758789
average overall reward:  0.19978943  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.045173056  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 19. Reward: 19.98, Length: 11
DEBUG (Env): Episode done for env 101. Reward: -18.17, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 11.90, Length: 16
DEBUG (Env): Episode done for env 116. Reward: 17.74, Length: 1
1283
Time taken for simulation:  7.122007608413696
average overall reward:  -0.046969682  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  0.0040984508  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: -22.89, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 23.03, Length: 13
DEBUG (Env): Episode done for env 92. Reward: 14.39, Length: 11
DEBUG (Env): Episode done for env 108. Reward: -7.09, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -25.83, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -16.44, Length: 36
1284
Time taken for simulation:  7.492676496505737
average overall reward:  0.087362304  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.052940823  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 57. Reward: 51.88, Length: 9
DEBUG (Env): Episode done for env 67. Reward: -11.54, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -15.55, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 21.67, Length: 1
1285
Time taken for simulation:  7.178958892822266
average overall reward:  -0.020521589  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.01933584  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 6. Reward: -14.00, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -5.15, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -16.60, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 24.67, Length: 14
DEBUG (Env): Episode done for env 81. Reward: -12.97, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -13.18, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 33.58, Length: 3
DEBUG (Env): Episode done for env 102. Reward: 24.83, Length: 8
DEBUG (Env): Episode done for env 115. Reward: -15.63, Length: 36
1286
Time taken for simulation:  7.0832366943359375
average overall reward:  -0.010570459  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.021671318  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 27. Reward: 26.45, Length: 14
DEBUG (Env): Episode done for env 68. Reward: 18.44, Length: 13
DEBUG (Env): Episode done for env 93. Reward: -23.93, Length: 36
1287
Time taken for simulation:  7.134030342102051
average overall reward:  -0.15421647  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  0.14876942  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 124. Reward: -16.16, Length: 36
1288
Time taken for simulation:  7.122265338897705
average overall reward:  0.07313652  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.0040097237  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: -18.97, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 10.95, Length: 30
DEBUG (Env): Episode done for env 63. Reward: -15.42, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -6.69, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 24.03, Length: 30
DEBUG (Env): Episode done for env 121. Reward: 34.19, Length: 4
1289
Time taken for simulation:  7.1603639125823975
average overall reward:  0.32557043  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  0.41064203  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: 19.13, Length: 1
DEBUG (Env): Episode done for env 10. Reward: -13.48, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -12.37, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -24.38, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -28.19, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -15.60, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -18.76, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 36.54, Length: 30
1290
Time taken for simulation:  7.373769998550415
average overall reward:  0.011141978  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.00015795231  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: -22.39, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 4.50, Length: 18
DEBUG (Env): Episode done for env 75. Reward: -11.80, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 25.24, Length: 11
1291
Time taken for simulation:  7.3764328956604
average overall reward:  0.27671748  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.1108333  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 16. Reward: 24.33, Length: 14
DEBUG (Env): Episode done for env 20. Reward: 25.54, Length: 11
DEBUG (Env): Episode done for env 59. Reward: -23.52, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -28.13, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -33.53, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 17.48, Length: 11
DEBUG (Env): Episode done for env 93. Reward: 29.86, Length: 5
1292
Time taken for simulation:  7.273563623428345
average overall reward:  0.37363812  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.10939276  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: 28.24, Length: 20
DEBUG (Env): Episode done for env 90. Reward: 9.07, Length: 27
DEBUG (Env): Episode done for env 91. Reward: 18.55, Length: 19
DEBUG (Env): Episode done for env 94. Reward: 26.54, Length: 14
DEBUG (Env): Episode done for env 106. Reward: -23.59, Length: 36
1293
Time taken for simulation:  7.331971168518066
average overall reward:  0.05408805  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  -0.22373068  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 12. Reward: -16.09, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -11.74, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 16.42, Length: 22
DEBUG (Env): Episode done for env 37. Reward: -14.25, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 27.67, Length: 5
DEBUG (Env): Episode done for env 72. Reward: 25.34, Length: 30
DEBUG (Env): Episode done for env 88. Reward: 27.17, Length: 13
DEBUG (Env): Episode done for env 95. Reward: -18.41, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 13.13, Length: 17
1294
Time taken for simulation:  7.145441055297852
average overall reward:  0.7567071  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.15445855 average distance reward:  0.10517201  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 0. Reward: -13.86, Length: 36
DEBUG (Env): Episode done for env 3. Reward: 8.82, Length: 19
DEBUG (Env): Episode done for env 17. Reward: 25.42, Length: 14
DEBUG (Env): Episode done for env 20. Reward: 24.29, Length: 3
DEBUG (Env): Episode done for env 39. Reward: -16.70, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -11.36, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -28.98, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 20.62, Length: 18
DEBUG (Env): Episode done for env 95. Reward: 16.50, Length: 1
DEBUG (Env): Episode done for env 119. Reward: 13.97, Length: 15
DEBUG (Env): Episode done for env 123. Reward: 21.99, Length: 17
1295
Time taken for simulation:  7.441360235214233
average overall reward:  -0.09328  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  0.05089634  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 37. Reward: 1.88, Length: 2
1296
Time taken for simulation:  7.864152908325195
average overall reward:  0.4506984  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.3277799  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -22.63, Length: 36
DEBUG (Env): Episode done for env 2. Reward: -18.55, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 23.20, Length: 26
DEBUG (Env): Episode done for env 68. Reward: 28.67, Length: 10
DEBUG (Env): Episode done for env 75. Reward: 27.86, Length: 6
DEBUG (Env): Episode done for env 100. Reward: -10.53, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -17.66, Length: 36
1297
Time taken for simulation:  7.383982181549072
average overall reward:  0.3343479  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.10641157  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: 21.98, Length: 12
DEBUG (Env): Episode done for env 48. Reward: 13.50, Length: 12
DEBUG (Env): Episode done for env 72. Reward: 20.75, Length: 4
DEBUG (Env): Episode done for env 83. Reward: -16.76, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -13.33, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 13.65, Length: 9
1298
Time taken for simulation:  7.0663347244262695
average overall reward:  -0.2048587  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.19835998  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: 18.52, Length: 3
DEBUG (Env): Episode done for env 117. Reward: -20.58, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 12.47, Length: 11
1299
Time taken for simulation:  7.709099054336548
average overall reward:  0.17145415  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.22713342  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 60. Reward: -17.67, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -21.50, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 38.16, Length: 5
DEBUG (Env): Episode done for env 112. Reward: 18.65, Length: 31
1300
Time taken for simulation:  7.204517602920532
average overall reward:  0.709764  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.06284007  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 9. Reward: -27.48, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 21.69, Length: 9
DEBUG (Env): Episode done for env 21. Reward: 28.25, Length: 8
DEBUG (Env): Episode done for env 30. Reward: 11.66, Length: 20
DEBUG (Env): Episode done for env 37. Reward: 25.02, Length: 2
DEBUG (Env): Episode done for env 58. Reward: -16.57, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 13.48, Length: 30
DEBUG (Env): Episode done for env 85. Reward: 28.54, Length: 15
DEBUG (Env): Episode done for env 122. Reward: 7.34, Length: 27
1301
Time taken for simulation:  7.6673743724823
average overall reward:  0.010699093  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.047159918  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: 22.62, Length: 7
DEBUG (Env): Episode done for env 52. Reward: -27.30, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 29.67, Length: 7
1302
Time taken for simulation:  7.158350229263306
average overall reward:  0.56020206  average fail penalty:  -0.0234375  and average goal bonus:  0.8122322  and average same cell penalty:  -0.20594473 average distance reward:  0.025212687  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 30. Reward: 17.27, Length: 2
DEBUG (Env): Episode done for env 31. Reward: 23.62, Length: 23
DEBUG (Env): Episode done for env 47. Reward: 11.10, Length: 6
DEBUG (Env): Episode done for env 92. Reward: 25.85, Length: 19
DEBUG (Env): Episode done for env 103. Reward: 1.74, Length: 34
DEBUG (Env): Episode done for env 104. Reward: -18.05, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 17.34, Length: 10
1303
Time taken for simulation:  7.166442394256592
average overall reward:  -0.11981645  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.29604554 average distance reward:  -0.08827646  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: -11.94, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 6.85, Length: 18
DEBUG (Env): Episode done for env 35. Reward: -13.57, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 10.85, Length: 32
DEBUG (Env): Episode done for env 74. Reward: -19.95, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 21.21, Length: 15
DEBUG (Env): Episode done for env 98. Reward: -14.24, Length: 36
1304
Time taken for simulation:  7.5819456577301025
average overall reward:  0.5822633  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.042662736  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 4. Reward: 1.35, Length: 31
DEBUG (Env): Episode done for env 5. Reward: -2.59, Length: 36
DEBUG (Env): Episode done for env 10. Reward: 19.42, Length: 15
DEBUG (Env): Episode done for env 22. Reward: 18.03, Length: 15
DEBUG (Env): Episode done for env 39. Reward: 7.38, Length: 10
DEBUG (Env): Episode done for env 41. Reward: -13.89, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 15.34, Length: 24
DEBUG (Env): Episode done for env 61. Reward: 32.29, Length: 13
DEBUG (Env): Episode done for env 71. Reward: -17.47, Length: 36
1305
Time taken for simulation:  7.399198293685913
average overall reward:  0.28060418  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.09793908  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: 14.16, Length: 9
DEBUG (Env): Episode done for env 31. Reward: 24.02, Length: 3
DEBUG (Env): Episode done for env 32. Reward: 13.72, Length: 16
DEBUG (Env): Episode done for env 109. Reward: -16.42, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -20.95, Length: 36
1306
Time taken for simulation:  7.628915071487427
average overall reward:  0.18618232  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.19037543  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 21. Reward: 26.82, Length: 6
DEBUG (Env): Episode done for env 45. Reward: -13.49, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -24.59, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 29.92, Length: 4
1307
Time taken for simulation:  7.058902025222778
average overall reward:  0.57484263  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.2931146  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 52. Reward: 24.28, Length: 6
DEBUG (Env): Episode done for env 62. Reward: -17.63, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -9.44, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 28.48, Length: 5
DEBUG (Env): Episode done for env 112. Reward: 16.56, Length: 8
DEBUG (Env): Episode done for env 116. Reward: 20.73, Length: 25
DEBUG (Env): Episode done for env 120. Reward: -23.86, Length: 36
1308
Time taken for simulation:  7.0910303592681885
average overall reward:  0.41579992  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.06435773 average distance reward:  0.033405095  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 17.85, Length: 19
DEBUG (Env): Episode done for env 48. Reward: 12.74, Length: 11
DEBUG (Env): Episode done for env 50. Reward: -12.09, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -15.96, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 24.26, Length: 2
DEBUG (Env): Episode done for env 119. Reward: 28.49, Length: 7
1309
Time taken for simulation:  7.10155463218689
average overall reward:  0.47242996  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.36929983  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: 27.38, Length: 15
DEBUG (Env): Episode done for env 57. Reward: 48.93, Length: 25
DEBUG (Env): Episode done for env 60. Reward: 23.59, Length: 10
DEBUG (Env): Episode done for env 113. Reward: -25.80, Length: 36
1310
Time taken for simulation:  7.262667894363403
average overall reward:  0.5832363  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.30976856  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 33. Reward: -14.15, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -6.23, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 20.85, Length: 7
DEBUG (Env): Episode done for env 86. Reward: -19.66, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 11.59, Length: 18
DEBUG (Env): Episode done for env 105. Reward: -10.08, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 16.03, Length: 28
DEBUG (Env): Episode done for env 114. Reward: -24.29, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 46.29, Length: 3
1311
Time taken for simulation:  7.263071775436401
average overall reward:  0.113490134  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.20387469  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 43. Reward: -13.88, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 33.50, Length: 14
1312
Time taken for simulation:  7.133772850036621
average overall reward:  0.28684735  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.31678358  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: 19.70, Length: 8
DEBUG (Env): Episode done for env 86. Reward: 21.45, Length: 2
DEBUG (Env): Episode done for env 89. Reward: -20.16, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -19.70, Length: 36
1313
Time taken for simulation:  7.191589832305908
average overall reward:  -0.41325936  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.19877051  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: -50.57, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -9.63, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -10.40, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 34.59, Length: 8
1314
Time taken for simulation:  7.354295015335083
average overall reward:  0.41717988  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.33518162  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: 26.94, Length: 18
DEBUG (Env): Episode done for env 7. Reward: -28.13, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 19.10, Length: 21
DEBUG (Env): Episode done for env 36. Reward: -15.94, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -18.60, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 14.59, Length: 12
1315
Time taken for simulation:  7.4946534633636475
average overall reward:  -0.053016245  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.061694615  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 26. Reward: -13.04, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -13.02, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 22.69, Length: 22
DEBUG (Env): Episode done for env 96. Reward: 12.05, Length: 12
1316
Time taken for simulation:  7.035064458847046
average overall reward:  0.68470263  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.484815  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: 2.53, Length: 33
DEBUG (Env): Episode done for env 42. Reward: 23.08, Length: 3
DEBUG (Env): Episode done for env 51. Reward: 32.81, Length: 6
DEBUG (Env): Episode done for env 59. Reward: 37.19, Length: 25
DEBUG (Env): Episode done for env 99. Reward: -21.03, Length: 36
1317
Time taken for simulation:  7.158502101898193
average overall reward:  0.016265541  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.0029788576  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 15. Reward: -16.09, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 15.66, Length: 2
DEBUG (Env): Episode done for env 112. Reward: 26.13, Length: 10
1318
Time taken for simulation:  7.425854444503784
average overall reward:  0.51883185  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.26745802  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: -17.62, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 29.39, Length: 14
DEBUG (Env): Episode done for env 25. Reward: 14.32, Length: 30
DEBUG (Env): Episode done for env 40. Reward: 8.77, Length: 28
DEBUG (Env): Episode done for env 56. Reward: 20.03, Length: 8
1319
Time taken for simulation:  7.344510793685913
average overall reward:  0.013534665  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.01542218  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 32. Reward: 29.77, Length: 14
DEBUG (Env): Episode done for env 55. Reward: -16.65, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 19.82, Length: 26
DEBUG (Env): Episode done for env 108. Reward: -12.55, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -10.39, Length: 36
1320
Time taken for simulation:  7.00871729850769
average overall reward:  -0.47114414  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  -0.22860658  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 67. Reward: -6.12, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -13.27, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 37.29, Length: 10
1321
Time taken for simulation:  7.691725969314575
average overall reward:  0.50113326  average fail penalty:  -0.1171875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.16733009 average distance reward:  0.15665129  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 12. Reward: 30.08, Length: 7
DEBUG (Env): Episode done for env 18. Reward: -17.41, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -0.45, Length: 14
DEBUG (Env): Episode done for env 81. Reward: -17.23, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 23.65, Length: 9
DEBUG (Env): Episode done for env 94. Reward: 15.63, Length: 29
DEBUG (Env): Episode done for env 101. Reward: -14.96, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -2.89, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -19.74, Length: 36
1322
Time taken for simulation:  7.5954694747924805
average overall reward:  0.10741034  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  0.18492338  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 27. Reward: -8.96, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 28.82, Length: 15
1323
Time taken for simulation:  7.236984014511108
average overall reward:  1.1409916  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.4471926  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: 22.22, Length: 20
DEBUG (Env): Episode done for env 14. Reward: 23.01, Length: 7
DEBUG (Env): Episode done for env 47. Reward: 42.31, Length: 21
DEBUG (Env): Episode done for env 85. Reward: 18.68, Length: 23
DEBUG (Env): Episode done for env 94. Reward: 13.99, Length: 2
DEBUG (Env): Episode done for env 109. Reward: 14.01, Length: 10
DEBUG (Env): Episode done for env 123. Reward: 28.90, Length: 29
1324
Time taken for simulation:  7.386267423629761
average overall reward:  0.7556822  average fail penalty:  -0.0234375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.14158702 average distance reward:  -0.2497811  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 5. Reward: 18.41, Length: 12
DEBUG (Env): Episode done for env 9. Reward: 11.38, Length: 24
DEBUG (Env): Episode done for env 16. Reward: 22.39, Length: 24
DEBUG (Env): Episode done for env 19. Reward: 27.83, Length: 6
DEBUG (Env): Episode done for env 20. Reward: 26.13, Length: 30
DEBUG (Env): Episode done for env 21. Reward: 35.80, Length: 18
DEBUG (Env): Episode done for env 45. Reward: 14.94, Length: 18
DEBUG (Env): Episode done for env 59. Reward: 20.94, Length: 8
DEBUG (Env): Episode done for env 70. Reward: -5.27, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 41.97, Length: 12
1325
Time taken for simulation:  7.116090536117554
average overall reward:  -0.2600787  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  -0.2090106  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: 10.08, Length: 1
DEBUG (Env): Episode done for env 11. Reward: -22.69, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 16.66, Length: 6
DEBUG (Env): Episode done for env 76. Reward: -21.24, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -15.11, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -14.85, Length: 36
1326
Time taken for simulation:  7.169513940811157
average overall reward:  0.54943883  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.12871546 average distance reward:  -0.1512768  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 16. Reward: 26.52, Length: 2
DEBUG (Env): Episode done for env 34. Reward: -11.87, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 7.89, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 25.72, Length: 22
DEBUG (Env): Episode done for env 73. Reward: 26.35, Length: 13
DEBUG (Env): Episode done for env 82. Reward: -17.31, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 21.38, Length: 2
DEBUG (Env): Episode done for env 112. Reward: 27.35, Length: 9
DEBUG (Env): Episode done for env 119. Reward: 31.10, Length: 18
1327
Time taken for simulation:  7.052452325820923
average overall reward:  0.8295072  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.20602076  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 24. Reward: 20.62, Length: 34
DEBUG (Env): Episode done for env 57. Reward: 4.07, Length: 18
DEBUG (Env): Episode done for env 63. Reward: 26.84, Length: 2
DEBUG (Env): Episode done for env 67. Reward: 27.81, Length: 7
DEBUG (Env): Episode done for env 77. Reward: -13.59, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -20.17, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 6.29, Length: 35
DEBUG (Env): Episode done for env 93. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 14.68, Length: 12
DEBUG (Env): Episode done for env 121. Reward: 15.89, Length: 16
1328
Time taken for simulation:  7.043536901473999
average overall reward:  0.57766294  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  0.18035117  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 29. Reward: 27.99, Length: 25
DEBUG (Env): Episode done for env 71. Reward: 15.92, Length: 24
DEBUG (Env): Episode done for env 85. Reward: 25.12, Length: 5
DEBUG (Env): Episode done for env 95. Reward: 11.42, Length: 29
DEBUG (Env): Episode done for env 103. Reward: 25.02, Length: 26
1329
Time taken for simulation:  7.284488916397095
average overall reward:  0.2179393  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.022868503  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 28. Reward: -18.08, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 12.66, Length: 6
DEBUG (Env): Episode done for env 95. Reward: 17.27, Length: 1
DEBUG (Env): Episode done for env 104. Reward: 24.90, Length: 7
DEBUG (Env): Episode done for env 118. Reward: -9.48, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 20.29, Length: 3
1330
Time taken for simulation:  7.070988178253174
average overall reward:  0.14867517  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  0.33511534  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -23.25, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -30.34, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -12.10, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -21.84, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 24.73, Length: 4
1331
Time taken for simulation:  7.26259708404541
average overall reward:  0.20823866  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  -0.027958013  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 82. Reward: 24.72, Length: 5
DEBUG (Env): Episode done for env 83. Reward: 6.69, Length: 34
DEBUG (Env): Episode done for env 88. Reward: 32.39, Length: 16
DEBUG (Env): Episode done for env 94. Reward: 16.10, Length: 2
1332
Time taken for simulation:  7.0685601234436035
average overall reward:  -0.35253614  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  -0.19183908  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 68. Reward: -17.74, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -14.33, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 23.93, Length: 12
DEBUG (Env): Episode done for env 100. Reward: -25.74, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -18.40, Length: 36
1333
Time taken for simulation:  7.296908378601074
average overall reward:  0.20887718  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.102972366 average distance reward:  0.023906514  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: -18.94, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -14.69, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 19.87, Length: 1
DEBUG (Env): Episode done for env 107. Reward: -23.55, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 24.97, Length: 14
DEBUG (Env): Episode done for env 121. Reward: 17.22, Length: 6
1334
Time taken for simulation:  7.450775623321533
average overall reward:  0.7242613  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168781 average distance reward:  0.23845251  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 11. Reward: 19.88, Length: 9
DEBUG (Env): Episode done for env 36. Reward: 21.07, Length: 20
DEBUG (Env): Episode done for env 40. Reward: 16.40, Length: 16
DEBUG (Env): Episode done for env 66. Reward: -1.26, Length: 34
DEBUG (Env): Episode done for env 95. Reward: 11.39, Length: 5
DEBUG (Env): Episode done for env 100. Reward: 23.56, Length: 2
DEBUG (Env): Episode done for env 117. Reward: -18.73, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -3.51, Length: 36
1335
Time taken for simulation:  7.219282865524292
average overall reward:  -0.103571355  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.1228157  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 54. Reward: 37.57, Length: 5
DEBUG (Env): Episode done for env 79. Reward: -13.50, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 9.63, Length: 27
1336
Time taken for simulation:  7.6098411083221436
average overall reward:  0.14721619  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.22633296  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: 19.57, Length: 3
DEBUG (Env): Episode done for env 37. Reward: -25.71, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -4.91, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 12.38, Length: 9
DEBUG (Env): Episode done for env 122. Reward: -5.36, Length: 36
1337
Time taken for simulation:  7.618279457092285
average overall reward:  0.28662384  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.009506948  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 22.68, Length: 13
DEBUG (Env): Episode done for env 17. Reward: -23.44, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 16.21, Length: 6
DEBUG (Env): Episode done for env 110. Reward: 6.42, Length: 27
DEBUG (Env): Episode done for env 111. Reward: 26.18, Length: 4
1338
Time taken for simulation:  7.131196737289429
average overall reward:  0.3578425  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.119340256  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: 12.89, Length: 14
DEBUG (Env): Episode done for env 30. Reward: -19.96, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 37.72, Length: 11
DEBUG (Env): Episode done for env 101. Reward: 25.98, Length: 17
DEBUG (Env): Episode done for env 111. Reward: 22.01, Length: 1
1339
Time taken for simulation:  7.099113941192627
average overall reward:  -0.00148651  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  -0.057741717  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 24. Reward: 29.80, Length: 12
DEBUG (Env): Episode done for env 35. Reward: -19.66, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -6.82, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 17.98, Length: 11
DEBUG (Env): Episode done for env 98. Reward: -17.79, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 21.13, Length: 1
1340
Time taken for simulation:  7.376367807388306
average overall reward:  0.6900007  average fail penalty:  -0.1171875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.11338925  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 0. Reward: 33.74, Length: 10
DEBUG (Env): Episode done for env 4. Reward: -24.78, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -17.25, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 17.63, Length: 14
DEBUG (Env): Episode done for env 23. Reward: 21.53, Length: 27
DEBUG (Env): Episode done for env 41. Reward: -28.87, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -14.33, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 31.59, Length: 25
DEBUG (Env): Episode done for env 54. Reward: 10.78, Length: 5
DEBUG (Env): Episode done for env 61. Reward: -21.63, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 19.06, Length: 5
DEBUG (Env): Episode done for env 98. Reward: 17.42, Length: 1
1341
Time taken for simulation:  7.132011890411377
average overall reward:  0.46159813  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.2699709  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: -17.78, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 16.39, Length: 16
DEBUG (Env): Episode done for env 12. Reward: 24.62, Length: 20
DEBUG (Env): Episode done for env 31. Reward: -18.56, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 19.21, Length: 14
DEBUG (Env): Episode done for env 126. Reward: 30.93, Length: 9
DEBUG (Env): Episode done for env 127. Reward: -12.77, Length: 36
1342
Time taken for simulation:  7.316177129745483
average overall reward:  0.5239743  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.3822295  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: 9.89, Length: 6
DEBUG (Env): Episode done for env 17. Reward: 16.44, Length: 5
DEBUG (Env): Episode done for env 58. Reward: 29.57, Length: 6
DEBUG (Env): Episode done for env 65. Reward: -28.73, Length: 36
1343
Time taken for simulation:  7.107137203216553
average overall reward:  0.3054063  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  -0.047336087  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 27. Reward: 14.11, Length: 21
DEBUG (Env): Episode done for env 41. Reward: 31.40, Length: 3
DEBUG (Env): Episode done for env 62. Reward: -15.17, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -16.94, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 26.08, Length: 4
DEBUG (Env): Episode done for env 86. Reward: 14.89, Length: 13
DEBUG (Env): Episode done for env 109. Reward: 18.18, Length: 20
DEBUG (Env): Episode done for env 116. Reward: -14.02, Length: 36
1344
Time taken for simulation:  7.144714117050171
average overall reward:  -0.099414885  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.11936107  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: -19.63, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 10.62, Length: 21
DEBUG (Env): Episode done for env 31. Reward: 20.70, Length: 3
DEBUG (Env): Episode done for env 48. Reward: -31.31, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -8.77, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -19.65, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 0.37, Length: 34
1345
Time taken for simulation:  7.045105695724487
average overall reward:  0.16927297  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.15828899  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: -17.82, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -29.01, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 14.60, Length: 18
DEBUG (Env): Episode done for env 70. Reward: 23.07, Length: 21
DEBUG (Env): Episode done for env 113. Reward: -23.00, Length: 36
1346
Time taken for simulation:  7.062434673309326
average overall reward:  -0.061433867  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  0.06916913  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 33. Reward: -23.98, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 21.37, Length: 3
DEBUG (Env): Episode done for env 73. Reward: 26.60, Length: 20
DEBUG (Env): Episode done for env 105. Reward: -16.11, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -16.35, Length: 36
1347
Time taken for simulation:  7.070642471313477
average overall reward:  1.0696952  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.102972366 average distance reward:  0.29636148  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 31. Reward: 23.15, Length: 3
DEBUG (Env): Episode done for env 43. Reward: -10.35, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 10.50, Length: 17
DEBUG (Env): Episode done for env 55. Reward: 6.41, Length: 28
DEBUG (Env): Episode done for env 63. Reward: 22.17, Length: 9
DEBUG (Env): Episode done for env 67. Reward: 24.55, Length: 2
DEBUG (Env): Episode done for env 68. Reward: 37.08, Length: 15
DEBUG (Env): Episode done for env 114. Reward: 20.09, Length: 1
1348
Time taken for simulation:  7.095632076263428
average overall reward:  0.56787926  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  0.1682619  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: 27.49, Length: 6
DEBUG (Env): Episode done for env 30. Reward: 22.18, Length: 10
DEBUG (Env): Episode done for env 44. Reward: 22.33, Length: 1
DEBUG (Env): Episode done for env 97. Reward: -16.73, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 15.38, Length: 14
DEBUG (Env): Episode done for env 123. Reward: 3.73, Length: 25
1349
Time taken for simulation:  7.1694746017456055
average overall reward:  0.09646488  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.06871751  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 61. Reward: 31.76, Length: 9
DEBUG (Env): Episode done for env 78. Reward: 20.05, Length: 22
DEBUG (Env): Episode done for env 84. Reward: 28.15, Length: 19
1350
Time taken for simulation:  7.0886664390563965
average overall reward:  -0.072399154  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030244 average distance reward:  0.2041418  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -20.36, Length: 36
DEBUG (Env): Episode done for env 7. Reward: -12.38, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -21.49, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 20.46, Length: 5
DEBUG (Env): Episode done for env 92. Reward: -20.70, Length: 36
1351
Time taken for simulation:  6.996311664581299
average overall reward:  0.1175221  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.17016074  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 45. Reward: 2.26, Length: 27
DEBUG (Env): Episode done for env 99. Reward: 7.33, Length: 35
DEBUG (Env): Episode done for env 105. Reward: 26.53, Length: 5
DEBUG (Env): Episode done for env 116. Reward: 25.81, Length: 8
1352
Time taken for simulation:  7.062323331832886
average overall reward:  0.5823565  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  0.19330506  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 42. Reward: -13.91, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -14.12, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 18.76, Length: 18
DEBUG (Env): Episode done for env 91. Reward: 8.17, Length: 11
DEBUG (Env): Episode done for env 92. Reward: 8.49, Length: 2
DEBUG (Env): Episode done for env 104. Reward: 21.04, Length: 23
DEBUG (Env): Episode done for env 122. Reward: 35.83, Length: 16
1353
Time taken for simulation:  7.0717222690582275
average overall reward:  -0.091009185  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.061072946  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 15. Reward: -20.18, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -22.19, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 11.57, Length: 13
DEBUG (Env): Episode done for env 118. Reward: 11.93, Length: 24
1354
Time taken for simulation:  7.120678901672363
average overall reward:  -0.3443008  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  0.0055600703  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 22. Reward: -26.19, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -14.69, Length: 36
1355
Time taken for simulation:  7.166363000869751
average overall reward:  1.4604337  average fail penalty:  -0.046875  and average goal bonus:  1.2183483  and average same cell penalty:  -0.18020165 average distance reward:  0.5170226  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 0. Reward: 29.46, Length: 15
DEBUG (Env): Episode done for env 9. Reward: 23.40, Length: 14
DEBUG (Env): Episode done for env 27. Reward: 27.11, Length: 12
DEBUG (Env): Episode done for env 32. Reward: -0.43, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 27.13, Length: 3
DEBUG (Env): Episode done for env 49. Reward: 26.87, Length: 5
DEBUG (Env): Episode done for env 54. Reward: 13.78, Length: 15
DEBUG (Env): Episode done for env 66. Reward: 19.49, Length: 3
DEBUG (Env): Episode done for env 76. Reward: 18.89, Length: 30
DEBUG (Env): Episode done for env 87. Reward: 27.32, Length: 15
DEBUG (Env): Episode done for env 108. Reward: -4.86, Length: 36
1356
Time taken for simulation:  7.176675796508789
average overall reward:  -0.03374876  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.027250025  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 14. Reward: 13.04, Length: 33
DEBUG (Env): Episode done for env 69. Reward: -10.39, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 14.52, Length: 19
1357
Time taken for simulation:  7.217013835906982
average overall reward:  0.13964012  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.28906947  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: -15.98, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -11.76, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 10.89, Length: 32
DEBUG (Env): Episode done for env 81. Reward: -22.97, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -13.44, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 16.13, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -25.31, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 15.34, Length: 16
1358
Time taken for simulation:  7.4201154708862305
average overall reward:  -0.29251835  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  -0.21269974  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 96. Reward: 12.44, Length: 31
1359
Time taken for simulation:  7.150079011917114
average overall reward:  0.19506116  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.18868835  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 6. Reward: 15.29, Length: 11
DEBUG (Env): Episode done for env 47. Reward: -26.64, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 5.03, Length: 10
1360
Time taken for simulation:  7.347753047943115
average overall reward:  0.02497387  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.069896  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: 32.56, Length: 5
DEBUG (Env): Episode done for env 19. Reward: -14.32, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -23.07, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -16.99, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 39.31, Length: 10
DEBUG (Env): Episode done for env 75. Reward: 13.96, Length: 27
1361
Time taken for simulation:  7.306917190551758
average overall reward:  -0.27884355  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  0.011270754  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 125. Reward: -18.97, Length: 36
1362
Time taken for simulation:  7.980167627334595
average overall reward:  -0.08850719  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.014047094  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 34. Reward: -18.72, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -22.46, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -17.65, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 16.29, Length: 15
DEBUG (Env): Episode done for env 106. Reward: 31.44, Length: 18
DEBUG (Env): Episode done for env 112. Reward: -22.00, Length: 36
1363
Time taken for simulation:  7.372525453567505
average overall reward:  0.3410523  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455936 average distance reward:  0.0034870356  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 34.08, Length: 4
DEBUG (Env): Episode done for env 28. Reward: 3.51, Length: 34
DEBUG (Env): Episode done for env 48. Reward: 4.79, Length: 19
DEBUG (Env): Episode done for env 57. Reward: -20.50, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 14.02, Length: 8
DEBUG (Env): Episode done for env 93. Reward: -6.27, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 14.95, Length: 19
1364
Time taken for simulation:  7.293935060501099
average overall reward:  0.06971838  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  -0.102380715  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 29. Reward: -14.67, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 28.07, Length: 2
DEBUG (Env): Episode done for env 71. Reward: -18.68, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 12.76, Length: 18
DEBUG (Env): Episode done for env 91. Reward: 27.08, Length: 12
DEBUG (Env): Episode done for env 103. Reward: -12.21, Length: 36
1365
Time taken for simulation:  7.0738115310668945
average overall reward:  0.95118564  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.39045316  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 31.39, Length: 20
DEBUG (Env): Episode done for env 22. Reward: 21.03, Length: 11
DEBUG (Env): Episode done for env 57. Reward: 21.69, Length: 2
DEBUG (Env): Episode done for env 87. Reward: 35.39, Length: 10
DEBUG (Env): Episode done for env 102. Reward: 24.19, Length: 8
DEBUG (Env): Episode done for env 108. Reward: 40.25, Length: 10
DEBUG (Env): Episode done for env 119. Reward: -23.93, Length: 36
1366
Time taken for simulation:  7.143682241439819
average overall reward:  0.34302077  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.21645308  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 25. Reward: 23.54, Length: 12
DEBUG (Env): Episode done for env 76. Reward: 21.67, Length: 11
DEBUG (Env): Episode done for env 123. Reward: 10.89, Length: 18
1367
Time taken for simulation:  7.206084728240967
average overall reward:  0.54847103  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.2574309 average distance reward:  0.11184281  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: 11.90, Length: 30
DEBUG (Env): Episode done for env 34. Reward: 32.41, Length: 5
DEBUG (Env): Episode done for env 36. Reward: 4.30, Length: 33
DEBUG (Env): Episode done for env 82. Reward: 13.30, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -14.71, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 23.51, Length: 24
DEBUG (Env): Episode done for env 88. Reward: -16.76, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 18.19, Length: 16
1368
Time taken for simulation:  7.362202167510986
average overall reward:  0.405482  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.19272277  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 33. Reward: 6.43, Length: 22
DEBUG (Env): Episode done for env 63. Reward: 36.67, Length: 21
DEBUG (Env): Episode done for env 90. Reward: -14.95, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 16.74, Length: 3
DEBUG (Env): Episode done for env 113. Reward: 15.58, Length: 23
1369
Time taken for simulation:  7.710439443588257
average overall reward:  -0.20614737  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.3010172  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 72. Reward: -14.27, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 16.75, Length: 5
DEBUG (Env): Episode done for env 107. Reward: -16.27, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 9.34, Length: 2
DEBUG (Env): Episode done for env 121. Reward: -18.81, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 20.44, Length: 8
1370
Time taken for simulation:  7.3212316036224365
average overall reward:  0.13754421  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.058694214  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 11. Reward: -13.59, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 22.94, Length: 10
DEBUG (Env): Episode done for env 29. Reward: 32.76, Length: 6
DEBUG (Env): Episode done for env 40. Reward: -14.87, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 20.02, Length: 15
DEBUG (Env): Episode done for env 88. Reward: 23.11, Length: 3
DEBUG (Env): Episode done for env 95. Reward: -15.71, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -16.78, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -17.17, Length: 36
1371
Time taken for simulation:  7.281752824783325
average overall reward:  -0.21440496  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  -0.046791114  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 79. Reward: -12.58, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 27.01, Length: 8
1372
Time taken for simulation:  7.2417426109313965
average overall reward:  0.292404  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.14835352  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: 10.86, Length: 16
DEBUG (Env): Episode done for env 37. Reward: -19.31, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 28.58, Length: 7
DEBUG (Env): Episode done for env 77. Reward: -28.25, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 25.95, Length: 5
1373
Time taken for simulation:  7.344468355178833
average overall reward:  0.3239563  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.07258254  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: 7.22, Length: 20
DEBUG (Env): Episode done for env 79. Reward: 23.19, Length: 2
DEBUG (Env): Episode done for env 110. Reward: -17.16, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 15.68, Length: 8
DEBUG (Env): Episode done for env 122. Reward: 10.53, Length: 21
1374
Time taken for simulation:  7.195287704467773
average overall reward:  0.13626565  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.3401885  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 21. Reward: -14.18, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 26.89, Length: 23
DEBUG (Env): Episode done for env 111. Reward: -19.75, Length: 36
1375
Time taken for simulation:  7.118606090545654
average overall reward:  0.06522432  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  -0.10296542  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 24. Reward: 22.23, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 18.51, Length: 20
DEBUG (Env): Episode done for env 35. Reward: -20.72, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -10.03, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -15.70, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 27.07, Length: 4
DEBUG (Env): Episode done for env 123. Reward: 29.63, Length: 9
1376
Time taken for simulation:  7.447296619415283
average overall reward:  0.15754917  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.13299179  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 4. Reward: -17.05, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -19.78, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -25.02, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -18.78, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 22.55, Length: 6
DEBUG (Env): Episode done for env 46. Reward: -14.22, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -9.12, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 20.41, Length: 27
DEBUG (Env): Episode done for env 103. Reward: 30.63, Length: 7
1377
Time taken for simulation:  7.173734188079834
average overall reward:  0.050701767  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.007318154  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: -14.23, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -3.55, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -5.34, Length: 1
DEBUG (Env): Episode done for env 108. Reward: 23.38, Length: 9
DEBUG (Env): Episode done for env 126. Reward: -20.10, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 38.71, Length: 20
1378
Time taken for simulation:  7.258308172225952
average overall reward:  -0.23884985  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  0.085267946  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: -21.55, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -20.25, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -27.23, Length: 36
1379
Time taken for simulation:  7.4323341846466064
average overall reward:  -0.020479858  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  0.12068909  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 62. Reward: -15.20, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -23.75, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 7.05, Length: 34
DEBUG (Env): Episode done for env 86. Reward: -11.33, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -17.09, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 28.77, Length: 6
1380
Time taken for simulation:  7.092070817947388
average overall reward:  -0.18923412  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.090100825 average distance reward:  0.01903978  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 8. Reward: -17.69, Length: 36
DEBUG (Env): Episode done for env 13. Reward: -15.34, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -24.19, Length: 36
1381
Time taken for simulation:  7.181105136871338
average overall reward:  0.49959677  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  0.2505286  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 25. Reward: 24.14, Length: 15
DEBUG (Env): Episode done for env 112. Reward: 9.92, Length: 19
DEBUG (Env): Episode done for env 121. Reward: 4.89, Length: 12
DEBUG (Env): Episode done for env 123. Reward: 26.61, Length: 6
1382
Time taken for simulation:  7.517594337463379
average overall reward:  -0.552099  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  -0.21049842  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 41. Reward: -11.62, Length: 36
1383
Time taken for simulation:  7.487435579299927
average overall reward:  -0.0017941073  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.1673301 average distance reward:  0.330584  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 31. Reward: -15.99, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -20.48, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -10.76, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -25.12, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -15.38, Length: 36
1384
Time taken for simulation:  7.165398597717285
average overall reward:  0.12939754  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  -0.12889302  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: 29.08, Length: 12
DEBUG (Env): Episode done for env 15. Reward: 13.15, Length: 11
DEBUG (Env): Episode done for env 30. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -16.12, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -22.35, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -23.06, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 23.35, Length: 10
DEBUG (Env): Episode done for env 120. Reward: 18.16, Length: 9
1385
Time taken for simulation:  7.165764331817627
average overall reward:  0.580147  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.15478654  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 8.95, Length: 35
DEBUG (Env): Episode done for env 24. Reward: 13.09, Length: 10
DEBUG (Env): Episode done for env 30. Reward: 21.15, Length: 1
DEBUG (Env): Episode done for env 35. Reward: 26.06, Length: 10
DEBUG (Env): Episode done for env 41. Reward: 17.40, Length: 3
DEBUG (Env): Episode done for env 61. Reward: -16.26, Length: 36
1386
Time taken for simulation:  7.482465744018555
average overall reward:  0.83576214  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.16540074  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: -13.45, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 18.33, Length: 1
DEBUG (Env): Episode done for env 35. Reward: 28.66, Length: 1
DEBUG (Env): Episode done for env 73. Reward: 16.43, Length: 22
DEBUG (Env): Episode done for env 77. Reward: 43.28, Length: 14
DEBUG (Env): Episode done for env 100. Reward: 27.19, Length: 2
DEBUG (Env): Episode done for env 103. Reward: 32.65, Length: 9
DEBUG (Env): Episode done for env 121. Reward: 22.33, Length: 5
1387
Time taken for simulation:  7.141939401626587
average overall reward:  0.17654496  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.08398066  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 32.51, Length: 11
DEBUG (Env): Episode done for env 45. Reward: -16.32, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 24.88, Length: 17
DEBUG (Env): Episode done for env 99. Reward: -5.93, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 8.13, Length: 22
1388
Time taken for simulation:  7.007302522659302
average overall reward:  0.3221751  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  -0.21742553  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: 20.08, Length: 11
DEBUG (Env): Episode done for env 35. Reward: 16.46, Length: 2
DEBUG (Env): Episode done for env 51. Reward: -12.24, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 20.13, Length: 20
DEBUG (Env): Episode done for env 67. Reward: 16.48, Length: 5
DEBUG (Env): Episode done for env 85. Reward: 26.22, Length: 16
DEBUG (Env): Episode done for env 92. Reward: -24.08, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -20.85, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 22.52, Length: 18
1389
Time taken for simulation:  7.354851722717285
average overall reward:  1.244714  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.141587 average distance reward:  0.5568699  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 25. Reward: 34.86, Length: 8
DEBUG (Env): Episode done for env 26. Reward: -7.60, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 5.30, Length: 6
DEBUG (Env): Episode done for env 44. Reward: 31.16, Length: 5
DEBUG (Env): Episode done for env 78. Reward: 26.01, Length: 13
DEBUG (Env): Episode done for env 87. Reward: 25.52, Length: 24
DEBUG (Env): Episode done for env 98. Reward: -22.21, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -24.93, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 18.94, Length: 5
DEBUG (Env): Episode done for env 122. Reward: 23.09, Length: 16
1390
Time taken for simulation:  7.673797369003296
average overall reward:  0.6492047  average fail penalty:  -0.0234375  and average goal bonus:  0.8122322  and average same cell penalty:  -0.141587 average distance reward:  0.049857564  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 44. Reward: 25.25, Length: 1
DEBUG (Env): Episode done for env 47. Reward: 3.54, Length: 31
DEBUG (Env): Episode done for env 49. Reward: 11.62, Length: 20
DEBUG (Env): Episode done for env 56. Reward: -13.30, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 25.85, Length: 4
DEBUG (Env): Episode done for env 92. Reward: 29.50, Length: 2
DEBUG (Env): Episode done for env 93. Reward: 17.42, Length: 27
1391
Time taken for simulation:  7.3073906898498535
average overall reward:  0.073038936  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.0016066432  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: -27.17, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 4.97, Length: 17
DEBUG (Env): Episode done for env 32. Reward: -22.89, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -15.77, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -16.24, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 17.66, Length: 1
DEBUG (Env): Episode done for env 93. Reward: 18.22, Length: 1
1392
Time taken for simulation:  7.215400457382202
average overall reward:  0.16091889  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.06835462  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 69. Reward: -28.24, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -19.81, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 12.52, Length: 8
DEBUG (Env): Episode done for env 111. Reward: 22.96, Length: 18
DEBUG (Env): Episode done for env 121. Reward: 31.03, Length: 6
1393
Time taken for simulation:  7.26692795753479
average overall reward:  0.44963235  average fail penalty:  -0.140625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.289703  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 18. Reward: -24.76, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -14.04, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 14.13, Length: 2
DEBUG (Env): Episode done for env 55. Reward: 11.39, Length: 10
DEBUG (Env): Episode done for env 77. Reward: 21.99, Length: 2
DEBUG (Env): Episode done for env 80. Reward: -17.43, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -21.29, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -27.27, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 49.79, Length: 24
DEBUG (Env): Episode done for env 115. Reward: -23.89, Length: 36
1394
Time taken for simulation:  7.200171947479248
average overall reward:  0.34307304  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.16271359  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: 19.98, Length: 29
DEBUG (Env): Episode done for env 67. Reward: 22.81, Length: 6
DEBUG (Env): Episode done for env 96. Reward: -13.51, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 27.72, Length: 6
1395
Time taken for simulation:  7.1816794872283936
average overall reward:  0.64231133  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  -0.0023070127  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: 12.03, Length: 9
DEBUG (Env): Episode done for env 15. Reward: 18.96, Length: 11
DEBUG (Env): Episode done for env 28. Reward: 6.32, Length: 32
DEBUG (Env): Episode done for env 44. Reward: 27.27, Length: 5
DEBUG (Env): Episode done for env 56. Reward: 38.76, Length: 5
DEBUG (Env): Episode done for env 84. Reward: -17.62, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 0.24, Length: 27
DEBUG (Env): Episode done for env 97. Reward: 25.50, Length: 3
1396
Time taken for simulation:  7.172741413116455
average overall reward:  0.2291746  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.032936156  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: -4.76, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 23.15, Length: 5
DEBUG (Env): Episode done for env 20. Reward: -7.39, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -13.39, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -16.99, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 15.33, Length: 18
DEBUG (Env): Episode done for env 75. Reward: -13.11, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 26.98, Length: 8
DEBUG (Env): Episode done for env 93. Reward: 18.96, Length: 5
1397
Time taken for simulation:  7.092414379119873
average overall reward:  1.3335009  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168783 average distance reward:  0.8008172  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 18. Reward: 24.65, Length: 4
DEBUG (Env): Episode done for env 37. Reward: 13.87, Length: 25
DEBUG (Env): Episode done for env 44. Reward: 21.67, Length: 2
DEBUG (Env): Episode done for env 55. Reward: 29.43, Length: 4
DEBUG (Env): Episode done for env 109. Reward: 15.42, Length: 18
DEBUG (Env): Episode done for env 115. Reward: 49.88, Length: 4
1398
Time taken for simulation:  7.179429531097412
average overall reward:  0.29232052  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.2231938  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 23. Reward: 21.98, Length: 22
DEBUG (Env): Episode done for env 38. Reward: -14.59, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -6.36, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 24.21, Length: 2
DEBUG (Env): Episode done for env 96. Reward: 24.41, Length: 4
DEBUG (Env): Episode done for env 106. Reward: -17.31, Length: 36
1399
Time taken for simulation:  7.050237655639648
average overall reward:  0.10040188  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  -0.19419773  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: -13.72, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 18.39, Length: 10
DEBUG (Env): Episode done for env 48. Reward: -23.92, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -14.09, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 4.64, Length: 35
DEBUG (Env): Episode done for env 78. Reward: 48.51, Length: 10
DEBUG (Env): Episode done for env 109. Reward: 27.55, Length: 2
1400
Time taken for simulation:  7.207840442657471
average overall reward:  -0.113952495  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  0.07709884  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 68. Reward: -15.24, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 28.78, Length: 7
DEBUG (Env): Episode done for env 91. Reward: -12.15, Length: 36
1401
Time taken for simulation:  7.360498428344727
average overall reward:  0.31500697  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.2957626  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 22. Reward: -14.96, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 33.95, Length: 8
DEBUG (Env): Episode done for env 115. Reward: 19.63, Length: 4
1402
Time taken for simulation:  7.103174209594727
average overall reward:  0.24792117  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  -0.054938804  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: 21.24, Length: 18
DEBUG (Env): Episode done for env 55. Reward: 19.04, Length: 5
DEBUG (Env): Episode done for env 76. Reward: -7.92, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 6.88, Length: 19
DEBUG (Env): Episode done for env 121. Reward: 20.40, Length: 10
1403
Time taken for simulation:  7.2648351192474365
average overall reward:  0.44746453  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.07723947  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 5. Reward: -18.05, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 20.62, Length: 12
DEBUG (Env): Episode done for env 31. Reward: 6.03, Length: 20
DEBUG (Env): Episode done for env 34. Reward: -20.85, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -22.30, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 13.37, Length: 27
DEBUG (Env): Episode done for env 41. Reward: 33.54, Length: 18
DEBUG (Env): Episode done for env 70. Reward: 13.55, Length: 24
DEBUG (Env): Episode done for env 82. Reward: -12.50, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -19.72, Length: 36
1404
Time taken for simulation:  7.483646631240845
average overall reward:  0.37934974  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.2352993  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 33. Reward: -21.08, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 22.82, Length: 11
DEBUG (Env): Episode done for env 90. Reward: 22.33, Length: 9
DEBUG (Env): Episode done for env 101. Reward: 16.69, Length: 29
DEBUG (Env): Episode done for env 113. Reward: -16.74, Length: 36
1405
Time taken for simulation:  7.093438148498535
average overall reward:  0.14021787  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  -0.16103825  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 15. Reward: -9.71, Length: 10
DEBUG (Env): Episode done for env 45. Reward: 10.29, Length: 18
DEBUG (Env): Episode done for env 61. Reward: 14.81, Length: 20
DEBUG (Env): Episode done for env 72. Reward: -18.90, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 30.80, Length: 2
DEBUG (Env): Episode done for env 97. Reward: 31.58, Length: 10
DEBUG (Env): Episode done for env 116. Reward: -18.72, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -14.17, Length: 36
1406
Time taken for simulation:  7.460338592529297
average overall reward:  0.28841937  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.47255397  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: -20.40, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -13.11, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -14.25, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -9.33, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -9.21, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 19.68, Length: 17
1407
Time taken for simulation:  7.092944145202637
average overall reward:  1.3716536  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.1673301 average distance reward:  0.7746119  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 19. Reward: 16.83, Length: 1
DEBUG (Env): Episode done for env 30. Reward: 40.87, Length: 22
DEBUG (Env): Episode done for env 38. Reward: 24.37, Length: 9
DEBUG (Env): Episode done for env 67. Reward: 30.12, Length: 13
DEBUG (Env): Episode done for env 77. Reward: 31.66, Length: 7
DEBUG (Env): Episode done for env 111. Reward: 30.17, Length: 15
1408
Time taken for simulation:  7.043239593505859
average overall reward:  -0.16059583  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.16696864  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 11. Reward: 23.50, Length: 2
DEBUG (Env): Episode done for env 57. Reward: -21.59, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 3.16, Length: 30
1409
Time taken for simulation:  7.298719167709351
average overall reward:  0.70365703  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.16636208  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 19. Reward: 22.62, Length: 2
DEBUG (Env): Episode done for env 26. Reward: 33.99, Length: 10
DEBUG (Env): Episode done for env 50. Reward: 12.02, Length: 29
DEBUG (Env): Episode done for env 57. Reward: 20.60, Length: 1
DEBUG (Env): Episode done for env 76. Reward: 31.78, Length: 7
DEBUG (Env): Episode done for env 79. Reward: -10.55, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 20.12, Length: 16
DEBUG (Env): Episode done for env 119. Reward: -16.30, Length: 36
1410
Time taken for simulation:  7.2794189453125
average overall reward:  1.1134348  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.07722928 average distance reward:  0.42629248  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: 21.95, Length: 14
DEBUG (Env): Episode done for env 2. Reward: 30.67, Length: 22
DEBUG (Env): Episode done for env 29. Reward: 19.88, Length: 4
DEBUG (Env): Episode done for env 87. Reward: 27.19, Length: 21
DEBUG (Env): Episode done for env 88. Reward: 13.36, Length: 23
DEBUG (Env): Episode done for env 117. Reward: 21.21, Length: 4
1411
Time taken for simulation:  7.281580924987793
average overall reward:  0.5468049  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.32178864 average distance reward:  0.15109691  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: 27.25, Length: 14
DEBUG (Env): Episode done for env 19. Reward: 27.59, Length: 2
DEBUG (Env): Episode done for env 26. Reward: 20.46, Length: 2
DEBUG (Env): Episode done for env 27. Reward: -8.14, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 26.93, Length: 7
DEBUG (Env): Episode done for env 57. Reward: 17.21, Length: 2
DEBUG (Env): Episode done for env 74. Reward: -17.71, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 23.89, Length: 16
1412
Time taken for simulation:  7.286635160446167
average overall reward:  0.37683734  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.41503397  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 10. Reward: -20.92, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -25.94, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -10.14, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -26.13, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 22.94, Length: 7
DEBUG (Env): Episode done for env 115. Reward: 8.81, Length: 11
1413
Time taken for simulation:  7.198432922363281
average overall reward:  -0.13387427  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020163 average distance reward:  -0.21817812  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: 13.91, Length: 33
DEBUG (Env): Episode done for env 12. Reward: -7.05, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 21.40, Length: 10
DEBUG (Env): Episode done for env 59. Reward: 30.30, Length: 17
DEBUG (Env): Episode done for env 108. Reward: -13.41, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -15.72, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -4.56, Length: 36
1414
Time taken for simulation:  7.204256772994995
average overall reward:  -0.029031657  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.34753174 average distance reward:  0.119054064  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: -19.92, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 30.03, Length: 15
DEBUG (Env): Episode done for env 53. Reward: 19.70, Length: 2
1415
Time taken for simulation:  7.120490550994873
average overall reward:  0.58310974  average fail penalty:  -0.09375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.1673301 average distance reward:  -0.19092584  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 5. Reward: 22.23, Length: 12
DEBUG (Env): Episode done for env 13. Reward: 4.98, Length: 35
DEBUG (Env): Episode done for env 34. Reward: 11.87, Length: 12
DEBUG (Env): Episode done for env 52. Reward: 25.09, Length: 4
DEBUG (Env): Episode done for env 54. Reward: 16.55, Length: 22
DEBUG (Env): Episode done for env 60. Reward: 2.74, Length: 19
DEBUG (Env): Episode done for env 62. Reward: -13.59, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -15.64, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -22.17, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 29.26, Length: 9
DEBUG (Env): Episode done for env 110. Reward: -19.33, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 5.26, Length: 34
1416
Time taken for simulation:  7.335941553115845
average overall reward:  -0.03913119  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  -0.13329923  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 99. Reward: 26.62, Length: 29
DEBUG (Env): Episode done for env 105. Reward: 8.25, Length: 32
1417
Time taken for simulation:  7.759405136108398
average overall reward:  0.12795892  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.19307318 average distance reward:  0.39233023  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 112. Reward: -13.86, Length: 36
1418
Time taken for simulation:  7.241757392883301
average overall reward:  -0.092852816  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  -0.10979158  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 100. Reward: 13.52, Length: 32
DEBUG (Env): Episode done for env 123. Reward: 16.75, Length: 3
1419
Time taken for simulation:  7.051114320755005
average overall reward:  0.49422628  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.032556742  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 28.49, Length: 32
DEBUG (Env): Episode done for env 11. Reward: 26.78, Length: 11
DEBUG (Env): Episode done for env 41. Reward: 30.10, Length: 6
DEBUG (Env): Episode done for env 104. Reward: 19.44, Length: 25
DEBUG (Env): Episode done for env 111. Reward: 28.57, Length: 12
1420
Time taken for simulation:  7.112779140472412
average overall reward:  0.77219504  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168783 average distance reward:  0.23951134  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 22.20, Length: 10
DEBUG (Env): Episode done for env 3. Reward: 6.06, Length: 26
DEBUG (Env): Episode done for env 18. Reward: 15.22, Length: 9
DEBUG (Env): Episode done for env 28. Reward: 11.66, Length: 25
DEBUG (Env): Episode done for env 77. Reward: 12.07, Length: 13
DEBUG (Env): Episode done for env 78. Reward: 25.02, Length: 21
1421
Time taken for simulation:  7.41428279876709
average overall reward:  -0.1994521  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.27030247 average distance reward:  0.1421484  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 7. Reward: -9.06, Length: 36
1422
Time taken for simulation:  7.2634546756744385
average overall reward:  0.014011577  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.06798664  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 24. Reward: -18.91, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 30.43, Length: 11
DEBUG (Env): Episode done for env 34. Reward: 24.24, Length: 7
DEBUG (Env): Episode done for env 73. Reward: -16.08, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 16.45, Length: 11
DEBUG (Env): Episode done for env 103. Reward: -20.72, Length: 36
1423
Time taken for simulation:  7.60796332359314
average overall reward:  0.20039907  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.032911103  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 50. Reward: 31.99, Length: 14
DEBUG (Env): Episode done for env 67. Reward: 22.39, Length: 16
DEBUG (Env): Episode done for env 72. Reward: 15.07, Length: 11
DEBUG (Env): Episode done for env 102. Reward: -19.47, Length: 36
1424
Time taken for simulation:  7.137983798980713
average overall reward:  -0.041165955  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168783 average distance reward:  -0.34472772  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: 24.88, Length: 5
DEBUG (Env): Episode done for env 7. Reward: 23.00, Length: 3
DEBUG (Env): Episode done for env 35. Reward: 1.24, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -2.64, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -19.87, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 22.84, Length: 14
DEBUG (Env): Episode done for env 97. Reward: 17.33, Length: 19
DEBUG (Env): Episode done for env 124. Reward: -22.93, Length: 36
1425
Time taken for simulation:  7.282365322113037
average overall reward:  0.018378682  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  -0.10063049  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 11. Reward: 9.71, Length: 6
DEBUG (Env): Episode done for env 17. Reward: 24.50, Length: 11
DEBUG (Env): Episode done for env 25. Reward: -14.61, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -9.86, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 12.34, Length: 22
DEBUG (Env): Episode done for env 98. Reward: -15.59, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 23.88, Length: 21
DEBUG (Env): Episode done for env 120. Reward: -18.19, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -18.25, Length: 36
1426
Time taken for simulation:  7.221048831939697
average overall reward:  0.39318386  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.20155665  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 47. Reward: -9.35, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 31.23, Length: 12
DEBUG (Env): Episode done for env 49. Reward: -19.94, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 29.39, Length: 2
DEBUG (Env): Episode done for env 92. Reward: -20.10, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 22.79, Length: 9
DEBUG (Env): Episode done for env 123. Reward: 37.12, Length: 8
1427
Time taken for simulation:  7.169332027435303
average overall reward:  0.28298545  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.24856398  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 32. Reward: -20.43, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -20.63, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 19.31, Length: 19
DEBUG (Env): Episode done for env 103. Reward: 16.52, Length: 5
1428
Time taken for simulation:  7.1538987159729
average overall reward:  0.5249438  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594473 average distance reward:  0.013391955  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 21. Reward: 15.83, Length: 25
DEBUG (Env): Episode done for env 35. Reward: 33.41, Length: 4
DEBUG (Env): Episode done for env 46. Reward: 14.99, Length: 16
DEBUG (Env): Episode done for env 48. Reward: 33.93, Length: 2
DEBUG (Env): Episode done for env 69. Reward: -18.50, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -16.09, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 7.36, Length: 29
DEBUG (Env): Episode done for env 124. Reward: 15.64, Length: 4
1429
Time taken for simulation:  7.248888731002808
average overall reward:  0.45726293  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  -0.20253253  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 6. Reward: 20.54, Length: 30
DEBUG (Env): Episode done for env 12. Reward: 13.42, Length: 16
DEBUG (Env): Episode done for env 25. Reward: 41.48, Length: 4
DEBUG (Env): Episode done for env 33. Reward: 16.16, Length: 25
DEBUG (Env): Episode done for env 80. Reward: -21.61, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 8.16, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 18.48, Length: 1
DEBUG (Env): Episode done for env 118. Reward: 13.32, Length: 23
1430
Time taken for simulation:  7.137552499771118
average overall reward:  0.6478206  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.06365055  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 19.32, Length: 28
DEBUG (Env): Episode done for env 50. Reward: 17.53, Length: 7
DEBUG (Env): Episode done for env 62. Reward: 38.46, Length: 15
DEBUG (Env): Episode done for env 83. Reward: 34.83, Length: 27
DEBUG (Env): Episode done for env 112. Reward: 18.73, Length: 4
DEBUG (Env): Episode done for env 116. Reward: 15.70, Length: 25
1431
Time taken for simulation:  7.200725078582764
average overall reward:  0.7425093  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.16733009 average distance reward:  0.32771486  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -20.39, Length: 36
DEBUG (Env): Episode done for env 4. Reward: 26.19, Length: 7
DEBUG (Env): Episode done for env 15. Reward: 13.59, Length: 26
DEBUG (Env): Episode done for env 56. Reward: -23.11, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 23.11, Length: 8
DEBUG (Env): Episode done for env 94. Reward: 20.01, Length: 3
DEBUG (Env): Episode done for env 113. Reward: 23.99, Length: 6
1432
Time taken for simulation:  7.1279075145721436
average overall reward:  0.19944097  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.3089171 average distance reward:  0.13191804  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: -21.15, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 7.06, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 13.48, Length: 10
DEBUG (Env): Episode done for env 48. Reward: 28.43, Length: 4
DEBUG (Env): Episode done for env 65. Reward: -29.08, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 30.69, Length: 2
DEBUG (Env): Episode done for env 85. Reward: -25.86, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -30.00, Length: 36
1433
Time taken for simulation:  7.443063735961914
average overall reward:  0.120544255  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.26010942  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: -27.44, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -26.80, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 25.09, Length: 15
1434
Time taken for simulation:  7.03972864151001
average overall reward:  -0.11253002  average fail penalty:  -0.1171875  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  0.20697653  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: -22.61, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -17.49, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -15.70, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -16.49, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -17.83, Length: 36
1435
Time taken for simulation:  7.131779909133911
average overall reward:  0.22199008  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.06506809  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 25.20, Length: 10
DEBUG (Env): Episode done for env 49. Reward: 28.45, Length: 9
DEBUG (Env): Episode done for env 66. Reward: -23.58, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 26.34, Length: 9
1436
Time taken for simulation:  7.060159206390381
average overall reward:  0.14868036  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  -0.027769666  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 28. Reward: 22.27, Length: 16
DEBUG (Env): Episode done for env 30. Reward: 7.02, Length: 29
DEBUG (Env): Episode done for env 68. Reward: -18.51, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 20.33, Length: 27
DEBUG (Env): Episode done for env 91. Reward: -9.67, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 23.69, Length: 5
1437
Time taken for simulation:  7.556756019592285
average overall reward:  0.050309435  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.090100825 average distance reward:  -0.035598293  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 13. Reward: 13.50, Length: 22
DEBUG (Env): Episode done for env 22. Reward: -16.58, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 20.32, Length: 30
DEBUG (Env): Episode done for env 89. Reward: -9.90, Length: 36
1438
Time taken for simulation:  6.990307092666626
average overall reward:  0.60693824  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  0.009194851  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 6. Reward: 23.24, Length: 9
DEBUG (Env): Episode done for env 14. Reward: 27.69, Length: 8
DEBUG (Env): Episode done for env 31. Reward: 10.43, Length: 35
DEBUG (Env): Episode done for env 55. Reward: -21.71, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 18.79, Length: 6
DEBUG (Env): Episode done for env 67. Reward: 21.90, Length: 15
DEBUG (Env): Episode done for env 97. Reward: 25.69, Length: 14
DEBUG (Env): Episode done for env 114. Reward: -20.72, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 20.14, Length: 28
DEBUG (Env): Episode done for env 121. Reward: -14.64, Length: 36
1439
Time taken for simulation:  7.414911985397339
average overall reward:  0.62007225  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.3535213  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 36. Reward: -22.78, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -1.91, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 16.13, Length: 14
DEBUG (Env): Episode done for env 77. Reward: 11.77, Length: 19
DEBUG (Env): Episode done for env 113. Reward: 15.27, Length: 3
DEBUG (Env): Episode done for env 124. Reward: 20.61, Length: 11
1440
Time taken for simulation:  7.404893636703491
average overall reward:  0.72685874  average fail penalty:  -0.046875  and average goal bonus:  0.8122322  and average same cell penalty:  -0.141587 average distance reward:  0.15094914  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 24. Reward: 17.55, Length: 18
DEBUG (Env): Episode done for env 50. Reward: 11.53, Length: 10
DEBUG (Env): Episode done for env 63. Reward: 28.08, Length: 14
DEBUG (Env): Episode done for env 72. Reward: 25.44, Length: 9
DEBUG (Env): Episode done for env 90. Reward: -21.66, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 36.24, Length: 6
DEBUG (Env): Episode done for env 101. Reward: -7.17, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 32.75, Length: 21
1441
Time taken for simulation:  7.92171049118042
average overall reward:  0.11822818  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.20791093  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 45. Reward: -18.15, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -2.48, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -16.94, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -32.29, Length: 25
DEBUG (Env): Episode done for env 115. Reward: 21.48, Length: 29
DEBUG (Env): Episode done for env 125. Reward: -16.30, Length: 36
1442
Time taken for simulation:  7.295712947845459
average overall reward:  0.32090867  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.020354271  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: 28.18, Length: 8
DEBUG (Env): Episode done for env 58. Reward: 25.40, Length: 15
DEBUG (Env): Episode done for env 65. Reward: 38.24, Length: 4
DEBUG (Env): Episode done for env 71. Reward: 19.06, Length: 7
1443
Time taken for simulation:  7.150182723999023
average overall reward:  0.74437904  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  0.30845258  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 40. Reward: 23.12, Length: 4
DEBUG (Env): Episode done for env 43. Reward: 25.73, Length: 4
DEBUG (Env): Episode done for env 51. Reward: 30.24, Length: 19
DEBUG (Env): Episode done for env 108. Reward: 14.95, Length: 30
DEBUG (Env): Episode done for env 123. Reward: 34.16, Length: 8
1444
Time taken for simulation:  7.823627471923828
average overall reward:  0.34352142  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.30083954  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 72. Reward: 17.67, Length: 4
DEBUG (Env): Episode done for env 90. Reward: 42.79, Length: 4
1445
Time taken for simulation:  7.157650947570801
average overall reward:  0.51393986  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.41906992  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 0.86, Length: 32
DEBUG (Env): Episode done for env 48. Reward: 37.00, Length: 13
DEBUG (Env): Episode done for env 79. Reward: -20.53, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -54.77, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -17.93, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 28.96, Length: 20
1446
Time taken for simulation:  7.297267436981201
average overall reward:  -0.05301714  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  -0.30900216  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -26.03, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -26.56, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 32.50, Length: 10
DEBUG (Env): Episode done for env 83. Reward: 24.57, Length: 14
DEBUG (Env): Episode done for env 84. Reward: 12.97, Length: 24
DEBUG (Env): Episode done for env 87. Reward: -15.24, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 18.28, Length: 5
1447
Time taken for simulation:  7.746218919754028
average overall reward:  0.088791594  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  -0.14375584  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 19. Reward: -2.61, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -21.86, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 9.07, Length: 20
DEBUG (Env): Episode done for env 51. Reward: 33.31, Length: 4
DEBUG (Env): Episode done for env 57. Reward: -20.76, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 19.69, Length: 7
DEBUG (Env): Episode done for env 74. Reward: -16.46, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 18.05, Length: 8
1448
Time taken for simulation:  7.023575305938721
average overall reward:  0.31180075  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  -0.12873685  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: -15.97, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -24.62, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 24.76, Length: 12
DEBUG (Env): Episode done for env 35. Reward: 15.02, Length: 20
DEBUG (Env): Episode done for env 67. Reward: 33.02, Length: 10
DEBUG (Env): Episode done for env 112. Reward: 4.25, Length: 18
DEBUG (Env): Episode done for env 125. Reward: 30.98, Length: 7
1449
Time taken for simulation:  7.116434812545776
average overall reward:  0.25129706  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  0.36281353  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 59. Reward: -17.96, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 9.60, Length: 20
DEBUG (Env): Episode done for env 126. Reward: -16.22, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -21.75, Length: 36
1450
Time taken for simulation:  7.438926696777344
average overall reward:  0.53629774  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.11584391 average distance reward:  0.18195155  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 43. Reward: 45.90, Length: 7
DEBUG (Env): Episode done for env 53. Reward: -7.73, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 5.16, Length: 35
DEBUG (Env): Episode done for env 81. Reward: 23.30, Length: 5
DEBUG (Env): Episode done for env 92. Reward: 23.78, Length: 24
1451
Time taken for simulation:  7.569415092468262
average overall reward:  0.26339808  average fail penalty:  -0.1640625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.2365351  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 5. Reward: -11.52, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 12.24, Length: 4
DEBUG (Env): Episode done for env 52. Reward: -12.23, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 36.03, Length: 4
DEBUG (Env): Episode done for env 60. Reward: -13.53, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -11.84, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -17.73, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -27.14, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 11.55, Length: 10
DEBUG (Env): Episode done for env 110. Reward: -16.45, Length: 36
1452
Time taken for simulation:  7.462438583374023
average overall reward:  0.57807195  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.1673301 average distance reward:  0.13983995  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 23.01, Length: 21
DEBUG (Env): Episode done for env 17. Reward: 18.23, Length: 17
DEBUG (Env): Episode done for env 49. Reward: 32.79, Length: 17
DEBUG (Env): Episode done for env 67. Reward: 29.88, Length: 4
DEBUG (Env): Episode done for env 89. Reward: 8.00, Length: 15
DEBUG (Env): Episode done for env 99. Reward: -20.23, Length: 36
1453
Time taken for simulation:  7.383917808532715
average overall reward:  0.13908368  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.05778715  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 27. Reward: 28.50, Length: 2
DEBUG (Env): Episode done for env 125. Reward: 33.21, Length: 5
1454
Time taken for simulation:  7.293752193450928
average overall reward:  -0.1044569  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.17288187  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 9. Reward: 23.08, Length: 22
DEBUG (Env): Episode done for env 117. Reward: 19.84, Length: 16
1455
Time taken for simulation:  7.241225004196167
average overall reward:  -0.04808171  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030244 average distance reward:  -0.22453183  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 17.97, Length: 17
DEBUG (Env): Episode done for env 41. Reward: -24.12, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -2.22, Length: 29
DEBUG (Env): Episode done for env 68. Reward: 22.45, Length: 19
DEBUG (Env): Episode done for env 111. Reward: -15.34, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 17.22, Length: 1
1456
Time taken for simulation:  7.462231159210205
average overall reward:  0.21548957  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.24081466  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: 32.94, Length: 10
DEBUG (Env): Episode done for env 2. Reward: -13.41, Length: 36
DEBUG (Env): Episode done for env 3. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -18.10, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -18.50, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 25.51, Length: 1
1457
Time taken for simulation:  7.1803858280181885
average overall reward:  0.9780715  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.19307318 average distance reward:  0.13602902  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: 32.88, Length: 1
DEBUG (Env): Episode done for env 24. Reward: 16.08, Length: 17
DEBUG (Env): Episode done for env 26. Reward: 10.22, Length: 25
DEBUG (Env): Episode done for env 34. Reward: 6.74, Length: 35
DEBUG (Env): Episode done for env 89. Reward: 29.37, Length: 5
DEBUG (Env): Episode done for env 92. Reward: 20.51, Length: 7
DEBUG (Env): Episode done for env 115. Reward: 21.29, Length: 11
DEBUG (Env): Episode done for env 117. Reward: 20.73, Length: 1
1458
Time taken for simulation:  7.310698509216309
average overall reward:  0.23813634  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.16740577  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 65. Reward: 20.89, Length: 16
DEBUG (Env): Episode done for env 73. Reward: -16.25, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 26.40, Length: 14
1459
Time taken for simulation:  7.268993377685547
average overall reward:  0.49246055  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.115843914 average distance reward:  0.13811438  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: 14.36, Length: 2
DEBUG (Env): Episode done for env 50. Reward: 23.95, Length: 19
DEBUG (Env): Episode done for env 87. Reward: 24.72, Length: 13
DEBUG (Env): Episode done for env 102. Reward: -11.98, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 29.56, Length: 8
1460
Time taken for simulation:  7.158128976821899
average overall reward:  0.13721247  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020163 average distance reward:  0.0060335547  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -14.54, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 13.38, Length: 22
DEBUG (Env): Episode done for env 79. Reward: 16.23, Length: 15
DEBUG (Env): Episode done for env 88. Reward: -20.46, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 25.89, Length: 3
1461
Time taken for simulation:  7.306543588638306
average overall reward:  0.64408875  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.5726563  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 23.32, Length: 5
DEBUG (Env): Episode done for env 11. Reward: -13.16, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 15.17, Length: 13
DEBUG (Env): Episode done for env 47. Reward: 56.54, Length: 6
DEBUG (Env): Episode done for env 70. Reward: -24.32, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -23.26, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -12.36, Length: 36
1462
Time taken for simulation:  7.10145378112793
average overall reward:  -0.04675839  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030244 average distance reward:  0.0006605759  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 40. Reward: 10.35, Length: 19
DEBUG (Env): Episode done for env 90. Reward: 22.39, Length: 4
1463
Time taken for simulation:  7.1681437492370605
average overall reward:  -0.55067724  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.24455938 average distance reward:  -0.21138233  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 42. Reward: -12.75, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -15.06, Length: 36
1464
Time taken for simulation:  7.008976459503174
average overall reward:  0.26824284  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.34735966  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 20.37, Length: 12
DEBUG (Env): Episode done for env 21. Reward: -16.95, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -19.90, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -15.01, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 38.19, Length: 6
1465
Time taken for simulation:  7.202790260314941
average overall reward:  0.2951319  average fail penalty:  -0.140625  and average goal bonus:  0.67686015  and average same cell penalty:  -0.27030247 average distance reward:  0.07705976  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 12. Reward: -20.13, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 24.92, Length: 13
DEBUG (Env): Episode done for env 25. Reward: -24.26, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -15.42, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 31.90, Length: 15
DEBUG (Env): Episode done for env 103. Reward: 41.68, Length: 2
DEBUG (Env): Episode done for env 107. Reward: -18.30, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -19.19, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 17.01, Length: 10
DEBUG (Env): Episode done for env 118. Reward: -18.74, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 13.77, Length: 12
1466
Time taken for simulation:  7.152893781661987
average overall reward:  0.29145828  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.2574309 average distance reward:  -0.3039795  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: 21.81, Length: 5
DEBUG (Env): Episode done for env 51. Reward: 11.55, Length: 19
DEBUG (Env): Episode done for env 56. Reward: 0.52, Length: 35
DEBUG (Env): Episode done for env 62. Reward: -21.46, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -0.49, Length: 4
DEBUG (Env): Episode done for env 99. Reward: 22.72, Length: 14
DEBUG (Env): Episode done for env 105. Reward: 29.45, Length: 7
DEBUG (Env): Episode done for env 116. Reward: -28.44, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 9.45, Length: 19
1467
Time taken for simulation:  7.637566804885864
average overall reward:  0.2586748  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.23481922  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -18.04, Length: 36
DEBUG (Env): Episode done for env 4. Reward: -13.64, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 24.63, Length: 7
DEBUG (Env): Episode done for env 34. Reward: 25.76, Length: 10
DEBUG (Env): Episode done for env 94. Reward: -15.69, Length: 36
1468
Time taken for simulation:  7.382760763168335
average overall reward:  0.32798868  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  0.0009894595  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: 11.35, Length: 31
DEBUG (Env): Episode done for env 20. Reward: -17.67, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 20.00, Length: 4
DEBUG (Env): Episode done for env 75. Reward: 5.69, Length: 34
DEBUG (Env): Episode done for env 85. Reward: -10.69, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -18.47, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 32.10, Length: 30
DEBUG (Env): Episode done for env 117. Reward: 31.13, Length: 8
1469
Time taken for simulation:  7.411046028137207
average overall reward:  0.044955358  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.059714444  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: 21.55, Length: 3
DEBUG (Env): Episode done for env 37. Reward: -19.97, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -22.27, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 4.09, Length: 22
DEBUG (Env): Episode done for env 100. Reward: -22.73, Length: 36
1470
Time taken for simulation:  7.4591310024261475
average overall reward:  0.25150156  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.023565259  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 23. Reward: 30.89, Length: 28
DEBUG (Env): Episode done for env 38. Reward: 4.70, Length: 33
DEBUG (Env): Episode done for env 39. Reward: -24.52, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 16.94, Length: 4
DEBUG (Env): Episode done for env 106. Reward: -13.89, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 35.59, Length: 19
1471
Time taken for simulation:  7.2962727546691895
average overall reward:  -0.058967285  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.16733009 average distance reward:  0.04428883  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 62. Reward: 27.16, Length: 5
DEBUG (Env): Episode done for env 66. Reward: -25.15, Length: 36
1472
Time taken for simulation:  7.229483604431152
average overall reward:  0.12054134  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455936 average distance reward:  0.18909217  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: -13.76, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 17.59, Length: 8
DEBUG (Env): Episode done for env 91. Reward: -15.31, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 7.59, Length: 27
1473
Time taken for simulation:  7.292043447494507
average overall reward:  0.9618182  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.12871546 average distance reward:  0.07885544  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 21. Reward: 26.64, Length: 9
DEBUG (Env): Episode done for env 22. Reward: -8.23, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 6.73, Length: 26
DEBUG (Env): Episode done for env 39. Reward: 20.00, Length: 3
DEBUG (Env): Episode done for env 40. Reward: 45.41, Length: 11
DEBUG (Env): Episode done for env 54. Reward: 27.69, Length: 23
DEBUG (Env): Episode done for env 64. Reward: 17.06, Length: 22
DEBUG (Env): Episode done for env 72. Reward: 21.36, Length: 29
DEBUG (Env): Episode done for env 104. Reward: 17.46, Length: 33
1474
Time taken for simulation:  7.228257179260254
average overall reward:  0.11148819  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  -0.05670154  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 6. Reward: -13.16, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 14.83, Length: 17
DEBUG (Env): Episode done for env 28. Reward: 17.28, Length: 2
DEBUG (Env): Episode done for env 55. Reward: -6.39, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 18.64, Length: 27
DEBUG (Env): Episode done for env 97. Reward: -24.78, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 26.72, Length: 9
DEBUG (Env): Episode done for env 121. Reward: -11.41, Length: 36
1475
Time taken for simulation:  7.457298994064331
average overall reward:  -0.04710199  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.045214437  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 28. Reward: 14.20, Length: 1
DEBUG (Env): Episode done for env 36. Reward: -15.68, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -13.41, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 34.70, Length: 15
DEBUG (Env): Episode done for env 113. Reward: -20.13, Length: 36
1476
Time taken for simulation:  7.570281982421875
average overall reward:  0.183444  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.065136634  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 60. Reward: 14.10, Length: 25
DEBUG (Env): Episode done for env 96. Reward: -11.04, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -22.13, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 25.09, Length: 6
DEBUG (Env): Episode done for env 113. Reward: 19.96, Length: 1
1477
Time taken for simulation:  7.22442364692688
average overall reward:  0.25954416  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.12605965  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: 18.31, Length: 21
DEBUG (Env): Episode done for env 28. Reward: 23.10, Length: 2
DEBUG (Env): Episode done for env 35. Reward: 5.54, Length: 16
DEBUG (Env): Episode done for env 45. Reward: -22.14, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -21.11, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -22.39, Length: 36
1478
Time taken for simulation:  7.114739179611206
average overall reward:  0.020243935  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  -0.18194929  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 9.95, Length: 11
DEBUG (Env): Episode done for env 28. Reward: 17.86, Length: 1
DEBUG (Env): Episode done for env 57. Reward: 4.91, Length: 27
DEBUG (Env): Episode done for env 58. Reward: -15.60, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -19.32, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 11.14, Length: 32
1479
Time taken for simulation:  7.069212198257446
average overall reward:  0.24188393  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.110705  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 65. Reward: 19.09, Length: 21
DEBUG (Env): Episode done for env 78. Reward: 34.61, Length: 23
DEBUG (Env): Episode done for env 103. Reward: 22.92, Length: 5
DEBUG (Env): Episode done for env 108. Reward: -9.91, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -25.13, Length: 36
1480
Time taken for simulation:  7.448148488998413
average overall reward:  0.0213629  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.31780618  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 22. Reward: 16.16, Length: 7
DEBUG (Env): Episode done for env 28. Reward: 26.01, Length: 2
DEBUG (Env): Episode done for env 49. Reward: 11.88, Length: 28
DEBUG (Env): Episode done for env 59. Reward: 8.75, Length: 31
1481
Time taken for simulation:  7.121793031692505
average overall reward:  0.16332935  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.054041  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: -15.28, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 14.96, Length: 34
DEBUG (Env): Episode done for env 38. Reward: 15.65, Length: 11
DEBUG (Env): Episode done for env 48. Reward: -22.50, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 26.42, Length: 5
DEBUG (Env): Episode done for env 118. Reward: 17.33, Length: 16
DEBUG (Env): Episode done for env 122. Reward: -11.61, Length: 36
1482
Time taken for simulation:  7.182357311248779
average overall reward:  -0.010681316  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.09267958  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 29. Reward: -8.69, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 16.45, Length: 27
DEBUG (Env): Episode done for env 73. Reward: 12.05, Length: 18
DEBUG (Env): Episode done for env 81. Reward: 15.92, Length: 17
DEBUG (Env): Episode done for env 83. Reward: -14.26, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -12.96, Length: 36
1483
Time taken for simulation:  7.119924068450928
average overall reward:  0.14275056  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.016182866  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 32. Reward: 9.14, Length: 10
DEBUG (Env): Episode done for env 74. Reward: 24.04, Length: 9
DEBUG (Env): Episode done for env 96. Reward: 16.52, Length: 2
1484
Time taken for simulation:  7.081824541091919
average overall reward:  0.15362836  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.20469654  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: 27.03, Length: 17
DEBUG (Env): Episode done for env 10. Reward: -16.74, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -16.49, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 22.53, Length: 16
DEBUG (Env): Episode done for env 30. Reward: -25.60, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -21.70, Length: 36
1485
Time taken for simulation:  7.198093414306641
average overall reward:  -0.119903624  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  -0.053658348  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 30. Reward: 17.12, Length: 1
DEBUG (Env): Episode done for env 80. Reward: -17.67, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 9.08, Length: 20
DEBUG (Env): Episode done for env 126. Reward: -16.28, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -21.79, Length: 36
1486
Time taken for simulation:  7.331573963165283
average overall reward:  0.45820755  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168781 average distance reward:  -0.027601272  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 43. Reward: -15.94, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -19.36, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 11.08, Length: 9
DEBUG (Env): Episode done for env 96. Reward: 30.25, Length: 3
DEBUG (Env): Episode done for env 101. Reward: 5.82, Length: 10
DEBUG (Env): Episode done for env 111. Reward: 20.35, Length: 21
DEBUG (Env): Episode done for env 126. Reward: 17.51, Length: 1
DEBUG (Env): Episode done for env 127. Reward: 25.40, Length: 1
1487
Time taken for simulation:  7.108079433441162
average overall reward:  0.026545852  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  0.04521431  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 5. Reward: -22.38, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -18.55, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 27.27, Length: 8
DEBUG (Env): Episode done for env 86. Reward: -23.49, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -20.19, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 18.03, Length: 14
DEBUG (Env): Episode done for env 114. Reward: 16.18, Length: 19
1488
Time taken for simulation:  7.02179741859436
average overall reward:  0.070637114  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.24509439  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: 20.74, Length: 28
DEBUG (Env): Episode done for env 67. Reward: -11.01, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 20.79, Length: 20
DEBUG (Env): Episode done for env 89. Reward: 16.75, Length: 31
DEBUG (Env): Episode done for env 111. Reward: 23.40, Length: 2
1489
Time taken for simulation:  7.008575201034546
average overall reward:  -0.059338436  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.0914544  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 27. Reward: -16.51, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 26.93, Length: 12
DEBUG (Env): Episode done for env 111. Reward: 19.81, Length: 1
1490
Time taken for simulation:  7.086918115615845
average overall reward:  0.3594447  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2188163 average distance reward:  0.108070984  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: -18.62, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 9.92, Length: 29
DEBUG (Env): Episode done for env 19. Reward: 24.81, Length: 9
DEBUG (Env): Episode done for env 40. Reward: 19.42, Length: 17
DEBUG (Env): Episode done for env 55. Reward: 9.28, Length: 16
1491
Time taken for simulation:  7.274791955947876
average overall reward:  0.31404942  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.23168783 average distance reward:  -0.03638731  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 24. Reward: 11.24, Length: 32
DEBUG (Env): Episode done for env 31. Reward: -8.65, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -34.97, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 3.71, Length: 19
DEBUG (Env): Episode done for env 113. Reward: 17.22, Length: 15
DEBUG (Env): Episode done for env 122. Reward: 19.52, Length: 10
DEBUG (Env): Episode done for env 124. Reward: 8.26, Length: 25
1492
Time taken for simulation:  7.125121116638184
average overall reward:  0.7238466  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.40811515  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: -17.75, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 32.53, Length: 27
DEBUG (Env): Episode done for env 32. Reward: 39.19, Length: 9
DEBUG (Env): Episode done for env 60. Reward: 32.20, Length: 16
DEBUG (Env): Episode done for env 71. Reward: 14.19, Length: 14
1493
Time taken for simulation:  7.292891263961792
average overall reward:  -0.03729622  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.0032059606  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: -22.71, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -26.86, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 19.91, Length: 23
DEBUG (Env): Episode done for env 115. Reward: -17.76, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 31.74, Length: 7
1494
Time taken for simulation:  7.11351203918457
average overall reward:  -0.11913121  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  -0.039312616  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 11. Reward: 25.85, Length: 4
1495
Time taken for simulation:  7.373003005981445
average overall reward:  0.010472883  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.14773247  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 50. Reward: -25.72, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 14.23, Length: 13
DEBUG (Env): Episode done for env 87. Reward: -16.96, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -28.29, Length: 36
1496
Time taken for simulation:  7.839081287384033
average overall reward:  0.16742033  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.051418602  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 61. Reward: 23.82, Length: 19
DEBUG (Env): Episode done for env 65. Reward: 21.36, Length: 9
DEBUG (Env): Episode done for env 79. Reward: -12.00, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 15.80, Length: 1
1497
Time taken for simulation:  7.301879405975342
average overall reward:  0.44180256  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.23499823  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 40. Reward: 32.01, Length: 7
DEBUG (Env): Episode done for env 47. Reward: -28.36, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -18.06, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -8.48, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 26.84, Length: 6
DEBUG (Env): Episode done for env 114. Reward: 18.64, Length: 10
DEBUG (Env): Episode done for env 120. Reward: -25.66, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 33.49, Length: 6
1498
Time taken for simulation:  7.165182828903198
average overall reward:  0.35338825  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.13006312  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: 16.49, Length: 14
DEBUG (Env): Episode done for env 52. Reward: 35.64, Length: 11
DEBUG (Env): Episode done for env 59. Reward: 14.30, Length: 18
DEBUG (Env): Episode done for env 104. Reward: 22.58, Length: 11
1499
Time taken for simulation:  7.191889524459839
average overall reward:  0.6151868  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  0.38955614  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: 50.50, Length: 6
DEBUG (Env): Episode done for env 27. Reward: 5.90, Length: 10
DEBUG (Env): Episode done for env 42. Reward: 5.40, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 30.45, Length: 7
1500
Time taken for simulation:  7.066331148147583
average overall reward:  0.0961118  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.018724684  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 4. Reward: 18.75, Length: 16
DEBUG (Env): Episode done for env 17. Reward: -16.68, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 27.88, Length: 10
DEBUG (Env): Episode done for env 100. Reward: 1.81, Length: 31
1501
Time taken for simulation:  7.0098395347595215
average overall reward:  0.70240945  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.43515676  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 12. Reward: -22.39, Length: 36
DEBUG (Env): Episode done for env 15. Reward: -22.96, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -13.11, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 25.51, Length: 15
DEBUG (Env): Episode done for env 54. Reward: 13.91, Length: 28
DEBUG (Env): Episode done for env 86. Reward: 22.53, Length: 14
DEBUG (Env): Episode done for env 107. Reward: -20.15, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 36.99, Length: 4
DEBUG (Env): Episode done for env 125. Reward: -21.40, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 12.38, Length: 15
1502
Time taken for simulation:  7.012506723403931
average overall reward:  -0.0038943514  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.083482854  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: 31.89, Length: 12
DEBUG (Env): Episode done for env 51. Reward: -14.64, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -16.91, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 17.32, Length: 16
DEBUG (Env): Episode done for env 90. Reward: -21.31, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -13.81, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -14.49, Length: 36
1503
Time taken for simulation:  7.452165603637695
average overall reward:  0.19313166  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.05964715  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -16.86, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 18.26, Length: 15
DEBUG (Env): Episode done for env 34. Reward: -10.90, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 33.22, Length: 5
DEBUG (Env): Episode done for env 94. Reward: -15.48, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 16.99, Length: 14
1504
Time taken for simulation:  7.113587856292725
average overall reward:  0.14872076  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.047517642  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 13. Reward: -19.06, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 25.27, Length: 12
DEBUG (Env): Episode done for env 69. Reward: -22.36, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -13.71, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -19.46, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 27.65, Length: 17
DEBUG (Env): Episode done for env 100. Reward: 23.58, Length: 4
DEBUG (Env): Episode done for env 117. Reward: -18.80, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 41.46, Length: 3
1505
Time taken for simulation:  7.005669355392456
average overall reward:  0.7593941  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.44296074  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: -16.35, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -18.84, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 32.29, Length: 8
DEBUG (Env): Episode done for env 44. Reward: -15.79, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 9.27, Length: 28
DEBUG (Env): Episode done for env 51. Reward: 44.01, Length: 3
DEBUG (Env): Episode done for env 63. Reward: -10.42, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 17.59, Length: 19
DEBUG (Env): Episode done for env 102. Reward: 21.65, Length: 10
1506
Time taken for simulation:  7.473029136657715
average overall reward:  0.721003  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.37722284  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: -14.47, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 0.60, Length: 26
DEBUG (Env): Episode done for env 64. Reward: 15.26, Length: 33
DEBUG (Env): Episode done for env 101. Reward: 23.43, Length: 1
DEBUG (Env): Episode done for env 110. Reward: 3.03, Length: 36
1507
Time taken for simulation:  7.419554710388184
average overall reward:  -0.08369815  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  -0.10524809  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 42. Reward: 27.91, Length: 8
DEBUG (Env): Episode done for env 62. Reward: -12.05, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 12.01, Length: 1
DEBUG (Env): Episode done for env 66. Reward: -21.47, Length: 36
1508
Time taken for simulation:  7.418048143386841
average overall reward:  0.08747173  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.1688941  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 31. Reward: 15.46, Length: 17
DEBUG (Env): Episode done for env 46. Reward: -27.09, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 16.95, Length: 29
DEBUG (Env): Episode done for env 119. Reward: -20.00, Length: 36
1509
Time taken for simulation:  7.181682348251343
average overall reward:  0.9507209  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.31436294  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 11. Reward: 30.23, Length: 15
DEBUG (Env): Episode done for env 20. Reward: 18.45, Length: 25
DEBUG (Env): Episode done for env 21. Reward: -17.34, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -15.50, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 31.00, Length: 4
DEBUG (Env): Episode done for env 58. Reward: 24.11, Length: 31
DEBUG (Env): Episode done for env 65. Reward: 13.79, Length: 13
DEBUG (Env): Episode done for env 72. Reward: -24.55, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 24.15, Length: 27
DEBUG (Env): Episode done for env 107. Reward: 22.89, Length: 8
1510
Time taken for simulation:  7.395660400390625
average overall reward:  0.8374907  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.30845606  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 4. Reward: 37.04, Length: 10
DEBUG (Env): Episode done for env 6. Reward: -22.56, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -10.31, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 28.52, Length: 21
DEBUG (Env): Episode done for env 59. Reward: 17.12, Length: 7
DEBUG (Env): Episode done for env 61. Reward: 25.31, Length: 14
DEBUG (Env): Episode done for env 97. Reward: -22.43, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 26.79, Length: 8
DEBUG (Env): Episode done for env 121. Reward: -21.00, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 32.23, Length: 6
1511
Time taken for simulation:  7.34512996673584
average overall reward:  0.79650414  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  0.19876081  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 11. Reward: 35.52, Length: 2
DEBUG (Env): Episode done for env 36. Reward: -22.44, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 24.11, Length: 9
DEBUG (Env): Episode done for env 61. Reward: 19.10, Length: 1
DEBUG (Env): Episode done for env 67. Reward: 14.37, Length: 23
DEBUG (Env): Episode done for env 77. Reward: -22.22, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -17.25, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 16.04, Length: 7
DEBUG (Env): Episode done for env 101. Reward: 17.27, Length: 5
DEBUG (Env): Episode done for env 110. Reward: 37.99, Length: 5
1512
Time taken for simulation:  7.025902509689331
average overall reward:  0.32276654  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.14240709  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 14. Reward: 28.46, Length: 9
DEBUG (Env): Episode done for env 39. Reward: 25.01, Length: 3
DEBUG (Env): Episode done for env 42. Reward: 25.95, Length: 5
DEBUG (Env): Episode done for env 105. Reward: -28.63, Length: 36
1513
Time taken for simulation:  7.1357011795043945
average overall reward:  -0.037194595  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.16606788  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: -15.69, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 5.20, Length: 30
DEBUG (Env): Episode done for env 98. Reward: 15.86, Length: 16
DEBUG (Env): Episode done for env 99. Reward: 20.57, Length: 11
1514
Time taken for simulation:  7.2759222984313965
average overall reward:  0.5188395  average fail penalty:  -0.0703125  and average goal bonus:  0.8122322  and average same cell penalty:  -0.16733009 average distance reward:  -0.007889502  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 7. Reward: -16.82, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 13.94, Length: 3
DEBUG (Env): Episode done for env 25. Reward: 23.83, Length: 10
DEBUG (Env): Episode done for env 34. Reward: 23.78, Length: 11
DEBUG (Env): Episode done for env 57. Reward: -14.13, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 26.94, Length: 15
DEBUG (Env): Episode done for env 76. Reward: -21.45, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 23.07, Length: 5
DEBUG (Env): Episode done for env 114. Reward: 30.50, Length: 13
1515
Time taken for simulation:  7.3200719356536865
average overall reward:  0.105384454  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.107271954  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: 26.06, Length: 24
DEBUG (Env): Episode done for env 102. Reward: 16.53, Length: 10
DEBUG (Env): Episode done for env 103. Reward: -16.09, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -17.18, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -12.11, Length: 36
1516
Time taken for simulation:  7.219969034194946
average overall reward:  0.04096084  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.06447497  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 22. Reward: -13.68, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -1.58, Length: 34
DEBUG (Env): Episode done for env 49. Reward: -16.33, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 16.08, Length: 15
DEBUG (Env): Episode done for env 112. Reward: 4.83, Length: 32
1517
Time taken for simulation:  7.271175384521484
average overall reward:  0.16460711  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.20280367  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: -17.03, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 28.40, Length: 16
DEBUG (Env): Episode done for env 38. Reward: -14.28, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -17.59, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -14.88, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 27.38, Length: 9
1518
Time taken for simulation:  7.057415246963501
average overall reward:  0.627481  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594473 average distance reward:  0.13936655  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 29. Reward: -23.45, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 19.78, Length: 17
DEBUG (Env): Episode done for env 38. Reward: 19.00, Length: 1
DEBUG (Env): Episode done for env 57. Reward: 21.95, Length: 4
DEBUG (Env): Episode done for env 77. Reward: 19.86, Length: 7
DEBUG (Env): Episode done for env 81. Reward: 20.02, Length: 9
DEBUG (Env): Episode done for env 83. Reward: -17.26, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -16.02, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 10.82, Length: 30
1519
Time taken for simulation:  7.209928274154663
average overall reward:  0.34811354  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.2539454  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 31. Reward: 37.36, Length: 11
DEBUG (Env): Episode done for env 105. Reward: 38.06, Length: 7
1520
Time taken for simulation:  7.279519557952881
average overall reward:  0.039373875  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.06375631  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 16. Reward: -22.03, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 15.94, Length: 25
DEBUG (Env): Episode done for env 81. Reward: 28.65, Length: 2
DEBUG (Env): Episode done for env 106. Reward: 15.27, Length: 27
1521
Time taken for simulation:  7.269771099090576
average overall reward:  -0.0039809346  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  0.023649719  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 30. Reward: -18.67, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 37.20, Length: 13
DEBUG (Env): Episode done for env 57. Reward: 24.27, Length: 3
DEBUG (Env): Episode done for env 80. Reward: -11.34, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -22.23, Length: 36
1522
Time taken for simulation:  7.158331632614136
average overall reward:  0.18666294  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.05548407  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: 28.91, Length: 8
DEBUG (Env): Episode done for env 53. Reward: -18.06, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 6.31, Length: 34
DEBUG (Env): Episode done for env 86. Reward: 18.35, Length: 6
DEBUG (Env): Episode done for env 96. Reward: -12.34, Length: 36
1523
Time taken for simulation:  7.024738311767578
average overall reward:  0.3921294  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.21176985  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: -18.09, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 35.92, Length: 9
DEBUG (Env): Episode done for env 72. Reward: 19.77, Length: 14
DEBUG (Env): Episode done for env 74. Reward: 24.32, Length: 10
1524
Time taken for simulation:  7.517048358917236
average overall reward:  0.36318356  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.26901552  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 30. Reward: 31.32, Length: 3
DEBUG (Env): Episode done for env 56. Reward: 16.15, Length: 13
1525
Time taken for simulation:  7.171076059341431
average overall reward:  0.7587015  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.16733009 average distance reward:  0.29703194  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 37.39, Length: 8
DEBUG (Env): Episode done for env 23. Reward: 29.59, Length: 19
DEBUG (Env): Episode done for env 82. Reward: 13.07, Length: 23
DEBUG (Env): Episode done for env 88. Reward: 15.28, Length: 14
DEBUG (Env): Episode done for env 114. Reward: 25.07, Length: 11
1526
Time taken for simulation:  7.263374090194702
average overall reward:  0.43538523  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020163 average distance reward:  0.1453968  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 35. Reward: 9.34, Length: 16
DEBUG (Env): Episode done for env 55. Reward: -15.16, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 19.32, Length: 15
DEBUG (Env): Episode done for env 95. Reward: 28.79, Length: 22
DEBUG (Env): Episode done for env 97. Reward: 24.97, Length: 16
1527
Time taken for simulation:  7.452876567840576
average overall reward:  0.7700392  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.26905322  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 25. Reward: 20.17, Length: 13
DEBUG (Env): Episode done for env 29. Reward: 18.31, Length: 9
DEBUG (Env): Episode done for env 40. Reward: 13.15, Length: 22
DEBUG (Env): Episode done for env 41. Reward: 35.86, Length: 11
DEBUG (Env): Episode done for env 68. Reward: -9.47, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 27.06, Length: 9
DEBUG (Env): Episode done for env 91. Reward: -19.17, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 33.63, Length: 12
DEBUG (Env): Episode done for env 124. Reward: -20.76, Length: 36
1528
Time taken for simulation:  7.173400640487671
average overall reward:  0.49377397  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.17343123  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 28.03, Length: 18
DEBUG (Env): Episode done for env 9. Reward: 12.46, Length: 26
DEBUG (Env): Episode done for env 18. Reward: -14.95, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 12.03, Length: 22
DEBUG (Env): Episode done for env 32. Reward: -16.13, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -23.54, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 28.03, Length: 18
1529
Time taken for simulation:  7.179463863372803
average overall reward:  0.5785831  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.43222705  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 55. Reward: 25.63, Length: 3
DEBUG (Env): Episode done for env 92. Reward: -16.92, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 38.98, Length: 31
DEBUG (Env): Episode done for env 115. Reward: -14.38, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 10.85, Length: 32
DEBUG (Env): Episode done for env 127. Reward: -23.46, Length: 36
1530
Time taken for simulation:  7.434523820877075
average overall reward:  0.3110066  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.002419293  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: 26.29, Length: 2
DEBUG (Env): Episode done for env 45. Reward: 20.44, Length: 25
DEBUG (Env): Episode done for env 47. Reward: 17.63, Length: 33
DEBUG (Env): Episode done for env 99. Reward: 27.63, Length: 17
1531
Time taken for simulation:  7.155543565750122
average overall reward:  0.030811828  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.14693946  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 31. Reward: 19.43, Length: 12
DEBUG (Env): Episode done for env 50. Reward: -21.03, Length: 36
1532
Time taken for simulation:  7.405086278915405
average overall reward:  -0.02810289  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.124333814  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 79. Reward: -23.03, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -19.10, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 29.42, Length: 10
1533
Time taken for simulation:  7.142966032028198
average overall reward:  0.23767045  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.07178636  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 26. Reward: 13.49, Length: 23
DEBUG (Env): Episode done for env 43. Reward: 15.80, Length: 32
DEBUG (Env): Episode done for env 70. Reward: -18.95, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 31.22, Length: 4
DEBUG (Env): Episode done for env 109. Reward: 39.46, Length: 12
DEBUG (Env): Episode done for env 113. Reward: -16.30, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -12.52, Length: 36
1534
Time taken for simulation:  7.215014696121216
average overall reward:  -0.048888303  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  0.25179198  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 10. Reward: -18.25, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -20.93, Length: 36
1535
Time taken for simulation:  7.152580499649048
average overall reward:  0.35226846  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.3049754  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: -18.45, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -15.79, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 23.44, Length: 2
DEBUG (Env): Episode done for env 89. Reward: 29.69, Length: 17
1536
Time taken for simulation:  7.3280229568481445
average overall reward:  0.77359295  average fail penalty:  -0.046875  and average goal bonus:  1.2183483  and average same cell penalty:  -0.24455938 average distance reward:  -0.105460376  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 4. Reward: 24.67, Length: 26
DEBUG (Env): Episode done for env 17. Reward: -18.16, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 6.27, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 25.79, Length: 22
DEBUG (Env): Episode done for env 39. Reward: 25.63, Length: 24
DEBUG (Env): Episode done for env 77. Reward: 37.47, Length: 9
DEBUG (Env): Episode done for env 79. Reward: 14.48, Length: 4
DEBUG (Env): Episode done for env 98. Reward: 24.35, Length: 23
DEBUG (Env): Episode done for env 105. Reward: 19.78, Length: 17
DEBUG (Env): Episode done for env 118. Reward: 29.61, Length: 19
1537
Time taken for simulation:  7.360200643539429
average overall reward:  0.69638467  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.44039968  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: -16.14, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -17.85, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 40.97, Length: 5
DEBUG (Env): Episode done for env 101. Reward: 15.92, Length: 26
DEBUG (Env): Episode done for env 103. Reward: 24.65, Length: 10
DEBUG (Env): Episode done for env 112. Reward: 18.47, Length: 21
DEBUG (Env): Episode done for env 125. Reward: -22.23, Length: 36
1538
Time taken for simulation:  7.363663196563721
average overall reward:  0.21537349  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.06075706  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 24. Reward: 16.23, Length: 23
DEBUG (Env): Episode done for env 73. Reward: 28.33, Length: 18
DEBUG (Env): Episode done for env 90. Reward: -17.36, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 30.70, Length: 9
1539
Time taken for simulation:  7.1792356967926025
average overall reward:  -0.2623107  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.1673301 average distance reward:  0.023192432  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 1. Reward: -10.72, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -13.02, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -14.87, Length: 36
1540
Time taken for simulation:  7.223730802536011
average overall reward:  0.5472753  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594475 average distance reward:  0.37677982  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 13. Reward: -14.97, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 15.61, Length: 33
DEBUG (Env): Episode done for env 69. Reward: -19.34, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 37.39, Length: 17
DEBUG (Env): Episode done for env 75. Reward: -15.32, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -17.31, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 11.51, Length: 25
DEBUG (Env): Episode done for env 117. Reward: -14.14, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 37.48, Length: 7
1541
Time taken for simulation:  7.089858293533325
average overall reward:  0.66129977  average fail penalty:  -0.09375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.18020163 average distance reward:  0.30625176  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: 21.96, Length: 6
DEBUG (Env): Episode done for env 3. Reward: -0.47, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 22.58, Length: 5
DEBUG (Env): Episode done for env 37. Reward: -11.21, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 31.50, Length: 8
DEBUG (Env): Episode done for env 51. Reward: -26.55, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 14.29, Length: 6
DEBUG (Env): Episode done for env 109. Reward: 16.47, Length: 8
1542
Time taken for simulation:  7.002992391586304
average overall reward:  0.2008634  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.022809431  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 11. Reward: 13.08, Length: 20
DEBUG (Env): Episode done for env 31. Reward: 33.09, Length: 11
DEBUG (Env): Episode done for env 108. Reward: 20.14, Length: 27
1543
Time taken for simulation:  7.128011226654053
average overall reward:  0.13063766  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  -0.013412714  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 28. Reward: 17.45, Length: 15
DEBUG (Env): Episode done for env 35. Reward: 30.16, Length: 17
DEBUG (Env): Episode done for env 62. Reward: -12.09, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -9.22, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 23.89, Length: 21
1544
Time taken for simulation:  7.844228267669678
average overall reward:  0.5522236  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.101120055  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 18. Reward: 31.52, Length: 16
DEBUG (Env): Episode done for env 69. Reward: 27.50, Length: 4
DEBUG (Env): Episode done for env 78. Reward: -12.57, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 26.69, Length: 22
DEBUG (Env): Episode done for env 121. Reward: 19.13, Length: 16
DEBUG (Env): Episode done for env 122. Reward: 9.94, Length: 15
1545
Time taken for simulation:  7.242250442504883
average overall reward:  0.3248932  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.15439782  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 20. Reward: -15.53, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -18.51, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 11.02, Length: 17
DEBUG (Env): Episode done for env 44. Reward: -15.68, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -12.37, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 27.08, Length: 2
DEBUG (Env): Episode done for env 65. Reward: -16.69, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 21.04, Length: 10
DEBUG (Env): Episode done for env 117. Reward: 26.82, Length: 5
1546
Time taken for simulation:  7.0461297035217285
average overall reward:  -0.0038488358  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.072975606  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 27.22, Length: 5
DEBUG (Env): Episode done for env 22. Reward: 15.52, Length: 30
DEBUG (Env): Episode done for env 24. Reward: 27.99, Length: 8
DEBUG (Env): Episode done for env 59. Reward: -15.00, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -25.12, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -7.94, Length: 36
1547
Time taken for simulation:  8.216117143630981
average overall reward:  0.7448424  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.141587 average distance reward:  0.08043577  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 21. Reward: 18.41, Length: 2
DEBUG (Env): Episode done for env 36. Reward: -15.78, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 9.10, Length: 16
DEBUG (Env): Episode done for env 53. Reward: 8.67, Length: 25
DEBUG (Env): Episode done for env 55. Reward: 19.50, Length: 18
DEBUG (Env): Episode done for env 63. Reward: 28.80, Length: 6
DEBUG (Env): Episode done for env 67. Reward: -23.84, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 7.42, Length: 29
DEBUG (Env): Episode done for env 93. Reward: -24.40, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 20.69, Length: 7
DEBUG (Env): Episode done for env 110. Reward: -17.03, Length: 36
1548
Time taken for simulation:  7.033602476119995
average overall reward:  0.3273163  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  -0.023120543  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: 15.70, Length: 11
DEBUG (Env): Episode done for env 14. Reward: -6.51, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 22.94, Length: 5
DEBUG (Env): Episode done for env 42. Reward: -15.73, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 19.93, Length: 18
DEBUG (Env): Episode done for env 86. Reward: 14.82, Length: 4
DEBUG (Env): Episode done for env 126. Reward: 31.27, Length: 2
1549
Time taken for simulation:  7.173976421356201
average overall reward:  0.37397435  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.2451011  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: -23.48, Length: 36
DEBUG (Env): Episode done for env 6. Reward: 15.42, Length: 19
DEBUG (Env): Episode done for env 51. Reward: 25.78, Length: 8
DEBUG (Env): Episode done for env 120. Reward: 33.68, Length: 9
1550
Time taken for simulation:  7.468507766723633
average overall reward:  0.11530145  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.10206887  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 53. Reward: 19.76, Length: 3
DEBUG (Env): Episode done for env 59. Reward: 25.74, Length: 4
DEBUG (Env): Episode done for env 60. Reward: -16.68, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -17.35, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 25.98, Length: 13
DEBUG (Env): Episode done for env 107. Reward: -15.92, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 22.39, Length: 6
1551
Time taken for simulation:  7.0433433055877686
average overall reward:  0.25975817  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.017358702  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 44. Reward: 20.64, Length: 6
DEBUG (Env): Episode done for env 89. Reward: 26.08, Length: 10
DEBUG (Env): Episode done for env 123. Reward: -17.04, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 17.13, Length: 14
DEBUG (Env): Episode done for env 126. Reward: 11.47, Length: 3
1552
Time taken for simulation:  7.167675495147705
average overall reward:  0.270936  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.04530529  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 29. Reward: 7.85, Length: 25
DEBUG (Env): Episode done for env 40. Reward: 20.15, Length: 25
DEBUG (Env): Episode done for env 49. Reward: -18.69, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 31.87, Length: 13
DEBUG (Env): Episode done for env 109. Reward: 28.42, Length: 11
1553
Time taken for simulation:  7.133289337158203
average overall reward:  0.26423052  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.16936067  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: -14.70, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 17.04, Length: 26
DEBUG (Env): Episode done for env 48. Reward: -20.83, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 18.09, Length: 17
DEBUG (Env): Episode done for env 119. Reward: -20.80, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 16.34, Length: 9
1554
Time taken for simulation:  7.215002536773682
average overall reward:  0.62087226  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.068400115  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 12. Reward: 30.09, Length: 6
DEBUG (Env): Episode done for env 18. Reward: 13.93, Length: 10
DEBUG (Env): Episode done for env 31. Reward: 17.04, Length: 12
DEBUG (Env): Episode done for env 33. Reward: -16.85, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -19.24, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 18.30, Length: 14
DEBUG (Env): Episode done for env 67. Reward: 16.08, Length: 7
DEBUG (Env): Episode done for env 84. Reward: -19.85, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 10.12, Length: 14
1555
Time taken for simulation:  7.033401966094971
average overall reward:  0.53954434  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.18750376  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 37. Reward: 36.13, Length: 14
DEBUG (Env): Episode done for env 47. Reward: 17.00, Length: 25
DEBUG (Env): Episode done for env 79. Reward: 40.03, Length: 19
DEBUG (Env): Episode done for env 102. Reward: 21.92, Length: 1
1556
Time taken for simulation:  7.141474962234497
average overall reward:  0.5795722  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.22682984  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: 17.03, Length: 33
DEBUG (Env): Episode done for env 16. Reward: -25.80, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 27.00, Length: 4
DEBUG (Env): Episode done for env 78. Reward: 0.63, Length: 12
DEBUG (Env): Episode done for env 81. Reward: -14.25, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 21.89, Length: 9
DEBUG (Env): Episode done for env 106. Reward: -15.89, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 24.36, Length: 9
1557
Time taken for simulation:  7.394956350326538
average overall reward:  0.36005855  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  -0.0055553764  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: 18.51, Length: 34
DEBUG (Env): Episode done for env 11. Reward: 28.20, Length: 15
DEBUG (Env): Episode done for env 46. Reward: -22.92, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -19.14, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 15.14, Length: 19
DEBUG (Env): Episode done for env 76. Reward: 22.14, Length: 7
DEBUG (Env): Episode done for env 80. Reward: -26.02, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 24.98, Length: 7
1558
Time taken for simulation:  7.156071186065674
average overall reward:  0.059012845  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.16457455  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 87. Reward: 11.17, Length: 21
1559
Time taken for simulation:  8.022852659225464
average overall reward:  0.8898741  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594475 average distance reward:  0.21951267  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 15. Reward: 21.59, Length: 6
DEBUG (Env): Episode done for env 25. Reward: 27.29, Length: 6
DEBUG (Env): Episode done for env 44. Reward: 38.59, Length: 8
DEBUG (Env): Episode done for env 72. Reward: -13.24, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 11.97, Length: 12
DEBUG (Env): Episode done for env 89. Reward: 17.98, Length: 8
DEBUG (Env): Episode done for env 93. Reward: 26.63, Length: 3
DEBUG (Env): Episode done for env 106. Reward: 18.29, Length: 3
1560
Time taken for simulation:  7.165904521942139
average overall reward:  0.2537288  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.10967837  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: 8.20, Length: 20
DEBUG (Env): Episode done for env 30. Reward: -16.35, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 29.20, Length: 3
DEBUG (Env): Episode done for env 53. Reward: 22.56, Length: 10
DEBUG (Env): Episode done for env 56. Reward: -25.03, Length: 36
1561
Time taken for simulation:  7.309070587158203
average overall reward:  0.37444484  average fail penalty:  -0.1171875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  0.055705957  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 2. Reward: 17.20, Length: 15
DEBUG (Env): Episode done for env 5. Reward: 16.70, Length: 5
DEBUG (Env): Episode done for env 8. Reward: -15.59, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 17.89, Length: 2
DEBUG (Env): Episode done for env 23. Reward: -23.24, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 10.97, Length: 24
DEBUG (Env): Episode done for env 82. Reward: -25.59, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -21.84, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 23.03, Length: 24
DEBUG (Env): Episode done for env 114. Reward: -17.01, Length: 36
1562
Time taken for simulation:  7.153984308242798
average overall reward:  -0.20979926  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.1692971  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 48. Reward: 33.68, Length: 9
DEBUG (Env): Episode done for env 61. Reward: -20.70, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -18.26, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -27.14, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 15.02, Length: 35
1563
Time taken for simulation:  7.287052392959595
average overall reward:  0.66675603  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  0.31401366  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: 7.73, Length: 35
DEBUG (Env): Episode done for env 24. Reward: 16.12, Length: 17
DEBUG (Env): Episode done for env 41. Reward: -20.92, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -18.60, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 19.72, Length: 23
DEBUG (Env): Episode done for env 91. Reward: -14.84, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 27.64, Length: 16
DEBUG (Env): Episode done for env 121. Reward: 21.11, Length: 10
1564
Time taken for simulation:  7.1374242305755615
average overall reward:  0.4226808  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.1326924  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: 19.03, Length: 10
DEBUG (Env): Episode done for env 43. Reward: 24.77, Length: 23
DEBUG (Env): Episode done for env 71. Reward: -22.20, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 15.59, Length: 28
DEBUG (Env): Episode done for env 97. Reward: 17.02, Length: 2
1565
Time taken for simulation:  7.142225980758667
average overall reward:  0.14487848  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.18768623  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 50. Reward: 13.71, Length: 18
DEBUG (Env): Episode done for env 58. Reward: 42.90, Length: 20
DEBUG (Env): Episode done for env 92. Reward: -21.54, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -32.37, Length: 36
1566
Time taken for simulation:  7.173015832901001
average overall reward:  0.3169905  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.17524566  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 17. Reward: 10.30, Length: 25
DEBUG (Env): Episode done for env 77. Reward: 35.51, Length: 2
DEBUG (Env): Episode done for env 99. Reward: -10.63, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 23.05, Length: 11
1567
Time taken for simulation:  7.262824296951294
average overall reward:  0.5483202  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.102972366 average distance reward:  0.022292987  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 64. Reward: 22.60, Length: 22
DEBUG (Env): Episode done for env 81. Reward: 25.43, Length: 11
DEBUG (Env): Episode done for env 92. Reward: 16.85, Length: 2
DEBUG (Env): Episode done for env 93. Reward: 23.57, Length: 8
DEBUG (Env): Episode done for env 122. Reward: 11.02, Length: 17
1568
Time taken for simulation:  7.179748773574829
average overall reward:  0.4250931  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.14797623  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: 20.35, Length: 19
DEBUG (Env): Episode done for env 59. Reward: 24.46, Length: 18
DEBUG (Env): Episode done for env 62. Reward: 22.47, Length: 25
DEBUG (Env): Episode done for env 93. Reward: 17.93, Length: 1
DEBUG (Env): Episode done for env 96. Reward: -19.74, Length: 36
1569
Time taken for simulation:  7.209258317947388
average overall reward:  0.24741206  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.13967061  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 26. Reward: -15.99, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 18.16, Length: 17
DEBUG (Env): Episode done for env 61. Reward: 41.17, Length: 7
DEBUG (Env): Episode done for env 104. Reward: -21.95, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -22.71, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 15.72, Length: 23
1570
Time taken for simulation:  7.09349250793457
average overall reward:  1.0947537  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.115843914 average distance reward:  0.49310112  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 10. Reward: -12.43, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 27.96, Length: 6
DEBUG (Env): Episode done for env 52. Reward: -23.25, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 26.10, Length: 9
DEBUG (Env): Episode done for env 68. Reward: 29.70, Length: 7
DEBUG (Env): Episode done for env 98. Reward: 12.06, Length: 17
DEBUG (Env): Episode done for env 106. Reward: 25.18, Length: 11
DEBUG (Env): Episode done for env 124. Reward: 14.88, Length: 8
1571
Time taken for simulation:  7.351552963256836
average overall reward:  1.2633758  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168783 average distance reward:  0.7541294  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 17. Reward: 37.04, Length: 5
DEBUG (Env): Episode done for env 26. Reward: 17.53, Length: 2
DEBUG (Env): Episode done for env 27. Reward: -26.99, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 25.42, Length: 24
DEBUG (Env): Episode done for env 65. Reward: 30.21, Length: 26
DEBUG (Env): Episode done for env 80. Reward: 38.75, Length: 14
DEBUG (Env): Episode done for env 94. Reward: 23.50, Length: 19
1572
Time taken for simulation:  7.335034370422363
average overall reward:  -0.13914514  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.1637025  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 4. Reward: -15.22, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -23.26, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -21.56, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -30.46, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 38.72, Length: 24
DEBUG (Env): Episode done for env 89. Reward: 20.44, Length: 13
DEBUG (Env): Episode done for env 105. Reward: -24.08, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 15.26, Length: 22
DEBUG (Env): Episode done for env 118. Reward: -16.76, Length: 36
1573
Time taken for simulation:  7.246169090270996
average overall reward:  0.7348021  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.18020165 average distance reward:  0.3094417  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: 15.97, Length: 13
DEBUG (Env): Episode done for env 31. Reward: 34.98, Length: 19
DEBUG (Env): Episode done for env 97. Reward: 23.26, Length: 9
DEBUG (Env): Episode done for env 100. Reward: 25.33, Length: 10
DEBUG (Env): Episode done for env 112. Reward: -19.91, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 15.30, Length: 22
1574
Time taken for simulation:  7.196532487869263
average overall reward:  0.526359  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.22119357  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 35.09, Length: 10
DEBUG (Env): Episode done for env 29. Reward: 16.51, Length: 18
DEBUG (Env): Episode done for env 43. Reward: 30.93, Length: 4
DEBUG (Env): Episode done for env 90. Reward: -14.02, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 26.08, Length: 5
DEBUG (Env): Episode done for env 115. Reward: -28.12, Length: 36
1575
Time taken for simulation:  7.850442409515381
average overall reward:  0.88751525  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.58234966  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -12.86, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 24.92, Length: 12
DEBUG (Env): Episode done for env 10. Reward: 18.06, Length: 5
DEBUG (Env): Episode done for env 63. Reward: 25.02, Length: 4
DEBUG (Env): Episode done for env 91. Reward: 24.81, Length: 12
DEBUG (Env): Episode done for env 111. Reward: -12.69, Length: 36
1576
Time taken for simulation:  6.9955830574035645
average overall reward:  0.07861123  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.18020165 average distance reward:  0.33011094  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 75. Reward: -21.08, Length: 36
1577
Time taken for simulation:  7.4337005615234375
average overall reward:  0.0960404  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.045704454  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: -11.16, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 20.03, Length: 3
DEBUG (Env): Episode done for env 19. Reward: 34.86, Length: 5
DEBUG (Env): Episode done for env 91. Reward: 19.50, Length: 2
1578
Time taken for simulation:  7.2259557247161865
average overall reward:  0.82683396  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.15647253  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: 47.94, Length: 5
DEBUG (Env): Episode done for env 40. Reward: 4.49, Length: 9
DEBUG (Env): Episode done for env 48. Reward: 19.26, Length: 16
DEBUG (Env): Episode done for env 76. Reward: 17.45, Length: 21
DEBUG (Env): Episode done for env 88. Reward: 22.93, Length: 17
DEBUG (Env): Episode done for env 95. Reward: 30.60, Length: 16
DEBUG (Env): Episode done for env 108. Reward: -17.88, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 18.49, Length: 29
1579
Time taken for simulation:  7.433641672134399
average overall reward:  0.7361458  average fail penalty:  -0.046875  and average goal bonus:  1.0829762  and average same cell penalty:  -0.15445855 average distance reward:  -0.097636335  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 27. Reward: 17.88, Length: 8
DEBUG (Env): Episode done for env 35. Reward: -19.63, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 31.72, Length: 31
DEBUG (Env): Episode done for env 53. Reward: 22.07, Length: 19
DEBUG (Env): Episode done for env 55. Reward: 7.04, Length: 32
DEBUG (Env): Episode done for env 72. Reward: 22.42, Length: 20
DEBUG (Env): Episode done for env 85. Reward: -21.87, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 25.84, Length: 10
DEBUG (Env): Episode done for env 118. Reward: 41.81, Length: 7
DEBUG (Env): Episode done for env 125. Reward: 17.20, Length: 6
1580
Time taken for simulation:  7.730095624923706
average overall reward:  0.6422807  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.055805087  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 31. Reward: 35.34, Length: 7
DEBUG (Env): Episode done for env 61. Reward: 20.62, Length: 11
DEBUG (Env): Episode done for env 69. Reward: -22.05, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 13.07, Length: 4
DEBUG (Env): Episode done for env 94. Reward: 27.05, Length: 9
DEBUG (Env): Episode done for env 104. Reward: 22.63, Length: 11
DEBUG (Env): Episode done for env 121. Reward: 24.55, Length: 17
1581
Time taken for simulation:  7.413630247116089
average overall reward:  -0.19778556  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  -0.03708843  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 20. Reward: -16.33, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -18.67, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -22.05, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 31.80, Length: 14
DEBUG (Env): Episode done for env 117. Reward: -18.26, Length: 36
1582
Time taken for simulation:  7.204218864440918
average overall reward:  0.036063522  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.003947623  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 22. Reward: -12.63, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 19.27, Length: 8
DEBUG (Env): Episode done for env 56. Reward: 20.44, Length: 22
1583
Time taken for simulation:  7.297715663909912
average overall reward:  0.48978966  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.21036716  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: 20.75, Length: 8
DEBUG (Env): Episode done for env 21. Reward: -16.70, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -20.77, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 40.74, Length: 9
DEBUG (Env): Episode done for env 92. Reward: 12.44, Length: 2
DEBUG (Env): Episode done for env 118. Reward: 29.22, Length: 4
1584
Time taken for simulation:  7.10078763961792
average overall reward:  0.07489972  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.090100825 average distance reward:  -0.2583146  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 14. Reward: -7.68, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -43.44, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -18.46, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 8.64, Length: 27
DEBUG (Env): Episode done for env 59. Reward: 19.66, Length: 16
DEBUG (Env): Episode done for env 77. Reward: 25.20, Length: 18
DEBUG (Env): Episode done for env 127. Reward: 17.42, Length: 19
1585
Time taken for simulation:  7.661906957626343
average overall reward:  0.3207538  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3346602 average distance reward:  0.34403342  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -13.72, Length: 36
DEBUG (Env): Episode done for env 7. Reward: 13.42, Length: 28
DEBUG (Env): Episode done for env 43. Reward: 22.38, Length: 3
DEBUG (Env): Episode done for env 51. Reward: -19.84, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 13.65, Length: 12
1586
Time taken for simulation:  7.093108415603638
average overall reward:  0.46530014  average fail penalty:  -0.0234375  and average goal bonus:  0.8122322  and average same cell penalty:  -0.141587 average distance reward:  -0.134047  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 14.94, Length: 32
DEBUG (Env): Episode done for env 56. Reward: 17.11, Length: 4
DEBUG (Env): Episode done for env 60. Reward: -17.24, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 35.25, Length: 9
DEBUG (Env): Episode done for env 106. Reward: 20.64, Length: 16
DEBUG (Env): Episode done for env 107. Reward: 10.01, Length: 14
DEBUG (Env): Episode done for env 117. Reward: 20.39, Length: 5
1587
Time taken for simulation:  7.110733270645142
average overall reward:  -0.10549732  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  0.034067854  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 22. Reward: 27.44, Length: 5
DEBUG (Env): Episode done for env 123. Reward: -18.00, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -27.68, Length: 36
1588
Time taken for simulation:  7.830209493637085
average overall reward:  0.8789133  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.4898619  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 31. Reward: 16.36, Length: 8
DEBUG (Env): Episode done for env 49. Reward: -16.98, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 24.47, Length: 3
DEBUG (Env): Episode done for env 55. Reward: 20.13, Length: 9
DEBUG (Env): Episode done for env 59. Reward: 31.61, Length: 4
DEBUG (Env): Episode done for env 68. Reward: 26.90, Length: 18
DEBUG (Env): Episode done for env 109. Reward: -22.68, Length: 36
1589
Time taken for simulation:  7.362969160079956
average overall reward:  0.16222855  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  -0.07627366  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 10. Reward: 50.35, Length: 14
DEBUG (Env): Episode done for env 31. Reward: 11.13, Length: 1
DEBUG (Env): Episode done for env 104. Reward: 16.53, Length: 9
DEBUG (Env): Episode done for env 109. Reward: 23.49, Length: 1
DEBUG (Env): Episode done for env 119. Reward: -14.83, Length: 36
1590
Time taken for simulation:  7.2517476081848145
average overall reward:  -0.2563094  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.02068865  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 21. Reward: 28.48, Length: 7
DEBUG (Env): Episode done for env 33. Reward: -15.79, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -6.27, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -13.61, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -12.15, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -17.00, Length: 36
1591
Time taken for simulation:  7.225915908813477
average overall reward:  -0.07506901  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.283174 average distance reward:  0.055533983  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 37. Reward: -25.69, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -12.17, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -17.99, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 18.88, Length: 5
DEBUG (Env): Episode done for env 109. Reward: 32.58, Length: 2
1592
Time taken for simulation:  7.295617341995239
average overall reward:  -0.105521575  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.3346602 average distance reward:  0.07656759  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 16. Reward: -15.55, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 22.54, Length: 21
DEBUG (Env): Episode done for env 78. Reward: -3.48, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 20.76, Length: 14
DEBUG (Env): Episode done for env 110. Reward: -7.69, Length: 36
1593
Time taken for simulation:  7.236881494522095
average overall reward:  0.7498634  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.48100677  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 11. Reward: -19.09, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 20.77, Length: 1
DEBUG (Env): Episode done for env 36. Reward: 27.70, Length: 10
DEBUG (Env): Episode done for env 40. Reward: 10.70, Length: 15
DEBUG (Env): Episode done for env 73. Reward: -15.04, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -13.74, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 14.99, Length: 14
1594
Time taken for simulation:  7.416090488433838
average overall reward:  0.27881607  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.090100825 average distance reward:  0.3048429  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 42. Reward: 25.06, Length: 10
DEBUG (Env): Episode done for env 87. Reward: -18.84, Length: 36
1595
Time taken for simulation:  7.324055910110474
average overall reward:  1.6910843  average fail penalty:  -0.0703125  and average goal bonus:  1.2183483  and average same cell penalty:  -0.15445855 average distance reward:  0.7453675  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 25. Reward: -23.05, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 35.37, Length: 11
DEBUG (Env): Episode done for env 39. Reward: 1.40, Length: 23
DEBUG (Env): Episode done for env 44. Reward: -15.90, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 52.40, Length: 9
DEBUG (Env): Episode done for env 67. Reward: 35.89, Length: 5
DEBUG (Env): Episode done for env 78. Reward: 20.51, Length: 3
DEBUG (Env): Episode done for env 83. Reward: -15.28, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 34.21, Length: 12
DEBUG (Env): Episode done for env 114. Reward: 5.40, Length: 34
DEBUG (Env): Episode done for env 117. Reward: 29.75, Length: 9
DEBUG (Env): Episode done for env 121. Reward: 31.40, Length: 15
1596
Time taken for simulation:  7.122671604156494
average overall reward:  0.6635121  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.16733009 average distance reward:  0.11334567  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: 14.08, Length: 35
DEBUG (Env): Episode done for env 30. Reward: -13.21, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 17.50, Length: 1
DEBUG (Env): Episode done for env 46. Reward: -9.36, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 33.66, Length: 8
DEBUG (Env): Episode done for env 90. Reward: 26.12, Length: 13
DEBUG (Env): Episode done for env 114. Reward: 24.83, Length: 1
DEBUG (Env): Episode done for env 119. Reward: 19.34, Length: 7
1597
Time taken for simulation:  7.0761449337005615
average overall reward:  0.07323277  average fail penalty:  -0.140625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.060953587  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 2. Reward: -14.93, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -15.30, Length: 36
DEBUG (Env): Episode done for env 15. Reward: -16.35, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 29.65, Length: 7
DEBUG (Env): Episode done for env 23. Reward: -20.60, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 23.62, Length: 7
DEBUG (Env): Episode done for env 37. Reward: 25.83, Length: 6
DEBUG (Env): Episode done for env 82. Reward: -12.90, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -9.75, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 12.65, Length: 25
1598
Time taken for simulation:  7.10457968711853
average overall reward:  -0.06587425  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.10855611  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 4. Reward: 28.01, Length: 26
DEBUG (Env): Episode done for env 53. Reward: 31.81, Length: 19
1599
Time taken for simulation:  7.800970792770386
average overall reward:  1.1605433  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.12871546 average distance reward:  0.5951997  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 13. Reward: 34.99, Length: 21
DEBUG (Env): Episode done for env 22. Reward: 23.59, Length: 12
DEBUG (Env): Episode done for env 24. Reward: -19.20, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 6.83, Length: 3
DEBUG (Env): Episode done for env 41. Reward: -5.54, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 35.33, Length: 5
DEBUG (Env): Episode done for env 74. Reward: -13.96, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 12.62, Length: 27
DEBUG (Env): Episode done for env 118. Reward: 23.15, Length: 16
1600
Time taken for simulation:  7.33126163482666
average overall reward:  -0.095550954  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  -0.15340996  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: 21.52, Length: 7
DEBUG (Env): Episode done for env 43. Reward: 19.02, Length: 15
DEBUG (Env): Episode done for env 71. Reward: -8.60, Length: 36
1601
Time taken for simulation:  7.183121919631958
average overall reward:  0.012841567  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.09426397  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: 23.05, Length: 4
DEBUG (Env): Episode done for env 50. Reward: -25.29, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -17.66, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 15.28, Length: 9
1602
Time taken for simulation:  7.078370094299316
average overall reward:  0.5934545  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.27030247 average distance reward:  0.1462603  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 12. Reward: 7.36, Length: 25
DEBUG (Env): Episode done for env 26. Reward: 36.29, Length: 31
DEBUG (Env): Episode done for env 28. Reward: 27.70, Length: 7
DEBUG (Env): Episode done for env 56. Reward: 22.11, Length: 7
DEBUG (Env): Episode done for env 78. Reward: 37.76, Length: 7
DEBUG (Env): Episode done for env 99. Reward: -17.72, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -15.87, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 21.37, Length: 5
1603
Time taken for simulation:  6.978405237197876
average overall reward:  0.4546179  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.12871546 average distance reward:  -0.110725775  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 18. Reward: 17.18, Length: 17
DEBUG (Env): Episode done for env 22. Reward: 24.71, Length: 4
DEBUG (Env): Episode done for env 47. Reward: 8.57, Length: 12
DEBUG (Env): Episode done for env 61. Reward: 27.31, Length: 23
DEBUG (Env): Episode done for env 64. Reward: -21.43, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -25.44, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 20.28, Length: 25
DEBUG (Env): Episode done for env 112. Reward: 34.41, Length: 18
DEBUG (Env): Episode done for env 122. Reward: -6.72, Length: 36
1604
Time taken for simulation:  7.051764249801636
average overall reward:  -0.013379976  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.06343126  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: -20.23, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 20.92, Length: 1
DEBUG (Env): Episode done for env 61. Reward: 20.71, Length: 1
DEBUG (Env): Episode done for env 62. Reward: -13.97, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -30.47, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -20.12, Length: 36
1605
Time taken for simulation:  7.344524145126343
average overall reward:  0.14152582  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  0.124587014  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 109. Reward: 8.46, Length: 14
DEBUG (Env): Episode done for env 110. Reward: 18.29, Length: 4
1606
Time taken for simulation:  7.092583894729614
average overall reward:  0.5716646  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168783 average distance reward:  0.13273084  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 15. Reward: 18.55, Length: 9
DEBUG (Env): Episode done for env 36. Reward: 30.05, Length: 13
DEBUG (Env): Episode done for env 52. Reward: -20.23, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -14.87, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 13.77, Length: 31
DEBUG (Env): Episode done for env 64. Reward: 26.46, Length: 3
DEBUG (Env): Episode done for env 74. Reward: 36.32, Length: 7
DEBUG (Env): Episode done for env 98. Reward: -12.53, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 26.33, Length: 17
DEBUG (Env): Episode done for env 124. Reward: -15.54, Length: 36
1607
Time taken for simulation:  7.502396583557129
average overall reward:  0.36151904  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.107839644  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: 14.24, Length: 24
DEBUG (Env): Episode done for env 28. Reward: 15.21, Length: 5
DEBUG (Env): Episode done for env 46. Reward: 22.57, Length: 11
DEBUG (Env): Episode done for env 56. Reward: 30.34, Length: 5
DEBUG (Env): Episode done for env 65. Reward: -31.50, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -9.47, Length: 36
1608
Time taken for simulation:  7.618701457977295
average overall reward:  0.67155206  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.45648727  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 34. Reward: -16.05, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 4.29, Length: 29
DEBUG (Env): Episode done for env 86. Reward: -15.50, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 50.78, Length: 3
DEBUG (Env): Episode done for env 118. Reward: 21.79, Length: 9
DEBUG (Env): Episode done for env 122. Reward: 39.24, Length: 5
1609
Time taken for simulation:  7.297712802886963
average overall reward:  0.42043206  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.2053673  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 8.14, Length: 20
DEBUG (Env): Episode done for env 66. Reward: 21.13, Length: 19
DEBUG (Env): Episode done for env 77. Reward: 4.94, Length: 25
DEBUG (Env): Episode done for env 78. Reward: 26.75, Length: 7
DEBUG (Env): Episode done for env 97. Reward: -19.40, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 2.66, Length: 36
1610
Time taken for simulation:  7.22496771812439
average overall reward:  -0.31793237  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.29030174  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: 26.18, Length: 8
DEBUG (Env): Episode done for env 29. Reward: -33.74, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 35.04, Length: 10
DEBUG (Env): Episode done for env 113. Reward: -19.90, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -17.05, Length: 36
1611
Time taken for simulation:  7.338282585144043
average overall reward:  -0.21062943  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  0.006164983  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: -19.13, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 25.83, Length: 12
DEBUG (Env): Episode done for env 111. Reward: -13.65, Length: 36
1612
Time taken for simulation:  7.364567518234253
average overall reward:  0.16600096  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.14906216  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: 20.57, Length: 15
DEBUG (Env): Episode done for env 60. Reward: 5.12, Length: 26
1613
Time taken for simulation:  7.17904806137085
average overall reward:  0.084496796  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.12730461  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: -23.33, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -13.66, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 41.53, Length: 17
DEBUG (Env): Episode done for env 31. Reward: 26.79, Length: 4
1614
Time taken for simulation:  7.228050231933594
average overall reward:  0.22392046  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.17823116  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 48. Reward: -26.58, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 15.83, Length: 13
DEBUG (Env): Episode done for env 51. Reward: 5.94, Length: 26
DEBUG (Env): Episode done for env 66. Reward: 17.55, Length: 5
DEBUG (Env): Episode done for env 76. Reward: -27.91, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -12.32, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -30.22, Length: 36
1615
Time taken for simulation:  7.383013725280762
average overall reward:  -0.06836744  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.283174 average distance reward:  -0.29700553  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 27. Reward: -25.72, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -22.67, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -28.66, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 25.76, Length: 27
DEBUG (Env): Episode done for env 84. Reward: 25.56, Length: 25
DEBUG (Env): Episode done for env 85. Reward: -30.14, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 18.48, Length: 21
DEBUG (Env): Episode done for env 101. Reward: 20.91, Length: 18
DEBUG (Env): Episode done for env 114. Reward: 12.31, Length: 19
DEBUG (Env): Episode done for env 116. Reward: -23.07, Length: 36
1616
Time taken for simulation:  7.415919542312622
average overall reward:  0.40594834  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.27246386  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 48. Reward: 13.50, Length: 2
DEBUG (Env): Episode done for env 69. Reward: -13.09, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 31.29, Length: 10
DEBUG (Env): Episode done for env 75. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -18.18, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 7.98, Length: 14
1617
Time taken for simulation:  7.237469673156738
average overall reward:  0.214748  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.054108545  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 20. Reward: -18.56, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -19.73, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 12.54, Length: 3
DEBUG (Env): Episode done for env 63. Reward: 24.32, Length: 11
DEBUG (Env): Episode done for env 70. Reward: -22.09, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 19.18, Length: 22
DEBUG (Env): Episode done for env 124. Reward: 26.63, Length: 11
1618
Time taken for simulation:  7.056139230728149
average overall reward:  0.31876028  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  -0.11716615  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: -5.71, Length: 34
DEBUG (Env): Episode done for env 69. Reward: 23.95, Length: 2
DEBUG (Env): Episode done for env 75. Reward: 25.16, Length: 2
DEBUG (Env): Episode done for env 110. Reward: 21.42, Length: 10
DEBUG (Env): Episode done for env 124. Reward: 18.28, Length: 1
1619
Time taken for simulation:  7.130740404129028
average overall reward:  0.71176714  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.28871232  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 62. Reward: 41.82, Length: 15
DEBUG (Env): Episode done for env 63. Reward: 17.02, Length: 2
DEBUG (Env): Episode done for env 79. Reward: 3.62, Length: 28
DEBUG (Env): Episode done for env 82. Reward: 19.94, Length: 22
DEBUG (Env): Episode done for env 121. Reward: 34.12, Length: 24
1620
Time taken for simulation:  7.17956280708313
average overall reward:  -0.058866687  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.21881628 average distance reward:  0.2546852  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 57. Reward: -24.41, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -18.28, Length: 36
1621
Time taken for simulation:  7.160887002944946
average overall reward:  -0.17069376  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  -0.17937215  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: -17.69, Length: 36
DEBUG (Env): Episode done for env 7. Reward: -18.97, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 17.58, Length: 7
DEBUG (Env): Episode done for env 122. Reward: 22.51, Length: 13
1622
Time taken for simulation:  7.172335386276245
average overall reward:  0.7634262  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020163 average distance reward:  0.36150324  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 23. Reward: 9.13, Length: 21
DEBUG (Env): Episode done for env 27. Reward: 29.35, Length: 7
DEBUG (Env): Episode done for env 28. Reward: 28.92, Length: 15
DEBUG (Env): Episode done for env 41. Reward: 14.12, Length: 23
DEBUG (Env): Episode done for env 91. Reward: -22.05, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 10.69, Length: 5
DEBUG (Env): Episode done for env 106. Reward: -12.05, Length: 36
1623
Time taken for simulation:  7.12895393371582
average overall reward:  1.1853619  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.1673301 average distance reward:  0.63519526  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 6. Reward: 18.39, Length: 19
DEBUG (Env): Episode done for env 38. Reward: 7.78, Length: 33
DEBUG (Env): Episode done for env 50. Reward: 30.39, Length: 6
DEBUG (Env): Episode done for env 57. Reward: 17.48, Length: 3
DEBUG (Env): Episode done for env 101. Reward: 23.75, Length: 8
DEBUG (Env): Episode done for env 111. Reward: 23.10, Length: 12
DEBUG (Env): Episode done for env 123. Reward: -12.14, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -24.27, Length: 36
1624
Time taken for simulation:  7.280231714248657
average overall reward:  0.74654543  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.06435773 average distance reward:  0.09340648  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: 14.76, Length: 28
DEBUG (Env): Episode done for env 36. Reward: 25.84, Length: 18
DEBUG (Env): Episode done for env 38. Reward: 20.00, Length: 1
DEBUG (Env): Episode done for env 55. Reward: -14.24, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -8.13, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 22.54, Length: 31
DEBUG (Env): Episode done for env 84. Reward: 13.09, Length: 9
DEBUG (Env): Episode done for env 115. Reward: 25.83, Length: 14
1625
Time taken for simulation:  7.430593490600586
average overall reward:  1.0071611  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.20594473 average distance reward:  0.20142767  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 10. Reward: -12.03, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 38.95, Length: 26
DEBUG (Env): Episode done for env 36. Reward: 24.83, Length: 1
DEBUG (Env): Episode done for env 75. Reward: 18.87, Length: 7
DEBUG (Env): Episode done for env 93. Reward: 26.02, Length: 21
DEBUG (Env): Episode done for env 104. Reward: 11.53, Length: 19
DEBUG (Env): Episode done for env 111. Reward: 16.49, Length: 2
DEBUG (Env): Episode done for env 112. Reward: 12.63, Length: 22
DEBUG (Env): Episode done for env 123. Reward: 27.50, Length: 2
1626
Time taken for simulation:  7.405206680297852
average overall reward:  1.3902087  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.20594473 average distance reward:  0.5610378  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: 17.58, Length: 29
DEBUG (Env): Episode done for env 55. Reward: 24.28, Length: 2
DEBUG (Env): Episode done for env 57. Reward: 26.08, Length: 3
DEBUG (Env): Episode done for env 73. Reward: 32.43, Length: 2
DEBUG (Env): Episode done for env 86. Reward: 47.63, Length: 18
DEBUG (Env): Episode done for env 89. Reward: 26.09, Length: 15
DEBUG (Env): Episode done for env 101. Reward: 24.83, Length: 3
DEBUG (Env): Episode done for env 113. Reward: 25.33, Length: 16
1627
Time taken for simulation:  7.074709892272949
average overall reward:  0.14423707  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.120008245  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 14.20, Length: 20
DEBUG (Env): Episode done for env 43. Reward: 8.37, Length: 27
DEBUG (Env): Episode done for env 70. Reward: 27.35, Length: 10
DEBUG (Env): Episode done for env 107. Reward: -9.00, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 24.86, Length: 7
1628
Time taken for simulation:  7.472623586654663
average overall reward:  -0.2124012  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.008478299  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 16. Reward: -25.13, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 19.50, Length: 6
DEBUG (Env): Episode done for env 108. Reward: -16.67, Length: 36
1629
Time taken for simulation:  7.201731204986572
average overall reward:  0.6759219  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168783 average distance reward:  0.101616114  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 3. Reward: 23.37, Length: 16
DEBUG (Env): Episode done for env 7. Reward: 39.28, Length: 8
DEBUG (Env): Episode done for env 11. Reward: -21.31, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -22.59, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 14.74, Length: 6
DEBUG (Env): Episode done for env 60. Reward: 18.51, Length: 17
DEBUG (Env): Episode done for env 64. Reward: 17.03, Length: 23
DEBUG (Env): Episode done for env 89. Reward: 14.47, Length: 3
DEBUG (Env): Episode done for env 103. Reward: -29.26, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 21.51, Length: 4
DEBUG (Env): Episode done for env 125. Reward: -15.92, Length: 36
1630
Time taken for simulation:  7.114015340805054
average overall reward:  1.3825766  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.21881628 average distance reward:  0.566277  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: 3.30, Length: 32
DEBUG (Env): Episode done for env 6. Reward: 20.15, Length: 7
DEBUG (Env): Episode done for env 27. Reward: 30.07, Length: 8
DEBUG (Env): Episode done for env 74. Reward: 21.70, Length: 14
DEBUG (Env): Episode done for env 93. Reward: 34.44, Length: 5
DEBUG (Env): Episode done for env 104. Reward: 18.11, Length: 5
DEBUG (Env): Episode done for env 112. Reward: 18.01, Length: 1
DEBUG (Env): Episode done for env 119. Reward: 2.69, Length: 34
1631
Time taken for simulation:  7.306509494781494
average overall reward:  0.1723567  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.0147328675  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 4. Reward: 19.24, Length: 1
DEBUG (Env): Episode done for env 25. Reward: -8.85, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 32.06, Length: 2
DEBUG (Env): Episode done for env 44. Reward: -15.33, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 22.37, Length: 5
DEBUG (Env): Episode done for env 67. Reward: -25.53, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -14.42, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -8.91, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 17.21, Length: 1
1632
Time taken for simulation:  7.109767436981201
average overall reward:  0.65031576  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  0.2226497  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 53. Reward: 2.93, Length: 34
DEBUG (Env): Episode done for env 59. Reward: -23.15, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 48.79, Length: 14
DEBUG (Env): Episode done for env 90. Reward: -21.00, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 25.55, Length: 2
DEBUG (Env): Episode done for env 116. Reward: 11.64, Length: 17
DEBUG (Env): Episode done for env 124. Reward: 22.93, Length: 14
1633
Time taken for simulation:  7.264813184738159
average overall reward:  0.41771373  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1930732 average distance reward:  0.18747188  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: 21.96, Length: 22
DEBUG (Env): Episode done for env 21. Reward: -35.42, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -16.78, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -17.40, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 3.29, Length: 31
DEBUG (Env): Episode done for env 101. Reward: 16.79, Length: 7
DEBUG (Env): Episode done for env 119. Reward: 23.31, Length: 2
1634
Time taken for simulation:  7.072558879852295
average overall reward:  0.68904424  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.29838914  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 47. Reward: 22.55, Length: 31
DEBUG (Env): Episode done for env 48. Reward: 16.09, Length: 18
DEBUG (Env): Episode done for env 51. Reward: 12.51, Length: 13
DEBUG (Env): Episode done for env 61. Reward: 24.93, Length: 30
1635
Time taken for simulation:  7.305605173110962
average overall reward:  0.8988188  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.27533236  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 24. Reward: -16.78, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -22.98, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -16.64, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 33.14, Length: 11
DEBUG (Env): Episode done for env 73. Reward: 0.06, Length: 9
DEBUG (Env): Episode done for env 82. Reward: 19.34, Length: 16
DEBUG (Env): Episode done for env 96. Reward: 17.86, Length: 31
DEBUG (Env): Episode done for env 103. Reward: 20.77, Length: 6
DEBUG (Env): Episode done for env 112. Reward: 21.07, Length: 3
DEBUG (Env): Episode done for env 121. Reward: 10.63, Length: 16
1636
Time taken for simulation:  7.556817293167114
average overall reward:  0.23896417  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  -0.06389581  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: -14.70, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 11.71, Length: 19
DEBUG (Env): Episode done for env 49. Reward: 20.00, Length: 21
DEBUG (Env): Episode done for env 60. Reward: 37.34, Length: 7
DEBUG (Env): Episode done for env 89. Reward: 25.17, Length: 7
1637
Time taken for simulation:  7.335407257080078
average overall reward:  0.56086653  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.23226349  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 55. Reward: 25.33, Length: 11
DEBUG (Env): Episode done for env 58. Reward: -28.32, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 18.41, Length: 18
DEBUG (Env): Episode done for env 95. Reward: 7.47, Length: 23
DEBUG (Env): Episode done for env 127. Reward: 26.05, Length: 10
1638
Time taken for simulation:  7.420001268386841
average overall reward:  0.10572505  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.058431976  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 22. Reward: 22.61, Length: 35
DEBUG (Env): Episode done for env 26. Reward: -33.77, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -12.21, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 22.70, Length: 17
1639
Time taken for simulation:  7.106400489807129
average overall reward:  -0.20677012  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1930732 average distance reward:  -0.05433342  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 81. Reward: -22.91, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -9.14, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 16.79, Length: 14
1640
Time taken for simulation:  7.292969703674316
average overall reward:  0.6002018  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.14909822  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 18. Reward: -17.38, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 13.25, Length: 18
DEBUG (Env): Episode done for env 32. Reward: 8.00, Length: 23
DEBUG (Env): Episode done for env 46. Reward: 4.84, Length: 33
DEBUG (Env): Episode done for env 82. Reward: 32.91, Length: 5
DEBUG (Env): Episode done for env 116. Reward: 16.32, Length: 8
1641
Time taken for simulation:  7.03189754486084
average overall reward:  0.5401502  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.46276313  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 26. Reward: 22.11, Length: 3
DEBUG (Env): Episode done for env 64. Reward: 22.12, Length: 12
DEBUG (Env): Episode done for env 109. Reward: -15.30, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 24.43, Length: 26
1642
Time taken for simulation:  7.365347146987915
average overall reward:  0.6465766  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.18020163 average distance reward:  0.020784587  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 4. Reward: 19.98, Length: 11
DEBUG (Env): Episode done for env 7. Reward: 21.62, Length: 13
DEBUG (Env): Episode done for env 15. Reward: -18.16, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 17.56, Length: 9
DEBUG (Env): Episode done for env 47. Reward: 19.48, Length: 8
DEBUG (Env): Episode done for env 50. Reward: 27.28, Length: 13
DEBUG (Env): Episode done for env 52. Reward: -16.77, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -21.26, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 15.65, Length: 7
DEBUG (Env): Episode done for env 98. Reward: -21.73, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 38.41, Length: 18
1643
Time taken for simulation:  7.118393898010254
average overall reward:  -0.4136938  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.11584391 average distance reward:  -0.45042092  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: 7.06, Length: 33
DEBUG (Env): Episode done for env 56. Reward: -18.34, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -18.16, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -23.44, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 35.72, Length: 35
1644
Time taken for simulation:  7.20123291015625
average overall reward:  0.17054605  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.077981815  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: -16.46, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 23.58, Length: 2
DEBUG (Env): Episode done for env 72. Reward: -22.92, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 25.46, Length: 19
DEBUG (Env): Episode done for env 127. Reward: 21.83, Length: 7
1645
Time taken for simulation:  7.154375791549683
average overall reward:  -0.1342627  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.07032303  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 54. Reward: 21.09, Length: 3
DEBUG (Env): Episode done for env 77. Reward: -20.05, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -19.41, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -10.95, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 28.16, Length: 3
DEBUG (Env): Episode done for env 100. Reward: -17.60, Length: 36
1646
Time taken for simulation:  7.399750232696533
average overall reward:  -0.35372922  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.20594472 average distance reward:  -0.053048924  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 29. Reward: -26.05, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -11.42, Length: 36
1647
Time taken for simulation:  7.522967576980591
average overall reward:  0.30934832  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.30528113  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 20. Reward: 22.98, Length: 11
DEBUG (Env): Episode done for env 113. Reward: 24.34, Length: 21
1648
Time taken for simulation:  7.516793251037598
average overall reward:  -0.04453075  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.109046325  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: -10.22, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 20.84, Length: 15
DEBUG (Env): Episode done for env 59. Reward: 16.91, Length: 16
DEBUG (Env): Episode done for env 105. Reward: 43.37, Length: 10
1649
Time taken for simulation:  7.025739431381226
average overall reward:  0.6913184  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.1517179  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 19. Reward: -8.35, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 34.67, Length: 9
DEBUG (Env): Episode done for env 30. Reward: -10.87, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -14.66, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 31.30, Length: 25
DEBUG (Env): Episode done for env 46. Reward: 23.66, Length: 9
DEBUG (Env): Episode done for env 65. Reward: 23.39, Length: 6
DEBUG (Env): Episode done for env 102. Reward: 10.83, Length: 33
DEBUG (Env): Episode done for env 121. Reward: 12.72, Length: 14
1650
Time taken for simulation:  7.108575344085693
average overall reward:  0.1220796  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.1625818  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 29. Reward: 25.17, Length: 4
DEBUG (Env): Episode done for env 37. Reward: 31.93, Length: 6
DEBUG (Env): Episode done for env 66. Reward: -21.49, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -11.14, Length: 36
1651
Time taken for simulation:  7.132709503173828
average overall reward:  0.22486722  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455938 average distance reward:  0.3402931  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 35. Reward: -32.08, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -26.65, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 20.47, Length: 14
DEBUG (Env): Episode done for env 85. Reward: -22.19, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -22.28, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 30.64, Length: 21
1652
Time taken for simulation:  7.3683249950408936
average overall reward:  0.7492031  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.21881628 average distance reward:  0.09171311  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 15. Reward: 24.93, Length: 10
DEBUG (Env): Episode done for env 22. Reward: 26.05, Length: 14
DEBUG (Env): Episode done for env 45. Reward: 22.81, Length: 1
DEBUG (Env): Episode done for env 56. Reward: 29.15, Length: 9
DEBUG (Env): Episode done for env 82. Reward: 23.81, Length: 12
DEBUG (Env): Episode done for env 90. Reward: 10.46, Length: 20
DEBUG (Env): Episode done for env 94. Reward: -3.56, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 22.89, Length: 17
1653
Time taken for simulation:  7.279626369476318
average overall reward:  0.5952694  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.2818435  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 17. Reward: 9.99, Length: 17
DEBUG (Env): Episode done for env 43. Reward: 9.20, Length: 26
DEBUG (Env): Episode done for env 60. Reward: 18.50, Length: 17
DEBUG (Env): Episode done for env 68. Reward: 15.83, Length: 18
1654
Time taken for simulation:  7.3735716342926025
average overall reward:  1.0285985  average fail penalty:  -0.046875  and average goal bonus:  1.2183483  and average same cell penalty:  -0.18020165 average distance reward:  0.085187405  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 14. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 31.73, Length: 2
DEBUG (Env): Episode done for env 31. Reward: 16.86, Length: 5
DEBUG (Env): Episode done for env 40. Reward: 10.26, Length: 23
DEBUG (Env): Episode done for env 52. Reward: 30.42, Length: 12
DEBUG (Env): Episode done for env 59. Reward: 33.88, Length: 6
DEBUG (Env): Episode done for env 94. Reward: 18.32, Length: 2
DEBUG (Env): Episode done for env 110. Reward: -13.15, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 10.22, Length: 14
DEBUG (Env): Episode done for env 120. Reward: 29.13, Length: 4
DEBUG (Env): Episode done for env 126. Reward: 10.40, Length: 31
1655
Time taken for simulation:  7.040437698364258
average overall reward:  0.1515215  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  -0.031143578  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: 19.00, Length: 13
DEBUG (Env): Episode done for env 36. Reward: 12.57, Length: 30
DEBUG (Env): Episode done for env 63. Reward: -11.14, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -9.45, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 24.03, Length: 10
1656
Time taken for simulation:  7.432725667953491
average overall reward:  0.16080603  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030244 average distance reward:  0.20822495  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 64. Reward: 45.52, Length: 15
DEBUG (Env): Episode done for env 76. Reward: 19.44, Length: 6
1657
Time taken for simulation:  7.1373069286346436
average overall reward:  0.103057116  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.03854142  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: -18.86, Length: 36
DEBUG (Env): Episode done for env 2. Reward: 17.50, Length: 9
DEBUG (Env): Episode done for env 20. Reward: 36.78, Length: 10
DEBUG (Env): Episode done for env 119. Reward: 11.66, Length: 24
1658
Time taken for simulation:  7.2330849170684814
average overall reward:  -0.24538729  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.1170899  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 23. Reward: -16.33, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -20.05, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 20.68, Length: 2
DEBUG (Env): Episode done for env 82. Reward: 37.73, Length: 6
DEBUG (Env): Episode done for env 91. Reward: -6.77, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -11.02, Length: 36
1659
Time taken for simulation:  7.2090442180633545
average overall reward:  0.17738909  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.27007926  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 104. Reward: 6.56, Length: 29
1660
Time taken for simulation:  7.276177644729614
average overall reward:  -0.02027246  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  0.15790734  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 1. Reward: 9.59, Length: 33
DEBUG (Env): Episode done for env 5. Reward: -17.77, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -18.65, Length: 36
1661
Time taken for simulation:  7.354463577270508
average overall reward:  0.9497032  average fail penalty:  -0.0703125  and average goal bonus:  1.2183483  and average same cell penalty:  -0.27030247 average distance reward:  0.119830385  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 10. Reward: -23.65, Length: 36
DEBUG (Env): Episode done for env 13. Reward: -24.85, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 1.65, Length: 30
DEBUG (Env): Episode done for env 30. Reward: 19.19, Length: 12
DEBUG (Env): Episode done for env 67. Reward: 0.10, Length: 30
DEBUG (Env): Episode done for env 79. Reward: 19.43, Length: 6
DEBUG (Env): Episode done for env 89. Reward: 25.02, Length: 25
DEBUG (Env): Episode done for env 92. Reward: 4.15, Length: 33
DEBUG (Env): Episode done for env 94. Reward: 23.82, Length: 7
DEBUG (Env): Episode done for env 104. Reward: 26.75, Length: 2
DEBUG (Env): Episode done for env 107. Reward: -0.25, Length: 34
DEBUG (Env): Episode done for env 111. Reward: -23.07, Length: 36
1662
Time taken for simulation:  7.107740879058838
average overall reward:  1.1974304  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.2574309 average distance reward:  0.73736465  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: -30.90, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 24.96, Length: 17
DEBUG (Env): Episode done for env 86. Reward: -20.55, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 22.08, Length: 1
DEBUG (Env): Episode done for env 101. Reward: 19.09, Length: 29
DEBUG (Env): Episode done for env 111. Reward: 19.80, Length: 1
DEBUG (Env): Episode done for env 121. Reward: 43.52, Length: 13
DEBUG (Env): Episode done for env 127. Reward: 22.32, Length: 18
1663
Time taken for simulation:  7.303733587265015
average overall reward:  0.45502368  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.094020985  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 70. Reward: -23.64, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 15.08, Length: 18
DEBUG (Env): Episode done for env 79. Reward: 4.60, Length: 2
DEBUG (Env): Episode done for env 88. Reward: 31.14, Length: 24
DEBUG (Env): Episode done for env 117. Reward: 10.23, Length: 32
DEBUG (Env): Episode done for env 122. Reward: 37.52, Length: 25
1664
Time taken for simulation:  6.973069429397583
average overall reward:  0.92350775  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.16733009 average distance reward:  0.23796919  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 16. Reward: -25.64, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 28.12, Length: 20
DEBUG (Env): Episode done for env 49. Reward: 6.01, Length: 28
DEBUG (Env): Episode done for env 71. Reward: 22.52, Length: 18
DEBUG (Env): Episode done for env 90. Reward: 15.98, Length: 12
DEBUG (Env): Episode done for env 96. Reward: 40.31, Length: 12
DEBUG (Env): Episode done for env 98. Reward: 14.51, Length: 9
DEBUG (Env): Episode done for env 108. Reward: -6.49, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 29.51, Length: 10
1665
Time taken for simulation:  7.13282585144043
average overall reward:  0.050383113  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.03161515  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: -15.24, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -12.40, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 35.41, Length: 22
DEBUG (Env): Episode done for env 84. Reward: 21.80, Length: 5
DEBUG (Env): Episode done for env 125. Reward: -13.65, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 40.32, Length: 3
1666
Time taken for simulation:  7.396316289901733
average overall reward:  0.38566244  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.1039344  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 22.37, Length: 1
DEBUG (Env): Episode done for env 6. Reward: -17.54, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -20.82, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 7.93, Length: 26
DEBUG (Env): Episode done for env 33. Reward: 20.50, Length: 18
DEBUG (Env): Episode done for env 48. Reward: 15.36, Length: 32
DEBUG (Env): Episode done for env 74. Reward: -21.42, Length: 36
1667
Time taken for simulation:  7.232649087905884
average overall reward:  0.5983957  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.278053  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: 25.67, Length: 7
DEBUG (Env): Episode done for env 4. Reward: 17.57, Length: 25
DEBUG (Env): Episode done for env 44. Reward: -21.04, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 20.56, Length: 1
DEBUG (Env): Episode done for env 57. Reward: -12.14, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 19.54, Length: 4
DEBUG (Env): Episode done for env 83. Reward: -28.82, Length: 36
1668
Time taken for simulation:  7.1339192390441895
average overall reward:  0.45565405  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.2254122  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 17. Reward: 44.56, Length: 15
DEBUG (Env): Episode done for env 34. Reward: 28.30, Length: 4
DEBUG (Env): Episode done for env 53. Reward: -23.43, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 38.03, Length: 13
DEBUG (Env): Episode done for env 69. Reward: -9.86, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 23.19, Length: 6
DEBUG (Env): Episode done for env 124. Reward: -19.17, Length: 36
1669
Time taken for simulation:  7.260499954223633
average overall reward:  0.3645155  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.20528795  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: -19.17, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -7.42, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 29.19, Length: 8
DEBUG (Env): Episode done for env 75. Reward: 13.20, Length: 25
DEBUG (Env): Episode done for env 99. Reward: -29.70, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 30.91, Length: 15
1670
Time taken for simulation:  7.033212661743164
average overall reward:  0.38743287  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.24338242  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 47. Reward: 5.18, Length: 28
DEBUG (Env): Episode done for env 51. Reward: -19.02, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 28.17, Length: 8
DEBUG (Env): Episode done for env 61. Reward: -11.94, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 29.36, Length: 7
1671
Time taken for simulation:  7.2332444190979
average overall reward:  -0.19046052  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  -0.26419848  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 11. Reward: 21.83, Length: 6
DEBUG (Env): Episode done for env 24. Reward: -11.95, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -22.43, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -15.46, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 24.18, Length: 3
DEBUG (Env): Episode done for env 63. Reward: 18.85, Length: 3
DEBUG (Env): Episode done for env 103. Reward: -27.73, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -11.97, Length: 36
1672
Time taken for simulation:  7.440816164016724
average overall reward:  0.8447861  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.5313602  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 20. Reward: 26.01, Length: 15
DEBUG (Env): Episode done for env 34. Reward: 29.61, Length: 4
DEBUG (Env): Episode done for env 101. Reward: 33.55, Length: 10
DEBUG (Env): Episode done for env 124. Reward: 20.80, Length: 4
1673
Time taken for simulation:  7.5659849643707275
average overall reward:  0.014864154  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  -0.10574882  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: 29.86, Length: 5
DEBUG (Env): Episode done for env 55. Reward: -16.78, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -11.55, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 37.11, Length: 5
DEBUG (Env): Episode done for env 91. Reward: 33.77, Length: 15
DEBUG (Env): Episode done for env 95. Reward: -9.98, Length: 36
1674
Time taken for simulation:  7.290054559707642
average overall reward:  0.121882565  average fail penalty:  0.0  and average goal bonus:  0.0  and average same cell penalty:  -0.141587 average distance reward:  0.31133008  and average step penalty:  -0.04786053509430681
Number of done instances:  0
1675
Time taken for simulation:  7.468397378921509
average overall reward:  0.23893046  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.24312362  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: 17.49, Length: 18
DEBUG (Env): Episode done for env 67. Reward: 17.95, Length: 6
DEBUG (Env): Episode done for env 81. Reward: -10.25, Length: 36
DEBUG (Env): Episode done for env 123. Reward: -15.79, Length: 36
1676
Time taken for simulation:  7.650233268737793
average overall reward:  0.3107329  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594475 average distance reward:  -0.08888454  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 18. Reward: -21.26, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 17.99, Length: 7
DEBUG (Env): Episode done for env 46. Reward: 17.27, Length: 27
DEBUG (Env): Episode done for env 60. Reward: 16.31, Length: 23
DEBUG (Env): Episode done for env 71. Reward: 49.62, Length: 12
DEBUG (Env): Episode done for env 78. Reward: 24.83, Length: 31
1677
Time taken for simulation:  7.161794185638428
average overall reward:  -0.12359293  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.15410505  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: 27.25, Length: 8
DEBUG (Env): Episode done for env 26. Reward: -44.70, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 27.30, Length: 24
DEBUG (Env): Episode done for env 82. Reward: 8.58, Length: 19
DEBUG (Env): Episode done for env 109. Reward: -28.25, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -11.72, Length: 36
1678
Time taken for simulation:  6.999318361282349
average overall reward:  0.4004938  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.33136714  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 4.40, Length: 35
DEBUG (Env): Episode done for env 33. Reward: 16.12, Length: 12
DEBUG (Env): Episode done for env 50. Reward: -2.03, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -19.11, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 19.75, Length: 22
DEBUG (Env): Episode done for env 115. Reward: -18.12, Length: 36
1679
Time taken for simulation:  7.479594469070435
average overall reward:  0.9874779  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.21881628 average distance reward:  0.32998797  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: 12.96, Length: 3
DEBUG (Env): Episode done for env 50. Reward: 24.50, Length: 1
DEBUG (Env): Episode done for env 51. Reward: 23.66, Length: 9
DEBUG (Env): Episode done for env 64. Reward: 37.47, Length: 21
DEBUG (Env): Episode done for env 90. Reward: 22.05, Length: 15
DEBUG (Env): Episode done for env 103. Reward: 38.51, Length: 8
DEBUG (Env): Episode done for env 105. Reward: 16.91, Length: 31
DEBUG (Env): Episode done for env 118. Reward: -7.65, Length: 36
1680
Time taken for simulation:  7.3246519565582275
average overall reward:  0.27743095  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.20004381  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 13. Reward: 19.53, Length: 19
DEBUG (Env): Episode done for env 63. Reward: 30.38, Length: 9
DEBUG (Env): Episode done for env 72. Reward: -6.69, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 37.68, Length: 13
1681
Time taken for simulation:  6.9478583335876465
average overall reward:  1.3315471  average fail penalty:  -0.046875  and average goal bonus:  1.0829762  and average same cell penalty:  -0.18020165 average distance reward:  0.5235082  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 15. Reward: 19.73, Length: 27
DEBUG (Env): Episode done for env 20. Reward: 29.48, Length: 9
DEBUG (Env): Episode done for env 21. Reward: 15.98, Length: 5
DEBUG (Env): Episode done for env 49. Reward: 13.34, Length: 17
DEBUG (Env): Episode done for env 79. Reward: 21.58, Length: 1
DEBUG (Env): Episode done for env 97. Reward: -20.78, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -24.27, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 24.33, Length: 3
DEBUG (Env): Episode done for env 120. Reward: 17.48, Length: 27
DEBUG (Env): Episode done for env 121. Reward: 29.68, Length: 13
1682
Time taken for simulation:  7.199975967407227
average overall reward:  0.28955323  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.0110011585  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 20. Reward: 14.95, Length: 1
DEBUG (Env): Episode done for env 54. Reward: 19.25, Length: 12
DEBUG (Env): Episode done for env 104. Reward: 6.50, Length: 21
DEBUG (Env): Episode done for env 117. Reward: 20.80, Length: 19
1683
Time taken for simulation:  7.244626998901367
average overall reward:  0.028392285  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  -0.21011001  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 27. Reward: 16.31, Length: 17
DEBUG (Env): Episode done for env 55. Reward: 28.94, Length: 10
DEBUG (Env): Episode done for env 77. Reward: 20.16, Length: 20
DEBUG (Env): Episode done for env 91. Reward: 17.61, Length: 10
DEBUG (Env): Episode done for env 113. Reward: -19.16, Length: 36
1684
Time taken for simulation:  7.112836122512817
average overall reward:  1.174956  average fail penalty:  0.0  and average goal bonus:  1.2183483  and average same cell penalty:  -0.21881628 average distance reward:  0.22328457  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: 24.63, Length: 18
DEBUG (Env): Episode done for env 12. Reward: 32.64, Length: 6
DEBUG (Env): Episode done for env 37. Reward: 4.36, Length: 34
DEBUG (Env): Episode done for env 49. Reward: 18.26, Length: 3
DEBUG (Env): Episode done for env 65. Reward: -4.03, Length: 35
DEBUG (Env): Episode done for env 81. Reward: 29.28, Length: 9
DEBUG (Env): Episode done for env 94. Reward: 27.96, Length: 23
DEBUG (Env): Episode done for env 111. Reward: 8.12, Length: 22
DEBUG (Env): Episode done for env 117. Reward: 20.21, Length: 2
1685
Time taken for simulation:  7.0617146492004395
average overall reward:  0.19933486  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.018273517  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 19. Reward: -15.36, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -19.88, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 1.03, Length: 34
DEBUG (Env): Episode done for env 37. Reward: 13.26, Length: 1
DEBUG (Env): Episode done for env 38. Reward: -13.51, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 42.40, Length: 18
DEBUG (Env): Episode done for env 61. Reward: 22.49, Length: 15
DEBUG (Env): Episode done for env 102. Reward: -15.77, Length: 36
1686
Time taken for simulation:  7.16211724281311
average overall reward:  0.92776906  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  0.5515892  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 39.27, Length: 25
DEBUG (Env): Episode done for env 29. Reward: -15.58, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 29.30, Length: 19
DEBUG (Env): Episode done for env 66. Reward: -20.59, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 11.68, Length: 23
DEBUG (Env): Episode done for env 99. Reward: 14.17, Length: 17
DEBUG (Env): Episode done for env 103. Reward: 21.64, Length: 7
1687
Time taken for simulation:  7.75832724571228
average overall reward:  0.055032283  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.11897197  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 39. Reward: 14.12, Length: 16
DEBUG (Env): Episode done for env 62. Reward: -23.41, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -18.10, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -22.83, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 34.05, Length: 8
DEBUG (Env): Episode done for env 93. Reward: -29.70, Length: 36
1688
Time taken for simulation:  7.271408796310425
average overall reward:  0.6262773  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.15445855 average distance reward:  -0.04869528  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 1. Reward: 4.04, Length: 21
DEBUG (Env): Episode done for env 22. Reward: 4.19, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 26.87, Length: 11
DEBUG (Env): Episode done for env 45. Reward: -22.49, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 19.16, Length: 17
DEBUG (Env): Episode done for env 56. Reward: -24.39, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 5.03, Length: 21
DEBUG (Env): Episode done for env 62. Reward: 15.38, Length: 1
DEBUG (Env): Episode done for env 66. Reward: 15.97, Length: 2
1689
Time taken for simulation:  7.154932975769043
average overall reward:  0.7391473  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.5006451  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 46.18, Length: 22
DEBUG (Env): Episode done for env 17. Reward: 24.78, Length: 16
DEBUG (Env): Episode done for env 21. Reward: 17.34, Length: 8
DEBUG (Env): Episode done for env 27. Reward: 40.25, Length: 6
DEBUG (Env): Episode done for env 43. Reward: -20.94, Length: 36
1690
Time taken for simulation:  7.172183990478516
average overall reward:  -0.014081791  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  0.17396215  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: -29.65, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -16.68, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 52. Reward: -14.32, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -17.98, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 6.05, Length: 13
DEBUG (Env): Episode done for env 78. Reward: 34.08, Length: 14
DEBUG (Env): Episode done for env 126. Reward: -20.67, Length: 36
1691
Time taken for simulation:  7.434866905212402
average overall reward:  0.542489  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  0.34695238  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: 28.18, Length: 7
DEBUG (Env): Episode done for env 7. Reward: -22.00, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -17.14, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 23.89, Length: 10
DEBUG (Env): Episode done for env 121. Reward: 28.22, Length: 10
1692
Time taken for simulation:  7.161449909210205
average overall reward:  0.8691551  average fail penalty:  0.0  and average goal bonus:  1.0829761  and average same cell penalty:  -0.21881628 average distance reward:  0.052855667  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: 15.83, Length: 13
DEBUG (Env): Episode done for env 53. Reward: 28.93, Length: 4
DEBUG (Env): Episode done for env 65. Reward: 24.03, Length: 8
DEBUG (Env): Episode done for env 66. Reward: 16.37, Length: 4
DEBUG (Env): Episode done for env 77. Reward: 27.42, Length: 9
DEBUG (Env): Episode done for env 80. Reward: 18.08, Length: 27
DEBUG (Env): Episode done for env 110. Reward: 14.85, Length: 23
DEBUG (Env): Episode done for env 112. Reward: 30.43, Length: 21
1693
Time taken for simulation:  7.508652210235596
average overall reward:  -0.11100724  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  0.08004407  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 0. Reward: -24.84, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 15.31, Length: 13
DEBUG (Env): Episode done for env 119. Reward: -18.28, Length: 36
1694
Time taken for simulation:  7.345675706863403
average overall reward:  1.1547238  average fail penalty:  -0.0703125  and average goal bonus:  1.2183483  and average same cell penalty:  -0.12871546 average distance reward:  0.18326396  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 14. Reward: 23.08, Length: 4
DEBUG (Env): Episode done for env 20. Reward: 34.39, Length: 12
DEBUG (Env): Episode done for env 23. Reward: -31.22, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -14.74, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 28.09, Length: 19
DEBUG (Env): Episode done for env 87. Reward: 26.59, Length: 7
DEBUG (Env): Episode done for env 91. Reward: 21.35, Length: 11
DEBUG (Env): Episode done for env 93. Reward: 27.11, Length: 7
DEBUG (Env): Episode done for env 98. Reward: 7.64, Length: 30
DEBUG (Env): Episode done for env 106. Reward: -33.23, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 35.04, Length: 13
DEBUG (Env): Episode done for env 123. Reward: 29.71, Length: 19
1695
Time taken for simulation:  7.049340009689331
average overall reward:  0.28701162  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.29604557 average distance reward:  0.0894296  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 29. Reward: 29.39, Length: 9
DEBUG (Env): Episode done for env 62. Reward: 13.52, Length: 7
DEBUG (Env): Episode done for env 78. Reward: 18.20, Length: 5
DEBUG (Env): Episode done for env 92. Reward: 22.66, Length: 34
1696
Time taken for simulation:  7.363818168640137
average overall reward:  0.25159046  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594475 average distance reward:  0.12271722  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: -9.84, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 20.53, Length: 19
DEBUG (Env): Episode done for env 85. Reward: 32.43, Length: 9
DEBUG (Env): Episode done for env 96. Reward: 10.65, Length: 32
1697
Time taken for simulation:  7.28170919418335
average overall reward:  0.3999006  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.102972366 average distance reward:  0.21492991  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 25. Reward: -25.81, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 30.30, Length: 9
DEBUG (Env): Episode done for env 30. Reward: -21.75, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 18.83, Length: 12
DEBUG (Env): Episode done for env 105. Reward: 7.36, Length: 18
DEBUG (Env): Episode done for env 107. Reward: -6.06, Length: 36
1698
Time taken for simulation:  7.392995119094849
average overall reward:  -0.24635398  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.057608277  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 8. Reward: -24.99, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 21.15, Length: 6
DEBUG (Env): Episode done for env 86. Reward: -18.89, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -14.82, Length: 36
1699
Time taken for simulation:  7.270221948623657
average overall reward:  0.59126437  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.191647  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 14.28, Length: 24
DEBUG (Env): Episode done for env 20. Reward: 25.38, Length: 5
DEBUG (Env): Episode done for env 67. Reward: 26.48, Length: 5
DEBUG (Env): Episode done for env 69. Reward: 36.63, Length: 26
DEBUG (Env): Episode done for env 70. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 7.41, Length: 19
1700
Time taken for simulation:  7.406680583953857
average overall reward:  0.41451222  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.24455938 average distance reward:  0.1003845  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 16. Reward: -18.20, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 8.11, Length: 24
DEBUG (Env): Episode done for env 47. Reward: 2.59, Length: 30
DEBUG (Env): Episode done for env 62. Reward: 13.99, Length: 5
DEBUG (Env): Episode done for env 108. Reward: -11.69, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 23.28, Length: 8
DEBUG (Env): Episode done for env 116. Reward: -25.37, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 16.45, Length: 10
1701
Time taken for simulation:  7.3468122482299805
average overall reward:  0.93762606  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.16733009 average distance reward:  0.27552503  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 5. Reward: 26.79, Length: 5
DEBUG (Env): Episode done for env 26. Reward: 29.77, Length: 4
DEBUG (Env): Episode done for env 56. Reward: 32.34, Length: 13
DEBUG (Env): Episode done for env 84. Reward: -11.99, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 13.69, Length: 6
DEBUG (Env): Episode done for env 109. Reward: 11.43, Length: 24
DEBUG (Env): Episode done for env 113. Reward: 15.24, Length: 18
DEBUG (Env): Episode done for env 114. Reward: 21.70, Length: 24
DEBUG (Env): Episode done for env 125. Reward: -14.51, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -29.39, Length: 36
1702
Time taken for simulation:  7.123647928237915
average overall reward:  1.0615155  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.090100825 average distance reward:  0.72830117  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: -19.93, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 24.17, Length: 8
DEBUG (Env): Episode done for env 15. Reward: 23.28, Length: 21
DEBUG (Env): Episode done for env 32. Reward: -11.88, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -17.98, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 20.17, Length: 7
DEBUG (Env): Episode done for env 96. Reward: 33.42, Length: 6
1703
Time taken for simulation:  7.026201963424683
average overall reward:  0.7998541  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.16733009 average distance reward:  0.22625007  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 58. Reward: 6.73, Length: 30
DEBUG (Env): Episode done for env 66. Reward: 22.64, Length: 11
DEBUG (Env): Episode done for env 76. Reward: 19.43, Length: 25
DEBUG (Env): Episode done for env 83. Reward: -10.21, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 10.75, Length: 30
DEBUG (Env): Episode done for env 112. Reward: 27.81, Length: 11
DEBUG (Env): Episode done for env 117. Reward: 14.73, Length: 19
1704
Time taken for simulation:  7.318843364715576
average overall reward:  1.0193993  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.141587 average distance reward:  0.1258705  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: 28.37, Length: 6
DEBUG (Env): Episode done for env 61. Reward: 28.53, Length: 7
DEBUG (Env): Episode done for env 66. Reward: 23.65, Length: 1
DEBUG (Env): Episode done for env 76. Reward: 18.64, Length: 1
DEBUG (Env): Episode done for env 79. Reward: 47.51, Length: 13
DEBUG (Env): Episode done for env 108. Reward: 17.31, Length: 4
DEBUG (Env): Episode done for env 113. Reward: 38.33, Length: 3
DEBUG (Env): Episode done for env 117. Reward: 15.84, Length: 1
1705
Time taken for simulation:  7.333123683929443
average overall reward:  0.5589278  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168781 average distance reward:  0.049681433  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 22.23, Length: 16
DEBUG (Env): Episode done for env 41. Reward: 20.36, Length: 11
DEBUG (Env): Episode done for env 67. Reward: 13.94, Length: 6
DEBUG (Env): Episode done for env 74. Reward: 22.99, Length: 3
DEBUG (Env): Episode done for env 75. Reward: -16.92, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 3.39, Length: 33
DEBUG (Env): Episode done for env 110. Reward: 24.67, Length: 5
1706
Time taken for simulation:  7.01536750793457
average overall reward:  0.48867846  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.12871546 average distance reward:  0.01183182  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 51. Reward: 31.97, Length: 27
DEBUG (Env): Episode done for env 53. Reward: 11.72, Length: 14
DEBUG (Env): Episode done for env 85. Reward: 21.14, Length: 10
DEBUG (Env): Episode done for env 102. Reward: 18.38, Length: 21
DEBUG (Env): Episode done for env 107. Reward: 32.29, Length: 9
DEBUG (Env): Episode done for env 122. Reward: -23.71, Length: 36
1707
Time taken for simulation:  7.080806493759155
average overall reward:  0.17603202  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.15217644  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: 14.23, Length: 14
DEBUG (Env): Episode done for env 11. Reward: -16.85, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -15.55, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -31.02, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 16.74, Length: 16
1708
Time taken for simulation:  7.199387073516846
average overall reward:  0.20686965  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.04994765  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: -12.69, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 28.10, Length: 8
DEBUG (Env): Episode done for env 71. Reward: 7.92, Length: 32
DEBUG (Env): Episode done for env 94. Reward: 13.12, Length: 24
DEBUG (Env): Episode done for env 124. Reward: -20.48, Length: 36
1709
Time taken for simulation:  7.120906352996826
average overall reward:  0.5376751  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594473 average distance reward:  -0.020751804  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 18. Reward: 29.70, Length: 11
DEBUG (Env): Episode done for env 68. Reward: 25.96, Length: 19
DEBUG (Env): Episode done for env 80. Reward: 20.07, Length: 17
DEBUG (Env): Episode done for env 89. Reward: 26.54, Length: 11
DEBUG (Env): Episode done for env 99. Reward: 5.80, Length: 23
DEBUG (Env): Episode done for env 114. Reward: 44.84, Length: 8
1710
Time taken for simulation:  7.8043177127838135
average overall reward:  0.9542372  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.102972366 average distance reward:  0.42821008  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 52. Reward: 3.53, Length: 20
DEBUG (Env): Episode done for env 65. Reward: 13.49, Length: 18
DEBUG (Env): Episode done for env 84. Reward: 22.70, Length: 9
DEBUG (Env): Episode done for env 85. Reward: 21.98, Length: 4
DEBUG (Env): Episode done for env 100. Reward: 22.37, Length: 29
1711
Time taken for simulation:  7.009660720825195
average overall reward:  0.37080917  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.044511713  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 30. Reward: 21.97, Length: 14
DEBUG (Env): Episode done for env 57. Reward: 10.33, Length: 23
DEBUG (Env): Episode done for env 91. Reward: 22.42, Length: 17
DEBUG (Env): Episode done for env 113. Reward: 19.99, Length: 7
1712
Time taken for simulation:  7.094802141189575
average overall reward:  0.7820647  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455938 average distance reward:  0.28568995  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 14.87, Length: 13
DEBUG (Env): Episode done for env 12. Reward: 13.94, Length: 28
DEBUG (Env): Episode done for env 27. Reward: 28.83, Length: 23
DEBUG (Env): Episode done for env 38. Reward: 10.97, Length: 27
DEBUG (Env): Episode done for env 60. Reward: -22.80, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 16.19, Length: 4
DEBUG (Env): Episode done for env 125. Reward: 24.19, Length: 11
1713
Time taken for simulation:  7.043167352676392
average overall reward:  0.34602743  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.2557688  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: 10.01, Length: 22
DEBUG (Env): Episode done for env 41. Reward: 31.70, Length: 8
DEBUG (Env): Episode done for env 71. Reward: 26.25, Length: 5
DEBUG (Env): Episode done for env 82. Reward: -8.98, Length: 36
1714
Time taken for simulation:  7.6035706996917725
average overall reward:  -0.3459154  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  -0.2449649  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 33. Reward: -12.68, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -8.72, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 25.53, Length: 3
1715
Time taken for simulation:  7.421034812927246
average overall reward:  0.06862329  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.026246578  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 50. Reward: -12.87, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -21.18, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 20.44, Length: 11
DEBUG (Env): Episode done for env 88. Reward: 15.06, Length: 29
DEBUG (Env): Episode done for env 118. Reward: -20.33, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 20.51, Length: 3
1716
Time taken for simulation:  7.290038585662842
average overall reward:  0.52428347  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.29865277  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 19.35, Length: 31
DEBUG (Env): Episode done for env 63. Reward: -23.68, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 23.28, Length: 1
DEBUG (Env): Episode done for env 107. Reward: 54.74, Length: 10
DEBUG (Env): Episode done for env 117. Reward: 23.29, Length: 12
1717
Time taken for simulation:  7.086404323577881
average overall reward:  1.2890247  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.20594472 average distance reward:  0.5067287  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 34. Reward: 38.84, Length: 9
DEBUG (Env): Episode done for env 35. Reward: 15.58, Length: 32
DEBUG (Env): Episode done for env 82. Reward: 36.31, Length: 4
DEBUG (Env): Episode done for env 84. Reward: 36.22, Length: 7
DEBUG (Env): Episode done for env 88. Reward: 29.40, Length: 1
DEBUG (Env): Episode done for env 97. Reward: -26.99, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 38.52, Length: 14
DEBUG (Env): Episode done for env 115. Reward: -20.83, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 13.78, Length: 2
DEBUG (Env): Episode done for env 125. Reward: 23.87, Length: 2
1718
Time taken for simulation:  7.722738981246948
average overall reward:  0.11956403  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  -0.08262913  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 19.98, Length: 16
DEBUG (Env): Episode done for env 38. Reward: 45.35, Length: 6
DEBUG (Env): Episode done for env 54. Reward: -16.66, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -16.23, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 16.88, Length: 24
DEBUG (Env): Episode done for env 115. Reward: 24.52, Length: 1
1719
Time taken for simulation:  7.487005949020386
average overall reward:  -0.1956639  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.099064365  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 36. Reward: 11.87, Length: 28
DEBUG (Env): Episode done for env 55. Reward: -14.32, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 4.17, Length: 25
1720
Time taken for simulation:  7.260588884353638
average overall reward:  0.09622397  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  0.09145494  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 49. Reward: -17.78, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 5.77, Length: 30
DEBUG (Env): Episode done for env 81. Reward: -21.10, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 24.15, Length: 16
DEBUG (Env): Episode done for env 111. Reward: -10.68, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 13.95, Length: 20
1721
Time taken for simulation:  7.174997806549072
average overall reward:  0.026905358  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  0.13842183  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: -14.07, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -30.54, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -16.57, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -0.69, Length: 21
1722
Time taken for simulation:  7.37678337097168
average overall reward:  0.4603048  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.21719131  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 14.18, Length: 20
DEBUG (Env): Episode done for env 10. Reward: -16.10, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 14.09, Length: 22
DEBUG (Env): Episode done for env 48. Reward: -17.08, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 35.10, Length: 9
DEBUG (Env): Episode done for env 84. Reward: 26.76, Length: 5
DEBUG (Env): Episode done for env 103. Reward: -25.29, Length: 36
1723
Time taken for simulation:  7.220585584640503
average overall reward:  -0.26011157  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.12871546 average distance reward:  -0.1720326  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 39. Reward: 21.78, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -18.54, Length: 36
1724
Time taken for simulation:  7.282771110534668
average overall reward:  0.004727315  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  0.12911537  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: -12.32, Length: 36
DEBUG (Env): Episode done for env 22. Reward: -26.86, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -17.61, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 30.18, Length: 15
1725
Time taken for simulation:  7.136088609695435
average overall reward:  0.68549025  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.16733009 average distance reward:  0.15876125  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 8. Reward: 20.35, Length: 21
DEBUG (Env): Episode done for env 17. Reward: -16.86, Length: 36
DEBUG (Env): Episode done for env 21. Reward: -13.51, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 22.19, Length: 31
DEBUG (Env): Episode done for env 28. Reward: 14.66, Length: 4
DEBUG (Env): Episode done for env 30. Reward: 25.84, Length: 14
DEBUG (Env): Episode done for env 43. Reward: -25.55, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 20.53, Length: 21
DEBUG (Env): Episode done for env 81. Reward: 31.37, Length: 5
1726
Time taken for simulation:  7.482218980789185
average overall reward:  0.6875975  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  0.36290383  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 22. Reward: 28.32, Length: 2
DEBUG (Env): Episode done for env 31. Reward: -23.87, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 37.26, Length: 12
DEBUG (Env): Episode done for env 40. Reward: -18.82, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 19.99, Length: 16
DEBUG (Env): Episode done for env 65. Reward: 16.49, Length: 16
DEBUG (Env): Episode done for env 81. Reward: 12.09, Length: 1
1727
Time taken for simulation:  7.333626985549927
average overall reward:  0.4953413  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.2697106  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -13.79, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 36.01, Length: 5
DEBUG (Env): Episode done for env 104. Reward: 38.52, Length: 9
DEBUG (Env): Episode done for env 106. Reward: 26.02, Length: 9
DEBUG (Env): Episode done for env 111. Reward: 27.66, Length: 7
1728
Time taken for simulation:  7.391793489456177
average overall reward:  0.2455478  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.1748173  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 39. Reward: 18.63, Length: 5
DEBUG (Env): Episode done for env 77. Reward: -19.81, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 28.81, Length: 8
1729
Time taken for simulation:  7.220128536224365
average overall reward:  0.3326005  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594472 average distance reward:  0.22716467  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: -14.54, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 19.36, Length: 12
DEBUG (Env): Episode done for env 94. Reward: 29.79, Length: 17
DEBUG (Env): Episode done for env 119. Reward: -18.81, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 16.64, Length: 35
1730
Time taken for simulation:  7.1704628467559814
average overall reward:  0.6649962  average fail penalty:  -0.0703125  and average goal bonus:  1.0829762  and average same cell penalty:  -0.21881628 average distance reward:  -0.080990724  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 40. Reward: 32.04, Length: 4
DEBUG (Env): Episode done for env 65. Reward: 33.00, Length: 4
DEBUG (Env): Episode done for env 87. Reward: -16.64, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 37.59, Length: 13
DEBUG (Env): Episode done for env 93. Reward: -13.63, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 22.25, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 18.86, Length: 3
DEBUG (Env): Episode done for env 113. Reward: 18.03, Length: 19
DEBUG (Env): Episode done for env 118. Reward: 28.03, Length: 13
DEBUG (Env): Episode done for env 119. Reward: 12.07, Length: 1
1731
Time taken for simulation:  7.4209887981414795
average overall reward:  0.4200376  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.18153542  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: 24.12, Length: 18
DEBUG (Env): Episode done for env 19. Reward: 19.89, Length: 15
DEBUG (Env): Episode done for env 29. Reward: -19.14, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 18.84, Length: 31
DEBUG (Env): Episode done for env 82. Reward: 23.31, Length: 2
1732
Time taken for simulation:  7.256488561630249
average overall reward:  0.46813723  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.12666263  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 26.09, Length: 7
DEBUG (Env): Episode done for env 9. Reward: -9.36, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 20.66, Length: 14
DEBUG (Env): Episode done for env 107. Reward: 16.80, Length: 16
DEBUG (Env): Episode done for env 118. Reward: 28.43, Length: 2
1733
Time taken for simulation:  7.356208324432373
average overall reward:  0.13024291  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  -0.013807524  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: -12.05, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 17.35, Length: 8
DEBUG (Env): Episode done for env 105. Reward: -5.71, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 22.68, Length: 25
DEBUG (Env): Episode done for env 126. Reward: 21.53, Length: 13
1734
Time taken for simulation:  7.043500185012817
average overall reward:  -0.08231915  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.05007734  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: 23.90, Length: 9
DEBUG (Env): Episode done for env 60. Reward: 10.41, Length: 22
DEBUG (Env): Episode done for env 86. Reward: -8.63, Length: 36
1735
Time taken for simulation:  7.303775072097778
average overall reward:  0.7129784  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.6672892  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 20. Reward: -11.59, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 24.97, Length: 9
DEBUG (Env): Episode done for env 52. Reward: 21.99, Length: 9
DEBUG (Env): Episode done for env 69. Reward: -15.31, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -17.33, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -29.05, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 8.54, Length: 20
1736
Time taken for simulation:  7.405306339263916
average overall reward:  0.07280484  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.068940006  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 19. Reward: 43.25, Length: 5
DEBUG (Env): Episode done for env 23. Reward: 22.56, Length: 11
DEBUG (Env): Episode done for env 62. Reward: -9.38, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 12.55, Length: 31
1737
Time taken for simulation:  7.096494674682617
average overall reward:  -0.18536209  average fail penalty:  -0.140625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  -0.061675813  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: -16.10, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -17.73, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 30.97, Length: 16
DEBUG (Env): Episode done for env 56. Reward: -26.46, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -28.71, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 29.02, Length: 13
DEBUG (Env): Episode done for env 109. Reward: -18.87, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -18.35, Length: 36
1738
Time taken for simulation:  7.229099750518799
average overall reward:  -0.28356835  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.155271  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: -14.20, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -18.97, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 19.68, Length: 12
DEBUG (Env): Episode done for env 62. Reward: 1.53, Length: 2
DEBUG (Env): Episode done for env 78. Reward: -11.54, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -22.60, Length: 36
1739
Time taken for simulation:  7.31541109085083
average overall reward:  0.3190198  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.16600724  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 22. Reward: 31.13, Length: 13
DEBUG (Env): Episode done for env 54. Reward: 9.31, Length: 21
DEBUG (Env): Episode done for env 58. Reward: -15.59, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 21.86, Length: 34
DEBUG (Env): Episode done for env 83. Reward: -15.64, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 27.10, Length: 9
DEBUG (Env): Episode done for env 95. Reward: -27.99, Length: 36
1740
Time taken for simulation:  7.0237181186676025
average overall reward:  0.51421404  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  0.13803414  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 61. Reward: -21.66, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 24.36, Length: 2
DEBUG (Env): Episode done for env 66. Reward: -21.81, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 16.01, Length: 3
DEBUG (Env): Episode done for env 103. Reward: 8.27, Length: 18
DEBUG (Env): Episode done for env 117. Reward: 20.45, Length: 24
DEBUG (Env): Episode done for env 125. Reward: 30.86, Length: 23
1741
Time taken for simulation:  7.228776931762695
average overall reward:  0.5338451  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.30129772  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: -20.51, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 24.37, Length: 14
DEBUG (Env): Episode done for env 65. Reward: 26.33, Length: 11
DEBUG (Env): Episode done for env 67. Reward: -18.77, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 22.18, Length: 6
DEBUG (Env): Episode done for env 74. Reward: -20.01, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -12.24, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 26.35, Length: 11
1742
Time taken for simulation:  7.308297157287598
average overall reward:  0.27063882  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.13484873  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 51. Reward: -6.81, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -15.86, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 29.66, Length: 7
DEBUG (Env): Episode done for env 74. Reward: 24.22, Length: 1
DEBUG (Env): Episode done for env 79. Reward: 25.79, Length: 7
DEBUG (Env): Episode done for env 102. Reward: -18.58, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -13.88, Length: 36
1743
Time taken for simulation:  7.204530954360962
average overall reward:  0.31786597  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.011998635  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 0. Reward: -14.64, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -23.58, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -12.96, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 32.65, Length: 10
DEBUG (Env): Episode done for env 42. Reward: -8.00, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 35.40, Length: 8
DEBUG (Env): Episode done for env 67. Reward: 25.98, Length: 2
DEBUG (Env): Episode done for env 84. Reward: 26.41, Length: 21
DEBUG (Env): Episode done for env 113. Reward: 17.47, Length: 2
DEBUG (Env): Episode done for env 121. Reward: -26.96, Length: 36
1744
Time taken for simulation:  7.270673990249634
average overall reward:  0.057127126  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  0.17325482  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 46. Reward: -5.78, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 20.72, Length: 21
1745
Time taken for simulation:  7.480161428451538
average overall reward:  1.1134725  average fail penalty:  -0.1171875  and average goal bonus:  1.0829762  and average same cell penalty:  -0.20594472 average distance reward:  0.4014888  and average step penalty:  -0.04786053509430681
Number of done instances:  13
DEBUG (Env): Episode done for env 0. Reward: 20.25, Length: 2
DEBUG (Env): Episode done for env 18. Reward: -13.51, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 21.13, Length: 10
DEBUG (Env): Episode done for env 32. Reward: 21.13, Length: 7
DEBUG (Env): Episode done for env 39. Reward: 35.19, Length: 17
DEBUG (Env): Episode done for env 68. Reward: -18.71, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 19.51, Length: 20
DEBUG (Env): Episode done for env 80. Reward: -16.84, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 34.73, Length: 6
DEBUG (Env): Episode done for env 88. Reward: 30.89, Length: 15
DEBUG (Env): Episode done for env 89. Reward: -21.31, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 8.49, Length: 31
DEBUG (Env): Episode done for env 114. Reward: -13.67, Length: 36
1746
Time taken for simulation:  7.308678865432739
average overall reward:  0.6836231  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594475 average distance reward:  0.3074433  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: 51.73, Length: 14
DEBUG (Env): Episode done for env 34. Reward: 18.09, Length: 29
DEBUG (Env): Episode done for env 57. Reward: 21.86, Length: 35
DEBUG (Env): Episode done for env 62. Reward: 26.08, Length: 6
DEBUG (Env): Episode done for env 85. Reward: -18.06, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -21.55, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 29.33, Length: 28
1747
Time taken for simulation:  7.101813554763794
average overall reward:  0.6581745  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.102972366 average distance reward:  0.13214731  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: -5.90, Length: 35
DEBUG (Env): Episode done for env 51. Reward: 23.84, Length: 5
DEBUG (Env): Episode done for env 60. Reward: 19.34, Length: 13
DEBUG (Env): Episode done for env 82. Reward: 22.56, Length: 16
DEBUG (Env): Episode done for env 105. Reward: 12.65, Length: 14
1748
Time taken for simulation:  7.228126287460327
average overall reward:  0.9523724  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.3054484  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: -14.88, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 14.07, Length: 7
DEBUG (Env): Episode done for env 27. Reward: -18.30, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 8.90, Length: 23
DEBUG (Env): Episode done for env 56. Reward: 23.54, Length: 11
DEBUG (Env): Episode done for env 63. Reward: 12.24, Length: 32
DEBUG (Env): Episode done for env 67. Reward: 22.14, Length: 5
DEBUG (Env): Episode done for env 88. Reward: 19.66, Length: 3
DEBUG (Env): Episode done for env 90. Reward: 23.89, Length: 4
1749
Time taken for simulation:  7.185646057128906
average overall reward:  0.010353342  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  -0.021762583  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 41. Reward: -19.93, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 16.16, Length: 1
DEBUG (Env): Episode done for env 116. Reward: 11.49, Length: 28
1750
Time taken for simulation:  7.0885515213012695
average overall reward:  0.40309083  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.12597403  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: 30.21, Length: 5
DEBUG (Env): Episode done for env 57. Reward: 27.05, Length: 4
DEBUG (Env): Episode done for env 73. Reward: -22.11, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 18.36, Length: 20
DEBUG (Env): Episode done for env 127. Reward: 18.54, Length: 13
1751
Time taken for simulation:  7.114067792892456
average overall reward:  0.23615314  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.11784582  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 50. Reward: -26.01, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -10.95, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 16.58, Length: 6
DEBUG (Env): Episode done for env 100. Reward: 29.17, Length: 5
DEBUG (Env): Episode done for env 103. Reward: 25.11, Length: 11
1752
Time taken for simulation:  7.106026649475098
average overall reward:  0.7961721  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.3087595  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 31. Reward: 23.84, Length: 17
DEBUG (Env): Episode done for env 45. Reward: 6.61, Length: 28
DEBUG (Env): Episode done for env 84. Reward: 21.02, Length: 9
DEBUG (Env): Episode done for env 104. Reward: 6.94, Length: 25
DEBUG (Env): Episode done for env 114. Reward: 25.78, Length: 7
1753
Time taken for simulation:  7.180485725402832
average overall reward:  0.34066856  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.11042664  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 25.11, Length: 8
DEBUG (Env): Episode done for env 8. Reward: 24.39, Length: 7
DEBUG (Env): Episode done for env 34. Reward: 20.32, Length: 7
DEBUG (Env): Episode done for env 35. Reward: -24.73, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 25.52, Length: 8
DEBUG (Env): Episode done for env 97. Reward: -23.57, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 2.47, Length: 36
1754
Time taken for simulation:  7.019752025604248
average overall reward:  -0.2539014  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  -0.30554542  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 38. Reward: -23.89, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 22.70, Length: 9
DEBUG (Env): Episode done for env 91. Reward: 24.01, Length: 9
DEBUG (Env): Episode done for env 127. Reward: 21.43, Length: 4
1755
Time taken for simulation:  7.1385178565979
average overall reward:  0.50110567  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.10974866  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 11.67, Length: 33
DEBUG (Env): Episode done for env 8. Reward: 25.24, Length: 2
DEBUG (Env): Episode done for env 36. Reward: -3.38, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 30.89, Length: 10
DEBUG (Env): Episode done for env 55. Reward: -28.22, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 31.11, Length: 2
DEBUG (Env): Episode done for env 120. Reward: -3.62, Length: 36
1756
Time taken for simulation:  7.125264406204224
average overall reward:  0.4940444  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.0921215  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 10.00, Length: 25
DEBUG (Env): Episode done for env 39. Reward: 12.08, Length: 1
DEBUG (Env): Episode done for env 49. Reward: -31.58, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 24.33, Length: 5
DEBUG (Env): Episode done for env 59. Reward: -17.06, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 32.96, Length: 15
DEBUG (Env): Episode done for env 105. Reward: 16.01, Length: 9
1757
Time taken for simulation:  7.088520288467407
average overall reward:  0.9716391  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.20594473 average distance reward:  0.1659055  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 6. Reward: 24.39, Length: 2
DEBUG (Env): Episode done for env 18. Reward: 19.63, Length: 7
DEBUG (Env): Episode done for env 22. Reward: 26.53, Length: 18
DEBUG (Env): Episode done for env 37. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 17.09, Length: 1
DEBUG (Env): Episode done for env 54. Reward: 22.40, Length: 18
DEBUG (Env): Episode done for env 66. Reward: 16.86, Length: 17
DEBUG (Env): Episode done for env 110. Reward: 31.61, Length: 21
DEBUG (Env): Episode done for env 111. Reward: 0.58, Length: 27
1758
Time taken for simulation:  7.19880485534668
average overall reward:  -0.043851204  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  -0.17733568  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 9.28, Length: 31
DEBUG (Env): Episode done for env 10. Reward: -18.06, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -10.53, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 17.79, Length: 2
DEBUG (Env): Episode done for env 71. Reward: -22.89, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 3.90, Length: 12
1759
Time taken for simulation:  7.056634426116943
average overall reward:  0.7315965  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.2574309 average distance reward:  0.22465585  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 24.77, Length: 3
DEBUG (Env): Episode done for env 40. Reward: 4.74, Length: 29
DEBUG (Env): Episode done for env 68. Reward: 2.48, Length: 14
DEBUG (Env): Episode done for env 92. Reward: 29.75, Length: 22
DEBUG (Env): Episode done for env 119. Reward: 21.44, Length: 9
DEBUG (Env): Episode done for env 127. Reward: 21.22, Length: 5
1760
Time taken for simulation:  7.128394603729248
average overall reward:  0.34822446  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.25796574  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: -21.50, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 39.71, Length: 8
DEBUG (Env): Episode done for env 58. Reward: -0.16, Length: 21
DEBUG (Env): Episode done for env 63. Reward: 19.25, Length: 12
1761
Time taken for simulation:  7.095687627792358
average overall reward:  0.10381111  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.102972366 average distance reward:  -0.10459709  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: -16.08, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -14.92, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 23.90, Length: 9
DEBUG (Env): Episode done for env 94. Reward: 10.75, Length: 32
DEBUG (Env): Episode done for env 100. Reward: 14.59, Length: 10
1762
Time taken for simulation:  7.715805768966675
average overall reward:  0.24218814  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  -0.13168609  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 22.87, Length: 7
DEBUG (Env): Episode done for env 22. Reward: 24.78, Length: 5
DEBUG (Env): Episode done for env 48. Reward: 23.08, Length: 4
DEBUG (Env): Episode done for env 81. Reward: -13.52, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 11.42, Length: 3
DEBUG (Env): Episode done for env 122. Reward: 24.02, Length: 20
1763
Time taken for simulation:  7.136464357376099
average overall reward:  -0.10218478  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  -0.26967278  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 34. Reward: 14.27, Length: 10
DEBUG (Env): Episode done for env 79. Reward: 19.46, Length: 21
DEBUG (Env): Episode done for env 91. Reward: 10.85, Length: 9
DEBUG (Env): Episode done for env 106. Reward: -17.36, Length: 36
1764
Time taken for simulation:  7.259025812149048
average overall reward:  0.37474555  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594475 average distance reward:  0.13393772  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 23.19, Length: 12
DEBUG (Env): Episode done for env 44. Reward: 9.44, Length: 27
DEBUG (Env): Episode done for env 54. Reward: 30.68, Length: 7
DEBUG (Env): Episode done for env 77. Reward: -20.38, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 15.79, Length: 3
DEBUG (Env): Episode done for env 108. Reward: -26.00, Length: 36
1765
Time taken for simulation:  7.824571132659912
average overall reward:  0.059353866  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  0.27614826  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 13. Reward: -23.13, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 12.70, Length: 22
DEBUG (Env): Episode done for env 123. Reward: -25.51, Length: 36
1766
Time taken for simulation:  7.162134408950806
average overall reward:  -0.3363133  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.1581335  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 25. Reward: 11.95, Length: 23
DEBUG (Env): Episode done for env 93. Reward: -18.16, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -16.05, Length: 36
1767
Time taken for simulation:  7.270224571228027
average overall reward:  0.082839936  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.14509636  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 29. Reward: -11.09, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 17.06, Length: 3
DEBUG (Env): Episode done for env 41. Reward: 33.15, Length: 18
DEBUG (Env): Episode done for env 47. Reward: -23.59, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 11.75, Length: 25
DEBUG (Env): Episode done for env 113. Reward: 13.88, Length: 24
1768
Time taken for simulation:  7.57863974571228
average overall reward:  -0.33600312  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  -0.16909105  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: -27.37, Length: 36
DEBUG (Env): Episode done for env 15. Reward: -22.10, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 29.60, Length: 7
DEBUG (Env): Episode done for env 34. Reward: 27.25, Length: 5
DEBUG (Env): Episode done for env 107. Reward: 0.06, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -25.29, Length: 36
1769
Time taken for simulation:  7.204858064651489
average overall reward:  0.72778946  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.32356092  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 43. Reward: -14.48, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 20.06, Length: 7
DEBUG (Env): Episode done for env 55. Reward: 17.81, Length: 14
DEBUG (Env): Episode done for env 71. Reward: 19.68, Length: 11
DEBUG (Env): Episode done for env 85. Reward: 13.77, Length: 23
DEBUG (Env): Episode done for env 98. Reward: 29.95, Length: 3
DEBUG (Env): Episode done for env 124. Reward: -22.29, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -14.12, Length: 36
1770
Time taken for simulation:  7.108758926391602
average overall reward:  0.35977632  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.11896843  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: 22.69, Length: 10
DEBUG (Env): Episode done for env 17. Reward: -17.01, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 11.08, Length: 22
DEBUG (Env): Episode done for env 63. Reward: 20.72, Length: 10
DEBUG (Env): Episode done for env 86. Reward: -16.93, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 28.59, Length: 18
1771
Time taken for simulation:  7.44261360168457
average overall reward:  0.07779527  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.051078063  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 69. Reward: -17.54, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 21.02, Length: 8
DEBUG (Env): Episode done for env 115. Reward: 22.01, Length: 13
DEBUG (Env): Episode done for env 123. Reward: 32.69, Length: 6
1772
Time taken for simulation:  7.08898138999939
average overall reward:  0.7542255  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.12871546 average distance reward:  0.30081636  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 19. Reward: -19.50, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -16.35, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 22.68, Length: 6
DEBUG (Env): Episode done for env 45. Reward: 21.50, Length: 12
DEBUG (Env): Episode done for env 49. Reward: 7.45, Length: 16
DEBUG (Env): Episode done for env 62. Reward: 13.79, Length: 26
DEBUG (Env): Episode done for env 115. Reward: 16.53, Length: 1
1773
Time taken for simulation:  7.152377367019653
average overall reward:  0.20930147  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.15304631  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: -25.25, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -22.01, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 26.00, Length: 4
DEBUG (Env): Episode done for env 81. Reward: 24.92, Length: 11
DEBUG (Env): Episode done for env 109. Reward: -30.08, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 17.55, Length: 2
1774
Time taken for simulation:  7.4700281620025635
average overall reward:  0.47001892  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594472 average distance reward:  0.14071402  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 14. Reward: -23.96, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 10.35, Length: 26
DEBUG (Env): Episode done for env 33. Reward: -18.44, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 20.65, Length: 17
DEBUG (Env): Episode done for env 66. Reward: 14.09, Length: 17
DEBUG (Env): Episode done for env 78. Reward: -13.09, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -11.99, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 24.74, Length: 18
DEBUG (Env): Episode done for env 124. Reward: 18.31, Length: 5
1775
Time taken for simulation:  7.499575853347778
average overall reward:  0.17622049  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.18020165 average distance reward:  -0.20226496  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: 23.86, Length: 10
DEBUG (Env): Episode done for env 33. Reward: 20.20, Length: 1
DEBUG (Env): Episode done for env 43. Reward: 22.24, Length: 6
DEBUG (Env): Episode done for env 49. Reward: 20.16, Length: 3
DEBUG (Env): Episode done for env 75. Reward: -20.14, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -14.72, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -14.83, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 24.44, Length: 22
1776
Time taken for simulation:  7.184642553329468
average overall reward:  -0.33486474  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  -0.122681506  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 36. Reward: 17.10, Length: 21
DEBUG (Env): Episode done for env 61. Reward: -27.95, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -15.62, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -20.44, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -31.16, Length: 36
1777
Time taken for simulation:  7.107979774475098
average overall reward:  0.33105022  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.27479503  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 10.17, Length: 29
DEBUG (Env): Episode done for env 4. Reward: -14.15, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -23.07, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -9.07, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 11.78, Length: 26
DEBUG (Env): Episode done for env 127. Reward: 37.75, Length: 18
1778
Time taken for simulation:  7.213799476623535
average overall reward:  0.024164509  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.03892365  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: 16.14, Length: 1
DEBUG (Env): Episode done for env 41. Reward: 27.90, Length: 11
DEBUG (Env): Episode done for env 53. Reward: -10.19, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 0.39, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -17.41, Length: 36
1779
Time taken for simulation:  7.177453994750977
average overall reward:  0.086324796  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.06637864  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 11. Reward: -19.95, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -19.70, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 27.00, Length: 4
DEBUG (Env): Episode done for env 42. Reward: -13.68, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 15.20, Length: 15
DEBUG (Env): Episode done for env 78. Reward: 29.61, Length: 5
DEBUG (Env): Episode done for env 121. Reward: -28.50, Length: 36
1780
Time taken for simulation:  7.208418130874634
average overall reward:  -0.18710816  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.23168781 average distance reward:  0.115877695  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 46. Reward: -17.72, Length: 36
1781
Time taken for simulation:  7.240295171737671
average overall reward:  0.38467735  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.10294926  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 20. Reward: -21.86, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -21.56, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 21.36, Length: 22
DEBUG (Env): Episode done for env 41. Reward: 23.70, Length: 3
DEBUG (Env): Episode done for env 89. Reward: -15.18, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 6.64, Length: 26
DEBUG (Env): Episode done for env 121. Reward: 4.50, Length: 2
1782
Time taken for simulation:  7.373852252960205
average overall reward:  0.5199659  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.10978258  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 83. Reward: 19.90, Length: 7
DEBUG (Env): Episode done for env 86. Reward: 30.80, Length: 12
DEBUG (Env): Episode done for env 87. Reward: 9.69, Length: 28
DEBUG (Env): Episode done for env 110. Reward: 20.50, Length: 25
DEBUG (Env): Episode done for env 115. Reward: 27.09, Length: 10
1783
Time taken for simulation:  7.410217523574829
average overall reward:  0.26737022  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.14445168  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: -15.60, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 26.27, Length: 4
DEBUG (Env): Episode done for env 51. Reward: -10.95, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -21.76, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -24.07, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 17.91, Length: 24
DEBUG (Env): Episode done for env 123. Reward: 34.84, Length: 10
1784
Time taken for simulation:  7.088780879974365
average overall reward:  0.7381501  average fail penalty:  -0.09375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.23168783 average distance reward:  -0.10689977  and average step penalty:  -0.04786053509430681
Number of done instances:  13
DEBUG (Env): Episode done for env 1. Reward: 23.58, Length: 14
DEBUG (Env): Episode done for env 16. Reward: -17.59, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 25.59, Length: 12
DEBUG (Env): Episode done for env 43. Reward: 22.12, Length: 9
DEBUG (Env): Episode done for env 63. Reward: 17.86, Length: 14
DEBUG (Env): Episode done for env 66. Reward: 24.88, Length: 10
DEBUG (Env): Episode done for env 67. Reward: -19.84, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 23.89, Length: 13
DEBUG (Env): Episode done for env 81. Reward: 20.92, Length: 11
DEBUG (Env): Episode done for env 87. Reward: 26.18, Length: 2
DEBUG (Env): Episode done for env 88. Reward: -21.32, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -24.19, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 14.69, Length: 8
1785
Time taken for simulation:  7.247710466384888
average overall reward:  0.06353027  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  0.16448078  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 56. Reward: -18.01, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -10.00, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 39.56, Length: 4
1786
Time taken for simulation:  7.174570322036743
average overall reward:  -0.22694848  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.010154039  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 57. Reward: -23.71, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -20.21, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 42.71, Length: 5
1787
Time taken for simulation:  7.423705101013184
average overall reward:  0.034171537  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.051236246  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 22. Reward: 2.11, Length: 25
DEBUG (Env): Episode done for env 64. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -35.99, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 18.55, Length: 5
1788
Time taken for simulation:  7.210857629776001
average overall reward:  0.22193262  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.028701589  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 20. Reward: 29.33, Length: 7
DEBUG (Env): Episode done for env 56. Reward: 17.13, Length: 3
DEBUG (Env): Episode done for env 67. Reward: 17.84, Length: 4
DEBUG (Env): Episode done for env 114. Reward: -22.17, Length: 36
1789
Time taken for simulation:  7.0505690574646
average overall reward:  0.43962818  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.23512933  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -24.25, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 12.91, Length: 17
DEBUG (Env): Episode done for env 35. Reward: -23.84, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 5.49, Length: 31
DEBUG (Env): Episode done for env 73. Reward: 31.85, Length: 3
DEBUG (Env): Episode done for env 97. Reward: -21.71, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 13.71, Length: 5
1790
Time taken for simulation:  7.473414421081543
average overall reward:  1.1412032  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.141587 average distance reward:  0.4064839  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: 8.11, Length: 28
DEBUG (Env): Episode done for env 17. Reward: 1.97, Length: 20
DEBUG (Env): Episode done for env 19. Reward: 33.55, Length: 1
DEBUG (Env): Episode done for env 38. Reward: -13.95, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 12.42, Length: 6
DEBUG (Env): Episode done for env 55. Reward: 21.02, Length: 21
DEBUG (Env): Episode done for env 64. Reward: 36.09, Length: 3
DEBUG (Env): Episode done for env 76. Reward: -0.42, Length: 35
1791
Time taken for simulation:  7.526874303817749
average overall reward:  0.6314647  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.021551654  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: 16.02, Length: 21
DEBUG (Env): Episode done for env 35. Reward: 24.61, Length: 2
DEBUG (Env): Episode done for env 48. Reward: 24.25, Length: 18
DEBUG (Env): Episode done for env 74. Reward: 23.03, Length: 13
DEBUG (Env): Episode done for env 79. Reward: 24.07, Length: 20
DEBUG (Env): Episode done for env 108. Reward: 9.92, Length: 27
1792
Time taken for simulation:  7.102788209915161
average overall reward:  0.3914208  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.124869876  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 26. Reward: 12.70, Length: 19
DEBUG (Env): Episode done for env 56. Reward: 20.92, Length: 4
DEBUG (Env): Episode done for env 59. Reward: -15.81, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -15.76, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 20.68, Length: 5
DEBUG (Env): Episode done for env 103. Reward: 25.27, Length: 15
1793
Time taken for simulation:  7.252295732498169
average overall reward:  0.21385676  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.4131685  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: -20.33, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -15.89, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -19.93, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 22.37, Length: 11
DEBUG (Env): Episode done for env 111. Reward: -25.30, Length: 36
1794
Time taken for simulation:  7.104372262954712
average overall reward:  0.15059403  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.032286607  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 19.46, Length: 21
DEBUG (Env): Episode done for env 7. Reward: -10.69, Length: 36
DEBUG (Env): Episode done for env 10. Reward: -13.85, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 11.41, Length: 22
DEBUG (Env): Episode done for env 64. Reward: 38.36, Length: 4
1795
Time taken for simulation:  7.219571352005005
average overall reward:  0.23448801  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.27030247 average distance reward:  0.32878193  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: -13.47, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 29.67, Length: 4
DEBUG (Env): Episode done for env 68. Reward: -16.61, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 14.64, Length: 34
1796
Time taken for simulation:  7.489497900009155
average overall reward:  0.9167181  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.24455938 average distance reward:  0.2849713  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: 25.48, Length: 6
DEBUG (Env): Episode done for env 36. Reward: 23.02, Length: 20
DEBUG (Env): Episode done for env 58. Reward: -10.21, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 31.72, Length: 13
DEBUG (Env): Episode done for env 65. Reward: 27.23, Length: 19
DEBUG (Env): Episode done for env 78. Reward: 16.79, Length: 17
DEBUG (Env): Episode done for env 80. Reward: 26.08, Length: 9
DEBUG (Env): Episode done for env 82. Reward: 24.06, Length: 13
1797
Time taken for simulation:  7.2726099491119385
average overall reward:  0.98062706  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.24455936 average distance reward:  0.64306176  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 24.61, Length: 8
DEBUG (Env): Episode done for env 21. Reward: -19.26, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 38.76, Length: 2
DEBUG (Env): Episode done for env 54. Reward: 27.17, Length: 18
DEBUG (Env): Episode done for env 59. Reward: 46.07, Length: 5
DEBUG (Env): Episode done for env 73. Reward: 43.04, Length: 8
DEBUG (Env): Episode done for env 100. Reward: -1.76, Length: 36
1798
Time taken for simulation:  7.1778881549835205
average overall reward:  0.5294876  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.16733009 average distance reward:  -0.156051  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 7. Reward: 18.88, Length: 4
DEBUG (Env): Episode done for env 19. Reward: 19.70, Length: 8
DEBUG (Env): Episode done for env 30. Reward: 12.97, Length: 30
DEBUG (Env): Episode done for env 48. Reward: 16.68, Length: 7
DEBUG (Env): Episode done for env 56. Reward: 23.65, Length: 6
DEBUG (Env): Episode done for env 77. Reward: 1.88, Length: 34
DEBUG (Env): Episode done for env 119. Reward: -21.69, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -23.34, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 18.11, Length: 22
1799
Time taken for simulation:  7.3161656856536865
average overall reward:  0.45309386  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.051170904  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 13.51, Length: 5
DEBUG (Env): Episode done for env 42. Reward: 14.61, Length: 20
DEBUG (Env): Episode done for env 54. Reward: 26.19, Length: 2
DEBUG (Env): Episode done for env 55. Reward: 23.90, Length: 9
DEBUG (Env): Episode done for env 80. Reward: 29.54, Length: 3
DEBUG (Env): Episode done for env 91. Reward: -21.23, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -12.59, Length: 36
1800
Time taken for simulation:  7.26393723487854
average overall reward:  0.83432883  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.4710205  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 20. Reward: 33.41, Length: 12
DEBUG (Env): Episode done for env 21. Reward: 16.68, Length: 3
DEBUG (Env): Episode done for env 26. Reward: 33.88, Length: 8
DEBUG (Env): Episode done for env 44. Reward: -21.73, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 21.52, Length: 22
DEBUG (Env): Episode done for env 73. Reward: 34.85, Length: 3
DEBUG (Env): Episode done for env 84. Reward: -18.97, Length: 36
1801
Time taken for simulation:  7.197876691818237
average overall reward:  0.3785324  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.23678756  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 52. Reward: -26.73, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 22.96, Length: 2
DEBUG (Env): Episode done for env 97. Reward: 41.81, Length: 12
DEBUG (Env): Episode done for env 119. Reward: 29.85, Length: 3
1802
Time taken for simulation:  7.181702375411987
average overall reward:  -0.27960914  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  -0.073380664  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 93. Reward: -16.18, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 23.63, Length: 20
1803
Time taken for simulation:  7.271374464035034
average overall reward:  0.47832868  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.28209025  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 13. Reward: 22.57, Length: 28
DEBUG (Env): Episode done for env 29. Reward: -21.17, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -14.45, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 25.40, Length: 22
DEBUG (Env): Episode done for env 47. Reward: -21.40, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 20.93, Length: 12
DEBUG (Env): Episode done for env 102. Reward: -6.23, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 7.85, Length: 33
DEBUG (Env): Episode done for env 113. Reward: -17.19, Length: 36
1804
Time taken for simulation:  7.320061683654785
average overall reward:  0.7124259  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.5161874  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 9. Reward: -26.05, Length: 36
DEBUG (Env): Episode done for env 15. Reward: -17.80, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -17.90, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 26.86, Length: 8
DEBUG (Env): Episode done for env 84. Reward: 32.06, Length: 4
DEBUG (Env): Episode done for env 90. Reward: 25.08, Length: 20
DEBUG (Env): Episode done for env 97. Reward: 20.59, Length: 3
DEBUG (Env): Episode done for env 107. Reward: -17.55, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -10.97, Length: 36
1805
Time taken for simulation:  7.38034200668335
average overall reward:  0.19973236  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.26367208  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 10. Reward: 28.82, Length: 6
DEBUG (Env): Episode done for env 40. Reward: 17.38, Length: 24
DEBUG (Env): Episode done for env 71. Reward: -14.77, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -7.39, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -15.21, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -14.21, Length: 36
1806
Time taken for simulation:  7.109064340591431
average overall reward:  1.2651904  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.20594473 average distance reward:  0.4360195  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: 20.24, Length: 32
DEBUG (Env): Episode done for env 16. Reward: 15.79, Length: 22
DEBUG (Env): Episode done for env 21. Reward: 31.67, Length: 6
DEBUG (Env): Episode done for env 46. Reward: 19.86, Length: 26
DEBUG (Env): Episode done for env 61. Reward: 11.74, Length: 30
DEBUG (Env): Episode done for env 72. Reward: 25.19, Length: 6
DEBUG (Env): Episode done for env 122. Reward: 35.42, Length: 8
DEBUG (Env): Episode done for env 123. Reward: 29.84, Length: 23
1807
Time taken for simulation:  7.096215486526489
average overall reward:  0.97269213  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.38852215  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 43. Reward: 23.60, Length: 17
DEBUG (Env): Episode done for env 60. Reward: 16.91, Length: 11
DEBUG (Env): Episode done for env 62. Reward: 29.81, Length: 13
DEBUG (Env): Episode done for env 74. Reward: 24.43, Length: 16
DEBUG (Env): Episode done for env 93. Reward: 28.31, Length: 5
DEBUG (Env): Episode done for env 109. Reward: 16.86, Length: 34
1808
Time taken for simulation:  7.0905539989471436
average overall reward:  0.57429975  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.14663365  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 16. Reward: 36.74, Length: 2
DEBUG (Env): Episode done for env 25. Reward: -33.48, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 18.43, Length: 17
DEBUG (Env): Episode done for env 45. Reward: -12.99, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 44.05, Length: 8
DEBUG (Env): Episode done for env 87. Reward: 32.10, Length: 24
DEBUG (Env): Episode done for env 108. Reward: 35.15, Length: 17
1809
Time taken for simulation:  7.301485538482666
average overall reward:  0.583321  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.32138118  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 14. Reward: 21.70, Length: 3
DEBUG (Env): Episode done for env 15. Reward: 31.91, Length: 5
DEBUG (Env): Episode done for env 64. Reward: 8.74, Length: 15
DEBUG (Env): Episode done for env 73. Reward: 20.73, Length: 1
1810
Time taken for simulation:  7.30220890045166
average overall reward:  0.40723664  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  0.12711233  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 28. Reward: -13.17, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 38.13, Length: 6
DEBUG (Env): Episode done for env 39. Reward: -21.80, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 24.99, Length: 4
DEBUG (Env): Episode done for env 91. Reward: 26.38, Length: 11
DEBUG (Env): Episode done for env 96. Reward: -35.29, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -9.11, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 28.56, Length: 12
DEBUG (Env): Episode done for env 127. Reward: 0.48, Length: 33
1811
Time taken for simulation:  7.182240962982178
average overall reward:  0.104429476  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020163 average distance reward:  -0.25061852  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 34. Reward: 25.23, Length: 1
DEBUG (Env): Episode done for env 35. Reward: 35.06, Length: 14
DEBUG (Env): Episode done for env 49. Reward: -11.30, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 34.54, Length: 6
DEBUG (Env): Episode done for env 75. Reward: -19.18, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 23.14, Length: 7
DEBUG (Env): Episode done for env 95. Reward: -10.77, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -16.70, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 18.08, Length: 1
1812
Time taken for simulation:  7.2696003913879395
average overall reward:  0.55440706  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.2386755  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: 7.79, Length: 33
DEBUG (Env): Episode done for env 34. Reward: 18.61, Length: 1
DEBUG (Env): Episode done for env 47. Reward: 36.93, Length: 9
DEBUG (Env): Episode done for env 75. Reward: 22.68, Length: 1
DEBUG (Env): Episode done for env 99. Reward: -10.08, Length: 36
1813
Time taken for simulation:  7.405740976333618
average overall reward:  0.76966673  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.32912913  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -2.44, Length: 29
DEBUG (Env): Episode done for env 4. Reward: -4.49, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 23.04, Length: 8
DEBUG (Env): Episode done for env 76. Reward: 18.35, Length: 23
DEBUG (Env): Episode done for env 82. Reward: 33.17, Length: 17
DEBUG (Env): Episode done for env 86. Reward: 12.49, Length: 21
DEBUG (Env): Episode done for env 101. Reward: -19.52, Length: 36
1814
Time taken for simulation:  7.435217618942261
average overall reward:  0.7201147  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.5374496  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: -24.90, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 29.30, Length: 16
DEBUG (Env): Episode done for env 53. Reward: -14.17, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 29.09, Length: 2
DEBUG (Env): Episode done for env 79. Reward: 30.87, Length: 11
1815
Time taken for simulation:  7.398838996887207
average overall reward:  0.0021941513  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.13955067  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 11. Reward: -16.94, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 25.68, Length: 17
DEBUG (Env): Episode done for env 46. Reward: 27.36, Length: 9
DEBUG (Env): Episode done for env 53. Reward: 2.06, Length: 1
1816
Time taken for simulation:  7.170362710952759
average overall reward:  0.4735133  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.29545945  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 21. Reward: 22.18, Length: 10
DEBUG (Env): Episode done for env 95. Reward: 21.82, Length: 5
DEBUG (Env): Episode done for env 113. Reward: 15.27, Length: 13
1817
Time taken for simulation:  7.327675819396973
average overall reward:  -0.055361986  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  -0.36052755  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 20. Reward: 15.89, Length: 17
DEBUG (Env): Episode done for env 26. Reward: 25.91, Length: 17
DEBUG (Env): Episode done for env 41. Reward: -19.57, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 17.19, Length: 21
DEBUG (Env): Episode done for env 89. Reward: -21.57, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 23.94, Length: 13
1818
Time taken for simulation:  7.115169286727905
average overall reward:  1.0596987  average fail penalty:  -0.0234375  and average goal bonus:  1.0829761  and average same cell penalty:  -0.15445855 average distance reward:  0.20247912  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: 22.22, Length: 4
DEBUG (Env): Episode done for env 4. Reward: 18.21, Length: 5
DEBUG (Env): Episode done for env 29. Reward: 19.98, Length: 15
DEBUG (Env): Episode done for env 45. Reward: 18.60, Length: 10
DEBUG (Env): Episode done for env 46. Reward: 27.46, Length: 3
DEBUG (Env): Episode done for env 51. Reward: 23.49, Length: 35
DEBUG (Env): Episode done for env 95. Reward: 22.17, Length: 2
DEBUG (Env): Episode done for env 105. Reward: 33.58, Length: 8
DEBUG (Env): Episode done for env 110. Reward: -22.57, Length: 36
1819
Time taken for simulation:  6.9728920459747314
average overall reward:  1.1344166  average fail penalty:  -0.0703125  and average goal bonus:  1.2183483  and average same cell penalty:  -0.18020165 average distance reward:  0.21444288  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 7. Reward: 14.92, Length: 21
DEBUG (Env): Episode done for env 12. Reward: -27.19, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 31.17, Length: 2
DEBUG (Env): Episode done for env 25. Reward: 23.43, Length: 11
DEBUG (Env): Episode done for env 33. Reward: -17.54, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 30.25, Length: 12
DEBUG (Env): Episode done for env 65. Reward: 29.29, Length: 2
DEBUG (Env): Episode done for env 81. Reward: -3.29, Length: 35
DEBUG (Env): Episode done for env 92. Reward: -19.43, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 23.02, Length: 7
DEBUG (Env): Episode done for env 123. Reward: 32.86, Length: 13
DEBUG (Env): Episode done for env 126. Reward: 28.33, Length: 14
1820
Time taken for simulation:  7.27184796333313
average overall reward:  0.28842252  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.2275561  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 23. Reward: -12.82, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 30.86, Length: 20
DEBUG (Env): Episode done for env 63. Reward: 7.14, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -8.71, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -17.06, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 39.19, Length: 7
DEBUG (Env): Episode done for env 88. Reward: -22.16, Length: 36
1821
Time taken for simulation:  7.282425165176392
average overall reward:  0.75392437  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.47450185  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 40. Reward: 25.74, Length: 8
DEBUG (Env): Episode done for env 68. Reward: 5.62, Length: 26
DEBUG (Env): Episode done for env 91. Reward: 26.79, Length: 11
DEBUG (Env): Episode done for env 116. Reward: -6.70, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -26.32, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 20.60, Length: 11
1822
Time taken for simulation:  6.997953414916992
average overall reward:  0.66560555  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.07722928 average distance reward:  0.2960823  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 17.29, Length: 19
DEBUG (Env): Episode done for env 57. Reward: -14.27, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 29.24, Length: 3
DEBUG (Env): Episode done for env 84. Reward: 13.33, Length: 18
DEBUG (Env): Episode done for env 93. Reward: 6.72, Length: 15
DEBUG (Env): Episode done for env 121. Reward: -19.53, Length: 36
1823
Time taken for simulation:  7.450242280960083
average overall reward:  0.9072816  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.30793443  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 25.19, Length: 5
DEBUG (Env): Episode done for env 22. Reward: -16.11, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 39.50, Length: 11
DEBUG (Env): Episode done for env 35. Reward: 15.80, Length: 12
DEBUG (Env): Episode done for env 82. Reward: 22.31, Length: 10
DEBUG (Env): Episode done for env 98. Reward: 24.00, Length: 18
DEBUG (Env): Episode done for env 103. Reward: 25.72, Length: 31
1824
Time taken for simulation:  7.20210862159729
average overall reward:  0.21636342  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  0.39454323  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 67. Reward: -13.14, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 30.44, Length: 1
DEBUG (Env): Episode done for env 114. Reward: -19.30, Length: 36
1825
Time taken for simulation:  7.252673625946045
average overall reward:  0.38769513  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.06965795  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: 29.23, Length: 32
DEBUG (Env): Episode done for env 11. Reward: 26.86, Length: 10
DEBUG (Env): Episode done for env 41. Reward: 47.92, Length: 8
DEBUG (Env): Episode done for env 50. Reward: -20.93, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 28.22, Length: 5
DEBUG (Env): Episode done for env 117. Reward: -22.71, Length: 36
1826
Time taken for simulation:  8.029147386550903
average overall reward:  -0.062196516  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.1547608  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: -16.84, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -24.47, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 37.47, Length: 16
DEBUG (Env): Episode done for env 104. Reward: 14.81, Length: 23
DEBUG (Env): Episode done for env 108. Reward: 20.72, Length: 18
1827
Time taken for simulation:  7.058252573013306
average overall reward:  0.29690117  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.23168783 average distance reward:  -0.10041061  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 29. Reward: 9.83, Length: 9
DEBUG (Env): Episode done for env 31. Reward: 25.16, Length: 5
DEBUG (Env): Episode done for env 45. Reward: 19.62, Length: 9
DEBUG (Env): Episode done for env 89. Reward: 17.94, Length: 10
DEBUG (Env): Episode done for env 125. Reward: 45.69, Length: 6
1828
Time taken for simulation:  7.432006120681763
average overall reward:  0.2650647  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.06435773 average distance reward:  0.12997639  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: 19.39, Length: 2
DEBUG (Env): Episode done for env 70. Reward: -19.37, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 16.31, Length: 10
1829
Time taken for simulation:  7.134930610656738
average overall reward:  0.40289897  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.3572097  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 17. Reward: 18.27, Length: 1
DEBUG (Env): Episode done for env 18. Reward: -18.09, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 5.91, Length: 17
DEBUG (Env): Episode done for env 37. Reward: -16.92, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 31.83, Length: 9
DEBUG (Env): Episode done for env 83. Reward: -19.91, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -11.30, Length: 36
1830
Time taken for simulation:  7.219790935516357
average overall reward:  0.14897448  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  -0.21824324  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: -16.48, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 24.06, Length: 27
DEBUG (Env): Episode done for env 69. Reward: 18.09, Length: 1
DEBUG (Env): Episode done for env 89. Reward: 35.80, Length: 3
DEBUG (Env): Episode done for env 117. Reward: 15.16, Length: 5
1831
Time taken for simulation:  7.451815366744995
average overall reward:  0.31024122  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.24455938 average distance reward:  -0.027323931  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: -20.76, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 18.85, Length: 8
DEBUG (Env): Episode done for env 42. Reward: 29.80, Length: 32
DEBUG (Env): Episode done for env 65. Reward: 15.39, Length: 12
DEBUG (Env): Episode done for env 75. Reward: 26.55, Length: 17
DEBUG (Env): Episode done for env 94. Reward: -9.19, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 28.88, Length: 7
1832
Time taken for simulation:  7.126425504684448
average overall reward:  -0.033434182  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.0058035403  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: -19.24, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 25.93, Length: 13
DEBUG (Env): Episode done for env 36. Reward: -14.93, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -17.99, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 8.30, Length: 24
1833
Time taken for simulation:  7.264285087585449
average overall reward:  0.24886613  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.12825319  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: -19.07, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 11.26, Length: 16
DEBUG (Env): Episode done for env 30. Reward: 23.71, Length: 18
DEBUG (Env): Episode done for env 59. Reward: -5.90, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -20.63, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 17.00, Length: 14
1834
Time taken for simulation:  7.146698236465454
average overall reward:  0.1624955  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.067746416  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: 33.04, Length: 4
DEBUG (Env): Episode done for env 23. Reward: 14.92, Length: 14
DEBUG (Env): Episode done for env 48. Reward: -18.30, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -25.44, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -18.01, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 21.03, Length: 12
DEBUG (Env): Episode done for env 97. Reward: 22.64, Length: 17
1835
Time taken for simulation:  7.203583717346191
average overall reward:  0.48820576  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.45769364  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 41. Reward: 25.28, Length: 10
DEBUG (Env): Episode done for env 55. Reward: -4.63, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -15.72, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 30.59, Length: 16
DEBUG (Env): Episode done for env 89. Reward: 20.79, Length: 5
DEBUG (Env): Episode done for env 106. Reward: -15.90, Length: 36
1836
Time taken for simulation:  7.334926605224609
average overall reward:  -0.04944244  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  -0.066381216  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 8. Reward: 27.46, Length: 4
DEBUG (Env): Episode done for env 17. Reward: 23.32, Length: 7
1837
Time taken for simulation:  7.308332920074463
average overall reward:  0.30966473  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.13090901  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: 20.23, Length: 3
DEBUG (Env): Episode done for env 27. Reward: 13.09, Length: 29
DEBUG (Env): Episode done for env 52. Reward: -24.50, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -18.54, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 13.51, Length: 31
DEBUG (Env): Episode done for env 119. Reward: -12.60, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 30.98, Length: 18
1838
Time taken for simulation:  7.371821403503418
average overall reward:  0.64965504  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  -0.020706393  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 20. Reward: 20.12, Length: 19
DEBUG (Env): Episode done for env 28. Reward: 2.69, Length: 28
DEBUG (Env): Episode done for env 55. Reward: 23.50, Length: 3
DEBUG (Env): Episode done for env 63. Reward: 23.66, Length: 18
DEBUG (Env): Episode done for env 78. Reward: 4.41, Length: 34
DEBUG (Env): Episode done for env 115. Reward: -29.57, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 14.54, Length: 8
DEBUG (Env): Episode done for env 120. Reward: 6.78, Length: 17
1839
Time taken for simulation:  6.9678850173950195
average overall reward:  1.094877  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.141587 average distance reward:  0.24822338  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 4. Reward: -2.50, Length: 16
DEBUG (Env): Episode done for env 5. Reward: 12.86, Length: 9
DEBUG (Env): Episode done for env 22. Reward: 27.91, Length: 8
DEBUG (Env): Episode done for env 32. Reward: -13.18, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 29.72, Length: 14
DEBUG (Env): Episode done for env 67. Reward: 23.23, Length: 15
DEBUG (Env): Episode done for env 77. Reward: 39.23, Length: 5
DEBUG (Env): Episode done for env 94. Reward: 24.43, Length: 8
DEBUG (Env): Episode done for env 102. Reward: -22.02, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 8.97, Length: 28
1840
Time taken for simulation:  7.366936206817627
average overall reward:  0.20472243  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.102972366 average distance reward:  0.1551238  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: -15.12, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 26.31, Length: 9
DEBUG (Env): Episode done for env 107. Reward: -15.47, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -21.76, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 24.36, Length: 3
1841
Time taken for simulation:  7.367163181304932
average overall reward:  0.47837585  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.33432537  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 10. Reward: -14.32, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 19.07, Length: 32
DEBUG (Env): Episode done for env 44. Reward: 16.86, Length: 21
DEBUG (Env): Episode done for env 81. Reward: 20.47, Length: 6
DEBUG (Env): Episode done for env 85. Reward: -14.99, Length: 36
1842
Time taken for simulation:  7.144818067550659
average overall reward:  0.84134316  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455936 average distance reward:  0.3449684  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 14. Reward: 5.06, Length: 33
DEBUG (Env): Episode done for env 31. Reward: 9.70, Length: 15
DEBUG (Env): Episode done for env 50. Reward: 24.62, Length: 3
DEBUG (Env): Episode done for env 87. Reward: 32.61, Length: 10
DEBUG (Env): Episode done for env 101. Reward: 21.96, Length: 29
DEBUG (Env): Episode done for env 115. Reward: 26.99, Length: 4
DEBUG (Env): Episode done for env 122. Reward: -23.83, Length: 36
1843
Time taken for simulation:  7.114613056182861
average overall reward:  0.09873147  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.065913714  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 5. Reward: 34.16, Length: 4
DEBUG (Env): Episode done for env 43. Reward: -21.10, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 24.84, Length: 11
DEBUG (Env): Episode done for env 60. Reward: -18.94, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -20.61, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 29.80, Length: 9
DEBUG (Env): Episode done for env 109. Reward: -22.01, Length: 36
1844
Time taken for simulation:  7.155841112136841
average overall reward:  0.23219278  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  -0.11593838  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: 15.68, Length: 7
DEBUG (Env): Episode done for env 15. Reward: 36.89, Length: 3
DEBUG (Env): Episode done for env 16. Reward: -17.83, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 24.31, Length: 7
DEBUG (Env): Episode done for env 107. Reward: 21.00, Length: 4
DEBUG (Env): Episode done for env 113. Reward: 15.71, Length: 28
1845
Time taken for simulation:  7.350064039230347
average overall reward:  0.18081191  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.22361973  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 31. Reward: 31.06, Length: 3
DEBUG (Env): Episode done for env 64. Reward: -13.05, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 18.95, Length: 25
DEBUG (Env): Episode done for env 73. Reward: -15.74, Length: 36
1846
Time taken for simulation:  7.476677179336548
average overall reward:  1.0277784  average fail penalty:  -0.0703125  and average goal bonus:  1.0829762  and average same cell penalty:  -0.12871546 average distance reward:  0.19169062  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 3. Reward: 13.08, Length: 15
DEBUG (Env): Episode done for env 12. Reward: 14.83, Length: 27
DEBUG (Env): Episode done for env 30. Reward: 27.71, Length: 13
DEBUG (Env): Episode done for env 32. Reward: 33.05, Length: 7
DEBUG (Env): Episode done for env 37. Reward: 20.15, Length: 17
DEBUG (Env): Episode done for env 39. Reward: 27.66, Length: 20
DEBUG (Env): Episode done for env 55. Reward: 24.51, Length: 8
DEBUG (Env): Episode done for env 68. Reward: 22.31, Length: 25
DEBUG (Env): Episode done for env 72. Reward: -33.84, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -17.89, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -21.99, Length: 36
1847
Time taken for simulation:  7.2145445346832275
average overall reward:  0.34388354  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.31106582  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 22.85, Length: 18
DEBUG (Env): Episode done for env 49. Reward: -52.30, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 21.75, Length: 10
DEBUG (Env): Episode done for env 71. Reward: -17.98, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -6.02, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 28.52, Length: 10
DEBUG (Env): Episode done for env 124. Reward: -8.60, Length: 36
1848
Time taken for simulation:  7.440241098403931
average overall reward:  0.007649552  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  -0.043994464  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 26. Reward: 26.48, Length: 15
DEBUG (Env): Episode done for env 37. Reward: 27.69, Length: 2
DEBUG (Env): Episode done for env 47. Reward: -23.94, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 26.68, Length: 8
1849
Time taken for simulation:  7.25861120223999
average overall reward:  0.7143606  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.1673301 average distance reward:  0.028822005  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 1. Reward: -20.05, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 31.49, Length: 17
DEBUG (Env): Episode done for env 59. Reward: 32.22, Length: 16
DEBUG (Env): Episode done for env 68. Reward: 38.37, Length: 3
DEBUG (Env): Episode done for env 76. Reward: 2.59, Length: 29
DEBUG (Env): Episode done for env 86. Reward: -10.64, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 18.00, Length: 21
DEBUG (Env): Episode done for env 109. Reward: 19.08, Length: 6
DEBUG (Env): Episode done for env 123. Reward: 24.12, Length: 16
1850
Time taken for simulation:  7.2356486320495605
average overall reward:  0.086588554  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.1293963  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 19. Reward: -25.39, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 24.42, Length: 2
DEBUG (Env): Episode done for env 36. Reward: 26.83, Length: 1
DEBUG (Env): Episode done for env 79. Reward: -33.25, Length: 36
1851
Time taken for simulation:  7.246391773223877
average overall reward:  0.3129392  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  -0.015663832  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: 24.59, Length: 7
DEBUG (Env): Episode done for env 34. Reward: 8.82, Length: 28
DEBUG (Env): Episode done for env 53. Reward: -11.54, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 18.70, Length: 6
DEBUG (Env): Episode done for env 93. Reward: 12.34, Length: 29
1852
Time taken for simulation:  7.357741117477417
average overall reward:  0.7334535  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455938 average distance reward:  0.23707879  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 21. Reward: -16.89, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -17.47, Length: 10
DEBUG (Env): Episode done for env 68. Reward: 23.65, Length: 3
DEBUG (Env): Episode done for env 71. Reward: 30.37, Length: 5
DEBUG (Env): Episode done for env 81. Reward: 33.45, Length: 11
DEBUG (Env): Episode done for env 96. Reward: 18.00, Length: 6
DEBUG (Env): Episode done for env 126. Reward: 32.06, Length: 12
1853
Time taken for simulation:  6.996866703033447
average overall reward:  0.5086548  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.059856903  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: 8.98, Length: 35
DEBUG (Env): Episode done for env 25. Reward: 7.36, Length: 34
DEBUG (Env): Episode done for env 28. Reward: 14.69, Length: 15
DEBUG (Env): Episode done for env 80. Reward: 27.19, Length: 18
DEBUG (Env): Episode done for env 101. Reward: 28.25, Length: 11
1854
Time taken for simulation:  7.3868725299835205
average overall reward:  0.62930274  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.18020165 average distance reward:  0.0035106987  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 9. Reward: 23.20, Length: 14
DEBUG (Env): Episode done for env 19. Reward: 19.72, Length: 4
DEBUG (Env): Episode done for env 32. Reward: 24.97, Length: 8
DEBUG (Env): Episode done for env 46. Reward: -23.30, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 31.32, Length: 6
DEBUG (Env): Episode done for env 51. Reward: -18.57, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 25.87, Length: 8
DEBUG (Env): Episode done for env 94. Reward: 13.07, Length: 15
DEBUG (Env): Episode done for env 95. Reward: 17.68, Length: 5
DEBUG (Env): Episode done for env 105. Reward: -18.35, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -21.92, Length: 36
1855
Time taken for simulation:  7.173184871673584
average overall reward:  0.6061367  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.32440865  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 7. Reward: -6.56, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 21.19, Length: 2
DEBUG (Env): Episode done for env 30. Reward: 26.51, Length: 9
DEBUG (Env): Episode done for env 40. Reward: 10.46, Length: 34
DEBUG (Env): Episode done for env 48. Reward: 14.38, Length: 21
DEBUG (Env): Episode done for env 92. Reward: -21.89, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -18.44, Length: 36
1856
Time taken for simulation:  7.3280863761901855
average overall reward:  0.315834  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.29889524  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 31. Reward: 11.48, Length: 11
DEBUG (Env): Episode done for env 114. Reward: 22.16, Length: 25
1857
Time taken for simulation:  7.171712875366211
average overall reward:  0.03350605  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  0.13445657  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 90. Reward: 22.60, Length: 10
DEBUG (Env): Episode done for env 91. Reward: -11.93, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -22.05, Length: 36
1858
Time taken for simulation:  7.32814621925354
average overall reward:  0.23971333  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.13197193  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 28. Reward: 19.69, Length: 3
DEBUG (Env): Episode done for env 57. Reward: -24.25, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -26.92, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 18.20, Length: 23
DEBUG (Env): Episode done for env 121. Reward: -17.47, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 4.95, Length: 31
1859
Time taken for simulation:  7.2822182178497314
average overall reward:  0.7458321  average fail penalty:  -0.0703125  and average goal bonus:  1.0829762  and average same cell penalty:  -0.2574309 average distance reward:  0.0384598  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 1. Reward: 13.41, Length: 10
DEBUG (Env): Episode done for env 9. Reward: 21.89, Length: 5
DEBUG (Env): Episode done for env 16. Reward: 12.97, Length: 15
DEBUG (Env): Episode done for env 35. Reward: -19.62, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 28.55, Length: 12
DEBUG (Env): Episode done for env 65. Reward: 30.70, Length: 19
DEBUG (Env): Episode done for env 85. Reward: 18.09, Length: 18
DEBUG (Env): Episode done for env 98. Reward: -10.73, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 10.84, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 25.91, Length: 12
1860
Time taken for simulation:  7.401899814605713
average overall reward:  0.8817488  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.19851586  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 3. Reward: 19.67, Length: 14
DEBUG (Env): Episode done for env 26. Reward: 15.75, Length: 10
DEBUG (Env): Episode done for env 47. Reward: 25.80, Length: 6
DEBUG (Env): Episode done for env 50. Reward: 26.45, Length: 8
DEBUG (Env): Episode done for env 55. Reward: 23.33, Length: 14
DEBUG (Env): Episode done for env 82. Reward: -13.91, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 25.74, Length: 3
DEBUG (Env): Episode done for env 109. Reward: 33.44, Length: 11
1861
Time taken for simulation:  7.349743843078613
average overall reward:  1.2343876  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.141587 average distance reward:  0.5465435  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 2. Reward: 18.99, Length: 8
DEBUG (Env): Episode done for env 6. Reward: -13.65, Length: 36
DEBUG (Env): Episode done for env 11. Reward: -17.08, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 23.84, Length: 3
DEBUG (Env): Episode done for env 61. Reward: 4.72, Length: 24
DEBUG (Env): Episode done for env 87. Reward: 15.42, Length: 19
DEBUG (Env): Episode done for env 88. Reward: -20.76, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 24.73, Length: 22
DEBUG (Env): Episode done for env 113. Reward: 33.02, Length: 17
DEBUG (Env): Episode done for env 120. Reward: 7.73, Length: 23
1862
Time taken for simulation:  7.307635307312012
average overall reward:  0.36672974  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.2461168  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 13.41, Length: 26
DEBUG (Env): Episode done for env 38. Reward: -19.84, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 18.06, Length: 19
DEBUG (Env): Episode done for env 71. Reward: 42.10, Length: 10
DEBUG (Env): Episode done for env 104. Reward: -22.84, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -21.55, Length: 36
1863
Time taken for simulation:  7.444128036499023
average overall reward:  0.50290376  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.115843914 average distance reward:  0.44273913  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: 35.70, Length: 16
DEBUG (Env): Episode done for env 29. Reward: -18.99, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -22.65, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 27.66, Length: 7
1864
Time taken for simulation:  7.2978668212890625
average overall reward:  0.66060156  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.07412598  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 56. Reward: 24.69, Length: 30
DEBUG (Env): Episode done for env 61. Reward: 23.06, Length: 3
DEBUG (Env): Episode done for env 70. Reward: -19.67, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 27.52, Length: 11
DEBUG (Env): Episode done for env 115. Reward: 28.49, Length: 22
DEBUG (Env): Episode done for env 116. Reward: 35.05, Length: 7
DEBUG (Env): Episode done for env 117. Reward: 14.74, Length: 26
1865
Time taken for simulation:  7.33363151550293
average overall reward:  0.62069535  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.16733009 average distance reward:  0.09396632  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 24. Reward: -15.54, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 11.50, Length: 22
DEBUG (Env): Episode done for env 73. Reward: 19.88, Length: 20
DEBUG (Env): Episode done for env 83. Reward: -14.46, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 21.93, Length: 11
DEBUG (Env): Episode done for env 106. Reward: 17.14, Length: 7
DEBUG (Env): Episode done for env 111. Reward: -17.39, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 23.06, Length: 1
DEBUG (Env): Episode done for env 125. Reward: 23.73, Length: 7
1866
Time taken for simulation:  7.158141613006592
average overall reward:  0.23530078  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.106427535  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 11. Reward: 36.34, Length: 5
DEBUG (Env): Episode done for env 64. Reward: 18.05, Length: 21
DEBUG (Env): Episode done for env 69. Reward: -20.48, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 9.37, Length: 14
1867
Time taken for simulation:  7.065821886062622
average overall reward:  0.22354262  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.13097835  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 42. Reward: -13.23, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 28.04, Length: 16
DEBUG (Env): Episode done for env 71. Reward: 21.25, Length: 5
DEBUG (Env): Episode done for env 75. Reward: -6.41, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 1.79, Length: 33
1868
Time taken for simulation:  7.3481667041778564
average overall reward:  0.6986821  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  0.29906482  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: 24.20, Length: 9
DEBUG (Env): Episode done for env 24. Reward: 24.30, Length: 3
DEBUG (Env): Episode done for env 26. Reward: 41.93, Length: 8
DEBUG (Env): Episode done for env 33. Reward: -23.09, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 20.82, Length: 19
DEBUG (Env): Episode done for env 92. Reward: 19.15, Length: 13
1869
Time taken for simulation:  7.401934385299683
average overall reward:  0.48379108  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  0.15909737  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -23.03, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 15.60, Length: 1
DEBUG (Env): Episode done for env 35. Reward: 32.97, Length: 10
DEBUG (Env): Episode done for env 100. Reward: -12.62, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 34.96, Length: 9
DEBUG (Env): Episode done for env 114. Reward: 24.64, Length: 6
DEBUG (Env): Episode done for env 124. Reward: 25.32, Length: 10
1870
Time taken for simulation:  7.2536845207214355
average overall reward:  0.565214  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.28809702  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 11.88, Length: 8
DEBUG (Env): Episode done for env 14. Reward: 11.67, Length: 28
DEBUG (Env): Episode done for env 23. Reward: -24.43, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 18.67, Length: 10
DEBUG (Env): Episode done for env 103. Reward: 24.74, Length: 11
1871
Time taken for simulation:  7.32414698600769
average overall reward:  0.360161  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.312868  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 41. Reward: -21.67, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -16.21, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 16.21, Length: 4
DEBUG (Env): Episode done for env 126. Reward: 14.81, Length: 19
1872
Time taken for simulation:  7.165914535522461
average overall reward:  0.5178024  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.27030247 average distance reward:  0.04717075  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 17. Reward: -15.59, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 20.14, Length: 16
DEBUG (Env): Episode done for env 65. Reward: 27.73, Length: 13
DEBUG (Env): Episode done for env 86. Reward: 27.88, Length: 23
DEBUG (Env): Episode done for env 88. Reward: 28.75, Length: 11
DEBUG (Env): Episode done for env 92. Reward: 18.76, Length: 4
DEBUG (Env): Episode done for env 123. Reward: 6.63, Length: 23
1873
Time taken for simulation:  7.364664554595947
average overall reward:  -0.28168115  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455936 average distance reward:  -0.64268386  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 26. Reward: 14.34, Length: 5
DEBUG (Env): Episode done for env 38. Reward: 44.18, Length: 11
DEBUG (Env): Episode done for env 52. Reward: -29.73, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 40.69, Length: 6
DEBUG (Env): Episode done for env 110. Reward: 19.98, Length: 19
DEBUG (Env): Episode done for env 112. Reward: 8.47, Length: 34
1874
Time taken for simulation:  7.229637384414673
average overall reward:  0.9553258  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.12871546 average distance reward:  0.38998207  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 6. Reward: 24.63, Length: 13
DEBUG (Env): Episode done for env 20. Reward: -8.51, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 20.11, Length: 6
DEBUG (Env): Episode done for env 41. Reward: 18.72, Length: 3
DEBUG (Env): Episode done for env 63. Reward: -24.22, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 26.17, Length: 7
DEBUG (Env): Episode done for env 78. Reward: -23.33, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 14.74, Length: 15
DEBUG (Env): Episode done for env 102. Reward: 19.61, Length: 13
1875
Time taken for simulation:  7.1929590702056885
average overall reward:  0.06548662  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594472 average distance reward:  -0.12844625  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: -15.64, Length: 36
DEBUG (Env): Episode done for env 14. Reward: -3.86, Length: 5
DEBUG (Env): Episode done for env 22. Reward: -15.59, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 25.21, Length: 17
DEBUG (Env): Episode done for env 66. Reward: 5.66, Length: 24
DEBUG (Env): Episode done for env 67. Reward: -28.89, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 19.82, Length: 9
DEBUG (Env): Episode done for env 77. Reward: -11.62, Length: 36
1876
Time taken for simulation:  7.186238765716553
average overall reward:  0.72152174  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.25985223  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: 28.24, Length: 6
DEBUG (Env): Episode done for env 35. Reward: 17.17, Length: 7
DEBUG (Env): Episode done for env 85. Reward: 25.20, Length: 17
DEBUG (Env): Episode done for env 105. Reward: 25.97, Length: 22
DEBUG (Env): Episode done for env 113. Reward: 30.80, Length: 15
1877
Time taken for simulation:  7.649529457092285
average overall reward:  0.41845125  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.5580164  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 10. Reward: -9.47, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -11.43, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 21.86, Length: 23
1878
Time taken for simulation:  7.342664957046509
average overall reward:  -0.052303046  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.0056818277  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 71. Reward: 24.44, Length: 4
DEBUG (Env): Episode done for env 110. Reward: 28.16, Length: 5
DEBUG (Env): Episode done for env 122. Reward: -13.98, Length: 36
1879
Time taken for simulation:  7.371153831481934
average overall reward:  -0.20971939  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  -0.08142199  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: -21.77, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -14.01, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -19.59, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 15.47, Length: 29
DEBUG (Env): Episode done for env 84. Reward: -17.51, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 20.59, Length: 5
1880
Time taken for simulation:  7.103327035903931
average overall reward:  0.4535107  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.15891102  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: -24.76, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 27.07, Length: 5
DEBUG (Env): Episode done for env 27. Reward: -23.09, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 26.59, Length: 6
DEBUG (Env): Episode done for env 107. Reward: -16.52, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 14.15, Length: 15
DEBUG (Env): Episode done for env 126. Reward: 26.71, Length: 9
1881
Time taken for simulation:  7.306390762329102
average overall reward:  0.56128573  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.33174574  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 38. Reward: 24.87, Length: 8
DEBUG (Env): Episode done for env 84. Reward: 19.05, Length: 2
DEBUG (Env): Episode done for env 96. Reward: 10.26, Length: 29
1882
Time taken for simulation:  7.022643327713013
average overall reward:  -0.041563377  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  0.16005391  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 12. Reward: -22.36, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -22.37, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 29.46, Length: 10
DEBUG (Env): Episode done for env 127. Reward: -16.62, Length: 36
1883
Time taken for simulation:  7.5816709995269775
average overall reward:  0.14294174  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  -0.0011087265  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 29. Reward: 15.85, Length: 20
DEBUG (Env): Episode done for env 54. Reward: -20.31, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 17.93, Length: 19
DEBUG (Env): Episode done for env 98. Reward: 23.77, Length: 3
DEBUG (Env): Episode done for env 119. Reward: -11.51, Length: 36
1884
Time taken for simulation:  7.189635276794434
average overall reward:  0.756034  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.283174 average distance reward:  0.32171145  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: 4.72, Length: 25
DEBUG (Env): Episode done for env 20. Reward: 11.09, Length: 10
DEBUG (Env): Episode done for env 30. Reward: 27.48, Length: 29
DEBUG (Env): Episode done for env 37. Reward: -21.72, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 23.74, Length: 14
DEBUG (Env): Episode done for env 62. Reward: 18.09, Length: 26
DEBUG (Env): Episode done for env 68. Reward: 7.34, Length: 32
DEBUG (Env): Episode done for env 118. Reward: -22.54, Length: 36
1885
Time taken for simulation:  7.200217008590698
average overall reward:  0.21440299  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.08552964  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 41. Reward: 34.41, Length: 11
DEBUG (Env): Episode done for env 45. Reward: 25.99, Length: 22
DEBUG (Env): Episode done for env 76. Reward: -13.28, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 30.39, Length: 12
1886
Time taken for simulation:  7.1833038330078125
average overall reward:  0.597667  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.3205501  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 22. Reward: 34.24, Length: 11
DEBUG (Env): Episode done for env 27. Reward: 33.54, Length: 6
DEBUG (Env): Episode done for env 30. Reward: 20.77, Length: 2
DEBUG (Env): Episode done for env 36. Reward: -21.56, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 19.55, Length: 11
1887
Time taken for simulation:  7.614668846130371
average overall reward:  0.26199985  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.11584391 average distance reward:  -0.045471337  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 33.16, Length: 5
DEBUG (Env): Episode done for env 15. Reward: 19.06, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -8.27, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 14.21, Length: 12
DEBUG (Env): Episode done for env 81. Reward: 33.39, Length: 21
DEBUG (Env): Episode done for env 93. Reward: -12.99, Length: 36
1888
Time taken for simulation:  7.520946741104126
average overall reward:  0.051575944  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.06442583  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: 18.29, Length: 19
DEBUG (Env): Episode done for env 21. Reward: -10.95, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 5.47, Length: 33
DEBUG (Env): Episode done for env 109. Reward: 26.49, Length: 19
1889
Time taken for simulation:  7.026335954666138
average overall reward:  0.24526113  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.16733009 average distance reward:  -0.16953337  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 5. Reward: 24.02, Length: 10
DEBUG (Env): Episode done for env 23. Reward: 10.13, Length: 13
DEBUG (Env): Episode done for env 25. Reward: -7.54, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 24.07, Length: 25
DEBUG (Env): Episode done for env 80. Reward: -10.87, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 35.16, Length: 5
DEBUG (Env): Episode done for env 119. Reward: 25.60, Length: 6
1890
Time taken for simulation:  7.196954011917114
average overall reward:  0.05355142  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.031299572  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: -9.26, Length: 22
DEBUG (Env): Episode done for env 19. Reward: -21.37, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 19.27, Length: 7
DEBUG (Env): Episode done for env 32. Reward: -12.10, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -16.63, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -18.30, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 13.01, Length: 17
DEBUG (Env): Episode done for env 94. Reward: -28.96, Length: 36
1891
Time taken for simulation:  7.197588920593262
average overall reward:  0.04509378  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.20594473 average distance reward:  0.23383954  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: -12.43, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -26.77, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -17.50, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 11.77, Length: 30
1892
Time taken for simulation:  7.194512844085693
average overall reward:  0.87389016  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.2511056  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 33. Reward: 23.67, Length: 18
DEBUG (Env): Episode done for env 48. Reward: 24.34, Length: 1
DEBUG (Env): Episode done for env 84. Reward: 45.68, Length: 11
DEBUG (Env): Episode done for env 85. Reward: 26.66, Length: 16
DEBUG (Env): Episode done for env 96. Reward: 16.64, Length: 11
DEBUG (Env): Episode done for env 124. Reward: 18.43, Length: 23
1893
Time taken for simulation:  7.452258348464966
average overall reward:  -0.084801406  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.095683984  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 54. Reward: 25.85, Length: 10
DEBUG (Env): Episode done for env 90. Reward: -4.16, Length: 36
1894
Time taken for simulation:  7.473330736160278
average overall reward:  0.3405553  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  -0.11054826  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 22. Reward: 15.52, Length: 8
DEBUG (Env): Episode done for env 50. Reward: 15.14, Length: 34
DEBUG (Env): Episode done for env 60. Reward: 20.27, Length: 15
DEBUG (Env): Episode done for env 100. Reward: 14.92, Length: 25
DEBUG (Env): Episode done for env 120. Reward: 26.66, Length: 33
DEBUG (Env): Episode done for env 121. Reward: -25.18, Length: 36
1895
Time taken for simulation:  7.0632569789886475
average overall reward:  0.32195818  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.24226548  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 16. Reward: -30.19, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 22.57, Length: 11
DEBUG (Env): Episode done for env 33. Reward: 17.55, Length: 3
DEBUG (Env): Episode done for env 49. Reward: -14.00, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 33.66, Length: 11
1896
Time taken for simulation:  7.183842658996582
average overall reward:  0.78515136  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.2561167  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 3. Reward: -18.95, Length: 36
DEBUG (Env): Episode done for env 8. Reward: 16.66, Length: 26
DEBUG (Env): Episode done for env 35. Reward: 14.98, Length: 20
DEBUG (Env): Episode done for env 55. Reward: -9.17, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 9.48, Length: 28
DEBUG (Env): Episode done for env 82. Reward: -15.79, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 20.58, Length: 24
DEBUG (Env): Episode done for env 91. Reward: -17.35, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 9.99, Length: 24
DEBUG (Env): Episode done for env 126. Reward: 27.80, Length: 16
1897
Time taken for simulation:  7.260704517364502
average overall reward:  0.44772965  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.12871546 average distance reward:  -0.1410515  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: -22.32, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 24.47, Length: 9
DEBUG (Env): Episode done for env 26. Reward: 29.04, Length: 24
DEBUG (Env): Episode done for env 28. Reward: -17.92, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 14.42, Length: 13
DEBUG (Env): Episode done for env 60. Reward: 15.26, Length: 3
DEBUG (Env): Episode done for env 92. Reward: 17.83, Length: 1
DEBUG (Env): Episode done for env 105. Reward: 5.18, Length: 21
1898
Time taken for simulation:  7.067294359207153
average overall reward:  0.8013297  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.16733009 average distance reward:  0.40997267  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: 31.59, Length: 18
DEBUG (Env): Episode done for env 43. Reward: -16.35, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 23.14, Length: 1
DEBUG (Env): Episode done for env 85. Reward: 23.24, Length: 6
DEBUG (Env): Episode done for env 102. Reward: 26.89, Length: 19
DEBUG (Env): Episode done for env 104. Reward: -27.53, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -18.38, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 27.44, Length: 2
1899
Time taken for simulation:  7.308003187179565
average overall reward:  0.4864053  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.24790308  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: -19.98, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 22.08, Length: 9
DEBUG (Env): Episode done for env 53. Reward: 31.96, Length: 9
DEBUG (Env): Episode done for env 83. Reward: 18.68, Length: 34
DEBUG (Env): Episode done for env 112. Reward: 22.80, Length: 14
1900
Time taken for simulation:  7.194864273071289
average overall reward:  0.15665095  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.18020163 average distance reward:  0.47846308  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 56. Reward: -27.31, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -20.77, Length: 36
DEBUG (Env): Episode done for env 115. Reward: -17.58, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -20.79, Length: 36
1901
Time taken for simulation:  7.6178367137908936
average overall reward:  0.5222795  average fail penalty:  -0.140625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.33660713  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 13. Reward: 23.21, Length: 21
DEBUG (Env): Episode done for env 40. Reward: 37.09, Length: 10
DEBUG (Env): Episode done for env 58. Reward: -16.79, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 7.82, Length: 26
DEBUG (Env): Episode done for env 73. Reward: -15.77, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -13.84, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -27.36, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -25.60, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 19.69, Length: 7
DEBUG (Env): Episode done for env 125. Reward: -16.02, Length: 36
1902
Time taken for simulation:  7.259042024612427
average overall reward:  0.44987828  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.03508374  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 11. Reward: -10.25, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 11.33, Length: 30
DEBUG (Env): Episode done for env 46. Reward: 39.50, Length: 12
DEBUG (Env): Episode done for env 58. Reward: 16.89, Length: 1
DEBUG (Env): Episode done for env 64. Reward: -14.04, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 19.60, Length: 22
DEBUG (Env): Episode done for env 125. Reward: 18.79, Length: 1
1903
Time taken for simulation:  7.28056263923645
average overall reward:  -0.032093644  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.115843914 average distance reward:  -0.09225823  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 21. Reward: 27.49, Length: 6
DEBUG (Env): Episode done for env 42. Reward: -16.14, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -15.83, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 25.00, Length: 5
1904
Time taken for simulation:  7.488166570663452
average overall reward:  0.7762979  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.16733009 average distance reward:  0.31462845  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: 27.42, Length: 17
DEBUG (Env): Episode done for env 21. Reward: 15.68, Length: 1
DEBUG (Env): Episode done for env 24. Reward: 15.43, Length: 35
DEBUG (Env): Episode done for env 88. Reward: 10.58, Length: 22
DEBUG (Env): Episode done for env 89. Reward: 11.78, Length: 33
1905
Time taken for simulation:  7.365841388702393
average overall reward:  0.49694914  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.12973148  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: 2.53, Length: 16
DEBUG (Env): Episode done for env 33. Reward: 23.78, Length: 10
DEBUG (Env): Episode done for env 76. Reward: -5.56, Length: 20
DEBUG (Env): Episode done for env 114. Reward: -15.71, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 25.48, Length: 27
1906
Time taken for simulation:  7.119155406951904
average overall reward:  1.3188025  average fail penalty:  -0.0234375  and average goal bonus:  1.0829761  and average same cell penalty:  -0.16733009 average distance reward:  0.47445446  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 19. Reward: 22.93, Length: 7
DEBUG (Env): Episode done for env 58. Reward: 28.53, Length: 4
DEBUG (Env): Episode done for env 59. Reward: 39.78, Length: 10
DEBUG (Env): Episode done for env 76. Reward: 22.64, Length: 1
DEBUG (Env): Episode done for env 82. Reward: 21.07, Length: 10
DEBUG (Env): Episode done for env 87. Reward: 27.10, Length: 15
DEBUG (Env): Episode done for env 103. Reward: -17.38, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 21.08, Length: 34
DEBUG (Env): Episode done for env 126. Reward: 23.56, Length: 8
1907
Time taken for simulation:  7.665741682052612
average overall reward:  1.1340309  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.12871546 average distance reward:  0.52181214  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 17.74, Length: 19
DEBUG (Env): Episode done for env 18. Reward: 23.55, Length: 8
DEBUG (Env): Episode done for env 52. Reward: 6.37, Length: 34
DEBUG (Env): Episode done for env 70. Reward: 30.09, Length: 18
DEBUG (Env): Episode done for env 73. Reward: 24.30, Length: 6
DEBUG (Env): Episode done for env 97. Reward: -23.23, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 17.33, Length: 2
1908
Time taken for simulation:  7.511515855789185
average overall reward:  0.41407  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.4053915  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 31. Reward: -12.61, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -15.65, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 23.95, Length: 7
DEBUG (Env): Episode done for env 81. Reward: 23.50, Length: 21
1909
Time taken for simulation:  7.114441633224487
average overall reward:  -0.010344684  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.14978397  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 0. Reward: 28.82, Length: 2
DEBUG (Env): Episode done for env 87. Reward: 33.89, Length: 3
DEBUG (Env): Episode done for env 111. Reward: 37.81, Length: 8
1910
Time taken for simulation:  7.230603933334351
average overall reward:  0.0032091364  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.043711282  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: -17.64, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 27.87, Length: 14
DEBUG (Env): Episode done for env 63. Reward: -18.61, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -14.93, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 19.84, Length: 9
1911
Time taken for simulation:  7.2210352420806885
average overall reward:  0.1331599  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.076904655  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: -14.63, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 23.73, Length: 7
DEBUG (Env): Episode done for env 23. Reward: 18.20, Length: 22
DEBUG (Env): Episode done for env 67. Reward: -15.70, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -13.39, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 33.86, Length: 7
1912
Time taken for simulation:  7.339083671569824
average overall reward:  0.24686569  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.27030247 average distance reward:  -0.08839391  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 25. Reward: 29.91, Length: 7
DEBUG (Env): Episode done for env 29. Reward: 15.66, Length: 22
DEBUG (Env): Episode done for env 46. Reward: 35.68, Length: 10
DEBUG (Env): Episode done for env 73. Reward: 23.07, Length: 5
DEBUG (Env): Episode done for env 92. Reward: 10.93, Length: 15
DEBUG (Env): Episode done for env 113. Reward: -8.13, Length: 36
1913
Time taken for simulation:  7.293633222579956
average overall reward:  0.86637497  average fail penalty:  -0.0703125  and average goal bonus:  1.0829761  and average same cell penalty:  -0.2574309 average distance reward:  0.15900269  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 5. Reward: 27.00, Length: 24
DEBUG (Env): Episode done for env 10. Reward: -12.08, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 20.19, Length: 2
DEBUG (Env): Episode done for env 44. Reward: -12.87, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 11.88, Length: 15
DEBUG (Env): Episode done for env 72. Reward: 6.12, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 27.27, Length: 4
DEBUG (Env): Episode done for env 90. Reward: 17.61, Length: 20
DEBUG (Env): Episode done for env 121. Reward: 13.29, Length: 19
DEBUG (Env): Episode done for env 125. Reward: 20.96, Length: 11
1914
Time taken for simulation:  7.100728511810303
average overall reward:  0.6068436  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.5271508  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: 25.08, Length: 1
DEBUG (Env): Episode done for env 71. Reward: -3.61, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 15.82, Length: 11
DEBUG (Env): Episode done for env 100. Reward: 22.63, Length: 20
DEBUG (Env): Episode done for env 110. Reward: -14.20, Length: 36
1915
Time taken for simulation:  7.241490125656128
average overall reward:  0.44682837  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.3027779  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 48. Reward: 31.81, Length: 23
DEBUG (Env): Episode done for env 74. Reward: -17.18, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -18.07, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 21.28, Length: 23
DEBUG (Env): Episode done for env 89. Reward: 29.24, Length: 11
1916
Time taken for simulation:  7.337169885635376
average overall reward:  0.025545403  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.24455936 average distance reward:  0.07065879  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 14. Reward: 28.41, Length: 18
DEBUG (Env): Episode done for env 24. Reward: 22.12, Length: 12
DEBUG (Env): Episode done for env 117. Reward: -18.65, Length: 36
1917
Time taken for simulation:  7.251859903335571
average overall reward:  1.3168397  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.24455938 average distance reward:  0.5497209  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 38. Reward: -10.21, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 23.76, Length: 14
DEBUG (Env): Episode done for env 44. Reward: 20.63, Length: 4
DEBUG (Env): Episode done for env 46. Reward: 34.29, Length: 5
DEBUG (Env): Episode done for env 56. Reward: 14.75, Length: 17
DEBUG (Env): Episode done for env 59. Reward: 24.43, Length: 11
DEBUG (Env): Episode done for env 91. Reward: 13.95, Length: 21
DEBUG (Env): Episode done for env 104. Reward: 24.73, Length: 19
DEBUG (Env): Episode done for env 115. Reward: 10.45, Length: 17
1918
Time taken for simulation:  7.5499231815338135
average overall reward:  0.5309814  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.032301098  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 26. Reward: 20.88, Length: 21
DEBUG (Env): Episode done for env 31. Reward: 25.54, Length: 10
DEBUG (Env): Episode done for env 34. Reward: 28.57, Length: 31
DEBUG (Env): Episode done for env 39. Reward: -15.70, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 17.73, Length: 1
DEBUG (Env): Episode done for env 88. Reward: 20.16, Length: 7
DEBUG (Env): Episode done for env 115. Reward: 23.25, Length: 1
DEBUG (Env): Episode done for env 127. Reward: -10.64, Length: 36
1919
Time taken for simulation:  7.2466912269592285
average overall reward:  0.022540674  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  0.026733756  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 61. Reward: -23.51, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 42.54, Length: 12
DEBUG (Env): Episode done for env 84. Reward: 18.74, Length: 4
DEBUG (Env): Episode done for env 98. Reward: -19.38, Length: 36
1920
Time taken for simulation:  7.312022686004639
average overall reward:  0.41783562  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.38732356  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -15.06, Length: 36
DEBUG (Env): Episode done for env 2. Reward: 24.15, Length: 23
DEBUG (Env): Episode done for env 9. Reward: 33.07, Length: 30
DEBUG (Env): Episode done for env 37. Reward: -23.33, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -25.10, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 21.09, Length: 6
1921
Time taken for simulation:  7.322389364242554
average overall reward:  0.5358385  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.24354438  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 4.60, Length: 30
DEBUG (Env): Episode done for env 25. Reward: 22.85, Length: 9
DEBUG (Env): Episode done for env 41. Reward: -9.47, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -19.32, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 33.02, Length: 14
DEBUG (Env): Episode done for env 87. Reward: 12.15, Length: 8
1922
Time taken for simulation:  7.310242414474487
average overall reward:  0.36600214  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.107711524  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 27. Reward: -9.36, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -20.88, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 23.41, Length: 12
DEBUG (Env): Episode done for env 36. Reward: -7.03, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 27.54, Length: 3
DEBUG (Env): Episode done for env 66. Reward: -13.95, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 31.75, Length: 12
DEBUG (Env): Episode done for env 107. Reward: 14.38, Length: 20
1923
Time taken for simulation:  7.4652934074401855
average overall reward:  0.25778618  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.00180123  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 29.28, Length: 12
DEBUG (Env): Episode done for env 15. Reward: -18.42, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 22.82, Length: 29
DEBUG (Env): Episode done for env 57. Reward: -12.03, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 34.02, Length: 17
DEBUG (Env): Episode done for env 90. Reward: 22.41, Length: 10
DEBUG (Env): Episode done for env 93. Reward: -12.39, Length: 36
1924
Time taken for simulation:  7.331061840057373
average overall reward:  -0.074277  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.018597685  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 88. Reward: 25.52, Length: 6
DEBUG (Env): Episode done for env 92. Reward: 23.46, Length: 12
DEBUG (Env): Episode done for env 99. Reward: -28.43, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -20.72, Length: 36
1925
Time taken for simulation:  7.245139837265015
average overall reward:  0.2197893  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.023324143  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 38. Reward: 30.17, Length: 8
DEBUG (Env): Episode done for env 42. Reward: 29.54, Length: 8
DEBUG (Env): Episode done for env 80. Reward: -13.29, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 6.51, Length: 35
DEBUG (Env): Episode done for env 97. Reward: 13.03, Length: 18
DEBUG (Env): Episode done for env 118. Reward: -12.70, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -17.74, Length: 36
1926
Time taken for simulation:  7.069612503051758
average overall reward:  0.28395218  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030244 average distance reward:  0.24287406  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 25.21, Length: 13
DEBUG (Env): Episode done for env 32. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 24.94, Length: 8
DEBUG (Env): Episode done for env 51. Reward: -18.08, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 10.42, Length: 23
1927
Time taken for simulation:  7.180617332458496
average overall reward:  0.7244984  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.41107258  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 26. Reward: 26.04, Length: 9
DEBUG (Env): Episode done for env 68. Reward: 32.48, Length: 7
DEBUG (Env): Episode done for env 88. Reward: 19.65, Length: 3
DEBUG (Env): Episode done for env 100. Reward: 14.50, Length: 13
1928
Time taken for simulation:  7.536191463470459
average overall reward:  0.7649634  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020163 average distance reward:  0.2276684  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 16. Reward: 21.60, Length: 33
DEBUG (Env): Episode done for env 39. Reward: 27.57, Length: 2
DEBUG (Env): Episode done for env 43. Reward: 24.83, Length: 30
DEBUG (Env): Episode done for env 65. Reward: 4.46, Length: 20
DEBUG (Env): Episode done for env 66. Reward: 34.04, Length: 6
DEBUG (Env): Episode done for env 96. Reward: -12.68, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 19.87, Length: 15
DEBUG (Env): Episode done for env 124. Reward: -15.42, Length: 36
1929
Time taken for simulation:  7.165612697601318
average overall reward:  0.75077516  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020163 average distance reward:  0.32541466  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 48. Reward: 12.43, Length: 14
DEBUG (Env): Episode done for env 54. Reward: -21.43, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 20.68, Length: 12
DEBUG (Env): Episode done for env 93. Reward: 26.00, Length: 6
DEBUG (Env): Episode done for env 118. Reward: 16.82, Length: 4
DEBUG (Env): Episode done for env 122. Reward: 2.24, Length: 24
1930
Time taken for simulation:  7.220946311950684
average overall reward:  0.28583837  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.09260733  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 42. Reward: 19.37, Length: 5
DEBUG (Env): Episode done for env 50. Reward: -23.74, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 31.10, Length: 22
DEBUG (Env): Episode done for env 97. Reward: 18.24, Length: 5
1931
Time taken for simulation:  7.564312219619751
average overall reward:  0.41370988  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.141587 average distance reward:  -0.003390193  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 20. Reward: -23.94, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 28.71, Length: 5
DEBUG (Env): Episode done for env 38. Reward: 19.90, Length: 6
DEBUG (Env): Episode done for env 49. Reward: -19.58, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -5.01, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 17.80, Length: 16
DEBUG (Env): Episode done for env 89. Reward: 33.84, Length: 16
DEBUG (Env): Episode done for env 96. Reward: 37.16, Length: 3
1932
Time taken for simulation:  7.23745322227478
average overall reward:  0.22979617  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.102972366 average distance reward:  0.203635  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: -13.85, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -21.42, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 18.37, Length: 11
DEBUG (Env): Episode done for env 55. Reward: -23.84, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 23.36, Length: 20
DEBUG (Env): Episode done for env 86. Reward: -16.74, Length: 36
1933
Time taken for simulation:  7.656003475189209
average overall reward:  0.5643462  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.3083613  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 39.09, Length: 20
DEBUG (Env): Episode done for env 28. Reward: -22.06, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 17.92, Length: 15
DEBUG (Env): Episode done for env 47. Reward: -12.32, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 29.90, Length: 31
DEBUG (Env): Episode done for env 66. Reward: 30.98, Length: 5
DEBUG (Env): Episode done for env 105. Reward: -7.30, Length: 36
1934
Time taken for simulation:  7.190293788909912
average overall reward:  0.25695875  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.090100825 average distance reward:  0.03567902  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: 25.65, Length: 24
DEBUG (Env): Episode done for env 26. Reward: 35.51, Length: 7
DEBUG (Env): Episode done for env 85. Reward: -20.56, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -15.17, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 11.03, Length: 16
1935
Time taken for simulation:  7.2491981983184814
average overall reward:  1.6447613  average fail penalty:  -0.0703125  and average goal bonus:  1.2183483  and average same cell penalty:  -0.18020165 average distance reward:  0.72478783  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 5. Reward: 17.36, Length: 9
DEBUG (Env): Episode done for env 18. Reward: 14.90, Length: 28
DEBUG (Env): Episode done for env 38. Reward: 48.46, Length: 4
DEBUG (Env): Episode done for env 45. Reward: 9.46, Length: 14
DEBUG (Env): Episode done for env 49. Reward: 25.95, Length: 4
DEBUG (Env): Episode done for env 53. Reward: -29.89, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -14.47, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 22.16, Length: 16
DEBUG (Env): Episode done for env 96. Reward: 40.32, Length: 4
DEBUG (Env): Episode done for env 97. Reward: 23.99, Length: 5
DEBUG (Env): Episode done for env 112. Reward: -11.84, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 34.23, Length: 10
1936
Time taken for simulation:  7.3125317096710205
average overall reward:  0.8520627  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.102972366 average distance reward:  0.23753847  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: 11.34, Length: 16
DEBUG (Env): Episode done for env 12. Reward: 15.53, Length: 32
DEBUG (Env): Episode done for env 31. Reward: 14.49, Length: 18
DEBUG (Env): Episode done for env 69. Reward: 32.05, Length: 6
DEBUG (Env): Episode done for env 73. Reward: 23.52, Length: 4
DEBUG (Env): Episode done for env 81. Reward: 16.78, Length: 28
DEBUG (Env): Episode done for env 101. Reward: -20.69, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -22.21, Length: 36
1937
Time taken for simulation:  7.302702903747559
average overall reward:  0.21490479  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.28317398 average distance reward:  0.098201126  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: -12.28, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -28.36, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 32.03, Length: 6
DEBUG (Env): Episode done for env 104. Reward: 11.34, Length: 20
DEBUG (Env): Episode done for env 106. Reward: -13.85, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 29.08, Length: 15
DEBUG (Env): Episode done for env 119. Reward: 16.11, Length: 2
DEBUG (Env): Episode done for env 120. Reward: -19.65, Length: 36
1938
Time taken for simulation:  7.20947790145874
average overall reward:  0.06569964  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.18797973  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 48.55, Length: 6
DEBUG (Env): Episode done for env 11. Reward: -4.44, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -17.51, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 10.96, Length: 15
DEBUG (Env): Episode done for env 85. Reward: 19.62, Length: 4
DEBUG (Env): Episode done for env 87. Reward: 16.26, Length: 17
1939
Time taken for simulation:  7.375438928604126
average overall reward:  1.1770328  average fail penalty:  0.0  and average goal bonus:  1.3537202  and average same cell penalty:  -0.21881628 average distance reward:  0.08998938  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 4. Reward: 15.72, Length: 16
DEBUG (Env): Episode done for env 15. Reward: 13.55, Length: 16
DEBUG (Env): Episode done for env 27. Reward: 30.99, Length: 17
DEBUG (Env): Episode done for env 30. Reward: 11.66, Length: 17
DEBUG (Env): Episode done for env 43. Reward: 39.12, Length: 11
DEBUG (Env): Episode done for env 59. Reward: 26.14, Length: 10
DEBUG (Env): Episode done for env 63. Reward: 12.95, Length: 29
DEBUG (Env): Episode done for env 65. Reward: 18.52, Length: 11
DEBUG (Env): Episode done for env 96. Reward: 31.30, Length: 4
DEBUG (Env): Episode done for env 98. Reward: 17.09, Length: 20
1940
Time taken for simulation:  7.383692979812622
average overall reward:  0.8037645  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.25820917  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 25.02, Length: 4
DEBUG (Env): Episode done for env 17. Reward: 23.28, Length: 2
DEBUG (Env): Episode done for env 31. Reward: 20.67, Length: 4
DEBUG (Env): Episode done for env 64. Reward: 18.62, Length: 7
DEBUG (Env): Episode done for env 86. Reward: 20.93, Length: 8
DEBUG (Env): Episode done for env 99. Reward: 25.08, Length: 16
1941
Time taken for simulation:  7.161130905151367
average overall reward:  1.0811981  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.090100825 average distance reward:  0.2949928  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 3. Reward: 15.39, Length: 9
DEBUG (Env): Episode done for env 16. Reward: 40.05, Length: 13
DEBUG (Env): Episode done for env 27. Reward: 28.33, Length: 2
DEBUG (Env): Episode done for env 33. Reward: -9.84, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 28.07, Length: 6
DEBUG (Env): Episode done for env 71. Reward: 3.09, Length: 27
DEBUG (Env): Episode done for env 76. Reward: 24.48, Length: 18
DEBUG (Env): Episode done for env 87. Reward: 25.03, Length: 3
1942
Time taken for simulation:  7.523203372955322
average overall reward:  0.038404897  average fail penalty:  -0.140625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.0957814  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 19. Reward: -20.03, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 7.58, Length: 20
DEBUG (Env): Episode done for env 58. Reward: -13.28, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -18.10, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 20.50, Length: 15
DEBUG (Env): Episode done for env 92. Reward: 22.18, Length: 18
DEBUG (Env): Episode done for env 103. Reward: -12.16, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 23.74, Length: 18
DEBUG (Env): Episode done for env 123. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -21.16, Length: 36
1943
Time taken for simulation:  7.159972190856934
average overall reward:  0.77614164  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.12871546 average distance reward:  0.16392298  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 28.70, Length: 9
DEBUG (Env): Episode done for env 15. Reward: 23.00, Length: 4
DEBUG (Env): Episode done for env 33. Reward: 22.72, Length: 2
DEBUG (Env): Episode done for env 62. Reward: 24.40, Length: 12
DEBUG (Env): Episode done for env 91. Reward: 15.59, Length: 26
DEBUG (Env): Episode done for env 113. Reward: -2.44, Length: 31
DEBUG (Env): Episode done for env 114. Reward: -15.11, Length: 36
1944
Time taken for simulation:  7.522793531417847
average overall reward:  0.19013673  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.09754616  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 7. Reward: 9.22, Length: 23
DEBUG (Env): Episode done for env 20. Reward: 8.43, Length: 13
DEBUG (Env): Episode done for env 75. Reward: 4.40, Length: 24
DEBUG (Env): Episode done for env 109. Reward: 17.74, Length: 2
1945
Time taken for simulation:  7.143192291259766
average overall reward:  0.6239675  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.24778765  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -9.52, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 9.77, Length: 29
DEBUG (Env): Episode done for env 90. Reward: 14.21, Length: 22
DEBUG (Env): Episode done for env 91. Reward: 21.35, Length: 2
DEBUG (Env): Episode done for env 93. Reward: 14.85, Length: 16
DEBUG (Env): Episode done for env 101. Reward: 17.99, Length: 9
DEBUG (Env): Episode done for env 111. Reward: -20.63, Length: 36
1946
Time taken for simulation:  7.413885593414307
average overall reward:  0.7607096  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.44497812  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: 12.44, Length: 32
DEBUG (Env): Episode done for env 78. Reward: -14.39, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 12.39, Length: 21
DEBUG (Env): Episode done for env 105. Reward: 43.17, Length: 13
DEBUG (Env): Episode done for env 109. Reward: 21.35, Length: 2
1947
Time taken for simulation:  7.301749229431152
average overall reward:  0.4011382  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.26765364  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 21. Reward: -17.10, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 17.92, Length: 8
DEBUG (Env): Episode done for env 67. Reward: -7.70, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -14.79, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 15.80, Length: 12
DEBUG (Env): Episode done for env 99. Reward: 20.55, Length: 7
1948
Time taken for simulation:  7.37007737159729
average overall reward:  0.5452795  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.18427676  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 16.75, Length: 3
DEBUG (Env): Episode done for env 19. Reward: 17.27, Length: 6
DEBUG (Env): Episode done for env 29. Reward: -14.27, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 22.15, Length: 11
DEBUG (Env): Episode done for env 63. Reward: 36.13, Length: 9
DEBUG (Env): Episode done for env 98. Reward: 26.95, Length: 9
1949
Time taken for simulation:  7.192420244216919
average overall reward:  0.63065434  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.12966844  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 27. Reward: 24.50, Length: 8
DEBUG (Env): Episode done for env 33. Reward: 15.58, Length: 6
DEBUG (Env): Episode done for env 52. Reward: 12.24, Length: 17
DEBUG (Env): Episode done for env 60. Reward: -18.88, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 38.93, Length: 16
DEBUG (Env): Episode done for env 72. Reward: -17.22, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 33.50, Length: 3
DEBUG (Env): Episode done for env 112. Reward: 29.61, Length: 14
DEBUG (Env): Episode done for env 125. Reward: -12.45, Length: 36
1950
Time taken for simulation:  7.5223071575164795
average overall reward:  0.30056462  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.13307664  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 58. Reward: 34.75, Length: 8
DEBUG (Env): Episode done for env 89. Reward: 9.06, Length: 13
DEBUG (Env): Episode done for env 97. Reward: 29.74, Length: 3
DEBUG (Env): Episode done for env 110. Reward: -25.49, Length: 36
1951
Time taken for simulation:  6.951194524765015
average overall reward:  0.30643505  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.05506122  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 25.09, Length: 3
DEBUG (Env): Episode done for env 57. Reward: 23.80, Length: 13
DEBUG (Env): Episode done for env 72. Reward: 24.11, Length: 2
DEBUG (Env): Episode done for env 79. Reward: -27.37, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 35.42, Length: 8
1952
Time taken for simulation:  7.278855562210083
average overall reward:  -0.2652213  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  -0.08704147  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 24. Reward: -18.42, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 19.48, Length: 13
DEBUG (Env): Episode done for env 117. Reward: -24.94, Length: 36
1953
Time taken for simulation:  7.821649789810181
average overall reward:  0.21712837  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.04067824  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 19.49, Length: 9
DEBUG (Env): Episode done for env 44. Reward: -25.54, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -9.99, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 27.97, Length: 27
DEBUG (Env): Episode done for env 110. Reward: 23.49, Length: 3
DEBUG (Env): Episode done for env 115. Reward: 15.78, Length: 19
1954
Time taken for simulation:  7.434954881668091
average overall reward:  0.27744347  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.04950716  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: 11.23, Length: 13
DEBUG (Env): Episode done for env 34. Reward: -2.49, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 25.95, Length: 3
DEBUG (Env): Episode done for env 63. Reward: 23.70, Length: 6
DEBUG (Env): Episode done for env 122. Reward: 21.55, Length: 25
DEBUG (Env): Episode done for env 127. Reward: -23.46, Length: 36
1955
Time taken for simulation:  7.448401927947998
average overall reward:  0.43840152  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.18702772  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: 25.41, Length: 2
DEBUG (Env): Episode done for env 41. Reward: -2.68, Length: 34
DEBUG (Env): Episode done for env 70. Reward: -28.36, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 20.02, Length: 4
DEBUG (Env): Episode done for env 93. Reward: 19.79, Length: 10
1956
Time taken for simulation:  7.211954832077026
average overall reward:  -0.2586112  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  -0.09560856  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: -14.48, Length: 36
DEBUG (Env): Episode done for env 9. Reward: -13.23, Length: 36
DEBUG (Env): Episode done for env 37. Reward: -18.74, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 18.50, Length: 5
1957
Time taken for simulation:  7.244932413101196
average overall reward:  0.49244228  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.29255468  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: -27.08, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 14.12, Length: 20
DEBUG (Env): Episode done for env 112. Reward: 18.41, Length: 8
DEBUG (Env): Episode done for env 117. Reward: 22.78, Length: 5
DEBUG (Env): Episode done for env 126. Reward: 21.11, Length: 15
1958
Time taken for simulation:  7.343944787979126
average overall reward:  0.13024095  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.112600416  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 25.47, Length: 18
DEBUG (Env): Episode done for env 35. Reward: -24.17, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 5.75, Length: 28
DEBUG (Env): Episode done for env 56. Reward: 25.01, Length: 5
DEBUG (Env): Episode done for env 61. Reward: -15.61, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -19.01, Length: 36
1959
Time taken for simulation:  7.394045114517212
average overall reward:  0.13400996  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.01800821  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 22. Reward: -13.83, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 25.39, Length: 11
DEBUG (Env): Episode done for env 79. Reward: 31.83, Length: 3
DEBUG (Env): Episode done for env 87. Reward: 25.26, Length: 18
1960
Time taken for simulation:  7.338647365570068
average overall reward:  1.2504882  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.19307318 average distance reward:  0.4084457  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: 20.75, Length: 21
DEBUG (Env): Episode done for env 12. Reward: 15.09, Length: 20
DEBUG (Env): Episode done for env 32. Reward: 19.54, Length: 29
DEBUG (Env): Episode done for env 74. Reward: 7.65, Length: 29
DEBUG (Env): Episode done for env 85. Reward: 39.84, Length: 22
DEBUG (Env): Episode done for env 89. Reward: 29.27, Length: 10
DEBUG (Env): Episode done for env 108. Reward: 40.12, Length: 7
DEBUG (Env): Episode done for env 127. Reward: 28.13, Length: 6
1961
Time taken for simulation:  7.202279329299927
average overall reward:  0.28201586  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020163 average distance reward:  -0.00797251  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 8.69, Length: 5
DEBUG (Env): Episode done for env 61. Reward: 24.90, Length: 3
DEBUG (Env): Episode done for env 94. Reward: -13.70, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 25.95, Length: 4
DEBUG (Env): Episode done for env 110. Reward: 26.02, Length: 8
1962
Time taken for simulation:  7.329045057296753
average overall reward:  0.856346  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.283174 average distance reward:  0.12784187  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: 29.54, Length: 21
DEBUG (Env): Episode done for env 6. Reward: 20.90, Length: 19
DEBUG (Env): Episode done for env 16. Reward: 11.18, Length: 8
DEBUG (Env): Episode done for env 44. Reward: 30.06, Length: 9
DEBUG (Env): Episode done for env 51. Reward: 2.35, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 16.95, Length: 22
DEBUG (Env): Episode done for env 81. Reward: 4.96, Length: 26
DEBUG (Env): Episode done for env 105. Reward: 27.41, Length: 16
DEBUG (Env): Episode done for env 109. Reward: 11.67, Length: 16
1963
Time taken for simulation:  7.310492515563965
average overall reward:  0.38346237  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.09116836  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 32. Reward: 27.35, Length: 3
DEBUG (Env): Episode done for env 56. Reward: 22.56, Length: 5
DEBUG (Env): Episode done for env 68. Reward: -17.24, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -22.63, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 27.52, Length: 26
DEBUG (Env): Episode done for env 114. Reward: 7.58, Length: 20
1964
Time taken for simulation:  7.218059539794922
average overall reward:  0.24848542  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.26324448  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 14.39, Length: 24
DEBUG (Env): Episode done for env 31. Reward: 19.25, Length: 6
DEBUG (Env): Episode done for env 39. Reward: -23.54, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -22.87, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -19.00, Length: 36
1965
Time taken for simulation:  7.188362121582031
average overall reward:  0.42596996  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.23434266  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 43. Reward: 23.78, Length: 26
DEBUG (Env): Episode done for env 48. Reward: -19.06, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -37.40, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 31.40, Length: 11
DEBUG (Env): Episode done for env 71. Reward: 12.51, Length: 24
DEBUG (Env): Episode done for env 118. Reward: -4.25, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 22.43, Length: 16
1966
Time taken for simulation:  7.268995046615601
average overall reward:  0.8237649  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.102972366 average distance reward:  0.18580315  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 11. Reward: 14.04, Length: 28
DEBUG (Env): Episode done for env 29. Reward: 18.53, Length: 18
DEBUG (Env): Episode done for env 41. Reward: 20.35, Length: 11
DEBUG (Env): Episode done for env 42. Reward: -30.30, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 33.98, Length: 5
DEBUG (Env): Episode done for env 79. Reward: 23.34, Length: 7
DEBUG (Env): Episode done for env 82. Reward: 14.33, Length: 24
1967
Time taken for simulation:  7.173654317855835
average overall reward:  0.38306898  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.04389994  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 38. Reward: 15.47, Length: 26
DEBUG (Env): Episode done for env 60. Reward: 35.52, Length: 18
DEBUG (Env): Episode done for env 85. Reward: 35.88, Length: 7
DEBUG (Env): Episode done for env 108. Reward: 23.05, Length: 7
1968
Time taken for simulation:  7.379210710525513
average overall reward:  0.18134588  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.11683031  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 30. Reward: 17.74, Length: 16
DEBUG (Env): Episode done for env 55. Reward: -17.14, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 27.71, Length: 29
DEBUG (Env): Episode done for env 97. Reward: 16.22, Length: 18
1969
Time taken for simulation:  7.186898231506348
average overall reward:  0.36644334  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  0.21778174  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: -16.61, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -10.71, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 24.89, Length: 3
DEBUG (Env): Episode done for env 46. Reward: -10.29, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -14.16, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 4.01, Length: 28
DEBUG (Env): Episode done for env 105. Reward: 19.67, Length: 7
1970
Time taken for simulation:  7.474424839019775
average overall reward:  0.037893176  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  -0.028927997  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 26. Reward: -13.01, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 19.25, Length: 1
DEBUG (Env): Episode done for env 72. Reward: 18.03, Length: 15
DEBUG (Env): Episode done for env 99. Reward: 8.58, Length: 23
DEBUG (Env): Episode done for env 102. Reward: -9.81, Length: 36
1971
Time taken for simulation:  7.343549728393555
average overall reward:  -0.09495792  average fail penalty:  -0.1640625  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.052165806  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 5. Reward: -19.94, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -15.69, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -21.99, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -18.95, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -17.85, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 2.54, Length: 21
DEBUG (Env): Episode done for env 66. Reward: 7.68, Length: 22
DEBUG (Env): Episode done for env 83. Reward: -24.72, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -36.97, Length: 36
1972
Time taken for simulation:  7.467784643173218
average overall reward:  -0.23211762  average fail penalty:  -0.09375  and average goal bonus:  0.0  and average same cell penalty:  -0.16733009 average distance reward:  0.07682304  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: -26.56, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -10.06, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -18.74, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -20.07, Length: 36
1973
Time taken for simulation:  7.326675176620483
average overall reward:  0.29819694  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594475 average distance reward:  0.2396361  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: -18.92, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 24.02, Length: 2
DEBUG (Env): Episode done for env 57. Reward: 28.39, Length: 19
DEBUG (Env): Episode done for env 65. Reward: 28.32, Length: 5
DEBUG (Env): Episode done for env 107. Reward: -16.47, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -22.18, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -29.10, Length: 36
1974
Time taken for simulation:  7.231867790222168
average overall reward:  -0.099335656  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  -0.3249663  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: 25.63, Length: 19
DEBUG (Env): Episode done for env 8. Reward: -20.97, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 9.46, Length: 25
DEBUG (Env): Episode done for env 87. Reward: 28.05, Length: 15
DEBUG (Env): Episode done for env 114. Reward: 33.38, Length: 11
1975
Time taken for simulation:  7.458514451980591
average overall reward:  0.37639678  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.38289544  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 43. Reward: 36.35, Length: 10
DEBUG (Env): Episode done for env 74. Reward: 34.62, Length: 15
DEBUG (Env): Episode done for env 96. Reward: -21.44, Length: 36
1976
Time taken for simulation:  7.399874448776245
average overall reward:  0.6852785  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.51779056  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 33. Reward: 6.75, Length: 27
DEBUG (Env): Episode done for env 37. Reward: 15.69, Length: 20
DEBUG (Env): Episode done for env 44. Reward: 13.25, Length: 14
DEBUG (Env): Episode done for env 86. Reward: -20.37, Length: 36
1977
Time taken for simulation:  7.33535099029541
average overall reward:  0.71936774  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.36732715  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: 42.52, Length: 5
DEBUG (Env): Episode done for env 8. Reward: 16.70, Length: 3
DEBUG (Env): Episode done for env 82. Reward: 23.69, Length: 11
DEBUG (Env): Episode done for env 87. Reward: 18.60, Length: 3
1978
Time taken for simulation:  7.242334842681885
average overall reward:  0.9395776  average fail penalty:  -0.1171875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.35009453  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 31. Reward: 19.92, Length: 14
DEBUG (Env): Episode done for env 36. Reward: -18.21, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 27.85, Length: 2
DEBUG (Env): Episode done for env 40. Reward: 8.37, Length: 19
DEBUG (Env): Episode done for env 53. Reward: 13.35, Length: 7
DEBUG (Env): Episode done for env 57. Reward: 26.81, Length: 5
DEBUG (Env): Episode done for env 79. Reward: 17.53, Length: 12
DEBUG (Env): Episode done for env 88. Reward: -8.83, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -24.84, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -22.98, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 29.35, Length: 14
DEBUG (Env): Episode done for env 123. Reward: -18.66, Length: 36
1979
Time taken for simulation:  7.315675497055054
average overall reward:  0.5967107  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.31728822  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: 45.74, Length: 6
DEBUG (Env): Episode done for env 15. Reward: 12.61, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 25.65, Length: 22
DEBUG (Env): Episode done for env 62. Reward: -19.82, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 34.61, Length: 9
DEBUG (Env): Episode done for env 117. Reward: 24.00, Length: 22
1980
Time taken for simulation:  7.4681220054626465
average overall reward:  0.3968587  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.09169314  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 15.94, Length: 1
DEBUG (Env): Episode done for env 20. Reward: -25.82, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 15.50, Length: 2
DEBUG (Env): Episode done for env 67. Reward: 7.60, Length: 33
DEBUG (Env): Episode done for env 75. Reward: -18.37, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 37.68, Length: 9
1981
Time taken for simulation:  7.326494216918945
average overall reward:  0.8512731  average fail penalty:  -0.1171875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.26179022  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 0. Reward: -23.26, Length: 36
DEBUG (Env): Episode done for env 8. Reward: 28.05, Length: 4
DEBUG (Env): Episode done for env 33. Reward: 45.27, Length: 5
DEBUG (Env): Episode done for env 46. Reward: 22.43, Length: 12
DEBUG (Env): Episode done for env 59. Reward: 12.29, Length: 34
DEBUG (Env): Episode done for env 76. Reward: 33.59, Length: 12
DEBUG (Env): Episode done for env 90. Reward: -25.48, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -10.36, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 6.59, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -13.76, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 26.77, Length: 24
1982
Time taken for simulation:  7.2426018714904785
average overall reward:  0.44246376  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.28554177  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: -10.15, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 11.69, Length: 28
DEBUG (Env): Episode done for env 40. Reward: 27.01, Length: 4
DEBUG (Env): Episode done for env 71. Reward: 18.18, Length: 17
DEBUG (Env): Episode done for env 78. Reward: -21.66, Length: 36
1983
Time taken for simulation:  7.22249960899353
average overall reward:  1.0102615  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.1673301 average distance reward:  0.460095  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 9.62, Length: 12
DEBUG (Env): Episode done for env 21. Reward: 18.01, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 26.18, Length: 5
DEBUG (Env): Episode done for env 39. Reward: 45.03, Length: 19
DEBUG (Env): Episode done for env 45. Reward: 48.89, Length: 12
DEBUG (Env): Episode done for env 77. Reward: -29.51, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 11.23, Length: 21
1984
Time taken for simulation:  7.396527051925659
average overall reward:  0.48497102  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  -0.07806705  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 14. Reward: -23.08, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 19.46, Length: 4
DEBUG (Env): Episode done for env 72. Reward: 23.94, Length: 5
DEBUG (Env): Episode done for env 79. Reward: 42.71, Length: 6
DEBUG (Env): Episode done for env 86. Reward: 23.92, Length: 8
DEBUG (Env): Episode done for env 98. Reward: -2.09, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 27.36, Length: 3
1985
Time taken for simulation:  7.600903034210205
average overall reward:  0.6047734  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.40258008  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: -25.31, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 9.15, Length: 22
DEBUG (Env): Episode done for env 39. Reward: 32.96, Length: 2
DEBUG (Env): Episode done for env 48. Reward: 24.80, Length: 20
DEBUG (Env): Episode done for env 51. Reward: 24.87, Length: 23
DEBUG (Env): Episode done for env 80. Reward: -42.74, Length: 36
1986
Time taken for simulation:  7.23628306388855
average overall reward:  1.0488362  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.12871546 average distance reward:  0.142436  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: 28.37, Length: 12
DEBUG (Env): Episode done for env 15. Reward: 17.25, Length: 6
DEBUG (Env): Episode done for env 25. Reward: 23.70, Length: 7
DEBUG (Env): Episode done for env 29. Reward: 19.15, Length: 20
DEBUG (Env): Episode done for env 49. Reward: 38.46, Length: 13
DEBUG (Env): Episode done for env 73. Reward: 23.34, Length: 14
DEBUG (Env): Episode done for env 82. Reward: 23.65, Length: 9
DEBUG (Env): Episode done for env 119. Reward: 30.08, Length: 13
1987
Time taken for simulation:  7.124840974807739
average overall reward:  0.3534121  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.115843914 average distance reward:  -0.11286855  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 7. Reward: 12.28, Length: 1
DEBUG (Env): Episode done for env 12. Reward: 24.91, Length: 27
DEBUG (Env): Episode done for env 19. Reward: -33.36, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 19.73, Length: 4
DEBUG (Env): Episode done for env 53. Reward: 16.14, Length: 7
DEBUG (Env): Episode done for env 59. Reward: 18.10, Length: 6
DEBUG (Env): Episode done for env 113. Reward: -23.30, Length: 36
1988
Time taken for simulation:  7.290032863616943
average overall reward:  0.3906017  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.08774181  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: 21.79, Length: 26
DEBUG (Env): Episode done for env 24. Reward: -22.13, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 16.97, Length: 25
DEBUG (Env): Episode done for env 76. Reward: 32.36, Length: 7
DEBUG (Env): Episode done for env 105. Reward: 39.93, Length: 19
1989
Time taken for simulation:  7.379615545272827
average overall reward:  1.031062  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.59282994  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 19.78, Length: 5
DEBUG (Env): Episode done for env 28. Reward: 15.57, Length: 20
DEBUG (Env): Episode done for env 29. Reward: 33.56, Length: 3
DEBUG (Env): Episode done for env 30. Reward: 18.98, Length: 21
DEBUG (Env): Episode done for env 110. Reward: 16.22, Length: 28
DEBUG (Env): Episode done for env 115. Reward: -16.05, Length: 36
1990
Time taken for simulation:  7.193573951721191
average overall reward:  1.136219  average fail penalty:  -0.0234375  and average goal bonus:  0.8122322  and average same cell penalty:  -0.19307318 average distance reward:  0.58835816  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 44.04, Length: 7
DEBUG (Env): Episode done for env 40. Reward: 29.06, Length: 8
DEBUG (Env): Episode done for env 52. Reward: 20.55, Length: 16
DEBUG (Env): Episode done for env 57. Reward: 32.40, Length: 12
DEBUG (Env): Episode done for env 88. Reward: 16.44, Length: 12
DEBUG (Env): Episode done for env 113. Reward: 36.26, Length: 3
DEBUG (Env): Episode done for env 122. Reward: -18.34, Length: 36
1991
Time taken for simulation:  7.540512561798096
average overall reward:  -0.03322171  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  0.15782961  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 70. Reward: -20.31, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -13.95, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 40.75, Length: 26
1992
Time taken for simulation:  7.43564248085022
average overall reward:  0.64473933  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.058263715  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: -19.14, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 38.86, Length: 8
DEBUG (Env): Episode done for env 31. Reward: 34.37, Length: 9
DEBUG (Env): Episode done for env 50. Reward: 2.41, Length: 34
DEBUG (Env): Episode done for env 68. Reward: 25.94, Length: 4
DEBUG (Env): Episode done for env 109. Reward: 21.15, Length: 9
DEBUG (Env): Episode done for env 111. Reward: 42.42, Length: 11
1993
Time taken for simulation:  7.5955212116241455
average overall reward:  0.6105652  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.19807622  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 71. Reward: 26.42, Length: 11
DEBUG (Env): Episode done for env 83. Reward: 16.07, Length: 13
DEBUG (Env): Episode done for env 111. Reward: 20.38, Length: 1
DEBUG (Env): Episode done for env 113. Reward: 19.07, Length: 3
DEBUG (Env): Episode done for env 122. Reward: 14.26, Length: 3
DEBUG (Env): Episode done for env 126. Reward: -15.51, Length: 36
1994
Time taken for simulation:  7.247330188751221
average overall reward:  0.46495736  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.0630344  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 32. Reward: 23.34, Length: 9
DEBUG (Env): Episode done for env 35. Reward: -17.86, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 6.59, Length: 18
DEBUG (Env): Episode done for env 67. Reward: 18.69, Length: 14
DEBUG (Env): Episode done for env 87. Reward: 16.75, Length: 17
DEBUG (Env): Episode done for env 88. Reward: 35.48, Length: 4
DEBUG (Env): Episode done for env 95. Reward: -27.51, Length: 36
1995
Time taken for simulation:  7.417776346206665
average overall reward:  0.6800052  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.6154896  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 22. Reward: -16.58, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 0.64, Length: 28
DEBUG (Env): Episode done for env 72. Reward: 38.66, Length: 11
DEBUG (Env): Episode done for env 98. Reward: 33.14, Length: 11
1996
Time taken for simulation:  7.476866006851196
average overall reward:  0.60938084  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455938 average distance reward:  0.15988103  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: 16.79, Length: 19
DEBUG (Env): Episode done for env 4. Reward: -20.50, Length: 36
DEBUG (Env): Episode done for env 11. Reward: 4.82, Length: 30
DEBUG (Env): Episode done for env 14. Reward: 30.23, Length: 7
DEBUG (Env): Episode done for env 20. Reward: 34.09, Length: 4
DEBUG (Env): Episode done for env 58. Reward: 27.38, Length: 25
DEBUG (Env): Episode done for env 66. Reward: 24.50, Length: 25
DEBUG (Env): Episode done for env 89. Reward: -17.16, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -19.59, Length: 36
1997
Time taken for simulation:  7.354296922683716
average overall reward:  0.897745  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.16733009 average distance reward:  0.23564401  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 1. Reward: -21.91, Length: 36
DEBUG (Env): Episode done for env 6. Reward: 25.56, Length: 9
DEBUG (Env): Episode done for env 14. Reward: 14.58, Length: 1
DEBUG (Env): Episode done for env 25. Reward: 18.94, Length: 11
DEBUG (Env): Episode done for env 30. Reward: 33.72, Length: 8
DEBUG (Env): Episode done for env 94. Reward: -10.42, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -15.33, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 28.27, Length: 9
DEBUG (Env): Episode done for env 110. Reward: 30.12, Length: 8
DEBUG (Env): Episode done for env 123. Reward: 20.20, Length: 19
1998
Time taken for simulation:  7.322906017303467
average overall reward:  0.40696144  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.064784996  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: -10.43, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -14.39, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 19.53, Length: 12
DEBUG (Env): Episode done for env 50. Reward: 35.33, Length: 6
DEBUG (Env): Episode done for env 55. Reward: 3.63, Length: 30
DEBUG (Env): Episode done for env 64. Reward: -27.76, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -11.99, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 10.17, Length: 28
DEBUG (Env): Episode done for env 114. Reward: 26.35, Length: 24
1999
Time taken for simulation:  7.334413528442383
average overall reward:  -0.1438882  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.103386045  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 19.13, Length: 3
DEBUG (Env): Episode done for env 9. Reward: 17.79, Length: 7
DEBUG (Env): Episode done for env 56. Reward: -17.81, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -14.05, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -13.73, Length: 36
2000
Time taken for simulation:  7.079154014587402
average overall reward:  0.82154435  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.21881628 average distance reward:  0.18749198  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 17. Reward: -25.78, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 16.18, Length: 8
DEBUG (Env): Episode done for env 36. Reward: 21.90, Length: 22
DEBUG (Env): Episode done for env 51. Reward: 23.12, Length: 15
DEBUG (Env): Episode done for env 73. Reward: 22.74, Length: 14
DEBUG (Env): Episode done for env 83. Reward: 25.41, Length: 7
DEBUG (Env): Episode done for env 95. Reward: 23.70, Length: 6
DEBUG (Env): Episode done for env 96. Reward: 17.00, Length: 25
DEBUG (Env): Episode done for env 124. Reward: -14.24, Length: 36
2001
Time taken for simulation:  7.285544157028198
average overall reward:  0.040883556  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  -0.028243206  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 54. Reward: -17.63, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -20.34, Length: 36
DEBUG (Env): Episode done for env 93. Reward: 25.66, Length: 10
DEBUG (Env): Episode done for env 100. Reward: 23.09, Length: 2
DEBUG (Env): Episode done for env 125. Reward: 10.30, Length: 36
2002
Time taken for simulation:  7.54915452003479
average overall reward:  0.31437457  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.03495203  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 13.37, Length: 5
DEBUG (Env): Episode done for env 33. Reward: 12.85, Length: 21
DEBUG (Env): Episode done for env 42. Reward: -1.65, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -21.29, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 17.63, Length: 5
DEBUG (Env): Episode done for env 120. Reward: 16.31, Length: 29
2003
Time taken for simulation:  7.229820966720581
average overall reward:  0.8303884  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.27030247 average distance reward:  0.2712597  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 7. Reward: 28.09, Length: 16
DEBUG (Env): Episode done for env 17. Reward: 22.05, Length: 3
DEBUG (Env): Episode done for env 30. Reward: 33.61, Length: 6
DEBUG (Env): Episode done for env 35. Reward: 15.91, Length: 9
DEBUG (Env): Episode done for env 60. Reward: -15.21, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 28.33, Length: 9
DEBUG (Env): Episode done for env 85. Reward: -10.82, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 17.49, Length: 9
DEBUG (Env): Episode done for env 93. Reward: 18.16, Length: 2
DEBUG (Env): Episode done for env 108. Reward: -15.85, Length: 36
2004
Time taken for simulation:  7.244492292404175
average overall reward:  0.22110662  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.18899071  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 33. Reward: 21.23, Length: 2
DEBUG (Env): Episode done for env 97. Reward: -22.19, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 21.84, Length: 18
2005
Time taken for simulation:  7.181893348693848
average overall reward:  1.2264222  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.11584391 average distance reward:  0.4893975  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: 22.95, Length: 9
DEBUG (Env): Episode done for env 6. Reward: 24.99, Length: 8
DEBUG (Env): Episode done for env 10. Reward: -10.53, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -15.42, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 24.93, Length: 5
DEBUG (Env): Episode done for env 87. Reward: 20.83, Length: 2
DEBUG (Env): Episode done for env 91. Reward: 26.01, Length: 24
DEBUG (Env): Episode done for env 116. Reward: 2.69, Length: 33
DEBUG (Env): Episode done for env 117. Reward: 21.66, Length: 26
2006
Time taken for simulation:  7.061488628387451
average overall reward:  -0.2863617  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.2587311  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 26. Reward: -17.02, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -22.45, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 9.87, Length: 34
DEBUG (Env): Episode done for env 99. Reward: -13.66, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 33.26, Length: 4
2007
Time taken for simulation:  7.283244371414185
average overall reward:  0.75945365  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.4671597  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: -22.06, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 23.48, Length: 18
DEBUG (Env): Episode done for env 31. Reward: 17.09, Length: 7
DEBUG (Env): Episode done for env 41. Reward: 12.83, Length: 2
DEBUG (Env): Episode done for env 84. Reward: -14.81, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 24.92, Length: 16
2008
Time taken for simulation:  7.189594268798828
average overall reward:  0.86761004  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.28344002  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 37. Reward: 11.31, Length: 30
DEBUG (Env): Episode done for env 66. Reward: 19.84, Length: 12
DEBUG (Env): Episode done for env 77. Reward: 20.07, Length: 25
DEBUG (Env): Episode done for env 80. Reward: 8.39, Length: 23
DEBUG (Env): Episode done for env 87. Reward: 21.72, Length: 3
DEBUG (Env): Episode done for env 106. Reward: 20.10, Length: 9
2009
Time taken for simulation:  7.1427130699157715
average overall reward:  0.7418964  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  0.12071549  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: 28.94, Length: 4
DEBUG (Env): Episode done for env 9. Reward: 19.74, Length: 10
DEBUG (Env): Episode done for env 16. Reward: 11.42, Length: 11
DEBUG (Env): Episode done for env 32. Reward: 12.72, Length: 15
DEBUG (Env): Episode done for env 40. Reward: 26.79, Length: 19
DEBUG (Env): Episode done for env 56. Reward: 38.44, Length: 10
DEBUG (Env): Episode done for env 65. Reward: -12.60, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 28.50, Length: 12
DEBUG (Env): Episode done for env 107. Reward: -21.36, Length: 36
2010
Time taken for simulation:  7.060959339141846
average overall reward:  0.5315656  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.24388282  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: 23.63, Length: 12
DEBUG (Env): Episode done for env 35. Reward: 33.12, Length: 7
DEBUG (Env): Episode done for env 91. Reward: 28.25, Length: 5
DEBUG (Env): Episode done for env 116. Reward: 27.09, Length: 5
2011
Time taken for simulation:  7.2733728885650635
average overall reward:  1.2835376  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.12871546 average distance reward:  0.55938447  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 10. Reward: 23.48, Length: 6
DEBUG (Env): Episode done for env 25. Reward: 19.06, Length: 14
DEBUG (Env): Episode done for env 37. Reward: 47.28, Length: 3
DEBUG (Env): Episode done for env 43. Reward: -15.98, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 15.43, Length: 10
DEBUG (Env): Episode done for env 67. Reward: 27.87, Length: 8
DEBUG (Env): Episode done for env 72. Reward: 16.28, Length: 16
DEBUG (Env): Episode done for env 74. Reward: -12.48, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 5.79, Length: 2
2012
Time taken for simulation:  7.170464992523193
average overall reward:  0.20205797  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.10788994  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 49. Reward: 21.60, Length: 14
DEBUG (Env): Episode done for env 108. Reward: 31.01, Length: 9
2013
Time taken for simulation:  7.235654830932617
average overall reward:  1.1543148  average fail penalty:  0.0  and average goal bonus:  1.0829761  and average same cell penalty:  -0.12871546 average distance reward:  0.24791439  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 23. Reward: 19.23, Length: 31
DEBUG (Env): Episode done for env 28. Reward: 14.51, Length: 24
DEBUG (Env): Episode done for env 59. Reward: 4.53, Length: 26
DEBUG (Env): Episode done for env 80. Reward: 14.66, Length: 5
DEBUG (Env): Episode done for env 85. Reward: 22.26, Length: 10
DEBUG (Env): Episode done for env 90. Reward: 6.16, Length: 32
DEBUG (Env): Episode done for env 118. Reward: 20.01, Length: 6
DEBUG (Env): Episode done for env 126. Reward: 21.04, Length: 20
2014
Time taken for simulation:  7.064862489700317
average overall reward:  -0.4537209  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.1673301 average distance reward:  -0.3035898  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 9. Reward: 31.90, Length: 5
DEBUG (Env): Episode done for env 92. Reward: -22.01, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -14.27, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -18.72, Length: 36
2015
Time taken for simulation:  7.253990411758423
average overall reward:  0.8314172  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.29412222  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: 23.95, Length: 1
DEBUG (Env): Episode done for env 13. Reward: -8.67, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 25.72, Length: 2
DEBUG (Env): Episode done for env 29. Reward: 26.93, Length: 8
DEBUG (Env): Episode done for env 62. Reward: -20.83, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 15.99, Length: 4
DEBUG (Env): Episode done for env 95. Reward: 28.96, Length: 15
DEBUG (Env): Episode done for env 117. Reward: 14.78, Length: 10
2016
Time taken for simulation:  7.239680767059326
average overall reward:  0.09464598  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.047098875  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: 9.33, Length: 19
DEBUG (Env): Episode done for env 6. Reward: 37.46, Length: 11
DEBUG (Env): Episode done for env 75. Reward: -17.43, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 5.05, Length: 32
2017
Time taken for simulation:  7.254767179489136
average overall reward:  0.090947725  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.019515403  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -17.00, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -21.88, Length: 36
DEBUG (Env): Episode done for env 46. Reward: -13.17, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 21.75, Length: 7
DEBUG (Env): Episode done for env 93. Reward: 21.33, Length: 14
DEBUG (Env): Episode done for env 112. Reward: -26.52, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 10.25, Length: 20
2018
Time taken for simulation:  7.4482221603393555
average overall reward:  0.1695246  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  -0.0841548  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: 22.43, Length: 11
DEBUG (Env): Episode done for env 34. Reward: -11.83, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 11.62, Length: 17
DEBUG (Env): Episode done for env 78. Reward: -6.60, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 39.43, Length: 10
DEBUG (Env): Episode done for env 120. Reward: 23.77, Length: 12
2019
Time taken for simulation:  7.415399551391602
average overall reward:  0.5953531  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  0.24722187  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 21. Reward: -26.11, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 16.08, Length: 19
DEBUG (Env): Episode done for env 47. Reward: 19.85, Length: 13
DEBUG (Env): Episode done for env 54. Reward: 25.73, Length: 8
DEBUG (Env): Episode done for env 118. Reward: 21.62, Length: 6
DEBUG (Env): Episode done for env 125. Reward: 6.17, Length: 18
2020
Time taken for simulation:  7.205606460571289
average overall reward:  0.70652735  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.5238622  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: 20.73, Length: 30
DEBUG (Env): Episode done for env 72. Reward: 13.00, Length: 5
DEBUG (Env): Episode done for env 79. Reward: -7.43, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 37.88, Length: 6
DEBUG (Env): Episode done for env 101. Reward: -8.53, Length: 36
2021
Time taken for simulation:  7.187448740005493
average overall reward:  0.12399437  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.07722928 average distance reward:  0.04865259  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 9.65, Length: 34
DEBUG (Env): Episode done for env 27. Reward: -27.29, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -19.49, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -21.80, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 30.46, Length: 24
2022
Time taken for simulation:  7.200494766235352
average overall reward:  0.38927746  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.10985496  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: -15.61, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 19.41, Length: 26
DEBUG (Env): Episode done for env 25. Reward: 13.49, Length: 11
DEBUG (Env): Episode done for env 82. Reward: -26.23, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 38.81, Length: 3
DEBUG (Env): Episode done for env 121. Reward: 30.77, Length: 8
2023
Time taken for simulation:  7.241974353790283
average overall reward:  0.34656096  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.064832896  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 16.70, Length: 13
DEBUG (Env): Episode done for env 4. Reward: 14.46, Length: 24
DEBUG (Env): Episode done for env 8. Reward: 28.45, Length: 6
DEBUG (Env): Episode done for env 12. Reward: -15.11, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -21.27, Length: 36
DEBUG (Env): Episode done for env 53. Reward: -16.80, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 26.57, Length: 25
2024
Time taken for simulation:  7.18097996711731
average overall reward:  0.92671835  average fail penalty:  -0.046875  and average goal bonus:  1.2183483  and average same cell penalty:  -0.21881628 average distance reward:  0.021921903  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 16. Reward: 23.57, Length: 15
DEBUG (Env): Episode done for env 24. Reward: -24.77, Length: 36
DEBUG (Env): Episode done for env 30. Reward: 17.04, Length: 21
DEBUG (Env): Episode done for env 31. Reward: 21.15, Length: 6
DEBUG (Env): Episode done for env 47. Reward: 44.47, Length: 5
DEBUG (Env): Episode done for env 51. Reward: 5.31, Length: 24
DEBUG (Env): Episode done for env 72. Reward: 24.18, Length: 4
DEBUG (Env): Episode done for env 76. Reward: -20.86, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 20.47, Length: 20
DEBUG (Env): Episode done for env 125. Reward: 26.60, Length: 5
DEBUG (Env): Episode done for env 126. Reward: 26.17, Length: 11
2025
Time taken for simulation:  7.321310043334961
average overall reward:  -0.18936825  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.20594473 average distance reward:  0.0878745  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 115. Reward: -24.30, Length: 36
2026
Time taken for simulation:  7.383400917053223
average overall reward:  0.5368284  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  -0.00046662614  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 26. Reward: 14.32, Length: 20
DEBUG (Env): Episode done for env 34. Reward: 16.14, Length: 8
DEBUG (Env): Episode done for env 52. Reward: -17.81, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 13.99, Length: 28
DEBUG (Env): Episode done for env 57. Reward: -27.05, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 23.99, Length: 13
DEBUG (Env): Episode done for env 80. Reward: 8.55, Length: 13
DEBUG (Env): Episode done for env 81. Reward: 19.83, Length: 28
2027
Time taken for simulation:  7.326598405838013
average overall reward:  0.28559318  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  0.29209188  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 12. Reward: 10.43, Length: 4
DEBUG (Env): Episode done for env 28. Reward: 20.75, Length: 12
DEBUG (Env): Episode done for env 70. Reward: -11.49, Length: 36
2028
Time taken for simulation:  7.464564800262451
average overall reward:  0.97732127  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.3089171 average distance reward:  0.43336973  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 6. Reward: 38.29, Length: 12
DEBUG (Env): Episode done for env 22. Reward: 20.58, Length: 33
DEBUG (Env): Episode done for env 25. Reward: 23.31, Length: 6
DEBUG (Env): Episode done for env 62. Reward: 15.01, Length: 13
DEBUG (Env): Episode done for env 66. Reward: 14.89, Length: 20
DEBUG (Env): Episode done for env 68. Reward: -18.29, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 32.88, Length: 4
DEBUG (Env): Episode done for env 90. Reward: 22.73, Length: 15
DEBUG (Env): Episode done for env 109. Reward: -17.20, Length: 36
2029
Time taken for simulation:  7.318844556808472
average overall reward:  0.5474273  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.25673708  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: 19.43, Length: 6
DEBUG (Env): Episode done for env 52. Reward: 38.83, Length: 3
DEBUG (Env): Episode done for env 71. Reward: -24.60, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 20.97, Length: 1
DEBUG (Env): Episode done for env 75. Reward: 20.81, Length: 13
DEBUG (Env): Episode done for env 111. Reward: -16.07, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -18.14, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 25.12, Length: 7
DEBUG (Env): Episode done for env 122. Reward: -17.30, Length: 36
2030
Time taken for simulation:  7.257564306259155
average overall reward:  -0.32297993  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.11905703  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 44. Reward: -15.26, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 19.29, Length: 6
DEBUG (Env): Episode done for env 88. Reward: -19.75, Length: 36
2031
Time taken for simulation:  7.109649896621704
average overall reward:  0.4722115  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.19278902  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 38. Reward: -16.23, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 23.85, Length: 19
DEBUG (Env): Episode done for env 80. Reward: 15.31, Length: 5
DEBUG (Env): Episode done for env 98. Reward: 9.66, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 48.77, Length: 30
2032
Time taken for simulation:  7.342849254608154
average overall reward:  -0.056028724  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.088846385  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 11. Reward: -21.82, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -23.17, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -17.21, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 8.57, Length: 26
DEBUG (Env): Episode done for env 102. Reward: 2.95, Length: 34
DEBUG (Env): Episode done for env 120. Reward: 11.30, Length: 14
DEBUG (Env): Episode done for env 127. Reward: -24.14, Length: 36
2033
Time taken for simulation:  7.593744277954102
average overall reward:  0.27142078  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.0071754977  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 36. Reward: 34.90, Length: 14
DEBUG (Env): Episode done for env 67. Reward: 8.96, Length: 22
DEBUG (Env): Episode done for env 87. Reward: 31.99, Length: 15
DEBUG (Env): Episode done for env 103. Reward: 24.77, Length: 19
DEBUG (Env): Episode done for env 110. Reward: -17.40, Length: 36
2034
Time taken for simulation:  7.412625312805176
average overall reward:  0.69019854  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.249661  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 20.58, Length: 11
DEBUG (Env): Episode done for env 11. Reward: 23.25, Length: 2
DEBUG (Env): Episode done for env 37. Reward: 15.38, Length: 23
DEBUG (Env): Episode done for env 50. Reward: -17.04, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 22.95, Length: 12
DEBUG (Env): Episode done for env 114. Reward: -30.81, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 16.87, Length: 12
2035
Time taken for simulation:  7.405632972717285
average overall reward:  0.2942104  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  0.23865704  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 45. Reward: 14.43, Length: 12
DEBUG (Env): Episode done for env 63. Reward: 34.79, Length: 17
2036
Time taken for simulation:  7.386373281478882
average overall reward:  -0.30986017  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.16733009 average distance reward:  -0.024357066  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 73. Reward: -26.90, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -16.80, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -7.53, Length: 36
2037
Time taken for simulation:  7.284512281417847
average overall reward:  0.41682094  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.064780384  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: 26.21, Length: 10
DEBUG (Env): Episode done for env 78. Reward: 22.49, Length: 19
DEBUG (Env): Episode done for env 101. Reward: 22.07, Length: 17
DEBUG (Env): Episode done for env 102. Reward: 34.86, Length: 5
2038
Time taken for simulation:  7.044827461242676
average overall reward:  0.081368  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.035678692  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 31.17, Length: 9
DEBUG (Env): Episode done for env 12. Reward: 27.51, Length: 11
DEBUG (Env): Episode done for env 14. Reward: -7.34, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -26.29, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 27.58, Length: 8
DEBUG (Env): Episode done for env 61. Reward: -10.75, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -14.56, Length: 36
2039
Time taken for simulation:  7.663392782211304
average overall reward:  0.1803092  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.11118242  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: -9.88, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 18.28, Length: 1
DEBUG (Env): Episode done for env 17. Reward: -7.04, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -21.35, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 9.62, Length: 2
DEBUG (Env): Episode done for env 114. Reward: 23.11, Length: 5
2040
Time taken for simulation:  7.295299530029297
average overall reward:  0.7982069  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.29604554 average distance reward:  0.10601175  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 4. Reward: 16.40, Length: 6
DEBUG (Env): Episode done for env 16. Reward: 23.75, Length: 16
DEBUG (Env): Episode done for env 23. Reward: 16.36, Length: 27
DEBUG (Env): Episode done for env 33. Reward: -14.20, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 24.71, Length: 2
DEBUG (Env): Episode done for env 77. Reward: 7.71, Length: 32
DEBUG (Env): Episode done for env 81. Reward: 35.10, Length: 14
DEBUG (Env): Episode done for env 87. Reward: 26.72, Length: 7
DEBUG (Env): Episode done for env 91. Reward: 25.21, Length: 23
DEBUG (Env): Episode done for env 119. Reward: -27.15, Length: 36
2041
Time taken for simulation:  7.14297080039978
average overall reward:  0.51274526  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.40961504  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 57. Reward: 26.62, Length: 15
DEBUG (Env): Episode done for env 64. Reward: 20.68, Length: 18
DEBUG (Env): Episode done for env 83. Reward: -18.05, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 22.64, Length: 4
2042
Time taken for simulation:  7.28392481803894
average overall reward:  0.47278544  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.16992548  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 66. Reward: 32.85, Length: 14
DEBUG (Env): Episode done for env 69. Reward: -23.98, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 20.40, Length: 25
DEBUG (Env): Episode done for env 113. Reward: 31.76, Length: 13
DEBUG (Env): Episode done for env 120. Reward: 20.15, Length: 10
2043
Time taken for simulation:  7.367130994796753
average overall reward:  0.7529115  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455938 average distance reward:  0.30341172  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 5. Reward: -12.00, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 26.37, Length: 3
DEBUG (Env): Episode done for env 37. Reward: 22.15, Length: 9
DEBUG (Env): Episode done for env 41. Reward: -14.99, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 24.42, Length: 5
DEBUG (Env): Episode done for env 50. Reward: 57.43, Length: 9
DEBUG (Env): Episode done for env 84. Reward: -24.62, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 21.41, Length: 14
DEBUG (Env): Episode done for env 113. Reward: 25.75, Length: 1
2044
Time taken for simulation:  7.246601104736328
average overall reward:  0.24190494  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  -0.086698085  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 18.14, Length: 21
DEBUG (Env): Episode done for env 83. Reward: 18.49, Length: 3
DEBUG (Env): Episode done for env 93. Reward: 13.14, Length: 27
DEBUG (Env): Episode done for env 102. Reward: 21.74, Length: 3
DEBUG (Env): Episode done for env 106. Reward: -8.60, Length: 36
2045
Time taken for simulation:  7.370499134063721
average overall reward:  0.38846177  average fail penalty:  -0.140625  and average goal bonus:  0.67686015  and average same cell penalty:  -0.141587 average distance reward:  0.0416742  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 2. Reward: -21.15, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 27.91, Length: 7
DEBUG (Env): Episode done for env 15. Reward: 8.41, Length: 23
DEBUG (Env): Episode done for env 32. Reward: -22.38, Length: 36
DEBUG (Env): Episode done for env 40. Reward: -10.13, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -22.02, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 23.21, Length: 6
DEBUG (Env): Episode done for env 65. Reward: -14.99, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 9.16, Length: 21
DEBUG (Env): Episode done for env 107. Reward: -22.18, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 22.71, Length: 11
2046
Time taken for simulation:  7.378129243850708
average overall reward:  0.8227254  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  0.2015445  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 14. Reward: 19.90, Length: 7
DEBUG (Env): Episode done for env 33. Reward: 20.41, Length: 6
DEBUG (Env): Episode done for env 35. Reward: -18.64, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 17.24, Length: 20
DEBUG (Env): Episode done for env 94. Reward: 31.64, Length: 8
DEBUG (Env): Episode done for env 100. Reward: 39.95, Length: 15
DEBUG (Env): Episode done for env 110. Reward: 12.21, Length: 13
DEBUG (Env): Episode done for env 111. Reward: 20.40, Length: 3
DEBUG (Env): Episode done for env 116. Reward: -15.57, Length: 36
2047
Time taken for simulation:  7.131628513336182
average overall reward:  0.3814412  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.25852263  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: -18.28, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 18.04, Length: 8
DEBUG (Env): Episode done for env 43. Reward: -9.68, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -14.05, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 9.09, Length: 16
DEBUG (Env): Episode done for env 86. Reward: 13.09, Length: 31
DEBUG (Env): Episode done for env 105. Reward: -22.28, Length: 36
2048
Time taken for simulation:  6.9095869064331055
average overall reward:  0.60642326  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.5485642  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 93. Reward: 36.58, Length: 4
DEBUG (Env): Episode done for env 108. Reward: -17.95, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 48.62, Length: 8
2049
Time taken for simulation:  7.3367743492126465
average overall reward:  0.16502328  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.19726509  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 35. Reward: 16.22, Length: 3
DEBUG (Env): Episode done for env 85. Reward: -14.36, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 22.99, Length: 4
2050
Time taken for simulation:  7.043903827667236
average overall reward:  0.27761102  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.002799753  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 73. Reward: 4.09, Length: 14
DEBUG (Env): Episode done for env 76. Reward: 31.13, Length: 5
DEBUG (Env): Episode done for env 80. Reward: 22.42, Length: 3
DEBUG (Env): Episode done for env 123. Reward: 7.11, Length: 33
2051
Time taken for simulation:  7.2162792682647705
average overall reward:  0.543413  average fail penalty:  -0.1171875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.16733009 average distance reward:  0.19893092  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 9. Reward: -16.62, Length: 36
DEBUG (Env): Episode done for env 13. Reward: -9.04, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -0.44, Length: 29
DEBUG (Env): Episode done for env 29. Reward: -19.62, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 19.03, Length: 20
DEBUG (Env): Episode done for env 82. Reward: 18.15, Length: 17
DEBUG (Env): Episode done for env 92. Reward: 13.64, Length: 31
DEBUG (Env): Episode done for env 95. Reward: -16.82, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 38.78, Length: 5
DEBUG (Env): Episode done for env 117. Reward: -17.17, Length: 36
2052
Time taken for simulation:  7.4661829471588135
average overall reward:  0.62748873  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168783 average distance reward:  0.25361443  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 22.75, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 27.70, Length: 7
DEBUG (Env): Episode done for env 16. Reward: 43.87, Length: 9
DEBUG (Env): Episode done for env 38. Reward: 31.83, Length: 1
DEBUG (Env): Episode done for env 118. Reward: 20.44, Length: 23
2053
Time taken for simulation:  7.187214136123657
average overall reward:  0.65414894  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.23935446  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -11.22, Length: 36
DEBUG (Env): Episode done for env 5. Reward: 20.23, Length: 10
DEBUG (Env): Episode done for env 29. Reward: 25.89, Length: 2
DEBUG (Env): Episode done for env 30. Reward: 11.78, Length: 29
DEBUG (Env): Episode done for env 35. Reward: 30.05, Length: 4
DEBUG (Env): Episode done for env 46. Reward: -10.92, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 10.89, Length: 22
2054
Time taken for simulation:  7.295709609985352
average overall reward:  0.625317  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.3376342  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 30. Reward: 18.34, Length: 1
DEBUG (Env): Episode done for env 47. Reward: 22.93, Length: 30
DEBUG (Env): Episode done for env 94. Reward: 27.79, Length: 8
DEBUG (Env): Episode done for env 107. Reward: 26.23, Length: 5
2055
Time taken for simulation:  7.164669752120972
average overall reward:  1.0012171  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.5025367  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 21. Reward: -17.51, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -16.11, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 20.36, Length: 15
DEBUG (Env): Episode done for env 67. Reward: 12.49, Length: 22
DEBUG (Env): Episode done for env 80. Reward: 22.51, Length: 5
DEBUG (Env): Episode done for env 105. Reward: 14.70, Length: 8
DEBUG (Env): Episode done for env 120. Reward: 17.76, Length: 13
DEBUG (Env): Episode done for env 123. Reward: 16.00, Length: 5
2056
Time taken for simulation:  7.174540042877197
average overall reward:  0.19172639  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.06054746  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: -21.50, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -22.12, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 27.98, Length: 5
DEBUG (Env): Episode done for env 106. Reward: 24.98, Length: 12
DEBUG (Env): Episode done for env 117. Reward: 37.77, Length: 5
2057
Time taken for simulation:  7.34389591217041
average overall reward:  0.2412855  average fail penalty:  -0.1171875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.16754748  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 19. Reward: -14.30, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -18.94, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 29.34, Length: 12
DEBUG (Env): Episode done for env 39. Reward: -10.56, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -25.08, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 23.08, Length: 2
DEBUG (Env): Episode done for env 89. Reward: 19.98, Length: 25
DEBUG (Env): Episode done for env 104. Reward: -9.44, Length: 36
2058
Time taken for simulation:  7.202197790145874
average overall reward:  1.095222  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168783 average distance reward:  0.4271662  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 36. Reward: 28.15, Length: 25
DEBUG (Env): Episode done for env 39. Reward: 14.04, Length: 1
DEBUG (Env): Episode done for env 49. Reward: 25.12, Length: 27
DEBUG (Env): Episode done for env 65. Reward: 28.30, Length: 13
DEBUG (Env): Episode done for env 66. Reward: 23.49, Length: 16
DEBUG (Env): Episode done for env 83. Reward: 13.36, Length: 14
DEBUG (Env): Episode done for env 115. Reward: 13.61, Length: 33
2059
Time taken for simulation:  7.099658250808716
average overall reward:  -0.06485154  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  -0.03260971  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 13. Reward: 29.87, Length: 8
DEBUG (Env): Episode done for env 53. Reward: -15.08, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 21.39, Length: 12
2060
Time taken for simulation:  7.074716329574585
average overall reward:  0.83472466  average fail penalty:  -0.1171875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  0.4773712  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 24. Reward: -20.02, Length: 36
DEBUG (Env): Episode done for env 31. Reward: -8.22, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 21.46, Length: 13
DEBUG (Env): Episode done for env 44. Reward: 20.73, Length: 22
DEBUG (Env): Episode done for env 48. Reward: 24.48, Length: 3
DEBUG (Env): Episode done for env 73. Reward: 25.00, Length: 10
DEBUG (Env): Episode done for env 97. Reward: -22.86, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 27.74, Length: 5
DEBUG (Env): Episode done for env 125. Reward: -14.10, Length: 36
DEBUG (Env): Episode done for env 126. Reward: -14.35, Length: 36
2061
Time taken for simulation:  7.561566352844238
average overall reward:  0.4620728  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.32263353  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 63. Reward: 1.37, Length: 26
DEBUG (Env): Episode done for env 67. Reward: 33.41, Length: 4
DEBUG (Env): Episode done for env 108. Reward: 22.33, Length: 13
2062
Time taken for simulation:  7.450669765472412
average overall reward:  0.8687086  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.24522227  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 0. Reward: 28.96, Length: 9
DEBUG (Env): Episode done for env 25. Reward: 4.00, Length: 34
DEBUG (Env): Episode done for env 26. Reward: -12.99, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -21.96, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 33.47, Length: 9
DEBUG (Env): Episode done for env 55. Reward: -26.35, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 34.00, Length: 5
DEBUG (Env): Episode done for env 92. Reward: 26.76, Length: 6
DEBUG (Env): Episode done for env 119. Reward: 22.54, Length: 14
DEBUG (Env): Episode done for env 124. Reward: 3.06, Length: 26
2063
Time taken for simulation:  7.473609924316406
average overall reward:  0.05342543  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  -0.15933368  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 40. Reward: 10.96, Length: 18
DEBUG (Env): Episode done for env 70. Reward: -1.58, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 25.05, Length: 23
DEBUG (Env): Episode done for env 82. Reward: 22.12, Length: 12
DEBUG (Env): Episode done for env 98. Reward: 42.78, Length: 10
2064
Time taken for simulation:  7.304415225982666
average overall reward:  0.7468459  average fail penalty:  -0.140625  and average goal bonus:  0.81223214  and average same cell penalty:  -0.2574309 average distance reward:  0.38053015  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 6. Reward: -23.97, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 24.52, Length: 13
DEBUG (Env): Episode done for env 22. Reward: -17.45, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 29.06, Length: 6
DEBUG (Env): Episode done for env 62. Reward: -21.59, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -17.65, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 23.58, Length: 24
DEBUG (Env): Episode done for env 90. Reward: -14.19, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 22.18, Length: 18
DEBUG (Env): Episode done for env 104. Reward: 28.54, Length: 7
DEBUG (Env): Episode done for env 109. Reward: -16.85, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 15.85, Length: 25
2065
Time taken for simulation:  7.31443190574646
average overall reward:  0.00050096214  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594472 average distance reward:  0.100749694  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 52. Reward: -26.82, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -11.75, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -17.11, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -8.02, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 6.52, Length: 26
DEBUG (Env): Episode done for env 109. Reward: 19.74, Length: 1
DEBUG (Env): Episode done for env 122. Reward: -21.84, Length: 36
2066
Time taken for simulation:  7.187142372131348
average overall reward:  0.55580086  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.35360768  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 42. Reward: 15.44, Length: 23
DEBUG (Env): Episode done for env 47. Reward: 17.83, Length: 12
DEBUG (Env): Episode done for env 51. Reward: -24.81, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -4.02, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 27.80, Length: 4
DEBUG (Env): Episode done for env 113. Reward: 26.62, Length: 23
2067
Time taken for simulation:  7.379767179489136
average overall reward:  0.19751936  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.11584391 average distance reward:  0.09047976  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 18. Reward: 21.61, Length: 11
DEBUG (Env): Episode done for env 43. Reward: 14.06, Length: 7
2068
Time taken for simulation:  7.507020950317383
average overall reward:  0.109624624  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.28549883  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: 30.30, Length: 16
DEBUG (Env): Episode done for env 58. Reward: -12.98, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -11.75, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -7.62, Length: 36
2069
Time taken for simulation:  7.213031530380249
average overall reward:  0.59452116  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.14341766  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: 17.11, Length: 35
DEBUG (Env): Episode done for env 20. Reward: 26.38, Length: 18
DEBUG (Env): Episode done for env 47. Reward: 21.43, Length: 3
DEBUG (Env): Episode done for env 74. Reward: 18.05, Length: 22
DEBUG (Env): Episode done for env 98. Reward: 24.88, Length: 6
DEBUG (Env): Episode done for env 103. Reward: -12.78, Length: 36
2070
Time taken for simulation:  7.13408899307251
average overall reward:  0.1715139  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.29604554 average distance reward:  -0.026068155  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 10. Reward: 22.26, Length: 23
DEBUG (Env): Episode done for env 26. Reward: 37.23, Length: 8
DEBUG (Env): Episode done for env 96. Reward: 6.54, Length: 34
DEBUG (Env): Episode done for env 99. Reward: 28.96, Length: 2
2071
Time taken for simulation:  7.198531866073608
average overall reward:  -0.010214068  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.009156249  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 15. Reward: 17.85, Length: 26
DEBUG (Env): Episode done for env 45. Reward: -9.96, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 33.69, Length: 13
2072
Time taken for simulation:  7.143482446670532
average overall reward:  0.91565543  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.18020165 average distance reward:  0.19611341  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 53. Reward: 21.17, Length: 13
DEBUG (Env): Episode done for env 71. Reward: 25.73, Length: 7
DEBUG (Env): Episode done for env 82. Reward: 10.00, Length: 9
DEBUG (Env): Episode done for env 88. Reward: 18.40, Length: 6
DEBUG (Env): Episode done for env 106. Reward: 21.95, Length: 16
DEBUG (Env): Episode done for env 114. Reward: 26.39, Length: 8
DEBUG (Env): Episode done for env 120. Reward: 24.48, Length: 17
2073
Time taken for simulation:  7.358122825622559
average overall reward:  -0.014047056  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  -0.15809749  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: -19.72, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 34.71, Length: 9
DEBUG (Env): Episode done for env 101. Reward: -13.72, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 19.61, Length: 21
2074
Time taken for simulation:  7.216267108917236
average overall reward:  0.6423563  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.2427389  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: -48.77, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 21.97, Length: 28
DEBUG (Env): Episode done for env 35. Reward: 23.42, Length: 21
DEBUG (Env): Episode done for env 44. Reward: 33.70, Length: 14
DEBUG (Env): Episode done for env 47. Reward: 23.82, Length: 5
DEBUG (Env): Episode done for env 118. Reward: 15.89, Length: 1
2075
Time taken for simulation:  7.371936798095703
average overall reward:  0.7661069  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.095745474  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: -19.92, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 27.93, Length: 5
DEBUG (Env): Episode done for env 65. Reward: 21.50, Length: 17
DEBUG (Env): Episode done for env 88. Reward: 23.25, Length: 3
DEBUG (Env): Episode done for env 107. Reward: 14.92, Length: 21
DEBUG (Env): Episode done for env 117. Reward: 14.13, Length: 19
DEBUG (Env): Episode done for env 126. Reward: 33.08, Length: 15
DEBUG (Env): Episode done for env 127. Reward: 35.34, Length: 7
2076
Time taken for simulation:  7.529759168624878
average overall reward:  0.4603892  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.44044316  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: -16.07, Length: 36
DEBUG (Env): Episode done for env 6. Reward: 24.77, Length: 12
DEBUG (Env): Episode done for env 11. Reward: 25.09, Length: 7
DEBUG (Env): Episode done for env 23. Reward: -21.29, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 23.83, Length: 13
DEBUG (Env): Episode done for env 87. Reward: -24.79, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -10.82, Length: 36
2077
Time taken for simulation:  7.2520904541015625
average overall reward:  -0.36650908  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  -0.14971465  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 57. Reward: -13.65, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -22.37, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 14.67, Length: 22
2078
Time taken for simulation:  8.395418643951416
average overall reward:  0.5899511  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.27030244 average distance reward:  0.0073849857  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: 24.48, Length: 4
DEBUG (Env): Episode done for env 11. Reward: 19.62, Length: 2
DEBUG (Env): Episode done for env 21. Reward: 5.60, Length: 23
DEBUG (Env): Episode done for env 52. Reward: 32.27, Length: 13
DEBUG (Env): Episode done for env 69. Reward: -24.83, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 23.88, Length: 12
DEBUG (Env): Episode done for env 97. Reward: 23.66, Length: 18
DEBUG (Env): Episode done for env 105. Reward: 22.56, Length: 18
DEBUG (Env): Episode done for env 112. Reward: -11.89, Length: 36
2079
Time taken for simulation:  7.216851472854614
average overall reward:  0.8852444  average fail penalty:  -0.09375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.23168783 average distance reward:  0.17556666  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 17. Reward: 17.83, Length: 32
DEBUG (Env): Episode done for env 19. Reward: 22.46, Length: 22
DEBUG (Env): Episode done for env 37. Reward: -24.20, Length: 36
DEBUG (Env): Episode done for env 41. Reward: -11.67, Length: 36
DEBUG (Env): Episode done for env 50. Reward: -10.47, Length: 36
DEBUG (Env): Episode done for env 57. Reward: 38.60, Length: 2
DEBUG (Env): Episode done for env 58. Reward: 17.17, Length: 11
DEBUG (Env): Episode done for env 63. Reward: 19.76, Length: 18
DEBUG (Env): Episode done for env 64. Reward: 18.98, Length: 2
DEBUG (Env): Episode done for env 84. Reward: -21.57, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 17.36, Length: 9
DEBUG (Env): Episode done for env 108. Reward: 9.39, Length: 18
2080
Time taken for simulation:  7.3189592361450195
average overall reward:  0.029757794  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594473 average distance reward:  0.05969404  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 8. Reward: -19.20, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -0.77, Length: 28
DEBUG (Env): Episode done for env 102. Reward: -19.45, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 16.66, Length: 2
2081
Time taken for simulation:  7.091720819473267
average overall reward:  0.7034953  average fail penalty:  -0.09375  and average goal bonus:  0.8122322  and average same cell penalty:  -0.15445855 average distance reward:  0.18733232  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: -18.94, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 29.83, Length: 5
DEBUG (Env): Episode done for env 56. Reward: 4.11, Length: 36
DEBUG (Env): Episode done for env 60. Reward: -19.73, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 21.25, Length: 5
DEBUG (Env): Episode done for env 96. Reward: 25.79, Length: 11
DEBUG (Env): Episode done for env 107. Reward: 15.11, Length: 6
DEBUG (Env): Episode done for env 121. Reward: 1.10, Length: 36
2082
Time taken for simulation:  7.0879693031311035
average overall reward:  0.86228716  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.33325252  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 14. Reward: 8.39, Length: 36
DEBUG (Env): Episode done for env 34. Reward: 9.99, Length: 20
DEBUG (Env): Episode done for env 45. Reward: 16.49, Length: 11
DEBUG (Env): Episode done for env 47. Reward: 32.30, Length: 8
DEBUG (Env): Episode done for env 59. Reward: -20.39, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -14.70, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -26.97, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 27.40, Length: 20
DEBUG (Env): Episode done for env 127. Reward: 17.46, Length: 7
2083
Time taken for simulation:  7.422208309173584
average overall reward:  0.6949005  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.56833285  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 37. Reward: 27.62, Length: 4
DEBUG (Env): Episode done for env 56. Reward: 47.91, Length: 2
DEBUG (Env): Episode done for env 100. Reward: 20.93, Length: 19
2084
Time taken for simulation:  7.274103879928589
average overall reward:  0.025951002  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.05143614  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 61. Reward: 32.76, Length: 29
DEBUG (Env): Episode done for env 67. Reward: 12.10, Length: 23
DEBUG (Env): Episode done for env 93. Reward: -22.99, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 21.25, Length: 2
2085
Time taken for simulation:  7.14311957359314
average overall reward:  0.19467947  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.18830663  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 50. Reward: 28.59, Length: 6
DEBUG (Env): Episode done for env 82. Reward: 31.08, Length: 13
DEBUG (Env): Episode done for env 85. Reward: -19.18, Length: 36
2086
Time taken for simulation:  7.61742377281189
average overall reward:  0.5640311  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.1386707  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 42.02, Length: 6
DEBUG (Env): Episode done for env 34. Reward: 18.77, Length: 4
DEBUG (Env): Episode done for env 49. Reward: 3.79, Length: 28
DEBUG (Env): Episode done for env 76. Reward: -22.68, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 33.28, Length: 10
DEBUG (Env): Episode done for env 96. Reward: 22.01, Length: 5
2087
Time taken for simulation:  7.514068841934204
average overall reward:  0.4777299  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.22405055  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 43. Reward: 13.46, Length: 20
DEBUG (Env): Episode done for env 49. Reward: 19.79, Length: 1
DEBUG (Env): Episode done for env 95. Reward: -20.86, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 31.37, Length: 8
DEBUG (Env): Episode done for env 109. Reward: 23.74, Length: 22
DEBUG (Env): Episode done for env 111. Reward: -14.39, Length: 36
2088
Time taken for simulation:  7.017019748687744
average overall reward:  0.9449975  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.29604554 average distance reward:  0.3881744  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 12. Reward: -15.62, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -13.58, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 48.50, Length: 10
DEBUG (Env): Episode done for env 30. Reward: 1.22, Length: 34
DEBUG (Env): Episode done for env 49. Reward: 22.17, Length: 1
DEBUG (Env): Episode done for env 56. Reward: 32.00, Length: 5
DEBUG (Env): Episode done for env 82. Reward: 27.48, Length: 3
DEBUG (Env): Episode done for env 83. Reward: 29.64, Length: 17
DEBUG (Env): Episode done for env 109. Reward: 32.14, Length: 1
2089
Time taken for simulation:  7.274956941604614
average overall reward:  0.65474236  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.21881628 average distance reward:  0.020689934  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 5. Reward: -23.38, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 16.34, Length: 29
DEBUG (Env): Episode done for env 28. Reward: 18.72, Length: 16
DEBUG (Env): Episode done for env 29. Reward: -20.88, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 21.17, Length: 24
DEBUG (Env): Episode done for env 88. Reward: 9.04, Length: 14
DEBUG (Env): Episode done for env 101. Reward: 35.47, Length: 16
DEBUG (Env): Episode done for env 110. Reward: 22.31, Length: 7
DEBUG (Env): Episode done for env 121. Reward: 30.81, Length: 8
2090
Time taken for simulation:  7.30012845993042
average overall reward:  0.4660398  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.18892293  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: 29.65, Length: 12
DEBUG (Env): Episode done for env 33. Reward: 13.82, Length: 16
DEBUG (Env): Episode done for env 44. Reward: 25.32, Length: 16
DEBUG (Env): Episode done for env 62. Reward: 8.46, Length: 26
DEBUG (Env): Episode done for env 94. Reward: -23.51, Length: 36
2091
Time taken for simulation:  7.720445156097412
average overall reward:  0.08815946  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.030147873  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 14. Reward: 18.58, Length: 9
DEBUG (Env): Episode done for env 54. Reward: -29.61, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 29.70, Length: 7
DEBUG (Env): Episode done for env 120. Reward: 24.79, Length: 19
DEBUG (Env): Episode done for env 123. Reward: -18.45, Length: 36
2092
Time taken for simulation:  7.423014879226685
average overall reward:  0.4783505  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  0.027246885  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: 23.58, Length: 4
DEBUG (Env): Episode done for env 29. Reward: 23.48, Length: 3
DEBUG (Env): Episode done for env 74. Reward: 13.89, Length: 23
DEBUG (Env): Episode done for env 79. Reward: -17.52, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 2.84, Length: 30
DEBUG (Env): Episode done for env 114. Reward: 20.45, Length: 20
2093
Time taken for simulation:  7.604808330535889
average overall reward:  0.63987386  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.25082248  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 15.11, Length: 17
DEBUG (Env): Episode done for env 27. Reward: -10.84, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 25.89, Length: 1
DEBUG (Env): Episode done for env 32. Reward: -13.44, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 15.89, Length: 4
DEBUG (Env): Episode done for env 80. Reward: 20.84, Length: 16
DEBUG (Env): Episode done for env 96. Reward: 12.34, Length: 7
2094
Time taken for simulation:  7.33688497543335
average overall reward:  0.9313373  average fail penalty:  -0.0703125  and average goal bonus:  1.0829761  and average same cell penalty:  -0.24455938 average distance reward:  0.2110936  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 1. Reward: 14.35, Length: 26
DEBUG (Env): Episode done for env 14. Reward: 30.46, Length: 3
DEBUG (Env): Episode done for env 26. Reward: 31.68, Length: 19
DEBUG (Env): Episode done for env 39. Reward: -20.89, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 33.88, Length: 6
DEBUG (Env): Episode done for env 55. Reward: 22.38, Length: 32
DEBUG (Env): Episode done for env 63. Reward: 6.57, Length: 15
DEBUG (Env): Episode done for env 66. Reward: -20.05, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 8.36, Length: 5
DEBUG (Env): Episode done for env 115. Reward: -15.16, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 11.68, Length: 20
2095
Time taken for simulation:  7.053104639053345
average overall reward:  0.27298018  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.10318667  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 17.14, Length: 9
DEBUG (Env): Episode done for env 13. Reward: -17.42, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 21.76, Length: 2
DEBUG (Env): Episode done for env 86. Reward: -17.25, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 16.01, Length: 17
2096
Time taken for simulation:  7.787902355194092
average overall reward:  -0.03177291  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.01929523  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 31. Reward: -25.67, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -12.18, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -22.72, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 34.60, Length: 17
DEBUG (Env): Episode done for env 110. Reward: 27.33, Length: 2
DEBUG (Env): Episode done for env 125. Reward: -21.08, Length: 36
2097
Time taken for simulation:  7.358069181442261
average overall reward:  1.1690824  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.5849123  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 24.69, Length: 2
DEBUG (Env): Episode done for env 52. Reward: 24.20, Length: 19
DEBUG (Env): Episode done for env 68. Reward: 16.33, Length: 24
DEBUG (Env): Episode done for env 94. Reward: 22.04, Length: 7
DEBUG (Env): Episode done for env 106. Reward: 9.11, Length: 25
DEBUG (Env): Episode done for env 123. Reward: 16.43, Length: 6
2098
Time taken for simulation:  7.001872777938843
average overall reward:  0.5292971  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.14850606  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: -16.91, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 20.52, Length: 4
DEBUG (Env): Episode done for env 25. Reward: -17.10, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 15.78, Length: 24
DEBUG (Env): Episode done for env 46. Reward: -8.23, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 18.40, Length: 4
DEBUG (Env): Episode done for env 72. Reward: 16.48, Length: 3
DEBUG (Env): Episode done for env 119. Reward: -20.76, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 21.53, Length: 1
2099
Time taken for simulation:  7.043007135391235
average overall reward:  1.1079506  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.115843914 average distance reward:  0.37092596  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 11. Reward: 43.40, Length: 9
DEBUG (Env): Episode done for env 23. Reward: 11.06, Length: 23
DEBUG (Env): Episode done for env 33. Reward: 11.45, Length: 9
DEBUG (Env): Episode done for env 70. Reward: -10.78, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 8.22, Length: 27
DEBUG (Env): Episode done for env 77. Reward: -18.13, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 29.92, Length: 20
DEBUG (Env): Episode done for env 85. Reward: 32.63, Length: 14
DEBUG (Env): Episode done for env 127. Reward: 33.63, Length: 17
2100
Time taken for simulation:  7.229777574539185
average overall reward:  0.5536801  average fail penalty:  -0.140625  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.25837868  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 9. Reward: -26.98, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 38.33, Length: 5
DEBUG (Env): Episode done for env 22. Reward: -22.66, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -21.58, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 14.23, Length: 19
DEBUG (Env): Episode done for env 80. Reward: 36.18, Length: 7
DEBUG (Env): Episode done for env 81. Reward: -22.80, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -18.87, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -30.14, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 17.61, Length: 19
DEBUG (Env): Episode done for env 116. Reward: 15.95, Length: 16
2101
Time taken for simulation:  7.240679740905762
average overall reward:  0.59281147  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.05321097  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 17. Reward: 21.47, Length: 22
DEBUG (Env): Episode done for env 49. Reward: 27.55, Length: 7
DEBUG (Env): Episode done for env 75. Reward: -19.04, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -19.58, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 20.28, Length: 1
DEBUG (Env): Episode done for env 107. Reward: 15.51, Length: 1
DEBUG (Env): Episode done for env 118. Reward: 41.26, Length: 7
DEBUG (Env): Episode done for env 122. Reward: -16.61, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 20.69, Length: 19
2102
Time taken for simulation:  7.591787576675415
average overall reward:  0.68947315  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.115843914 average distance reward:  0.24663006  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 11. Reward: 21.68, Length: 3
DEBUG (Env): Episode done for env 36. Reward: 29.61, Length: 2
DEBUG (Env): Episode done for env 42. Reward: -20.75, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -41.94, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 17.55, Length: 1
DEBUG (Env): Episode done for env 79. Reward: 25.48, Length: 10
DEBUG (Env): Episode done for env 84. Reward: 26.18, Length: 3
DEBUG (Env): Episode done for env 113. Reward: -18.12, Length: 36
2103
Time taken for simulation:  7.379144668579102
average overall reward:  0.38995856  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.09997018  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: -12.32, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 27.71, Length: 7
DEBUG (Env): Episode done for env 34. Reward: 7.74, Length: 17
DEBUG (Env): Episode done for env 59. Reward: 18.82, Length: 21
DEBUG (Env): Episode done for env 111. Reward: 18.98, Length: 16
2104
Time taken for simulation:  7.5072922706604
average overall reward:  0.14324498  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.0038057156  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 38. Reward: 4.90, Length: 24
DEBUG (Env): Episode done for env 45. Reward: -7.27, Length: 22
DEBUG (Env): Episode done for env 72. Reward: 25.86, Length: 6
2105
Time taken for simulation:  7.193075180053711
average overall reward:  0.30482316  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.17133865  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 20. Reward: -14.57, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 38.19, Length: 16
DEBUG (Env): Episode done for env 41. Reward: 11.27, Length: 26
DEBUG (Env): Episode done for env 98. Reward: -19.21, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -15.82, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 12.62, Length: 30
2106
Time taken for simulation:  7.1296727657318115
average overall reward:  0.23413202  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.1673301 average distance reward:  0.20201606  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 10. Reward: -13.08, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 23.41, Length: 8
DEBUG (Env): Episode done for env 38. Reward: 25.77, Length: 2
2107
Time taken for simulation:  7.358856439590454
average overall reward:  1.2688271  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.12871546 average distance reward:  0.65660846  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 15. Reward: -20.38, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 32.38, Length: 4
DEBUG (Env): Episode done for env 22. Reward: 14.14, Length: 7
DEBUG (Env): Episode done for env 27. Reward: 18.55, Length: 14
DEBUG (Env): Episode done for env 44. Reward: 15.74, Length: 17
DEBUG (Env): Episode done for env 69. Reward: 26.95, Length: 29
DEBUG (Env): Episode done for env 119. Reward: 12.28, Length: 9
2108
Time taken for simulation:  7.2109055519104
average overall reward:  0.6530132  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.06653765  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 26. Reward: 23.09, Length: 14
DEBUG (Env): Episode done for env 53. Reward: -22.26, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 28.49, Length: 20
DEBUG (Env): Episode done for env 68. Reward: 41.26, Length: 11
DEBUG (Env): Episode done for env 84. Reward: 10.36, Length: 6
DEBUG (Env): Episode done for env 110. Reward: 22.54, Length: 12
DEBUG (Env): Episode done for env 117. Reward: 10.20, Length: 33
2109
Time taken for simulation:  7.3262200355529785
average overall reward:  1.116894  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.18020165 average distance reward:  0.26198  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: 24.00, Length: 15
DEBUG (Env): Episode done for env 21. Reward: 9.49, Length: 21
DEBUG (Env): Episode done for env 28. Reward: 12.90, Length: 4
DEBUG (Env): Episode done for env 60. Reward: 29.50, Length: 9
DEBUG (Env): Episode done for env 61. Reward: 23.18, Length: 18
DEBUG (Env): Episode done for env 103. Reward: 30.89, Length: 4
DEBUG (Env): Episode done for env 110. Reward: 23.48, Length: 1
DEBUG (Env): Episode done for env 113. Reward: 22.30, Length: 7
2110
Time taken for simulation:  7.253324508666992
average overall reward:  0.86321247  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.27030247 average distance reward:  0.23377126  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 15. Reward: 50.74, Length: 3
DEBUG (Env): Episode done for env 21. Reward: 16.86, Length: 1
DEBUG (Env): Episode done for env 39. Reward: 15.15, Length: 16
DEBUG (Env): Episode done for env 48. Reward: 41.39, Length: 14
DEBUG (Env): Episode done for env 75. Reward: 15.42, Length: 9
DEBUG (Env): Episode done for env 82. Reward: 18.94, Length: 22
DEBUG (Env): Episode done for env 126. Reward: 45.73, Length: 5
2111
Time taken for simulation:  7.01271915435791
average overall reward:  0.33600423  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.043710217  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: 2.73, Length: 35
DEBUG (Env): Episode done for env 7. Reward: -16.54, Length: 36
DEBUG (Env): Episode done for env 65. Reward: -10.59, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 29.74, Length: 9
DEBUG (Env): Episode done for env 94. Reward: 22.86, Length: 14
DEBUG (Env): Episode done for env 106. Reward: 26.57, Length: 14
2112
Time taken for simulation:  7.144526243209839
average overall reward:  0.7042988  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020163 average distance reward:  0.25550085  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: 13.11, Length: 23
DEBUG (Env): Episode done for env 41. Reward: 36.31, Length: 7
DEBUG (Env): Episode done for env 71. Reward: 28.49, Length: 13
DEBUG (Env): Episode done for env 80. Reward: 16.29, Length: 12
DEBUG (Env): Episode done for env 96. Reward: 19.86, Length: 19
2113
Time taken for simulation:  7.128633975982666
average overall reward:  0.98100233  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.1930732 average distance reward:  0.2743318  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: 46.59, Length: 16
DEBUG (Env): Episode done for env 13. Reward: 11.97, Length: 13
DEBUG (Env): Episode done for env 33. Reward: 28.26, Length: 14
DEBUG (Env): Episode done for env 35. Reward: 44.81, Length: 7
DEBUG (Env): Episode done for env 52. Reward: 18.61, Length: 16
DEBUG (Env): Episode done for env 77. Reward: 22.00, Length: 14
DEBUG (Env): Episode done for env 89. Reward: 24.50, Length: 21
2114
Time taken for simulation:  7.178992509841919
average overall reward:  1.0959979  average fail penalty:  -0.0703125  and average goal bonus:  1.3537202  and average same cell penalty:  -0.15445855 average distance reward:  0.014909208  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 3. Reward: -11.75, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 25.86, Length: 7
DEBUG (Env): Episode done for env 32. Reward: 25.46, Length: 21
DEBUG (Env): Episode done for env 41. Reward: 29.59, Length: 2
DEBUG (Env): Episode done for env 56. Reward: 14.19, Length: 6
DEBUG (Env): Episode done for env 59. Reward: 27.92, Length: 11
DEBUG (Env): Episode done for env 60. Reward: 24.36, Length: 5
DEBUG (Env): Episode done for env 90. Reward: 19.42, Length: 14
DEBUG (Env): Episode done for env 97. Reward: -19.21, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 28.21, Length: 25
DEBUG (Env): Episode done for env 105. Reward: 5.79, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 13.90, Length: 34
2115
Time taken for simulation:  7.331296920776367
average overall reward:  0.8859247  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.3697616  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 6. Reward: 14.90, Length: 22
DEBUG (Env): Episode done for env 19. Reward: -14.61, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 28.80, Length: 6
DEBUG (Env): Episode done for env 46. Reward: 18.30, Length: 17
DEBUG (Env): Episode done for env 51. Reward: 14.98, Length: 13
DEBUG (Env): Episode done for env 57. Reward: 13.78, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -14.92, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -13.80, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 25.44, Length: 14
2116
Time taken for simulation:  6.525468111038208
average overall reward:  0.11027496  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.14251679  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 53. Reward: 8.54, Length: 8
DEBUG (Env): Episode done for env 102. Reward: -21.35, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 13.64, Length: 17
2117
Time taken for simulation:  6.955809116363525
average overall reward:  0.8403864  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.5586583  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: -39.58, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 26.93, Length: 7
DEBUG (Env): Episode done for env 16. Reward: 30.10, Length: 25
DEBUG (Env): Episode done for env 40. Reward: -9.09, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 19.16, Length: 2
DEBUG (Env): Episode done for env 62. Reward: 37.38, Length: 27
DEBUG (Env): Episode done for env 87. Reward: -11.92, Length: 36
2118
Time taken for simulation:  7.223602294921875
average overall reward:  0.3844265  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455936 average distance reward:  0.29416788  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 46. Reward: 18.40, Length: 1
DEBUG (Env): Episode done for env 47. Reward: -11.92, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 32.31, Length: 6
DEBUG (Env): Episode done for env 84. Reward: 26.59, Length: 10
2119
Time taken for simulation:  7.152400732040405
average overall reward:  0.34327146  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.12871546 average distance reward:  0.2959784  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 26. Reward: 35.32, Length: 11
DEBUG (Env): Episode done for env 37. Reward: -15.59, Length: 36
DEBUG (Env): Episode done for env 100. Reward: -19.37, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 8.69, Length: 23
2120
Time taken for simulation:  7.1207544803619385
average overall reward:  0.68452257  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168781 average distance reward:  0.19871376  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: 9.09, Length: 9
DEBUG (Env): Episode done for env 17. Reward: 36.85, Length: 19
DEBUG (Env): Episode done for env 18. Reward: 16.46, Length: 13
DEBUG (Env): Episode done for env 20. Reward: 24.54, Length: 15
DEBUG (Env): Episode done for env 41. Reward: 11.23, Length: 6
DEBUG (Env): Episode done for env 67. Reward: -14.95, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 18.02, Length: 2
DEBUG (Env): Episode done for env 93. Reward: -6.03, Length: 36
2121
Time taken for simulation:  7.264011859893799
average overall reward:  0.39401716  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.104028754  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: 24.20, Length: 8
DEBUG (Env): Episode done for env 50. Reward: -16.48, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 32.03, Length: 3
DEBUG (Env): Episode done for env 117. Reward: 10.16, Length: 13
DEBUG (Env): Episode done for env 118. Reward: 13.77, Length: 20
2122
Time taken for simulation:  7.247081279754639
average overall reward:  0.41066983  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.2537478  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: 24.22, Length: 12
DEBUG (Env): Episode done for env 26. Reward: 29.49, Length: 3
DEBUG (Env): Episode done for env 76. Reward: -21.32, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 22.20, Length: 5
DEBUG (Env): Episode done for env 91. Reward: -26.71, Length: 36
2123
Time taken for simulation:  7.408988952636719
average overall reward:  0.6417521  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.08927998  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 24. Reward: 20.00, Length: 34
DEBUG (Env): Episode done for env 43. Reward: -16.72, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 20.08, Length: 5
DEBUG (Env): Episode done for env 90. Reward: 31.33, Length: 9
DEBUG (Env): Episode done for env 95. Reward: -5.79, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 25.57, Length: 11
DEBUG (Env): Episode done for env 99. Reward: -21.50, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 19.31, Length: 4
DEBUG (Env): Episode done for env 114. Reward: 23.74, Length: 31
2124
Time taken for simulation:  7.006927967071533
average overall reward:  0.71874344  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.21881628 average distance reward:  0.13156606  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 12. Reward: 3.11, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -27.00, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 40.41, Length: 9
DEBUG (Env): Episode done for env 53. Reward: 24.14, Length: 8
DEBUG (Env): Episode done for env 56. Reward: 19.27, Length: 10
DEBUG (Env): Episode done for env 66. Reward: 15.35, Length: 30
DEBUG (Env): Episode done for env 76. Reward: 19.73, Length: 2
DEBUG (Env): Episode done for env 83. Reward: -10.49, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -22.13, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 12.35, Length: 15
2125
Time taken for simulation:  7.214495897293091
average overall reward:  0.7264153  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.38885003  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 5. Reward: 15.90, Length: 13
DEBUG (Env): Episode done for env 51. Reward: 22.37, Length: 1
DEBUG (Env): Episode done for env 61. Reward: 17.63, Length: 16
DEBUG (Env): Episode done for env 81. Reward: 23.61, Length: 24
DEBUG (Env): Episode done for env 88. Reward: -15.44, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 20.15, Length: 3
DEBUG (Env): Episode done for env 121. Reward: -17.43, Length: 36
2126
Time taken for simulation:  7.642214059829712
average overall reward:  0.3178262  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.13977224  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 15. Reward: 32.05, Length: 9
DEBUG (Env): Episode done for env 19. Reward: 28.57, Length: 11
DEBUG (Env): Episode done for env 21. Reward: 22.70, Length: 4
2127
Time taken for simulation:  7.246073007583618
average overall reward:  0.8362375  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.102972366 average distance reward:  0.22171323  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 16. Reward: 36.19, Length: 10
DEBUG (Env): Episode done for env 19. Reward: 20.35, Length: 1
DEBUG (Env): Episode done for env 21. Reward: 11.74, Length: 1
DEBUG (Env): Episode done for env 32. Reward: 24.34, Length: 13
DEBUG (Env): Episode done for env 40. Reward: 31.95, Length: 10
DEBUG (Env): Episode done for env 54. Reward: -9.44, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 17.96, Length: 8
DEBUG (Env): Episode done for env 120. Reward: -20.30, Length: 36
2128
Time taken for simulation:  7.377376317977905
average overall reward:  0.039457157  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.283174 average distance reward:  0.25855717  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 41. Reward: 25.89, Length: 8
DEBUG (Env): Episode done for env 74. Reward: -21.34, Length: 36
2129
Time taken for simulation:  7.443177700042725
average overall reward:  0.20800628  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.066261396  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 3. Reward: 36.66, Length: 15
DEBUG (Env): Episode done for env 7. Reward: 10.62, Length: 18
DEBUG (Env): Episode done for env 29. Reward: -9.54, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 24.52, Length: 23
2130
Time taken for simulation:  7.718013048171997
average overall reward:  0.4208784  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.15432745  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 22.12, Length: 6
DEBUG (Env): Episode done for env 50. Reward: 36.64, Length: 9
DEBUG (Env): Episode done for env 55. Reward: -17.45, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 16.98, Length: 6
DEBUG (Env): Episode done for env 115. Reward: -21.89, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 5.37, Length: 14
2131
Time taken for simulation:  7.278908014297485
average overall reward:  0.15496296  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  -0.027702115  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 74. Reward: 16.90, Length: 3
DEBUG (Env): Episode done for env 82. Reward: 9.76, Length: 21
DEBUG (Env): Episode done for env 86. Reward: -13.02, Length: 36
DEBUG (Env): Episode done for env 92. Reward: -22.57, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 25.79, Length: 10
2132
Time taken for simulation:  7.247506618499756
average overall reward:  0.4995792  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  -0.03771585  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: 8.33, Length: 15
DEBUG (Env): Episode done for env 32. Reward: 27.66, Length: 5
DEBUG (Env): Episode done for env 44. Reward: 19.90, Length: 25
DEBUG (Env): Episode done for env 68. Reward: 6.08, Length: 24
DEBUG (Env): Episode done for env 73. Reward: -9.01, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 11.66, Length: 8
DEBUG (Env): Episode done for env 112. Reward: 34.65, Length: 18
DEBUG (Env): Episode done for env 125. Reward: -24.91, Length: 36
2133
Time taken for simulation:  7.517121315002441
average overall reward:  0.41109258  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.22016716  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 27. Reward: 7.17, Length: 26
DEBUG (Env): Episode done for env 60. Reward: 24.46, Length: 19
DEBUG (Env): Episode done for env 120. Reward: 41.42, Length: 6
2134
Time taken for simulation:  7.2447168827056885
average overall reward:  -0.10545792  average fail penalty:  -0.1171875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.1687775  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: -16.62, Length: 36
DEBUG (Env): Episode done for env 14. Reward: -19.34, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -23.17, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -32.83, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 31.92, Length: 13
DEBUG (Env): Episode done for env 123. Reward: -14.85, Length: 36
2135
Time taken for simulation:  7.548096656799316
average overall reward:  -0.09857531  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.12878507  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 23. Reward: -7.58, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -30.09, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 18.07, Length: 15
DEBUG (Env): Episode done for env 85. Reward: -26.47, Length: 36
2136
Time taken for simulation:  7.205326795578003
average overall reward:  0.6332449  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168783 average distance reward:  0.57698965  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: -18.72, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 20.20, Length: 14
DEBUG (Env): Episode done for env 92. Reward: 24.48, Length: 5
DEBUG (Env): Episode done for env 104. Reward: -11.54, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -23.46, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 39.47, Length: 3
2137
Time taken for simulation:  7.355716705322266
average overall reward:  0.5802026  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.066345006  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 42. Reward: 16.15, Length: 35
DEBUG (Env): Episode done for env 49. Reward: -21.42, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 15.31, Length: 20
DEBUG (Env): Episode done for env 73. Reward: 16.99, Length: 5
DEBUG (Env): Episode done for env 74. Reward: 22.38, Length: 6
DEBUG (Env): Episode done for env 112. Reward: 31.92, Length: 5
DEBUG (Env): Episode done for env 122. Reward: -0.83, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -9.26, Length: 36
2138
Time taken for simulation:  7.3011908531188965
average overall reward:  0.3953984  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.05552759  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 10. Reward: 11.65, Length: 32
DEBUG (Env): Episode done for env 11. Reward: -14.98, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 29.66, Length: 15
DEBUG (Env): Episode done for env 78. Reward: -18.35, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 28.15, Length: 7
DEBUG (Env): Episode done for env 110. Reward: 21.50, Length: 8
DEBUG (Env): Episode done for env 124. Reward: 20.94, Length: 1
2139
Time taken for simulation:  7.38962459564209
average overall reward:  0.08552778  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.141587 average distance reward:  0.20991576  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 31. Reward: -19.39, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -29.44, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -23.39, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 29.38, Length: 18
2140
Time taken for simulation:  7.668865203857422
average overall reward:  0.31143564  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.19312833  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: 27.91, Length: 14
DEBUG (Env): Episode done for env 45. Reward: -11.19, Length: 36
DEBUG (Env): Episode done for env 72. Reward: -9.09, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 24.85, Length: 17
DEBUG (Env): Episode done for env 100. Reward: 13.58, Length: 17
2141
Time taken for simulation:  7.394377708435059
average overall reward:  0.10337681  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.02549649  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 9. Reward: 20.25, Length: 5
DEBUG (Env): Episode done for env 47. Reward: 16.17, Length: 23
DEBUG (Env): Episode done for env 81. Reward: 28.20, Length: 16
DEBUG (Env): Episode done for env 98. Reward: -4.07, Length: 36
2142
Time taken for simulation:  7.540513753890991
average overall reward:  0.173512  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  -0.114170834  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: 12.66, Length: 10
DEBUG (Env): Episode done for env 44. Reward: 30.54, Length: 10
DEBUG (Env): Episode done for env 63. Reward: 18.60, Length: 8
DEBUG (Env): Episode done for env 126. Reward: 12.39, Length: 32
2143
Time taken for simulation:  7.102383136749268
average overall reward:  0.44015673  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.28323478  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 10.90, Length: 34
DEBUG (Env): Episode done for env 69. Reward: -32.45, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 29.86, Length: 6
DEBUG (Env): Episode done for env 119. Reward: -20.23, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 27.07, Length: 9
2144
Time taken for simulation:  7.231330394744873
average overall reward:  1.0493579  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.34268743  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: 21.65, Length: 1
DEBUG (Env): Episode done for env 50. Reward: 27.43, Length: 14
DEBUG (Env): Episode done for env 53. Reward: 18.55, Length: 20
DEBUG (Env): Episode done for env 70. Reward: 16.70, Length: 9
DEBUG (Env): Episode done for env 80. Reward: 25.17, Length: 9
DEBUG (Env): Episode done for env 81. Reward: 28.60, Length: 3
DEBUG (Env): Episode done for env 107. Reward: 36.24, Length: 29
2145
Time taken for simulation:  7.121048450469971
average overall reward:  0.03023012  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.021551698  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 36. Reward: 23.50, Length: 7
DEBUG (Env): Episode done for env 83. Reward: 12.03, Length: 21
DEBUG (Env): Episode done for env 103. Reward: -17.23, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -19.48, Length: 36
2146
Time taken for simulation:  7.068349838256836
average overall reward:  0.6597167  average fail penalty:  -0.0703125  and average goal bonus:  1.0829762  and average same cell penalty:  -0.27030247 average distance reward:  -0.03478398  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 5. Reward: 11.81, Length: 21
DEBUG (Env): Episode done for env 10. Reward: 29.26, Length: 8
DEBUG (Env): Episode done for env 15. Reward: 17.07, Length: 6
DEBUG (Env): Episode done for env 39. Reward: -22.06, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 17.47, Length: 9
DEBUG (Env): Episode done for env 43. Reward: 34.48, Length: 8
DEBUG (Env): Episode done for env 48. Reward: -22.08, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 13.68, Length: 22
DEBUG (Env): Episode done for env 66. Reward: 27.68, Length: 22
DEBUG (Env): Episode done for env 75. Reward: -18.77, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 42.07, Length: 10
2147
Time taken for simulation:  7.314625263214111
average overall reward:  0.85876447  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455936 average distance reward:  0.5680742  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 36. Reward: 31.24, Length: 2
DEBUG (Env): Episode done for env 65. Reward: -10.59, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -15.70, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -12.84, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -21.83, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 21.92, Length: 8
DEBUG (Env): Episode done for env 112. Reward: 35.89, Length: 4
DEBUG (Env): Episode done for env 113. Reward: 23.22, Length: 2
DEBUG (Env): Episode done for env 115. Reward: 26.84, Length: 17
2148
Time taken for simulation:  7.068666219711304
average overall reward:  1.0921235  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.6796346  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: 37.08, Length: 21
DEBUG (Env): Episode done for env 35. Reward: 24.47, Length: 35
DEBUG (Env): Episode done for env 36. Reward: 20.50, Length: 1
DEBUG (Env): Episode done for env 51. Reward: 15.68, Length: 23
DEBUG (Env): Episode done for env 71. Reward: -23.94, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 20.23, Length: 25
2149
Time taken for simulation:  7.2481584548950195
average overall reward:  0.8002317  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.55250704  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 13. Reward: -27.90, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -16.96, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 23.12, Length: 1
DEBUG (Env): Episode done for env 52. Reward: -14.32, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -4.45, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 31.18, Length: 14
DEBUG (Env): Episode done for env 89. Reward: -19.16, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 25.56, Length: 5
DEBUG (Env): Episode done for env 117. Reward: 27.15, Length: 10
2150
Time taken for simulation:  7.176773548126221
average overall reward:  1.0559056  average fail penalty:  -0.1171875  and average goal bonus:  1.2183483  and average same cell penalty:  -0.2574309 average distance reward:  0.2600364  and average step penalty:  -0.04786053509430681
Number of done instances:  14
DEBUG (Env): Episode done for env 7. Reward: 15.37, Length: 21
DEBUG (Env): Episode done for env 11. Reward: 18.56, Length: 12
DEBUG (Env): Episode done for env 15. Reward: 18.96, Length: 4
DEBUG (Env): Episode done for env 22. Reward: -14.56, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 24.05, Length: 18
DEBUG (Env): Episode done for env 54. Reward: 8.50, Length: 23
DEBUG (Env): Episode done for env 55. Reward: 42.49, Length: 20
DEBUG (Env): Episode done for env 59. Reward: -15.23, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 20.99, Length: 14
DEBUG (Env): Episode done for env 97. Reward: -10.55, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -9.08, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -21.04, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 23.90, Length: 23
DEBUG (Env): Episode done for env 109. Reward: 24.28, Length: 18
2151
Time taken for simulation:  7.274921417236328
average overall reward:  0.2990098  average fail penalty:  -0.1171875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  -0.15510121  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 6. Reward: -14.81, Length: 36
DEBUG (Env): Episode done for env 8. Reward: 4.47, Length: 30
DEBUG (Env): Episode done for env 28. Reward: -20.88, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 15.66, Length: 2
DEBUG (Env): Episode done for env 57. Reward: -10.68, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -12.56, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -23.40, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 22.61, Length: 11
DEBUG (Env): Episode done for env 110. Reward: 22.88, Length: 13
DEBUG (Env): Episode done for env 117. Reward: 14.50, Length: 2
DEBUG (Env): Episode done for env 125. Reward: 15.43, Length: 19
2152
Time taken for simulation:  7.167311191558838
average overall reward:  0.75298905  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.06435773 average distance reward:  0.34715676  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: 23.28, Length: 11
DEBUG (Env): Episode done for env 34. Reward: 24.70, Length: 13
DEBUG (Env): Episode done for env 78. Reward: 45.74, Length: 14
DEBUG (Env): Episode done for env 102. Reward: -17.90, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 15.08, Length: 5
2153
Time taken for simulation:  7.4147021770477295
average overall reward:  1.0460835  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.11584391 average distance reward:  0.53292763  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 61. Reward: 25.29, Length: 28
DEBUG (Env): Episode done for env 69. Reward: 32.50, Length: 10
DEBUG (Env): Episode done for env 80. Reward: 9.94, Length: 9
DEBUG (Env): Episode done for env 83. Reward: 30.12, Length: 8
DEBUG (Env): Episode done for env 95. Reward: 22.48, Length: 5
2154
Time taken for simulation:  7.494175434112549
average overall reward:  1.477865  average fail penalty:  0.0  and average goal bonus:  1.3537202  and average same cell penalty:  -0.15445855 average distance reward:  0.3264636  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 1. Reward: 27.48, Length: 10
DEBUG (Env): Episode done for env 7. Reward: 32.70, Length: 4
DEBUG (Env): Episode done for env 10. Reward: 34.59, Length: 8
DEBUG (Env): Episode done for env 26. Reward: 30.32, Length: 32
DEBUG (Env): Episode done for env 29. Reward: 1.92, Length: 25
DEBUG (Env): Episode done for env 47. Reward: 36.51, Length: 13
DEBUG (Env): Episode done for env 50. Reward: 22.80, Length: 10
DEBUG (Env): Episode done for env 52. Reward: 25.11, Length: 5
DEBUG (Env): Episode done for env 93. Reward: -1.83, Length: 34
DEBUG (Env): Episode done for env 105. Reward: 24.11, Length: 4
2155
Time taken for simulation:  7.47804069519043
average overall reward:  0.71225613  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.051486183 average distance reward:  0.29355225  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 27. Reward: 26.18, Length: 22
DEBUG (Env): Episode done for env 37. Reward: -17.13, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 39.65, Length: 6
DEBUG (Env): Episode done for env 67. Reward: 7.69, Length: 35
DEBUG (Env): Episode done for env 105. Reward: 21.66, Length: 1
2156
Time taken for simulation:  7.026024103164673
average overall reward:  0.33998236  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.15445855 average distance reward:  -0.31155276  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 4. Reward: -17.06, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -6.45, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -12.77, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -14.89, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 27.31, Length: 14
DEBUG (Env): Episode done for env 46. Reward: 24.70, Length: 33
DEBUG (Env): Episode done for env 55. Reward: 31.00, Length: 6
DEBUG (Env): Episode done for env 100. Reward: 28.55, Length: 16
DEBUG (Env): Episode done for env 103. Reward: 17.47, Length: 11
DEBUG (Env): Episode done for env 110. Reward: 8.44, Length: 5
DEBUG (Env): Episode done for env 111. Reward: 27.61, Length: 9
2157
Time taken for simulation:  7.282732725143433
average overall reward:  0.798108  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.3106954  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: 25.81, Length: 22
DEBUG (Env): Episode done for env 28. Reward: 44.59, Length: 6
DEBUG (Env): Episode done for env 58. Reward: 36.31, Length: 6
DEBUG (Env): Episode done for env 80. Reward: 28.35, Length: 4
DEBUG (Env): Episode done for env 116. Reward: 23.38, Length: 21
2158
Time taken for simulation:  7.222484588623047
average overall reward:  0.5042396  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.2875711  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 50. Reward: 38.87, Length: 4
DEBUG (Env): Episode done for env 72. Reward: 18.44, Length: 18
DEBUG (Env): Episode done for env 108. Reward: 12.01, Length: 8
2159
Time taken for simulation:  7.308769226074219
average overall reward:  0.523284  average fail penalty:  -0.09375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.102972366 average distance reward:  0.091006756  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 24. Reward: -17.31, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 24.48, Length: 20
DEBUG (Env): Episode done for env 36. Reward: 27.48, Length: 11
DEBUG (Env): Episode done for env 47. Reward: 26.48, Length: 5
DEBUG (Env): Episode done for env 55. Reward: 18.40, Length: 3
DEBUG (Env): Episode done for env 66. Reward: 20.31, Length: 13
DEBUG (Env): Episode done for env 96. Reward: -12.16, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -17.27, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -9.83, Length: 36
2160
Time taken for simulation:  7.17982292175293
average overall reward:  0.7651396  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.23168781 average distance reward:  0.41470277  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: 18.48, Length: 6
DEBUG (Env): Episode done for env 23. Reward: 20.39, Length: 3
DEBUG (Env): Episode done for env 30. Reward: -23.52, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 22.53, Length: 14
DEBUG (Env): Episode done for env 76. Reward: -16.22, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 25.72, Length: 9
DEBUG (Env): Episode done for env 123. Reward: 23.24, Length: 17
2161
Time taken for simulation:  7.304309129714966
average overall reward:  0.24137123  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3089171 average distance reward:  0.2623453  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: 26.99, Length: 15
DEBUG (Env): Episode done for env 39. Reward: 19.21, Length: 15
DEBUG (Env): Episode done for env 88. Reward: -26.35, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -1.36, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 8.48, Length: 20
DEBUG (Env): Episode done for env 121. Reward: -16.85, Length: 36
2162
Time taken for simulation:  7.397353172302246
average overall reward:  1.0534536  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.43066898  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: 35.51, Length: 12
DEBUG (Env): Episode done for env 50. Reward: 24.52, Length: 4
DEBUG (Env): Episode done for env 91. Reward: 17.80, Length: 1
DEBUG (Env): Episode done for env 93. Reward: 53.45, Length: 8
DEBUG (Env): Episode done for env 98. Reward: 18.05, Length: 1
DEBUG (Env): Episode done for env 123. Reward: 19.11, Length: 2
2163
Time taken for simulation:  7.09859561920166
average overall reward:  0.73565346  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.09929555  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 19. Reward: -13.43, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 18.06, Length: 7
DEBUG (Env): Episode done for env 21. Reward: -20.94, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 23.14, Length: 2
DEBUG (Env): Episode done for env 40. Reward: -24.08, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 24.85, Length: 7
DEBUG (Env): Episode done for env 50. Reward: 19.23, Length: 1
DEBUG (Env): Episode done for env 99. Reward: 28.15, Length: 4
DEBUG (Env): Episode done for env 107. Reward: 32.57, Length: 14
DEBUG (Env): Episode done for env 118. Reward: -1.04, Length: 32
2164
Time taken for simulation:  7.0801682472229
average overall reward:  0.0013284832  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  -0.0179159  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 41. Reward: -25.03, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 2.42, Length: 22
DEBUG (Env): Episode done for env 118. Reward: 19.19, Length: 1
2165
Time taken for simulation:  7.484176397323608
average overall reward:  1.696642  average fail penalty:  -0.046875  and average goal bonus:  1.3537203  and average same cell penalty:  -0.18020165 average distance reward:  0.61785907  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 1. Reward: 34.76, Length: 5
DEBUG (Env): Episode done for env 2. Reward: 30.50, Length: 23
DEBUG (Env): Episode done for env 3. Reward: -12.37, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 36.82, Length: 2
DEBUG (Env): Episode done for env 31. Reward: 20.47, Length: 6
DEBUG (Env): Episode done for env 38. Reward: -23.34, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 19.06, Length: 28
DEBUG (Env): Episode done for env 57. Reward: 35.77, Length: 14
DEBUG (Env): Episode done for env 58. Reward: 29.84, Length: 8
DEBUG (Env): Episode done for env 82. Reward: 5.89, Length: 34
DEBUG (Env): Episode done for env 90. Reward: 28.96, Length: 5
DEBUG (Env): Episode done for env 125. Reward: 19.61, Length: 14
2166
Time taken for simulation:  7.354974746704102
average overall reward:  0.33223695  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.2574309 average distance reward:  0.007543251  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: 20.11, Length: 1
DEBUG (Env): Episode done for env 12. Reward: -22.79, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 16.57, Length: 11
DEBUG (Env): Episode done for env 71. Reward: 12.22, Length: 18
DEBUG (Env): Episode done for env 91. Reward: 31.85, Length: 4
DEBUG (Env): Episode done for env 96. Reward: 33.68, Length: 7
DEBUG (Env): Episode done for env 127. Reward: -15.70, Length: 36
2167
Time taken for simulation:  7.257824659347534
average overall reward:  0.6060061  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168783 average distance reward:  0.20869431  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 23. Reward: 25.17, Length: 7
DEBUG (Env): Episode done for env 30. Reward: 14.93, Length: 7
DEBUG (Env): Episode done for env 91. Reward: 15.80, Length: 1
DEBUG (Env): Episode done for env 95. Reward: 16.42, Length: 14
DEBUG (Env): Episode done for env 105. Reward: 20.93, Length: 12
2168
Time taken for simulation:  7.747341156005859
average overall reward:  0.17275052  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  0.09536342  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 47. Reward: 24.47, Length: 9
DEBUG (Env): Episode done for env 68. Reward: -12.09, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 1.92, Length: 22
DEBUG (Env): Episode done for env 116. Reward: 19.60, Length: 11
2169
Time taken for simulation:  7.167843341827393
average overall reward:  0.19025359  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.009894105  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 42. Reward: 17.42, Length: 9
DEBUG (Env): Episode done for env 60. Reward: -14.76, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 11.13, Length: 22
DEBUG (Env): Episode done for env 94. Reward: 26.34, Length: 22
2170
Time taken for simulation:  7.124768257141113
average overall reward:  0.5645519  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.17088927  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: -10.90, Length: 36
DEBUG (Env): Episode done for env 14. Reward: -22.62, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 18.80, Length: 3
DEBUG (Env): Episode done for env 25. Reward: -13.70, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 25.71, Length: 24
DEBUG (Env): Episode done for env 59. Reward: 28.82, Length: 20
DEBUG (Env): Episode done for env 84. Reward: -12.99, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 18.31, Length: 18
DEBUG (Env): Episode done for env 107. Reward: 14.56, Length: 7
2171
Time taken for simulation:  7.267337322235107
average overall reward:  0.34622407  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.1295555  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 49. Reward: 23.08, Length: 6
DEBUG (Env): Episode done for env 61. Reward: 9.84, Length: 18
DEBUG (Env): Episode done for env 88. Reward: 23.38, Length: 10
2172
Time taken for simulation:  7.402072429656982
average overall reward:  -0.15507573  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  0.04884716  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 92. Reward: -20.18, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -16.77, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 25.44, Length: 6
2173
Time taken for simulation:  7.07453465461731
average overall reward:  0.7795033  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.12871546 average distance reward:  0.102225095  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 2. Reward: 31.10, Length: 8
DEBUG (Env): Episode done for env 27. Reward: 16.10, Length: 18
DEBUG (Env): Episode done for env 39. Reward: 16.54, Length: 10
DEBUG (Env): Episode done for env 47. Reward: 18.96, Length: 5
DEBUG (Env): Episode done for env 61. Reward: 19.40, Length: 2
DEBUG (Env): Episode done for env 62. Reward: -12.92, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -19.74, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 22.50, Length: 3
DEBUG (Env): Episode done for env 116. Reward: 29.79, Length: 5
DEBUG (Env): Episode done for env 122. Reward: -12.45, Length: 36
2174
Time taken for simulation:  7.143921852111816
average overall reward:  0.10814501  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  -0.106919765  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 29.64, Length: 24
DEBUG (Env): Episode done for env 49. Reward: 25.13, Length: 3
DEBUG (Env): Episode done for env 86. Reward: -13.35, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 24.45, Length: 24
DEBUG (Env): Episode done for env 115. Reward: 14.05, Length: 27
DEBUG (Env): Episode done for env 124. Reward: -13.60, Length: 36
2175
Time taken for simulation:  7.1978535652160645
average overall reward:  0.18134084  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.0032869354  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: 10.95, Length: 23
DEBUG (Env): Episode done for env 66. Reward: 22.74, Length: 16
DEBUG (Env): Episode done for env 105. Reward: 13.74, Length: 8
2176
Time taken for simulation:  7.234677791595459
average overall reward:  0.7695044  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.4409014  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 4. Reward: 30.48, Length: 20
DEBUG (Env): Episode done for env 5. Reward: 21.35, Length: 15
DEBUG (Env): Episode done for env 45. Reward: -20.86, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 9.77, Length: 3
DEBUG (Env): Episode done for env 122. Reward: 23.77, Length: 3
2177
Time taken for simulation:  7.005145788192749
average overall reward:  1.1274123  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.556114  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: 34.67, Length: 15
DEBUG (Env): Episode done for env 30. Reward: 39.56, Length: 10
DEBUG (Env): Episode done for env 46. Reward: 18.90, Length: 14
DEBUG (Env): Episode done for env 60. Reward: 17.99, Length: 8
DEBUG (Env): Episode done for env 75. Reward: 27.00, Length: 9
DEBUG (Env): Episode done for env 108. Reward: 20.94, Length: 19
2178
Time taken for simulation:  7.009175539016724
average overall reward:  0.04700212  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455936 average distance reward:  0.2274875  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: 34.06, Length: 5
DEBUG (Env): Episode done for env 126. Reward: -17.55, Length: 36
2179
Time taken for simulation:  7.2532806396484375
average overall reward:  0.44887865  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.283174 average distance reward:  0.26186267  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 52. Reward: 7.53, Length: 25
DEBUG (Env): Episode done for env 68. Reward: 56.53, Length: 11
DEBUG (Env): Episode done for env 79. Reward: 22.57, Length: 10
DEBUG (Env): Episode done for env 115. Reward: 16.22, Length: 5
DEBUG (Env): Episode done for env 119. Reward: -21.53, Length: 36
2180
Time taken for simulation:  7.054973125457764
average overall reward:  0.2675744  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.07594713  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 26. Reward: 25.78, Length: 26
DEBUG (Env): Episode done for env 33. Reward: 19.24, Length: 29
DEBUG (Env): Episode done for env 53. Reward: -5.89, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 13.06, Length: 1
DEBUG (Env): Episode done for env 70. Reward: -17.36, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -19.06, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 15.40, Length: 18
2181
Time taken for simulation:  7.217959642410278
average overall reward:  1.2917255  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.5850552  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 16. Reward: 16.62, Length: 33
DEBUG (Env): Episode done for env 35. Reward: -1.62, Length: 33
DEBUG (Env): Episode done for env 67. Reward: 18.93, Length: 26
DEBUG (Env): Episode done for env 76. Reward: 19.25, Length: 21
DEBUG (Env): Episode done for env 94. Reward: 24.25, Length: 12
DEBUG (Env): Episode done for env 109. Reward: -0.08, Length: 31
DEBUG (Env): Episode done for env 126. Reward: 27.63, Length: 3
2182
Time taken for simulation:  7.089725971221924
average overall reward:  0.12248994  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.10484935  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: 20.12, Length: 26
DEBUG (Env): Episode done for env 43. Reward: -13.11, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -20.38, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 22.59, Length: 2
DEBUG (Env): Episode done for env 88. Reward: 11.62, Length: 11
DEBUG (Env): Episode done for env 104. Reward: -19.55, Length: 36
2183
Time taken for simulation:  7.16080904006958
average overall reward:  -0.047101557  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.32178864 average distance reward:  -0.14862797  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 10. Reward: 26.99, Length: 29
DEBUG (Env): Episode done for env 65. Reward: -2.16, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -24.96, Length: 36
DEBUG (Env): Episode done for env 108. Reward: 32.41, Length: 6
DEBUG (Env): Episode done for env 112. Reward: -15.67, Length: 36
DEBUG (Env): Episode done for env 119. Reward: 21.46, Length: 4
2184
Time taken for simulation:  7.218871116638184
average overall reward:  1.1167808  average fail penalty:  0.0  and average goal bonus:  1.0829762  and average same cell penalty:  -0.23168783 average distance reward:  0.31335294  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: 35.69, Length: 28
DEBUG (Env): Episode done for env 42. Reward: 16.43, Length: 15
DEBUG (Env): Episode done for env 53. Reward: 24.66, Length: 4
DEBUG (Env): Episode done for env 69. Reward: 21.29, Length: 31
DEBUG (Env): Episode done for env 70. Reward: 31.41, Length: 4
DEBUG (Env): Episode done for env 75. Reward: 28.70, Length: 7
DEBUG (Env): Episode done for env 94. Reward: 39.71, Length: 3
DEBUG (Env): Episode done for env 112. Reward: 18.27, Length: 1
2185
Time taken for simulation:  7.021505832672119
average overall reward:  1.0120356  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.39911518  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 2. Reward: 20.71, Length: 7
DEBUG (Env): Episode done for env 4. Reward: 24.20, Length: 9
DEBUG (Env): Episode done for env 7. Reward: 2.09, Length: 31
DEBUG (Env): Episode done for env 11. Reward: 37.04, Length: 8
DEBUG (Env): Episode done for env 13. Reward: -18.29, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 26.57, Length: 11
DEBUG (Env): Episode done for env 44. Reward: 4.05, Length: 29
DEBUG (Env): Episode done for env 57. Reward: 21.70, Length: 20
DEBUG (Env): Episode done for env 77. Reward: -25.76, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -7.38, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -16.96, Length: 36
2186
Time taken for simulation:  7.4557905197143555
average overall reward:  0.5989876  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.09010082 average distance reward:  0.3126483  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 11. Reward: 21.82, Length: 1
DEBUG (Env): Episode done for env 22. Reward: -30.81, Length: 36
DEBUG (Env): Episode done for env 23. Reward: 6.25, Length: 16
DEBUG (Env): Episode done for env 27. Reward: 28.77, Length: 13
DEBUG (Env): Episode done for env 32. Reward: -16.80, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -26.86, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 17.51, Length: 7
DEBUG (Env): Episode done for env 87. Reward: -11.88, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -21.80, Length: 36
2187
Time taken for simulation:  7.180972337722778
average overall reward:  0.8985496  average fail penalty:  -0.09375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.28562915  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 6. Reward: -15.68, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -29.91, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 24.72, Length: 24
DEBUG (Env): Episode done for env 64. Reward: -11.60, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 14.48, Length: 30
DEBUG (Env): Episode done for env 89. Reward: 29.39, Length: 2
DEBUG (Env): Episode done for env 100. Reward: 14.24, Length: 31
DEBUG (Env): Episode done for env 105. Reward: 18.82, Length: 12
DEBUG (Env): Episode done for env 109. Reward: 18.57, Length: 6
DEBUG (Env): Episode done for env 115. Reward: 15.67, Length: 8
DEBUG (Env): Episode done for env 117. Reward: -24.79, Length: 36
2188
Time taken for simulation:  7.221628665924072
average overall reward:  0.19196196  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.115843914 average distance reward:  0.15523481  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: -21.13, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 35.49, Length: 15
DEBUG (Env): Episode done for env 78. Reward: -22.22, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 17.83, Length: 21
DEBUG (Env): Episode done for env 113. Reward: -14.78, Length: 36
2189
Time taken for simulation:  7.471121788024902
average overall reward:  1.0874795  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.115843914 average distance reward:  0.5977612  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 43. Reward: 27.42, Length: 7
DEBUG (Env): Episode done for env 53. Reward: 24.15, Length: 5
DEBUG (Env): Episode done for env 70. Reward: 16.12, Length: 5
DEBUG (Env): Episode done for env 71. Reward: 22.47, Length: 23
DEBUG (Env): Episode done for env 83. Reward: -24.17, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 23.76, Length: 2
2190
Time taken for simulation:  7.338563680648804
average overall reward:  0.85700816  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.44451928  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 22. Reward: 22.45, Length: 4
DEBUG (Env): Episode done for env 29. Reward: -27.88, Length: 36
DEBUG (Env): Episode done for env 32. Reward: 21.81, Length: 4
DEBUG (Env): Episode done for env 62. Reward: 26.48, Length: 17
DEBUG (Env): Episode done for env 115. Reward: 23.43, Length: 3
DEBUG (Env): Episode done for env 124. Reward: 21.90, Length: 16
2191
Time taken for simulation:  7.327423572540283
average overall reward:  1.1760049  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.23168781 average distance reward:  0.39601445  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 51. Reward: -23.03, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 29.02, Length: 2
DEBUG (Env): Episode done for env 75. Reward: 24.68, Length: 7
DEBUG (Env): Episode done for env 83. Reward: 25.26, Length: 2
DEBUG (Env): Episode done for env 84. Reward: 42.65, Length: 18
DEBUG (Env): Episode done for env 89. Reward: 25.01, Length: 4
DEBUG (Env): Episode done for env 107. Reward: 29.86, Length: 21
DEBUG (Env): Episode done for env 120. Reward: 27.14, Length: 19
DEBUG (Env): Episode done for env 122. Reward: 22.02, Length: 15
2192
Time taken for simulation:  7.299163103103638
average overall reward:  0.580376  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.16733009 average distance reward:  -0.081725046  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 9. Reward: 18.98, Length: 17
DEBUG (Env): Episode done for env 10. Reward: 16.98, Length: 9
DEBUG (Env): Episode done for env 14. Reward: 23.23, Length: 22
DEBUG (Env): Episode done for env 58. Reward: 29.26, Length: 27
DEBUG (Env): Episode done for env 100. Reward: 20.20, Length: 3
DEBUG (Env): Episode done for env 103. Reward: -9.11, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 26.77, Length: 10
DEBUG (Env): Episode done for env 110. Reward: -11.34, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -7.13, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 19.84, Length: 5
2193
Time taken for simulation:  7.132767677307129
average overall reward:  0.87515587  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.15445855 average distance reward:  0.15330824  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: 13.99, Length: 27
DEBUG (Env): Episode done for env 16. Reward: 26.53, Length: 12
DEBUG (Env): Episode done for env 20. Reward: 21.27, Length: 6
DEBUG (Env): Episode done for env 25. Reward: 22.77, Length: 23
DEBUG (Env): Episode done for env 28. Reward: -12.65, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 26.48, Length: 28
DEBUG (Env): Episode done for env 34. Reward: 23.09, Length: 5
DEBUG (Env): Episode done for env 116. Reward: 35.64, Length: 20
2194
Time taken for simulation:  7.388564825057983
average overall reward:  1.109592  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.5488595  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 36.29, Length: 7
DEBUG (Env): Episode done for env 28. Reward: 29.77, Length: 1
DEBUG (Env): Episode done for env 49. Reward: 18.82, Length: 20
DEBUG (Env): Episode done for env 57. Reward: 43.33, Length: 9
DEBUG (Env): Episode done for env 60. Reward: 12.05, Length: 17
DEBUG (Env): Episode done for env 63. Reward: 32.92, Length: 30
DEBUG (Env): Episode done for env 72. Reward: -20.22, Length: 36
2195
Time taken for simulation:  7.06235146522522
average overall reward:  0.39992717  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.12876502  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: 25.68, Length: 10
DEBUG (Env): Episode done for env 24. Reward: -18.33, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -12.01, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 26.59, Length: 9
DEBUG (Env): Episode done for env 55. Reward: -20.90, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 2.22, Length: 7
DEBUG (Env): Episode done for env 114. Reward: -10.60, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 44.76, Length: 2
2196
Time taken for simulation:  7.44478702545166
average overall reward:  0.8142173  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.141587 average distance reward:  0.32680476  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 32. Reward: 22.80, Length: 6
DEBUG (Env): Episode done for env 34. Reward: 17.43, Length: 3
DEBUG (Env): Episode done for env 35. Reward: 21.48, Length: 15
DEBUG (Env): Episode done for env 69. Reward: 23.32, Length: 12
DEBUG (Env): Episode done for env 90. Reward: 18.64, Length: 31
2197
Time taken for simulation:  7.608595132827759
average overall reward:  0.76910424  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.07722928 average distance reward:  0.24077144  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: 44.54, Length: 12
DEBUG (Env): Episode done for env 48. Reward: 22.81, Length: 15
DEBUG (Env): Episode done for env 66. Reward: 16.69, Length: 22
DEBUG (Env): Episode done for env 73. Reward: 20.58, Length: 9
DEBUG (Env): Episode done for env 83. Reward: 23.98, Length: 6
DEBUG (Env): Episode done for env 121. Reward: -16.54, Length: 36
2198
Time taken for simulation:  7.264240264892578
average overall reward:  1.2058645  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.141587 average distance reward:  0.35921097  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 15. Reward: 14.08, Length: 13
DEBUG (Env): Episode done for env 24. Reward: 32.77, Length: 3
DEBUG (Env): Episode done for env 27. Reward: 16.40, Length: 12
DEBUG (Env): Episode done for env 68. Reward: 27.62, Length: 18
DEBUG (Env): Episode done for env 79. Reward: 29.14, Length: 12
DEBUG (Env): Episode done for env 80. Reward: 33.64, Length: 11
DEBUG (Env): Episode done for env 93. Reward: -15.82, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 18.30, Length: 28
DEBUG (Env): Episode done for env 116. Reward: 20.34, Length: 3
DEBUG (Env): Episode done for env 123. Reward: -23.26, Length: 36
2199
Time taken for simulation:  7.599083662033081
average overall reward:  1.065946  average fail penalty:  -0.09375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.20594473 average distance reward:  0.33052504  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 1. Reward: 17.18, Length: 6
DEBUG (Env): Episode done for env 4. Reward: 12.65, Length: 14
DEBUG (Env): Episode done for env 21. Reward: -14.72, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 15.13, Length: 6
DEBUG (Env): Episode done for env 40. Reward: -23.18, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 0.01, Length: 35
DEBUG (Env): Episode done for env 48. Reward: 27.90, Length: 2
DEBUG (Env): Episode done for env 50. Reward: -14.71, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 31.93, Length: 5
DEBUG (Env): Episode done for env 68. Reward: 21.67, Length: 1
DEBUG (Env): Episode done for env 99. Reward: -21.37, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 25.71, Length: 7
2200
Time taken for simulation:  7.108103036880493
average overall reward:  1.0635673  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.141587 average distance reward:  0.32884806  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 6. Reward: 19.60, Length: 6
DEBUG (Env): Episode done for env 26. Reward: 20.08, Length: 20
DEBUG (Env): Episode done for env 51. Reward: 22.02, Length: 9
DEBUG (Env): Episode done for env 70. Reward: 22.70, Length: 9
DEBUG (Env): Episode done for env 71. Reward: 35.98, Length: 11
DEBUG (Env): Episode done for env 101. Reward: 29.75, Length: 14
DEBUG (Env): Episode done for env 110. Reward: 27.50, Length: 8
DEBUG (Env): Episode done for env 118. Reward: -13.46, Length: 36
2201
Time taken for simulation:  7.870445728302002
average overall reward:  0.6482772  average fail penalty:  -0.1171875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  0.29092366  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: -15.03, Length: 36
DEBUG (Env): Episode done for env 12. Reward: 10.99, Length: 35
DEBUG (Env): Episode done for env 14. Reward: 26.99, Length: 9
DEBUG (Env): Episode done for env 15. Reward: 19.68, Length: 3
DEBUG (Env): Episode done for env 19. Reward: -18.31, Length: 36
DEBUG (Env): Episode done for env 38. Reward: -30.08, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 11.47, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 14.79, Length: 13
DEBUG (Env): Episode done for env 125. Reward: -11.91, Length: 36
2202
Time taken for simulation:  7.038533449172974
average overall reward:  0.7231977  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.2574309 average distance reward:  0.263132  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: 34.83, Length: 5
DEBUG (Env): Episode done for env 37. Reward: -20.89, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 15.76, Length: 19
DEBUG (Env): Episode done for env 67. Reward: 18.81, Length: 21
DEBUG (Env): Episode done for env 73. Reward: 36.36, Length: 5
DEBUG (Env): Episode done for env 79. Reward: 22.82, Length: 4
DEBUG (Env): Episode done for env 96. Reward: -20.42, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 15.18, Length: 1
2203
Time taken for simulation:  7.7188475131988525
average overall reward:  0.11649301  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.23262066  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 91. Reward: -16.31, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 26.32, Length: 13
2204
Time taken for simulation:  7.179280042648315
average overall reward:  0.026495576  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.13868675  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 93. Reward: 9.44, Length: 6
DEBUG (Env): Episode done for env 94. Reward: 38.12, Length: 20
DEBUG (Env): Episode done for env 105. Reward: 34.27, Length: 17
2205
Time taken for simulation:  7.842099905014038
average overall reward:  0.44513762  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.034954317  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: 28.53, Length: 13
DEBUG (Env): Episode done for env 28. Reward: 11.51, Length: 11
DEBUG (Env): Episode done for env 64. Reward: 8.54, Length: 18
DEBUG (Env): Episode done for env 86. Reward: -2.54, Length: 31
DEBUG (Env): Episode done for env 126. Reward: 26.11, Length: 24
2206
Time taken for simulation:  7.142438888549805
average overall reward:  1.0266322  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.11584391 average distance reward:  0.44841695  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: -16.08, Length: 36
DEBUG (Env): Episode done for env 2. Reward: 14.63, Length: 11
DEBUG (Env): Episode done for env 30. Reward: 19.27, Length: 29
DEBUG (Env): Episode done for env 49. Reward: 24.17, Length: 12
DEBUG (Env): Episode done for env 51. Reward: 20.43, Length: 6
DEBUG (Env): Episode done for env 56. Reward: -6.71, Length: 36
DEBUG (Env): Episode done for env 59. Reward: -20.28, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 42.87, Length: 4
DEBUG (Env): Episode done for env 78. Reward: 22.35, Length: 11
2207
Time taken for simulation:  7.124196767807007
average overall reward:  0.51609653  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  0.080170125  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: 31.01, Length: 6
DEBUG (Env): Episode done for env 29. Reward: 10.42, Length: 17
DEBUG (Env): Episode done for env 43. Reward: 33.05, Length: 18
DEBUG (Env): Episode done for env 54. Reward: 17.69, Length: 12
DEBUG (Env): Episode done for env 101. Reward: 22.53, Length: 7
2208
Time taken for simulation:  7.334321975708008
average overall reward:  0.41533312  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.110167585  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: 27.38, Length: 9
DEBUG (Env): Episode done for env 40. Reward: 18.82, Length: 9
DEBUG (Env): Episode done for env 72. Reward: 3.19, Length: 14
DEBUG (Env): Episode done for env 92. Reward: -17.66, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 22.40, Length: 17
DEBUG (Env): Episode done for env 127. Reward: -27.99, Length: 36
2209
Time taken for simulation:  7.228378057479858
average overall reward:  0.13487001  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.2978727  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 39. Reward: -27.21, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 28.59, Length: 24
DEBUG (Env): Episode done for env 47. Reward: -27.59, Length: 36
DEBUG (Env): Episode done for env 61. Reward: -16.25, Length: 36
2210
Time taken for simulation:  7.074392318725586
average overall reward:  0.49278593  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.12871546 average distance reward:  0.28668332  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 31. Reward: 25.12, Length: 17
DEBUG (Env): Episode done for env 97. Reward: -20.83, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 30.08, Length: 12
DEBUG (Env): Episode done for env 104. Reward: 26.56, Length: 18
2211
Time taken for simulation:  7.272099256515503
average overall reward:  0.19552326  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.043212466  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 41. Reward: 15.57, Length: 12
DEBUG (Env): Episode done for env 55. Reward: 9.36, Length: 16
DEBUG (Env): Episode done for env 83. Reward: 22.06, Length: 14
2212
Time taken for simulation:  7.219799995422363
average overall reward:  0.46127942  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.27030247 average distance reward:  0.1728948  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: -14.31, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 36.16, Length: 22
DEBUG (Env): Episode done for env 40. Reward: 22.65, Length: 4
DEBUG (Env): Episode done for env 45. Reward: -20.18, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 37.47, Length: 13
DEBUG (Env): Episode done for env 105. Reward: 16.15, Length: 8
DEBUG (Env): Episode done for env 125. Reward: 38.57, Length: 10
2213
Time taken for simulation:  7.2551186084747314
average overall reward:  0.7214694  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455936 average distance reward:  0.36046666  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 12.55, Length: 12
DEBUG (Env): Episode done for env 38. Reward: 25.50, Length: 12
DEBUG (Env): Episode done for env 41. Reward: 20.28, Length: 2
DEBUG (Env): Episode done for env 46. Reward: -15.17, Length: 36
DEBUG (Env): Episode done for env 77. Reward: 11.90, Length: 28
DEBUG (Env): Episode done for env 109. Reward: 33.23, Length: 26
2214
Time taken for simulation:  7.095855712890625
average overall reward:  0.35738233  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  -0.10428721  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 60. Reward: 3.70, Length: 20
DEBUG (Env): Episode done for env 85. Reward: 13.43, Length: 29
DEBUG (Env): Episode done for env 86. Reward: 17.09, Length: 9
DEBUG (Env): Episode done for env 111. Reward: 23.46, Length: 15
DEBUG (Env): Episode done for env 126. Reward: 25.48, Length: 9
2215
Time taken for simulation:  7.622103691101074
average overall reward:  0.46272278  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.07722928 average distance reward:  0.34050596  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 52. Reward: 1.04, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 21.80, Length: 7
2216
Time taken for simulation:  7.284561634063721
average overall reward:  0.64246047  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.16733009 average distance reward:  0.22766598  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 25.72, Length: 10
DEBUG (Env): Episode done for env 19. Reward: 37.75, Length: 15
DEBUG (Env): Episode done for env 33. Reward: -22.08, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -36.45, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 30.24, Length: 9
DEBUG (Env): Episode done for env 121. Reward: 19.20, Length: 19
DEBUG (Env): Episode done for env 123. Reward: 18.63, Length: 18
2217
Time taken for simulation:  7.455690383911133
average overall reward:  0.71589285  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.15516046  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 26.34, Length: 11
DEBUG (Env): Episode done for env 4. Reward: 24.05, Length: 9
DEBUG (Env): Episode done for env 10. Reward: -1.03, Length: 25
DEBUG (Env): Episode done for env 30. Reward: 38.82, Length: 11
DEBUG (Env): Episode done for env 76. Reward: 11.66, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 36.62, Length: 3
DEBUG (Env): Episode done for env 123. Reward: 20.23, Length: 1
2218
Time taken for simulation:  7.702261209487915
average overall reward:  0.5770268  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  -0.046459705  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 9. Reward: 31.28, Length: 13
DEBUG (Env): Episode done for env 17. Reward: -12.08, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 28.66, Length: 13
DEBUG (Env): Episode done for env 40. Reward: 22.22, Length: 6
DEBUG (Env): Episode done for env 51. Reward: 20.70, Length: 12
DEBUG (Env): Episode done for env 57. Reward: 15.38, Length: 24
DEBUG (Env): Episode done for env 65. Reward: 28.38, Length: 12
DEBUG (Env): Episode done for env 81. Reward: -28.96, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 19.98, Length: 1
DEBUG (Env): Episode done for env 88. Reward: -16.40, Length: 36
2219
Time taken for simulation:  7.180963039398193
average overall reward:  0.2397762  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.28027838  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 105. Reward: 31.99, Length: 7
DEBUG (Env): Episode done for env 106. Reward: -15.91, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -19.09, Length: 36
DEBUG (Env): Episode done for env 111. Reward: 23.28, Length: 5
DEBUG (Env): Episode done for env 119. Reward: -22.62, Length: 36
2220
Time taken for simulation:  7.690094232559204
average overall reward:  0.7809185  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.51206195  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 20.12, Length: 4
DEBUG (Env): Episode done for env 9. Reward: 25.14, Length: 2
DEBUG (Env): Episode done for env 18. Reward: -24.24, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -17.38, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 33.64, Length: 8
DEBUG (Env): Episode done for env 97. Reward: 32.79, Length: 10
DEBUG (Env): Episode done for env 112. Reward: -15.40, Length: 36
2221
Time taken for simulation:  6.927491188049316
average overall reward:  0.6965693  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168781 average distance reward:  0.18732303  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 7. Reward: -18.76, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 19.66, Length: 1
DEBUG (Env): Episode done for env 49. Reward: 19.20, Length: 15
DEBUG (Env): Episode done for env 96. Reward: 23.96, Length: 19
DEBUG (Env): Episode done for env 116. Reward: 13.51, Length: 23
DEBUG (Env): Episode done for env 117. Reward: 29.19, Length: 29
DEBUG (Env): Episode done for env 121. Reward: 18.28, Length: 5
2222
Time taken for simulation:  7.395946025848389
average overall reward:  0.38616067  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.23168781 average distance reward:  -0.076210625  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 11. Reward: -22.22, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -14.11, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 15.94, Length: 26
DEBUG (Env): Episode done for env 43. Reward: 8.82, Length: 15
DEBUG (Env): Episode done for env 87. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 2.62, Length: 26
DEBUG (Env): Episode done for env 100. Reward: 10.05, Length: 30
DEBUG (Env): Episode done for env 110. Reward: 12.01, Length: 22
DEBUG (Env): Episode done for env 118. Reward: 20.61, Length: 22
2223
Time taken for simulation:  7.369481563568115
average overall reward:  0.5091244  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.141587 average distance reward:  0.31589335  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 8. Reward: -19.82, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 19.96, Length: 1
DEBUG (Env): Episode done for env 86. Reward: 15.35, Length: 9
DEBUG (Env): Episode done for env 125. Reward: 23.96, Length: 11
2224
Time taken for simulation:  7.859510183334351
average overall reward:  1.2638113  average fail penalty:  -0.0234375  and average goal bonus:  1.3537202  and average same cell penalty:  -0.27030247 average distance reward:  0.25169167  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 1. Reward: 14.35, Length: 25
DEBUG (Env): Episode done for env 23. Reward: 34.45, Length: 2
DEBUG (Env): Episode done for env 28. Reward: 25.17, Length: 6
DEBUG (Env): Episode done for env 30. Reward: 29.24, Length: 7
DEBUG (Env): Episode done for env 52. Reward: 25.85, Length: 9
DEBUG (Env): Episode done for env 71. Reward: 19.15, Length: 24
DEBUG (Env): Episode done for env 78. Reward: 29.49, Length: 18
DEBUG (Env): Episode done for env 96. Reward: 24.87, Length: 3
DEBUG (Env): Episode done for env 98. Reward: 24.50, Length: 8
DEBUG (Env): Episode done for env 107. Reward: 35.86, Length: 33
DEBUG (Env): Episode done for env 113. Reward: -16.26, Length: 36
2225
Time taken for simulation:  7.034311294555664
average overall reward:  0.59099805  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594472 average distance reward:  0.32675272  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: 18.57, Length: 24
DEBUG (Env): Episode done for env 22. Reward: 35.38, Length: 13
DEBUG (Env): Episode done for env 53. Reward: -25.43, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 7.22, Length: 28
DEBUG (Env): Episode done for env 93. Reward: 5.59, Length: 21
2226
Time taken for simulation:  7.3305628299713135
average overall reward:  0.7689712  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.3670483  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 26.41, Length: 9
DEBUG (Env): Episode done for env 38. Reward: 34.35, Length: 13
DEBUG (Env): Episode done for env 40. Reward: 49.42, Length: 8
DEBUG (Env): Episode done for env 57. Reward: 17.66, Length: 8
DEBUG (Env): Episode done for env 62. Reward: -13.36, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 28.55, Length: 10
DEBUG (Env): Episode done for env 115. Reward: -22.54, Length: 36
2227
Time taken for simulation:  7.040876865386963
average overall reward:  0.62981975  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.39727235  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 54. Reward: 13.97, Length: 20
DEBUG (Env): Episode done for env 62. Reward: 19.37, Length: 1
DEBUG (Env): Episode done for env 67. Reward: 16.30, Length: 25
DEBUG (Env): Episode done for env 75. Reward: -17.64, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -20.29, Length: 36
DEBUG (Env): Episode done for env 89. Reward: -25.94, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 22.12, Length: 6
DEBUG (Env): Episode done for env 120. Reward: -27.32, Length: 36
2228
Time taken for simulation:  7.239281177520752
average overall reward:  0.81698  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594475 average distance reward:  0.30542815  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: 35.12, Length: 8
DEBUG (Env): Episode done for env 33. Reward: 38.57, Length: 12
DEBUG (Env): Episode done for env 44. Reward: 24.05, Length: 19
DEBUG (Env): Episode done for env 58. Reward: -34.89, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 32.85, Length: 16
DEBUG (Env): Episode done for env 86. Reward: 18.76, Length: 5
DEBUG (Env): Episode done for env 101. Reward: 23.28, Length: 2
DEBUG (Env): Episode done for env 103. Reward: -16.20, Length: 36
2229
Time taken for simulation:  7.409131765365601
average overall reward:  0.9158365  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.23168781 average distance reward:  0.15928355  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 6. Reward: 17.35, Length: 29
DEBUG (Env): Episode done for env 11. Reward: 40.82, Length: 7
DEBUG (Env): Episode done for env 13. Reward: 12.80, Length: 27
DEBUG (Env): Episode done for env 16. Reward: -8.60, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -14.29, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 17.73, Length: 23
DEBUG (Env): Episode done for env 62. Reward: 24.37, Length: 2
DEBUG (Env): Episode done for env 70. Reward: 25.37, Length: 29
DEBUG (Env): Episode done for env 107. Reward: 25.53, Length: 5
DEBUG (Env): Episode done for env 108. Reward: 28.07, Length: 10
2230
Time taken for simulation:  7.464059114456177
average overall reward:  0.9865581  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.55063164  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 18. Reward: 24.23, Length: 2
DEBUG (Env): Episode done for env 55. Reward: 14.41, Length: 19
DEBUG (Env): Episode done for env 65. Reward: 23.22, Length: 12
DEBUG (Env): Episode done for env 74. Reward: 24.59, Length: 2
DEBUG (Env): Episode done for env 94. Reward: 12.28, Length: 26
2231
Time taken for simulation:  7.251781225204468
average overall reward:  0.533817  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.26726606  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 22. Reward: 35.86, Length: 6
DEBUG (Env): Episode done for env 36. Reward: -17.88, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 15.27, Length: 32
DEBUG (Env): Episode done for env 108. Reward: 24.55, Length: 2
DEBUG (Env): Episode done for env 114. Reward: -17.84, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 24.50, Length: 5
2232
Time taken for simulation:  7.040019273757935
average overall reward:  0.7386311  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.11514474  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 23. Reward: 18.67, Length: 8
DEBUG (Env): Episode done for env 32. Reward: -15.09, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -25.22, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 24.94, Length: 19
DEBUG (Env): Episode done for env 47. Reward: 5.67, Length: 23
DEBUG (Env): Episode done for env 57. Reward: 23.64, Length: 6
DEBUG (Env): Episode done for env 69. Reward: -24.63, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 19.65, Length: 8
DEBUG (Env): Episode done for env 86. Reward: 26.57, Length: 4
DEBUG (Env): Episode done for env 93. Reward: 17.30, Length: 7
2233
Time taken for simulation:  7.132702589035034
average overall reward:  1.1076411  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.102972366 average distance reward:  0.31086987  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 13. Reward: 26.61, Length: 4
DEBUG (Env): Episode done for env 50. Reward: 6.39, Length: 34
DEBUG (Env): Episode done for env 57. Reward: 18.96, Length: 1
DEBUG (Env): Episode done for env 58. Reward: 24.66, Length: 5
DEBUG (Env): Episode done for env 66. Reward: 16.13, Length: 8
DEBUG (Env): Episode done for env 97. Reward: 15.23, Length: 13
DEBUG (Env): Episode done for env 111. Reward: 14.16, Length: 14
2234
Time taken for simulation:  7.859670639038086
average overall reward:  0.15787736  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.19837956  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: -2.49, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -18.27, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 14.57, Length: 1
DEBUG (Env): Episode done for env 72. Reward: 13.47, Length: 26
DEBUG (Env): Episode done for env 80. Reward: -13.12, Length: 36
2235
Time taken for simulation:  7.167038202285767
average overall reward:  0.9855183  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.115843914 average distance reward:  0.43074054  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 21. Reward: -17.89, Length: 36
DEBUG (Env): Episode done for env 25. Reward: -2.85, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 47.92, Length: 7
DEBUG (Env): Episode done for env 45. Reward: 22.83, Length: 15
DEBUG (Env): Episode done for env 57. Reward: 41.06, Length: 2
DEBUG (Env): Episode done for env 63. Reward: -20.29, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -16.28, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 30.99, Length: 17
DEBUG (Env): Episode done for env 111. Reward: 21.84, Length: 2
DEBUG (Env): Episode done for env 121. Reward: 20.55, Length: 14
2236
Time taken for simulation:  7.484762907028198
average overall reward:  0.5689163  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.1564274  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 24. Reward: 24.61, Length: 2
DEBUG (Env): Episode done for env 26. Reward: -17.16, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 21.01, Length: 4
DEBUG (Env): Episode done for env 99. Reward: 25.21, Length: 24
DEBUG (Env): Episode done for env 124. Reward: 13.14, Length: 33
DEBUG (Env): Episode done for env 125. Reward: 20.13, Length: 13
2237
Time taken for simulation:  7.326012134552002
average overall reward:  1.1576712  average fail penalty:  -0.0703125  and average goal bonus:  1.3537202  and average same cell penalty:  -0.18020165 average distance reward:  0.10232569  and average step penalty:  -0.04786053509430681
Number of done instances:  13
DEBUG (Env): Episode done for env 9. Reward: 13.44, Length: 17
DEBUG (Env): Episode done for env 14. Reward: -14.37, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 10.47, Length: 19
DEBUG (Env): Episode done for env 31. Reward: 13.70, Length: 27
DEBUG (Env): Episode done for env 39. Reward: 5.70, Length: 28
DEBUG (Env): Episode done for env 41. Reward: 20.79, Length: 24
DEBUG (Env): Episode done for env 53. Reward: 9.86, Length: 12
DEBUG (Env): Episode done for env 57. Reward: 26.91, Length: 2
DEBUG (Env): Episode done for env 76. Reward: 13.28, Length: 20
DEBUG (Env): Episode done for env 82. Reward: -22.01, Length: 36
DEBUG (Env): Episode done for env 95. Reward: -21.17, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 21.09, Length: 13
DEBUG (Env): Episode done for env 117. Reward: 32.31, Length: 16
2238
Time taken for simulation:  7.262872934341431
average overall reward:  0.26749554  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.15975416  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 37. Reward: -16.07, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -7.40, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -10.68, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 22.71, Length: 3
DEBUG (Env): Episode done for env 102. Reward: 15.91, Length: 28
DEBUG (Env): Episode done for env 112. Reward: 11.22, Length: 18
2239
Time taken for simulation:  7.671938419342041
average overall reward:  1.1456115  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.20594473 average distance reward:  0.33987802  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 11. Reward: 20.37, Length: 10
DEBUG (Env): Episode done for env 39. Reward: 24.98, Length: 2
DEBUG (Env): Episode done for env 47. Reward: 13.26, Length: 7
DEBUG (Env): Episode done for env 76. Reward: 23.36, Length: 2
DEBUG (Env): Episode done for env 91. Reward: -13.13, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 27.17, Length: 15
DEBUG (Env): Episode done for env 100. Reward: 19.95, Length: 17
DEBUG (Env): Episode done for env 121. Reward: 20.01, Length: 4
DEBUG (Env): Episode done for env 122. Reward: 31.19, Length: 31
2240
Time taken for simulation:  7.166556358337402
average overall reward:  0.1196775  average fail penalty:  0.0  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  0.21236765  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 26. Reward: 21.49, Length: 4
2241
Time taken for simulation:  7.344905138015747
average overall reward:  0.7908913  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.090100825 average distance reward:  0.004685968  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 3. Reward: 8.58, Length: 28
DEBUG (Env): Episode done for env 7. Reward: 20.98, Length: 20
DEBUG (Env): Episode done for env 15. Reward: 18.78, Length: 16
DEBUG (Env): Episode done for env 39. Reward: 17.71, Length: 2
DEBUG (Env): Episode done for env 50. Reward: 24.20, Length: 7
DEBUG (Env): Episode done for env 51. Reward: 1.27, Length: 23
DEBUG (Env): Episode done for env 64. Reward: -20.37, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 22.99, Length: 4
2242
Time taken for simulation:  7.186723470687866
average overall reward:  1.3866075  average fail penalty:  -0.0234375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.15445855 average distance reward:  0.39401588  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 16. Reward: 20.60, Length: 13
DEBUG (Env): Episode done for env 18. Reward: 24.80, Length: 12
DEBUG (Env): Episode done for env 37. Reward: 16.76, Length: 4
DEBUG (Env): Episode done for env 38. Reward: 21.98, Length: 16
DEBUG (Env): Episode done for env 43. Reward: 25.57, Length: 19
DEBUG (Env): Episode done for env 59. Reward: -19.73, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 25.17, Length: 12
DEBUG (Env): Episode done for env 86. Reward: 15.20, Length: 10
DEBUG (Env): Episode done for env 124. Reward: 27.13, Length: 6
DEBUG (Env): Episode done for env 125. Reward: 31.66, Length: 6
2243
Time taken for simulation:  7.230645179748535
average overall reward:  -0.13443345  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.15445855 average distance reward:  0.11476068  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 12. Reward: -18.62, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -16.55, Length: 36
2244
Time taken for simulation:  7.099794626235962
average overall reward:  0.30608535  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.2574309 average distance reward:  -0.04204584  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 6. Reward: 21.95, Length: 15
DEBUG (Env): Episode done for env 28. Reward: 3.51, Length: 20
DEBUG (Env): Episode done for env 52. Reward: 17.29, Length: 20
DEBUG (Env): Episode done for env 74. Reward: 20.42, Length: 2
DEBUG (Env): Episode done for env 126. Reward: 11.22, Length: 30
DEBUG (Env): Episode done for env 127. Reward: -14.53, Length: 36
2245
Time taken for simulation:  7.788766384124756
average overall reward:  0.0009473115  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020163 average distance reward:  -0.28904113  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: 26.75, Length: 12
DEBUG (Env): Episode done for env 61. Reward: -14.77, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 19.15, Length: 3
DEBUG (Env): Episode done for env 98. Reward: 32.17, Length: 6
DEBUG (Env): Episode done for env 113. Reward: 25.74, Length: 21
2246
Time taken for simulation:  7.0891923904418945
average overall reward:  0.3956833  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.26681  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 30. Reward: 10.34, Length: 22
DEBUG (Env): Episode done for env 74. Reward: 17.64, Length: 2
DEBUG (Env): Episode done for env 104. Reward: -24.35, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 17.63, Length: 24
2247
Time taken for simulation:  7.3778464794158936
average overall reward:  -0.0779171  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.115843914 average distance reward:  0.109224826  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 83. Reward: -25.99, Length: 36
2248
Time taken for simulation:  7.143270492553711
average overall reward:  0.27389175  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  -0.15146866  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 6.54, Length: 31
DEBUG (Env): Episode done for env 5. Reward: -19.31, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 24.28, Length: 11
DEBUG (Env): Episode done for env 38. Reward: 17.66, Length: 6
DEBUG (Env): Episode done for env 57. Reward: 28.03, Length: 11
DEBUG (Env): Episode done for env 77. Reward: 1.70, Length: 35
2249
Time taken for simulation:  7.930703639984131
average overall reward:  -0.06719859  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.048929073  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 70. Reward: 18.69, Length: 20
DEBUG (Env): Episode done for env 109. Reward: -17.80, Length: 36
2250
Time taken for simulation:  7.6420886516571045
average overall reward:  0.87893397  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.3568161  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 41. Reward: 31.91, Length: 13
DEBUG (Env): Episode done for env 60. Reward: -16.09, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 13.80, Length: 20
DEBUG (Env): Episode done for env 69. Reward: 14.93, Length: 18
DEBUG (Env): Episode done for env 72. Reward: 19.72, Length: 16
DEBUG (Env): Episode done for env 122. Reward: 34.94, Length: 11
DEBUG (Env): Episode done for env 127. Reward: 30.68, Length: 6
2251
Time taken for simulation:  7.434342622756958
average overall reward:  0.55674744  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.092772365  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 42.13, Length: 8
DEBUG (Env): Episode done for env 32. Reward: 22.93, Length: 19
DEBUG (Env): Episode done for env 37. Reward: 28.08, Length: 9
DEBUG (Env): Episode done for env 58. Reward: 26.77, Length: 18
DEBUG (Env): Episode done for env 79. Reward: 12.90, Length: 13
DEBUG (Env): Episode done for env 92. Reward: -10.46, Length: 36
2252
Time taken for simulation:  7.439128637313843
average overall reward:  0.65926266  average fail penalty:  -0.0234375  and average goal bonus:  0.8122322  and average same cell penalty:  -0.20594473 average distance reward:  0.12427325  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 18.48, Length: 26
DEBUG (Env): Episode done for env 18. Reward: 26.21, Length: 10
DEBUG (Env): Episode done for env 19. Reward: -26.71, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 18.56, Length: 17
DEBUG (Env): Episode done for env 43. Reward: 27.34, Length: 10
DEBUG (Env): Episode done for env 46. Reward: 11.87, Length: 16
DEBUG (Env): Episode done for env 51. Reward: 25.35, Length: 11
2253
Time taken for simulation:  7.007282018661499
average overall reward:  0.12059818  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  0.13766283  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 4. Reward: -8.26, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 18.84, Length: 12
DEBUG (Env): Episode done for env 52. Reward: 23.55, Length: 9
DEBUG (Env): Episode done for env 123. Reward: -10.98, Length: 36
2254
Time taken for simulation:  7.128776550292969
average overall reward:  0.35745257  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.14238788  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: 22.51, Length: 15
DEBUG (Env): Episode done for env 49. Reward: 10.64, Length: 33
DEBUG (Env): Episode done for env 66. Reward: 13.19, Length: 21
DEBUG (Env): Episode done for env 81. Reward: -15.67, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -7.35, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 33.45, Length: 4
2255
Time taken for simulation:  7.173486232757568
average overall reward:  -0.003614124  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.27030247 average distance reward:  0.24948934  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 65. Reward: 29.88, Length: 5
DEBUG (Env): Episode done for env 105. Reward: -11.02, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -16.83, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -17.73, Length: 36
2256
Time taken for simulation:  7.579176187515259
average overall reward:  0.7171662  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.51727855  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -18.64, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 22.08, Length: 6
DEBUG (Env): Episode done for env 74. Reward: 27.81, Length: 10
DEBUG (Env): Episode done for env 91. Reward: 19.45, Length: 17
DEBUG (Env): Episode done for env 126. Reward: 38.16, Length: 12
2257
Time taken for simulation:  7.233420372009277
average overall reward:  1.3438952  average fail penalty:  -0.0234375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.16733009 average distance reward:  0.3641752  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 5. Reward: 33.29, Length: 9
DEBUG (Env): Episode done for env 21. Reward: 32.03, Length: 22
DEBUG (Env): Episode done for env 37. Reward: 30.27, Length: 6
DEBUG (Env): Episode done for env 42. Reward: -19.56, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 0.38, Length: 33
DEBUG (Env): Episode done for env 79. Reward: 34.30, Length: 6
DEBUG (Env): Episode done for env 96. Reward: 18.13, Length: 20
DEBUG (Env): Episode done for env 98. Reward: 18.31, Length: 12
DEBUG (Env): Episode done for env 110. Reward: 22.92, Length: 11
DEBUG (Env): Episode done for env 121. Reward: 11.97, Length: 18
2258
Time taken for simulation:  7.125840187072754
average overall reward:  0.61060977  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594473 average distance reward:  0.14593284  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 2. Reward: 33.28, Length: 10
DEBUG (Env): Episode done for env 6. Reward: 16.18, Length: 14
DEBUG (Env): Episode done for env 24. Reward: 18.70, Length: 22
DEBUG (Env): Episode done for env 29. Reward: 17.44, Length: 15
DEBUG (Env): Episode done for env 31. Reward: 0.64, Length: 21
DEBUG (Env): Episode done for env 35. Reward: -19.34, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 4.85, Length: 36
DEBUG (Env): Episode done for env 90. Reward: -22.44, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -19.90, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 31.98, Length: 8
2259
Time taken for simulation:  7.4911417961120605
average overall reward:  1.2861521  average fail penalty:  -0.0234375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.18020163 average distance reward:  0.31930357  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 8. Reward: -19.30, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 26.95, Length: 11
DEBUG (Env): Episode done for env 26. Reward: 35.35, Length: 19
DEBUG (Env): Episode done for env 29. Reward: 27.22, Length: 1
DEBUG (Env): Episode done for env 39. Reward: 28.24, Length: 18
DEBUG (Env): Episode done for env 40. Reward: 16.04, Length: 33
DEBUG (Env): Episode done for env 68. Reward: 18.94, Length: 24
DEBUG (Env): Episode done for env 86. Reward: 18.70, Length: 14
DEBUG (Env): Episode done for env 105. Reward: 21.91, Length: 4
DEBUG (Env): Episode done for env 114. Reward: 6.73, Length: 28
2260
Time taken for simulation:  7.489882469177246
average overall reward:  0.47493315  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.21068779  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -22.09, Length: 36
DEBUG (Env): Episode done for env 5. Reward: 39.54, Length: 3
DEBUG (Env): Episode done for env 25. Reward: 5.62, Length: 25
DEBUG (Env): Episode done for env 38. Reward: 17.81, Length: 12
DEBUG (Env): Episode done for env 40. Reward: 12.30, Length: 1
2261
Time taken for simulation:  7.571828365325928
average overall reward:  0.19958487  average fail penalty:  0.0  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.19551763  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 103. Reward: -2.41, Length: 33
DEBUG (Env): Episode done for env 122. Reward: 34.09, Length: 7
2262
Time taken for simulation:  7.139768123626709
average overall reward:  0.885998  average fail penalty:  0.0  and average goal bonus:  0.8122322  and average same cell penalty:  -0.18020163 average distance reward:  0.3018281  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: 16.77, Length: 8
DEBUG (Env): Episode done for env 52. Reward: 25.04, Length: 9
DEBUG (Env): Episode done for env 100. Reward: 12.93, Length: 23
DEBUG (Env): Episode done for env 102. Reward: 17.83, Length: 24
DEBUG (Env): Episode done for env 108. Reward: 29.66, Length: 31
DEBUG (Env): Episode done for env 124. Reward: 26.96, Length: 20
2263
Time taken for simulation:  7.307202100753784
average overall reward:  0.97890687  average fail penalty:  -0.1640625  and average goal bonus:  1.0829761  and average same cell penalty:  -0.115843914 average distance reward:  0.22369763  and average step penalty:  -0.04786053509430681
Number of done instances:  15
DEBUG (Env): Episode done for env 32. Reward: 30.30, Length: 12
DEBUG (Env): Episode done for env 33. Reward: 30.02, Length: 11
DEBUG (Env): Episode done for env 46. Reward: 19.92, Length: 11
DEBUG (Env): Episode done for env 54. Reward: -20.07, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -10.30, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 23.23, Length: 7
DEBUG (Env): Episode done for env 75. Reward: -14.96, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -16.25, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 22.60, Length: 5
DEBUG (Env): Episode done for env 89. Reward: -7.89, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 28.76, Length: 17
DEBUG (Env): Episode done for env 109. Reward: 18.96, Length: 14
DEBUG (Env): Episode done for env 116. Reward: -11.44, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -12.14, Length: 36
DEBUG (Env): Episode done for env 125. Reward: 20.25, Length: 21
2264
Time taken for simulation:  7.114365577697754
average overall reward:  0.19703561  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020165 average distance reward:  0.33660072  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 39. Reward: 22.76, Length: 5
DEBUG (Env): Episode done for env 44. Reward: -18.70, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -23.02, Length: 36
2265
Time taken for simulation:  7.4233927726745605
average overall reward:  0.1308797  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.11584391 average distance reward:  0.25296214  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 20. Reward: -19.39, Length: 36
DEBUG (Env): Episode done for env 56. Reward: -11.38, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 107. Reward: -13.37, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 27.46, Length: 9
2266
Time taken for simulation:  7.161516427993774
average overall reward:  0.42670774  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.13441366  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: 23.63, Length: 6
DEBUG (Env): Episode done for env 16. Reward: 23.37, Length: 24
DEBUG (Env): Episode done for env 55. Reward: -9.61, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 25.44, Length: 12
DEBUG (Env): Episode done for env 94. Reward: -21.15, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 14.38, Length: 11
2267
Time taken for simulation:  7.135376453399658
average overall reward:  0.08827019  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  -0.06704797  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 22. Reward: -29.54, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 14.79, Length: 23
DEBUG (Env): Episode done for env 36. Reward: -26.83, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -10.67, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 25.03, Length: 2
DEBUG (Env): Episode done for env 115. Reward: -22.54, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 23.21, Length: 10
DEBUG (Env): Episode done for env 126. Reward: 19.95, Length: 2
2268
Time taken for simulation:  7.406390905380249
average overall reward:  0.68512976  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.1673301 average distance reward:  0.18183815  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 9. Reward: 37.89, Length: 9
DEBUG (Env): Episode done for env 23. Reward: -21.16, Length: 36
DEBUG (Env): Episode done for env 34. Reward: -22.19, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 18.04, Length: 9
DEBUG (Env): Episode done for env 71. Reward: -8.38, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 25.04, Length: 30
DEBUG (Env): Episode done for env 81. Reward: 35.73, Length: 14
DEBUG (Env): Episode done for env 84. Reward: 23.32, Length: 5
DEBUG (Env): Episode done for env 93. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 16.58, Length: 30
2269
Time taken for simulation:  7.568485736846924
average overall reward:  0.47943777  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.2409355  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: 27.47, Length: 13
DEBUG (Env): Episode done for env 29. Reward: 40.61, Length: 10
DEBUG (Env): Episode done for env 46. Reward: 36.94, Length: 6
DEBUG (Env): Episode done for env 85. Reward: 16.58, Length: 31
DEBUG (Env): Episode done for env 97. Reward: -21.75, Length: 36
2270
Time taken for simulation:  7.178547620773315
average overall reward:  -0.0032339916  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.08292669  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 19.68, Length: 10
DEBUG (Env): Episode done for env 27. Reward: -11.64, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 29.42, Length: 20
DEBUG (Env): Episode done for env 80. Reward: -17.26, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 9.20, Length: 33
2271
Time taken for simulation:  7.0125603675842285
average overall reward:  0.24512908  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  -0.023727437  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 2.40, Length: 30
DEBUG (Env): Episode done for env 27. Reward: 15.41, Length: 1
DEBUG (Env): Episode done for env 45. Reward: -17.42, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 23.61, Length: 1
DEBUG (Env): Episode done for env 63. Reward: -16.97, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 20.74, Length: 8
DEBUG (Env): Episode done for env 111. Reward: -18.81, Length: 36
2272
Time taken for simulation:  7.391523838043213
average overall reward:  0.44089574  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.102972366 average distance reward:  0.47979414  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 2. Reward: 34.81, Length: 14
DEBUG (Env): Episode done for env 99. Reward: -9.77, Length: 36
2273
Time taken for simulation:  7.067112922668457
average overall reward:  0.50273967  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020165 average distance reward:  0.5538079  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: -21.51, Length: 36
DEBUG (Env): Episode done for env 17. Reward: -17.20, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 26.09, Length: 9
DEBUG (Env): Episode done for env 53. Reward: -11.41, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 30.09, Length: 2
DEBUG (Env): Episode done for env 82. Reward: -22.50, Length: 36
2274
Time taken for simulation:  7.184653043746948
average overall reward:  0.6082362  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.21758103  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 44. Reward: 24.70, Length: 10
DEBUG (Env): Episode done for env 54. Reward: 26.99, Length: 11
DEBUG (Env): Episode done for env 60. Reward: 50.75, Length: 3
DEBUG (Env): Episode done for env 125. Reward: 28.14, Length: 11
2275
Time taken for simulation:  7.2585365772247314
average overall reward:  0.3733254  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.28076115  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: 31.89, Length: 6
DEBUG (Env): Episode done for env 47. Reward: -19.06, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -20.80, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 13.54, Length: 18
DEBUG (Env): Episode done for env 117. Reward: 23.30, Length: 5
2276
Time taken for simulation:  7.818649768829346
average overall reward:  0.43171975  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.12871546 average distance reward:  -0.068564385  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 16. Reward: 26.46, Length: 10
DEBUG (Env): Episode done for env 32. Reward: 26.42, Length: 13
DEBUG (Env): Episode done for env 33. Reward: 20.57, Length: 13
DEBUG (Env): Episode done for env 58. Reward: 20.02, Length: 25
DEBUG (Env): Episode done for env 62. Reward: 23.02, Length: 9
2277
Time taken for simulation:  7.542754411697388
average overall reward:  0.40665627  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.14836572  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: -17.50, Length: 36
DEBUG (Env): Episode done for env 15. Reward: -28.11, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -13.63, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 23.77, Length: 6
DEBUG (Env): Episode done for env 89. Reward: 31.74, Length: 14
DEBUG (Env): Episode done for env 95. Reward: -25.00, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 17.22, Length: 2
DEBUG (Env): Episode done for env 106. Reward: 23.19, Length: 11
2278
Time taken for simulation:  7.47358512878418
average overall reward:  0.28092042  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  -0.021939557  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 15. Reward: 18.52, Length: 1
DEBUG (Env): Episode done for env 24. Reward: 18.51, Length: 20
DEBUG (Env): Episode done for env 39. Reward: 15.57, Length: 5
DEBUG (Env): Episode done for env 59. Reward: -21.19, Length: 36
DEBUG (Env): Episode done for env 107. Reward: 23.49, Length: 13
2279
Time taken for simulation:  7.285184860229492
average overall reward:  0.9968734  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.64483285  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 11. Reward: 25.71, Length: 17
DEBUG (Env): Episode done for env 23. Reward: 19.38, Length: 11
DEBUG (Env): Episode done for env 54. Reward: 21.24, Length: 5
DEBUG (Env): Episode done for env 98. Reward: 32.49, Length: 22
2280
Time taken for simulation:  7.327402591705322
average overall reward:  0.30282587  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.32178864 average distance reward:  0.13098694  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: 25.53, Length: 8
DEBUG (Env): Episode done for env 28. Reward: 20.73, Length: 13
DEBUG (Env): Episode done for env 43. Reward: 23.45, Length: 28
DEBUG (Env): Episode done for env 62. Reward: 30.52, Length: 4
2281
Time taken for simulation:  7.105535984039307
average overall reward:  1.1827979  average fail penalty:  -0.0703125  and average goal bonus:  1.2183483  and average same cell penalty:  -0.21881628 average distance reward:  0.30143908  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 3. Reward: 27.27, Length: 10
DEBUG (Env): Episode done for env 13. Reward: -19.07, Length: 36
DEBUG (Env): Episode done for env 22. Reward: 25.35, Length: 14
DEBUG (Env): Episode done for env 29. Reward: -3.71, Length: 12
DEBUG (Env): Episode done for env 58. Reward: 30.33, Length: 5
DEBUG (Env): Episode done for env 61. Reward: -18.62, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 23.49, Length: 1
DEBUG (Env): Episode done for env 82. Reward: 28.45, Length: 8
DEBUG (Env): Episode done for env 93. Reward: 33.80, Length: 13
DEBUG (Env): Episode done for env 99. Reward: 16.25, Length: 9
DEBUG (Env): Episode done for env 106. Reward: 23.79, Length: 4
DEBUG (Env): Episode done for env 113. Reward: -16.62, Length: 36
2282
Time taken for simulation:  7.258570909500122
average overall reward:  0.2560817  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.28317398 average distance reward:  0.069065616  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 2. Reward: 27.71, Length: 2
DEBUG (Env): Episode done for env 28. Reward: 22.82, Length: 2
DEBUG (Env): Episode done for env 30. Reward: -18.74, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 22.13, Length: 24
DEBUG (Env): Episode done for env 55. Reward: 20.87, Length: 16
2283
Time taken for simulation:  7.494040012359619
average overall reward:  0.67825687  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.5493836  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 63. Reward: 19.12, Length: 10
DEBUG (Env): Episode done for env 83. Reward: -24.79, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 20.40, Length: 14
DEBUG (Env): Episode done for env 97. Reward: 24.50, Length: 14
2284
Time taken for simulation:  7.28627347946167
average overall reward:  0.35384917  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  0.3256426  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 33. Reward: 24.68, Length: 8
DEBUG (Env): Episode done for env 57. Reward: -18.32, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -11.20, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 20.93, Length: 1
DEBUG (Env): Episode done for env 88. Reward: 24.62, Length: 30
2285
Time taken for simulation:  7.056865453720093
average overall reward:  0.97312826  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.18020165 average distance reward:  0.2770238  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 45. Reward: 27.08, Length: 14
DEBUG (Env): Episode done for env 49. Reward: 8.05, Length: 31
DEBUG (Env): Episode done for env 54. Reward: 40.49, Length: 6
DEBUG (Env): Episode done for env 70. Reward: -21.19, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 27.11, Length: 8
DEBUG (Env): Episode done for env 90. Reward: 26.74, Length: 27
DEBUG (Env): Episode done for env 104. Reward: 20.40, Length: 22
DEBUG (Env): Episode done for env 113. Reward: 16.43, Length: 4
2286
Time taken for simulation:  7.32314395904541
average overall reward:  0.3773486  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  0.17515537  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 7.15, Length: 35
DEBUG (Env): Episode done for env 41. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 38.15, Length: 5
DEBUG (Env): Episode done for env 72. Reward: -19.97, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 28.55, Length: 9
DEBUG (Env): Episode done for env 121. Reward: 15.35, Length: 19
2287
Time taken for simulation:  7.133275747299194
average overall reward:  0.64751494  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.28651226  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: 15.23, Length: 16
DEBUG (Env): Episode done for env 39. Reward: 30.23, Length: 9
DEBUG (Env): Episode done for env 81. Reward: 24.05, Length: 19
DEBUG (Env): Episode done for env 92. Reward: -6.03, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 24.28, Length: 6
DEBUG (Env): Episode done for env 110. Reward: 40.03, Length: 30
2288
Time taken for simulation:  7.305230140686035
average overall reward:  0.94674337  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455938 average distance reward:  0.52068114  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 10. Reward: -17.31, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 29.23, Length: 12
DEBUG (Env): Episode done for env 18. Reward: -26.54, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -15.51, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 19.51, Length: 7
DEBUG (Env): Episode done for env 30. Reward: 25.49, Length: 6
DEBUG (Env): Episode done for env 38. Reward: 4.13, Length: 28
DEBUG (Env): Episode done for env 43. Reward: 28.18, Length: 8
DEBUG (Env): Episode done for env 51. Reward: -10.06, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 22.14, Length: 13
2289
Time taken for simulation:  7.443290948867798
average overall reward:  0.35482797  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.27030244 average distance reward:  -0.2043007  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 4. Reward: -11.76, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 13.62, Length: 32
DEBUG (Env): Episode done for env 23. Reward: 26.04, Length: 10
DEBUG (Env): Episode done for env 34. Reward: 15.42, Length: 21
DEBUG (Env): Episode done for env 50. Reward: -0.92, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 17.96, Length: 15
DEBUG (Env): Episode done for env 71. Reward: 29.05, Length: 21
DEBUG (Env): Episode done for env 93. Reward: 25.86, Length: 8
DEBUG (Env): Episode done for env 106. Reward: 19.89, Length: 8
DEBUG (Env): Episode done for env 123. Reward: -18.03, Length: 36
2290
Time taken for simulation:  7.096332311630249
average overall reward:  0.24615227  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.10671301  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 9. Reward: 15.02, Length: 22
DEBUG (Env): Episode done for env 21. Reward: 20.61, Length: 1
DEBUG (Env): Episode done for env 42. Reward: 8.78, Length: 33
2291
Time taken for simulation:  7.311779260635376
average overall reward:  0.85935915  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.16733009 average distance reward:  0.30919257  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: 25.00, Length: 18
DEBUG (Env): Episode done for env 55. Reward: 20.57, Length: 9
DEBUG (Env): Episode done for env 64. Reward: 29.27, Length: 14
DEBUG (Env): Episode done for env 65. Reward: -14.40, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 26.90, Length: 14
DEBUG (Env): Episode done for env 102. Reward: -4.21, Length: 29
DEBUG (Env): Episode done for env 113. Reward: 32.11, Length: 6
DEBUG (Env): Episode done for env 119. Reward: -17.47, Length: 36
2292
Time taken for simulation:  7.1466429233551025
average overall reward:  -0.41799313  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.23168783 average distance reward:  -0.09156969  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 74. Reward: -24.08, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -20.41, Length: 36
2293
Time taken for simulation:  7.3418495655059814
average overall reward:  -0.21805277  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.19307318 average distance reward:  -0.17755061  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 37. Reward: -16.03, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 12.73, Length: 2
DEBUG (Env): Episode done for env 64. Reward: 22.29, Length: 2
DEBUG (Env): Episode done for env 78. Reward: -30.49, Length: 36
DEBUG (Env): Episode done for env 79. Reward: -13.57, Length: 36
2294
Time taken for simulation:  7.241900444030762
average overall reward:  0.7827736  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.102972366 average distance reward:  0.35049632  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 6. Reward: -22.84, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 37.44, Length: 34
DEBUG (Env): Episode done for env 30. Reward: 23.78, Length: 6
DEBUG (Env): Episode done for env 31. Reward: -11.90, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 26.64, Length: 3
DEBUG (Env): Episode done for env 72. Reward: 28.06, Length: 8
DEBUG (Env): Episode done for env 114. Reward: 11.91, Length: 35
DEBUG (Env): Episode done for env 118. Reward: -23.03, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -18.84, Length: 36
2295
Time taken for simulation:  7.113954305648804
average overall reward:  -0.15340467  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.23168781 average distance reward:  0.08452168  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 8. Reward: -11.43, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -19.11, Length: 36
DEBUG (Env): Episode done for env 86. Reward: -16.65, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 27.59, Length: 8
DEBUG (Env): Episode done for env 105. Reward: -26.20, Length: 36
2296
Time taken for simulation:  7.096705436706543
average overall reward:  1.3724954  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.090100825 average distance reward:  0.5862901  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: 27.66, Length: 6
DEBUG (Env): Episode done for env 14. Reward: 45.68, Length: 5
DEBUG (Env): Episode done for env 19. Reward: 36.50, Length: 8
DEBUG (Env): Episode done for env 39. Reward: 37.33, Length: 9
DEBUG (Env): Episode done for env 40. Reward: -17.05, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 22.84, Length: 28
DEBUG (Env): Episode done for env 121. Reward: 18.73, Length: 10
DEBUG (Env): Episode done for env 126. Reward: 11.45, Length: 29
2297
Time taken for simulation:  7.170105934143066
average overall reward:  0.4846704  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.2438626  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 14. Reward: 26.11, Length: 1
DEBUG (Env): Episode done for env 61. Reward: 15.54, Length: 16
DEBUG (Env): Episode done for env 65. Reward: 11.57, Length: 6
DEBUG (Env): Episode done for env 93. Reward: 37.33, Length: 8
DEBUG (Env): Episode done for env 103. Reward: -17.30, Length: 36
DEBUG (Env): Episode done for env 122. Reward: -11.08, Length: 36
2298
Time taken for simulation:  7.057630777359009
average overall reward:  0.42073923  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.283174 average distance reward:  0.033291638  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 14. Reward: 16.37, Length: 1
DEBUG (Env): Episode done for env 18. Reward: 8.85, Length: 10
DEBUG (Env): Episode done for env 52. Reward: -12.53, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 30.08, Length: 9
DEBUG (Env): Episode done for env 61. Reward: 12.73, Length: 1
DEBUG (Env): Episode done for env 74. Reward: 22.15, Length: 6
DEBUG (Env): Episode done for env 82. Reward: 39.79, Length: 17
DEBUG (Env): Episode done for env 100. Reward: -13.17, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -17.76, Length: 36
DEBUG (Env): Episode done for env 124. Reward: -22.11, Length: 36
2299
Time taken for simulation:  7.3789262771606445
average overall reward:  -0.31615013  average fail penalty:  -0.140625  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  -0.4503364  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 17. Reward: 3.89, Length: 26
DEBUG (Env): Episode done for env 29. Reward: 24.30, Length: 11
DEBUG (Env): Episode done for env 34. Reward: 16.85, Length: 10
DEBUG (Env): Episode done for env 67. Reward: -16.77, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -14.50, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -20.41, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -23.25, Length: 36
DEBUG (Env): Episode done for env 116. Reward: -23.97, Length: 36
DEBUG (Env): Episode done for env 120. Reward: -19.05, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 35.14, Length: 3
2300
Time taken for simulation:  7.238452196121216
average overall reward:  0.6374299  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.090100825 average distance reward:  0.12196855  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 13. Reward: 17.59, Length: 19
DEBUG (Env): Episode done for env 36. Reward: 13.29, Length: 33
DEBUG (Env): Episode done for env 81. Reward: 22.42, Length: 13
DEBUG (Env): Episode done for env 85. Reward: 18.73, Length: 17
DEBUG (Env): Episode done for env 86. Reward: 19.49, Length: 5
DEBUG (Env): Episode done for env 101. Reward: -16.59, Length: 36
2301
Time taken for simulation:  7.349213123321533
average overall reward:  0.8640802  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.4492857  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 20. Reward: -14.10, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 16.20, Length: 7
DEBUG (Env): Episode done for env 56. Reward: -19.11, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 15.54, Length: 15
DEBUG (Env): Episode done for env 72. Reward: 37.62, Length: 7
DEBUG (Env): Episode done for env 101. Reward: 22.27, Length: 1
DEBUG (Env): Episode done for env 123. Reward: 31.50, Length: 12
2302
Time taken for simulation:  7.249578237533569
average overall reward:  0.7544155  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.25342953  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 5. Reward: -24.31, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 21.57, Length: 14
DEBUG (Env): Episode done for env 50. Reward: 22.79, Length: 13
DEBUG (Env): Episode done for env 66. Reward: -24.52, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 8.70, Length: 3
DEBUG (Env): Episode done for env 94. Reward: -12.88, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 33.88, Length: 8
DEBUG (Env): Episode done for env 125. Reward: 20.03, Length: 28
DEBUG (Env): Episode done for env 127. Reward: 41.97, Length: 8
2303
Time taken for simulation:  7.597904205322266
average overall reward:  0.49456233  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594475 average distance reward:  0.2537545  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 44. Reward: 8.75, Length: 29
DEBUG (Env): Episode done for env 48. Reward: -14.14, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 17.65, Length: 6
DEBUG (Env): Episode done for env 90. Reward: 18.03, Length: 18
DEBUG (Env): Episode done for env 115. Reward: -9.16, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 3.93, Length: 28
2304
Time taken for simulation:  7.331515550613403
average overall reward:  0.3500989  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020163 average distance reward:  -0.028386474  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: 15.31, Length: 6
DEBUG (Env): Episode done for env 66. Reward: 29.25, Length: 2
DEBUG (Env): Episode done for env 68. Reward: -28.27, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 10.59, Length: 19
DEBUG (Env): Episode done for env 73. Reward: -12.25, Length: 36
DEBUG (Env): Episode done for env 84. Reward: -18.94, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 24.32, Length: 13
DEBUG (Env): Episode done for env 116. Reward: 30.03, Length: 5
2305
Time taken for simulation:  7.248313665390015
average overall reward:  0.37239277  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.141587 average distance reward:  0.31453374  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 3. Reward: 16.31, Length: 24
DEBUG (Env): Episode done for env 46. Reward: -24.03, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 19.38, Length: 20
2306
Time taken for simulation:  7.74282169342041
average overall reward:  0.89643973  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.1673301 average distance reward:  0.34627318  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 1. Reward: -14.91, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 20.41, Length: 4
DEBUG (Env): Episode done for env 42. Reward: 24.19, Length: 16
DEBUG (Env): Episode done for env 45. Reward: 7.46, Length: 21
DEBUG (Env): Episode done for env 70. Reward: 20.25, Length: 2
DEBUG (Env): Episode done for env 80. Reward: -27.08, Length: 36
DEBUG (Env): Episode done for env 115. Reward: 18.92, Length: 3
DEBUG (Env): Episode done for env 123. Reward: 37.82, Length: 5
2307
Time taken for simulation:  7.1733198165893555
average overall reward:  0.99229944  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.27030247 average distance reward:  0.38629574  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 10. Reward: 17.95, Length: 19
DEBUG (Env): Episode done for env 12. Reward: 6.72, Length: 21
DEBUG (Env): Episode done for env 41. Reward: 33.97, Length: 21
DEBUG (Env): Episode done for env 61. Reward: 33.73, Length: 9
DEBUG (Env): Episode done for env 79. Reward: 23.01, Length: 14
DEBUG (Env): Episode done for env 82. Reward: 35.13, Length: 9
DEBUG (Env): Episode done for env 84. Reward: 28.76, Length: 3
DEBUG (Env): Episode done for env 111. Reward: -19.48, Length: 36
2308
Time taken for simulation:  7.2711522579193115
average overall reward:  0.91509926  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.16733009 average distance reward:  0.18268578  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 18.45, Length: 26
DEBUG (Env): Episode done for env 11. Reward: 18.45, Length: 29
DEBUG (Env): Episode done for env 39. Reward: 24.16, Length: 12
DEBUG (Env): Episode done for env 56. Reward: 43.71, Length: 7
DEBUG (Env): Episode done for env 91. Reward: 21.87, Length: 16
DEBUG (Env): Episode done for env 96. Reward: 8.40, Length: 31
DEBUG (Env): Episode done for env 119. Reward: 21.43, Length: 17
2309
Time taken for simulation:  7.454342603683472
average overall reward:  0.6117456  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.32175726  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 34. Reward: 21.92, Length: 10
DEBUG (Env): Episode done for env 53. Reward: -20.62, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 24.31, Length: 9
DEBUG (Env): Episode done for env 117. Reward: 27.02, Length: 6
DEBUG (Env): Episode done for env 122. Reward: 18.85, Length: 12
2310
Time taken for simulation:  7.144065618515015
average overall reward:  0.8930631  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.41852212  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: 29.79, Length: 16
DEBUG (Env): Episode done for env 29. Reward: 24.97, Length: 11
DEBUG (Env): Episode done for env 56. Reward: 18.77, Length: 2
DEBUG (Env): Episode done for env 77. Reward: 18.32, Length: 26
DEBUG (Env): Episode done for env 91. Reward: 28.28, Length: 2
2311
Time taken for simulation:  7.121347904205322
average overall reward:  0.3959743  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.25192386  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 0. Reward: -18.07, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -18.47, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 54.91, Length: 7
DEBUG (Env): Episode done for env 102. Reward: 21.99, Length: 7
DEBUG (Env): Episode done for env 114. Reward: 26.20, Length: 17
2312
Time taken for simulation:  7.463206768035889
average overall reward:  0.52298975  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.19438669  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 32. Reward: -28.73, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 8.57, Length: 34
DEBUG (Env): Episode done for env 61. Reward: 16.66, Length: 5
DEBUG (Env): Episode done for env 96. Reward: 53.05, Length: 4
DEBUG (Env): Episode done for env 103. Reward: 25.59, Length: 15
2313
Time taken for simulation:  7.279757976531982
average overall reward:  0.8421631  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  0.19754481  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: -9.65, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 23.28, Length: 14
DEBUG (Env): Episode done for env 54. Reward: 43.67, Length: 8
DEBUG (Env): Episode done for env 55. Reward: 11.78, Length: 20
DEBUG (Env): Episode done for env 69. Reward: 40.20, Length: 19
DEBUG (Env): Episode done for env 96. Reward: 13.30, Length: 1
DEBUG (Env): Episode done for env 112. Reward: 19.55, Length: 17
DEBUG (Env): Episode done for env 122. Reward: 31.51, Length: 4
2314
Time taken for simulation:  7.165004253387451
average overall reward:  0.5806383  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.3246534  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 38.83, Length: 25
DEBUG (Env): Episode done for env 15. Reward: -4.51, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 16.66, Length: 8
DEBUG (Env): Episode done for env 24. Reward: -18.95, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 18.56, Length: 1
DEBUG (Env): Episode done for env 89. Reward: 8.40, Length: 29
DEBUG (Env): Episode done for env 107. Reward: -4.02, Length: 36
2315
Time taken for simulation:  6.998015403747559
average overall reward:  0.60276985  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.12871546 average distance reward:  0.12592319  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: 11.57, Length: 9
DEBUG (Env): Episode done for env 19. Reward: 24.27, Length: 19
DEBUG (Env): Episode done for env 60. Reward: 23.83, Length: 17
DEBUG (Env): Episode done for env 98. Reward: -9.38, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 27.32, Length: 16
DEBUG (Env): Episode done for env 118. Reward: 23.81, Length: 13
2316
Time taken for simulation:  7.260816335678101
average overall reward:  0.20707273  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.29604554 average distance reward:  0.009490706  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 9. Reward: 9.10, Length: 20
DEBUG (Env): Episode done for env 10. Reward: 29.41, Length: 9
DEBUG (Env): Episode done for env 29. Reward: 15.61, Length: 6
DEBUG (Env): Episode done for env 91. Reward: 47.36, Length: 6
2317
Time taken for simulation:  7.03989577293396
average overall reward:  0.578436  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.33762828  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 19.15, Length: 9
DEBUG (Env): Episode done for env 22. Reward: -19.37, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 9.07, Length: 35
DEBUG (Env): Episode done for env 36. Reward: 29.34, Length: 17
DEBUG (Env): Episode done for env 62. Reward: -12.52, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 14.68, Length: 15
2318
Time taken for simulation:  7.039035797119141
average overall reward:  0.5837114  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.18409401  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 12. Reward: 37.67, Length: 11
DEBUG (Env): Episode done for env 23. Reward: 14.66, Length: 29
DEBUG (Env): Episode done for env 24. Reward: 21.47, Length: 4
DEBUG (Env): Episode done for env 28. Reward: -12.41, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 27.83, Length: 5
DEBUG (Env): Episode done for env 122. Reward: 26.86, Length: 5
2319
Time taken for simulation:  7.079157829284668
average overall reward:  0.9985275  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  0.5708615  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 16.75, Length: 25
DEBUG (Env): Episode done for env 17. Reward: 25.21, Length: 6
DEBUG (Env): Episode done for env 55. Reward: 18.43, Length: 6
DEBUG (Env): Episode done for env 63. Reward: -23.45, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 13.11, Length: 6
DEBUG (Env): Episode done for env 97. Reward: -14.64, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 23.23, Length: 4
2320
Time taken for simulation:  7.390524625778198
average overall reward:  0.07129505  average fail penalty:  -0.09375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  0.25773522  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 33. Reward: -16.97, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -14.73, Length: 36
DEBUG (Env): Episode done for env 83. Reward: -30.39, Length: 36
DEBUG (Env): Episode done for env 88. Reward: -22.61, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 26.82, Length: 11
2321
Time taken for simulation:  7.197029113769531
average overall reward:  0.6433526  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.16733009 average distance reward:  0.22855814  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 26. Reward: 8.08, Length: 26
DEBUG (Env): Episode done for env 33. Reward: 21.88, Length: 1
DEBUG (Env): Episode done for env 49. Reward: -24.30, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -32.18, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 20.15, Length: 17
DEBUG (Env): Episode done for env 122. Reward: 26.91, Length: 3
DEBUG (Env): Episode done for env 125. Reward: 22.98, Length: 19
2322
Time taken for simulation:  7.454519510269165
average overall reward:  -0.046888508  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.2574309 average distance reward:  -0.12427561  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 73. Reward: 23.67, Length: 18
DEBUG (Env): Episode done for env 79. Reward: 15.74, Length: 15
DEBUG (Env): Episode done for env 85. Reward: 11.03, Length: 22
DEBUG (Env): Episode done for env 95. Reward: -22.22, Length: 36
2323
Time taken for simulation:  6.974064826965332
average overall reward:  0.25273985  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.283174 average distance reward:  0.24797079  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 27. Reward: -12.72, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 35.21, Length: 20
DEBUG (Env): Episode done for env 66. Reward: 32.21, Length: 19
DEBUG (Env): Episode done for env 99. Reward: -9.63, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 21.52, Length: 8
DEBUG (Env): Episode done for env 110. Reward: -12.61, Length: 36
2324
Time taken for simulation:  7.336463212966919
average overall reward:  -0.21156168  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  -0.3540083  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 27. Reward: 20.53, Length: 1
DEBUG (Env): Episode done for env 35. Reward: 19.26, Length: 7
DEBUG (Env): Episode done for env 38. Reward: -17.97, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -12.77, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -26.95, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 16.52, Length: 14
DEBUG (Env): Episode done for env 76. Reward: -14.98, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 20.32, Length: 18
2325
Time taken for simulation:  7.15411376953125
average overall reward:  0.42986345  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594473 average distance reward:  -0.08168846  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: 18.40, Length: 12
DEBUG (Env): Episode done for env 24. Reward: 25.74, Length: 7
DEBUG (Env): Episode done for env 57. Reward: 16.83, Length: 5
DEBUG (Env): Episode done for env 71. Reward: -21.21, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 11.02, Length: 12
DEBUG (Env): Episode done for env 101. Reward: 9.20, Length: 24
DEBUG (Env): Episode done for env 106. Reward: -20.27, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 3.12, Length: 26
2326
Time taken for simulation:  7.533338308334351
average overall reward:  0.7104116  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.43329474  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: -19.67, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 29.96, Length: 9
DEBUG (Env): Episode done for env 89. Reward: 31.70, Length: 12
DEBUG (Env): Episode done for env 94. Reward: 20.90, Length: 24
DEBUG (Env): Episode done for env 124. Reward: 21.75, Length: 28
2327
Time taken for simulation:  7.286373138427734
average overall reward:  0.5615154  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.29727006  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: 13.35, Length: 2
DEBUG (Env): Episode done for env 91. Reward: 18.68, Length: 11
DEBUG (Env): Episode done for env 99. Reward: 25.67, Length: 4
DEBUG (Env): Episode done for env 101. Reward: 20.53, Length: 2
DEBUG (Env): Episode done for env 113. Reward: -13.23, Length: 36
2328
Time taken for simulation:  7.1513824462890625
average overall reward:  0.52636963  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.3030445  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 20. Reward: 24.29, Length: 27
DEBUG (Env): Episode done for env 74. Reward: 10.04, Length: 30
DEBUG (Env): Episode done for env 104. Reward: 29.88, Length: 7
DEBUG (Env): Episode done for env 124. Reward: 24.89, Length: 2
2329
Time taken for simulation:  7.031350612640381
average overall reward:  0.69667387  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.46643192  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 25.33, Length: 15
DEBUG (Env): Episode done for env 27. Reward: 28.28, Length: 5
DEBUG (Env): Episode done for env 37. Reward: -18.97, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 17.84, Length: 17
DEBUG (Env): Episode done for env 64. Reward: -11.01, Length: 36
DEBUG (Env): Episode done for env 78. Reward: -8.74, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 33.12, Length: 18
2330
Time taken for simulation:  7.458050012588501
average overall reward:  0.62041366  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.18218173  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 24. Reward: 29.59, Length: 5
DEBUG (Env): Episode done for env 30. Reward: -25.73, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 23.22, Length: 1
DEBUG (Env): Episode done for env 84. Reward: 21.25, Length: 23
DEBUG (Env): Episode done for env 94. Reward: 32.31, Length: 4
DEBUG (Env): Episode done for env 98. Reward: 30.02, Length: 15
2331
Time taken for simulation:  7.125875473022461
average overall reward:  0.37365434  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.05952658  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 0. Reward: 32.30, Length: 20
DEBUG (Env): Episode done for env 8. Reward: -14.44, Length: 36
DEBUG (Env): Episode done for env 29. Reward: 29.23, Length: 15
DEBUG (Env): Episode done for env 43. Reward: 20.07, Length: 7
DEBUG (Env): Episode done for env 92. Reward: -15.04, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -11.76, Length: 36
DEBUG (Env): Episode done for env 112. Reward: 7.18, Length: 13
DEBUG (Env): Episode done for env 117. Reward: 31.14, Length: 11
2332
Time taken for simulation:  7.065415859222412
average overall reward:  0.72579896  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.22711861  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 29. Reward: 15.99, Length: 1
DEBUG (Env): Episode done for env 40. Reward: -13.47, Length: 36
DEBUG (Env): Episode done for env 64. Reward: 28.16, Length: 3
DEBUG (Env): Episode done for env 67. Reward: 21.55, Length: 15
DEBUG (Env): Episode done for env 73. Reward: 26.97, Length: 10
DEBUG (Env): Episode done for env 101. Reward: 17.79, Length: 5
DEBUG (Env): Episode done for env 115. Reward: 9.98, Length: 26
DEBUG (Env): Episode done for env 121. Reward: -10.72, Length: 36
2333
Time taken for simulation:  7.016197204589844
average overall reward:  0.9377502  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.16733009 average distance reward:  0.22877425  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 0. Reward: 30.43, Length: 2
DEBUG (Env): Episode done for env 4. Reward: 13.87, Length: 4
DEBUG (Env): Episode done for env 49. Reward: 13.29, Length: 12
DEBUG (Env): Episode done for env 58. Reward: 19.38, Length: 32
DEBUG (Env): Episode done for env 64. Reward: 22.18, Length: 1
DEBUG (Env): Episode done for env 69. Reward: 20.59, Length: 14
DEBUG (Env): Episode done for env 88. Reward: 24.01, Length: 13
DEBUG (Env): Episode done for env 93. Reward: -19.43, Length: 36
2334
Time taken for simulation:  7.089183330535889
average overall reward:  0.64409184  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.26330066  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 14. Reward: -24.29, Length: 36
DEBUG (Env): Episode done for env 19. Reward: 29.53, Length: 19
DEBUG (Env): Episode done for env 40. Reward: 20.18, Length: 2
DEBUG (Env): Episode done for env 41. Reward: 15.92, Length: 27
DEBUG (Env): Episode done for env 51. Reward: 22.20, Length: 10
DEBUG (Env): Episode done for env 52. Reward: -24.75, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 9.42, Length: 22
DEBUG (Env): Episode done for env 100. Reward: -17.01, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -9.38, Length: 36
2335
Time taken for simulation:  7.166552782058716
average overall reward:  0.6654357  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.141587 average distance reward:  0.24833557  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 3. Reward: 8.87, Length: 30
DEBUG (Env): Episode done for env 35. Reward: 14.21, Length: 11
DEBUG (Env): Episode done for env 55. Reward: 20.93, Length: 16
DEBUG (Env): Episode done for env 75. Reward: -35.81, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -26.22, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 22.48, Length: 13
DEBUG (Env): Episode done for env 124. Reward: 26.21, Length: 7
DEBUG (Env): Episode done for env 126. Reward: -21.56, Length: 36
2336
Time taken for simulation:  7.205357074737549
average overall reward:  -0.20427391  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  -0.3225813  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 13. Reward: -16.58, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 36.83, Length: 13
DEBUG (Env): Episode done for env 68. Reward: 21.42, Length: 25
DEBUG (Env): Episode done for env 81. Reward: -27.45, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 34.66, Length: 11
2337
Time taken for simulation:  7.139500856399536
average overall reward:  1.055633  average fail penalty:  -0.046875  and average goal bonus:  1.0829762  and average same cell penalty:  -0.19307318 average distance reward:  0.2604654  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 9. Reward: 15.68, Length: 21
DEBUG (Env): Episode done for env 31. Reward: -23.42, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 2.04, Length: 34
DEBUG (Env): Episode done for env 56. Reward: 16.71, Length: 13
DEBUG (Env): Episode done for env 63. Reward: 14.72, Length: 18
DEBUG (Env): Episode done for env 72. Reward: -15.18, Length: 36
DEBUG (Env): Episode done for env 80. Reward: 15.31, Length: 31
DEBUG (Env): Episode done for env 85. Reward: 20.14, Length: 15
DEBUG (Env): Episode done for env 103. Reward: 14.01, Length: 25
DEBUG (Env): Episode done for env 123. Reward: 29.69, Length: 13
2338
Time taken for simulation:  7.0712666511535645
average overall reward:  1.3080264  average fail penalty:  -0.0703125  and average goal bonus:  1.2183483  and average same cell penalty:  -0.23168783 average distance reward:  0.4395391  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 5. Reward: -13.48, Length: 36
DEBUG (Env): Episode done for env 10. Reward: 13.34, Length: 22
DEBUG (Env): Episode done for env 15. Reward: 16.08, Length: 24
DEBUG (Env): Episode done for env 41. Reward: 19.28, Length: 4
DEBUG (Env): Episode done for env 43. Reward: 12.28, Length: 7
DEBUG (Env): Episode done for env 50. Reward: -16.58, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 13.71, Length: 23
DEBUG (Env): Episode done for env 79. Reward: 9.94, Length: 16
DEBUG (Env): Episode done for env 113. Reward: 30.22, Length: 11
DEBUG (Env): Episode done for env 114. Reward: 36.42, Length: 9
DEBUG (Env): Episode done for env 124. Reward: 32.51, Length: 3
DEBUG (Env): Episode done for env 127. Reward: -14.80, Length: 36
2339
Time taken for simulation:  7.4896392822265625
average overall reward:  0.35453877  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.19761673  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 48. Reward: -6.38, Length: 36
DEBUG (Env): Episode done for env 82. Reward: 3.44, Length: 32
DEBUG (Env): Episode done for env 83. Reward: 20.32, Length: 19
DEBUG (Env): Episode done for env 90. Reward: -26.48, Length: 36
DEBUG (Env): Episode done for env 95. Reward: 20.58, Length: 4
2340
Time taken for simulation:  7.8231141567230225
average overall reward:  0.94099605  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.141587 average distance reward:  0.20627682  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: -17.44, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 33.29, Length: 6
DEBUG (Env): Episode done for env 55. Reward: 19.72, Length: 5
DEBUG (Env): Episode done for env 56. Reward: 30.91, Length: 3
DEBUG (Env): Episode done for env 74. Reward: 18.53, Length: 12
DEBUG (Env): Episode done for env 80. Reward: 13.90, Length: 3
DEBUG (Env): Episode done for env 88. Reward: 15.58, Length: 7
DEBUG (Env): Episode done for env 111. Reward: 0.25, Length: 33
2341
Time taken for simulation:  7.136427164077759
average overall reward:  1.2275858  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.12871546 average distance reward:  0.7507392  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 16. Reward: 18.88, Length: 27
DEBUG (Env): Episode done for env 46. Reward: -17.59, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 21.56, Length: 7
DEBUG (Env): Episode done for env 82. Reward: 21.78, Length: 2
DEBUG (Env): Episode done for env 93. Reward: 31.47, Length: 8
DEBUG (Env): Episode done for env 119. Reward: 33.54, Length: 33
2342
Time taken for simulation:  7.154160022735596
average overall reward:  0.45230058  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  0.04807201  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 5. Reward: 21.24, Length: 4
DEBUG (Env): Episode done for env 42. Reward: -16.92, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -18.42, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 16.45, Length: 9
DEBUG (Env): Episode done for env 58. Reward: 36.87, Length: 9
DEBUG (Env): Episode done for env 70. Reward: -15.83, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 15.98, Length: 6
DEBUG (Env): Episode done for env 98. Reward: 19.06, Length: 12
2343
Time taken for simulation:  7.3918023109436035
average overall reward:  0.5851268  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.102972366 average distance reward:  0.059099644  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 59. Reward: 18.13, Length: 2
DEBUG (Env): Episode done for env 61. Reward: 25.71, Length: 14
DEBUG (Env): Episode done for env 72. Reward: 23.35, Length: 6
DEBUG (Env): Episode done for env 114. Reward: 23.50, Length: 5
DEBUG (Env): Episode done for env 115. Reward: 21.63, Length: 11
2344
Time taken for simulation:  7.054329872131348
average overall reward:  0.7768997  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.40071982  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 3. Reward: 23.96, Length: 9
DEBUG (Env): Episode done for env 11. Reward: -27.19, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 38.75, Length: 6
DEBUG (Env): Episode done for env 17. Reward: 18.13, Length: 25
DEBUG (Env): Episode done for env 39. Reward: -10.26, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 37.96, Length: 8
DEBUG (Env): Episode done for env 108. Reward: 23.86, Length: 10
2345
Time taken for simulation:  7.253074884414673
average overall reward:  1.5392013  average fail penalty:  -0.0703125  and average goal bonus:  1.6244643  and average same cell penalty:  -0.141587 average distance reward:  0.17449692  and average step penalty:  -0.04786053509430681
Number of done instances:  15
DEBUG (Env): Episode done for env 33. Reward: 11.22, Length: 24
DEBUG (Env): Episode done for env 34. Reward: -15.65, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 24.47, Length: 7
DEBUG (Env): Episode done for env 42. Reward: 21.52, Length: 3
DEBUG (Env): Episode done for env 43. Reward: 20.10, Length: 7
DEBUG (Env): Episode done for env 46. Reward: 24.89, Length: 4
DEBUG (Env): Episode done for env 53. Reward: -18.22, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 19.08, Length: 31
DEBUG (Env): Episode done for env 55. Reward: 18.79, Length: 5
DEBUG (Env): Episode done for env 75. Reward: 19.71, Length: 10
DEBUG (Env): Episode done for env 86. Reward: -26.06, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 24.23, Length: 10
DEBUG (Env): Episode done for env 98. Reward: 21.30, Length: 3
DEBUG (Env): Episode done for env 122. Reward: 21.91, Length: 24
DEBUG (Env): Episode done for env 125. Reward: 28.76, Length: 24
2346
Time taken for simulation:  7.352838754653931
average overall reward:  0.5622696  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.44396222  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 31.37, Length: 12
DEBUG (Env): Episode done for env 21. Reward: 15.70, Length: 20
DEBUG (Env): Episode done for env 25. Reward: -17.41, Length: 36
DEBUG (Env): Episode done for env 77. Reward: -27.58, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 37.22, Length: 12
2347
Time taken for simulation:  7.764200210571289
average overall reward:  0.48832715  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.447249  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 47. Reward: -17.00, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 3.63, Length: 21
DEBUG (Env): Episode done for env 101. Reward: 22.68, Length: 15
DEBUG (Env): Episode done for env 102. Reward: -10.80, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 11.49, Length: 16
2348
Time taken for simulation:  7.086759090423584
average overall reward:  0.79844123  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.21881628 average distance reward:  0.14095142  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: 42.12, Length: 8
DEBUG (Env): Episode done for env 19. Reward: 15.27, Length: 2
DEBUG (Env): Episode done for env 32. Reward: -24.72, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 18.54, Length: 5
DEBUG (Env): Episode done for env 65. Reward: 27.64, Length: 12
DEBUG (Env): Episode done for env 87. Reward: 19.40, Length: 3
DEBUG (Env): Episode done for env 93. Reward: 20.38, Length: 7
DEBUG (Env): Episode done for env 120. Reward: 28.83, Length: 23
2349
Time taken for simulation:  7.041678428649902
average overall reward:  1.203886  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.12871546 average distance reward:  0.43285787  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: 25.03, Length: 18
DEBUG (Env): Episode done for env 11. Reward: 25.41, Length: 5
DEBUG (Env): Episode done for env 40. Reward: 34.98, Length: 15
DEBUG (Env): Episode done for env 67. Reward: 16.38, Length: 17
DEBUG (Env): Episode done for env 85. Reward: 29.30, Length: 12
DEBUG (Env): Episode done for env 110. Reward: 17.81, Length: 26
DEBUG (Env): Episode done for env 126. Reward: 5.54, Length: 14
2350
Time taken for simulation:  7.2556915283203125
average overall reward:  0.92795515  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.1673301 average distance reward:  0.3543512  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 8. Reward: 21.71, Length: 1
DEBUG (Env): Episode done for env 16. Reward: 29.26, Length: 9
DEBUG (Env): Episode done for env 21. Reward: 35.24, Length: 4
DEBUG (Env): Episode done for env 37. Reward: 20.52, Length: 20
DEBUG (Env): Episode done for env 104. Reward: 37.62, Length: 22
DEBUG (Env): Episode done for env 107. Reward: -22.30, Length: 36
DEBUG (Env): Episode done for env 121. Reward: 19.44, Length: 18
2351
Time taken for simulation:  7.46227765083313
average overall reward:  0.87700164  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.49025583  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -16.64, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 26.35, Length: 4
DEBUG (Env): Episode done for env 90. Reward: 26.58, Length: 12
DEBUG (Env): Episode done for env 107. Reward: 22.38, Length: 1
DEBUG (Env): Episode done for env 120. Reward: 25.06, Length: 3
DEBUG (Env): Episode done for env 124. Reward: 20.90, Length: 13
2352
Time taken for simulation:  6.951214551925659
average overall reward:  0.7549875  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  0.31906113  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: 26.13, Length: 8
DEBUG (Env): Episode done for env 9. Reward: 20.60, Length: 15
DEBUG (Env): Episode done for env 15. Reward: 42.44, Length: 8
DEBUG (Env): Episode done for env 56. Reward: 26.09, Length: 12
DEBUG (Env): Episode done for env 96. Reward: 19.47, Length: 10
2353
Time taken for simulation:  7.155591726303101
average overall reward:  0.55842733  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.15445855 average distance reward:  0.15419886  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: -14.44, Length: 36
DEBUG (Env): Episode done for env 20. Reward: 19.72, Length: 25
DEBUG (Env): Episode done for env 22. Reward: -23.44, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -0.45, Length: 35
DEBUG (Env): Episode done for env 36. Reward: -12.28, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 18.58, Length: 8
DEBUG (Env): Episode done for env 80. Reward: 21.45, Length: 13
DEBUG (Env): Episode done for env 84. Reward: 27.85, Length: 23
2354
Time taken for simulation:  7.447366237640381
average overall reward:  0.21524516  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3089171 average distance reward:  0.21278171  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 12. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 15. Reward: 28.06, Length: 2
DEBUG (Env): Episode done for env 23. Reward: -21.85, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 12.09, Length: 9
DEBUG (Env): Episode done for env 50. Reward: 34.83, Length: 16
2355
Time taken for simulation:  7.449462890625
average overall reward:  -0.04849552  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  -0.13049385  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: 38.55, Length: 13
DEBUG (Env): Episode done for env 6. Reward: -13.97, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 32.76, Length: 7
DEBUG (Env): Episode done for env 97. Reward: -20.43, Length: 36
DEBUG (Env): Episode done for env 104. Reward: 16.24, Length: 5
DEBUG (Env): Episode done for env 118. Reward: -16.88, Length: 36
2356
Time taken for simulation:  7.0542895793914795
average overall reward:  0.532245  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.21881908  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 24. Reward: 17.63, Length: 26
DEBUG (Env): Episode done for env 59. Reward: 19.19, Length: 13
DEBUG (Env): Episode done for env 95. Reward: 27.60, Length: 17
DEBUG (Env): Episode done for env 113. Reward: 30.21, Length: 18
2357
Time taken for simulation:  7.261993408203125
average overall reward:  0.022942886  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.13676496  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 26. Reward: -18.63, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 32.65, Length: 14
DEBUG (Env): Episode done for env 116. Reward: -15.86, Length: 36
2358
Time taken for simulation:  7.434898614883423
average overall reward:  0.38306713  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.12112736  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 24. Reward: 18.50, Length: 2
DEBUG (Env): Episode done for env 28. Reward: 29.20, Length: 5
DEBUG (Env): Episode done for env 56. Reward: 25.48, Length: 6
DEBUG (Env): Episode done for env 125. Reward: 39.47, Length: 13
2359
Time taken for simulation:  7.2275800704956055
average overall reward:  0.2052232  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  -0.009841487  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 10. Reward: 20.96, Length: 21
DEBUG (Env): Episode done for env 20. Reward: 29.39, Length: 6
DEBUG (Env): Episode done for env 25. Reward: 22.85, Length: 13
DEBUG (Env): Episode done for env 46. Reward: 16.92, Length: 14
DEBUG (Env): Episode done for env 66. Reward: -7.31, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -16.10, Length: 36
2360
Time taken for simulation:  7.280122518539429
average overall reward:  0.6737329  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594473 average distance reward:  0.16218108  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: 40.51, Length: 7
DEBUG (Env): Episode done for env 16. Reward: 27.39, Length: 10
DEBUG (Env): Episode done for env 38. Reward: -10.26, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 10.86, Length: 15
DEBUG (Env): Episode done for env 58. Reward: 9.42, Length: 18
DEBUG (Env): Episode done for env 76. Reward: -17.61, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 16.58, Length: 13
DEBUG (Env): Episode done for env 122. Reward: 16.68, Length: 15
2361
Time taken for simulation:  6.968209981918335
average overall reward:  0.6095232  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.1673301 average distance reward:  0.08279415  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 52. Reward: 21.47, Length: 21
DEBUG (Env): Episode done for env 57. Reward: -14.46, Length: 36
DEBUG (Env): Episode done for env 71. Reward: -13.11, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 10.97, Length: 29
DEBUG (Env): Episode done for env 79. Reward: 12.45, Length: 23
DEBUG (Env): Episode done for env 85. Reward: 22.67, Length: 12
DEBUG (Env): Episode done for env 106. Reward: -14.17, Length: 36
DEBUG (Env): Episode done for env 110. Reward: 18.21, Length: 12
DEBUG (Env): Episode done for env 123. Reward: 30.21, Length: 24
2362
Time taken for simulation:  7.080560684204102
average overall reward:  0.7286937  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.283174 average distance reward:  0.27093375  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 34.07, Length: 3
DEBUG (Env): Episode done for env 21. Reward: 21.22, Length: 12
DEBUG (Env): Episode done for env 37. Reward: 23.00, Length: 12
DEBUG (Env): Episode done for env 89. Reward: -11.37, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 21.01, Length: 1
DEBUG (Env): Episode done for env 119. Reward: 30.03, Length: 21
DEBUG (Env): Episode done for env 125. Reward: 30.60, Length: 4
2363
Time taken for simulation:  7.363443851470947
average overall reward:  0.124592885  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881627 average distance reward:  0.19083816  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: -15.62, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 23.06, Length: 12
DEBUG (Env): Episode done for env 57. Reward: 23.05, Length: 2
DEBUG (Env): Episode done for env 91. Reward: -22.89, Length: 36
DEBUG (Env): Episode done for env 99. Reward: -17.76, Length: 36
2364
Time taken for simulation:  7.13639497756958
average overall reward:  0.44603783  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.14548346  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 72. Reward: 18.92, Length: 7
DEBUG (Env): Episode done for env 73. Reward: 28.45, Length: 3
DEBUG (Env): Episode done for env 95. Reward: 18.65, Length: 8
DEBUG (Env): Episode done for env 126. Reward: 23.55, Length: 15
2365
Time taken for simulation:  7.042477369308472
average overall reward:  0.5694055  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.12871546 average distance reward:  0.2513684  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: 43.14, Length: 13
DEBUG (Env): Episode done for env 26. Reward: 15.75, Length: 8
DEBUG (Env): Episode done for env 27. Reward: -22.64, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 21.43, Length: 4
DEBUG (Env): Episode done for env 78. Reward: -18.27, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 15.57, Length: 20
2366
Time taken for simulation:  7.436913013458252
average overall reward:  0.9021473  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.102972366 average distance reward:  0.42299512  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 19. Reward: 22.94, Length: 18
DEBUG (Env): Episode done for env 30. Reward: -24.84, Length: 36
DEBUG (Env): Episode done for env 74. Reward: 16.68, Length: 26
DEBUG (Env): Episode done for env 81. Reward: 10.43, Length: 30
DEBUG (Env): Episode done for env 94. Reward: -6.28, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 13.26, Length: 14
DEBUG (Env): Episode done for env 118. Reward: 15.42, Length: 11
2367
Time taken for simulation:  7.1249260902404785
average overall reward:  -0.15181044  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594472 average distance reward:  -0.09843673  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: 21.63, Length: 1
DEBUG (Env): Episode done for env 45. Reward: 26.94, Length: 25
DEBUG (Env): Episode done for env 92. Reward: -22.82, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -20.81, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -21.18, Length: 36
2368
Time taken for simulation:  7.570027589797974
average overall reward:  0.2654446  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.13657126  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 22. Reward: 22.40, Length: 15
DEBUG (Env): Episode done for env 29. Reward: -19.80, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 27.76, Length: 19
DEBUG (Env): Episode done for env 121. Reward: 31.50, Length: 18
2369
Time taken for simulation:  7.148647785186768
average overall reward:  0.42988783  average fail penalty:  -0.09375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.19307318 average distance reward:  0.08771146  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 0. Reward: -17.42, Length: 36
DEBUG (Env): Episode done for env 4. Reward: -21.34, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 19.49, Length: 9
DEBUG (Env): Episode done for env 33. Reward: 16.95, Length: 15
DEBUG (Env): Episode done for env 52. Reward: 15.35, Length: 4
DEBUG (Env): Episode done for env 64. Reward: -26.80, Length: 36
DEBUG (Env): Episode done for env 69. Reward: -17.82, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 13.93, Length: 12
DEBUG (Env): Episode done for env 120. Reward: 29.65, Length: 18
2370
Time taken for simulation:  7.152329206466675
average overall reward:  0.38837242  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.29604554 average distance reward:  0.10229346  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 14. Reward: -21.12, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -18.99, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 4.21, Length: 23
DEBUG (Env): Episode done for env 73. Reward: 27.48, Length: 6
DEBUG (Env): Episode done for env 75. Reward: 13.92, Length: 25
DEBUG (Env): Episode done for env 89. Reward: 25.33, Length: 8
DEBUG (Env): Episode done for env 110. Reward: 16.84, Length: 9
2371
Time taken for simulation:  7.096364498138428
average overall reward:  0.5972607  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  0.18477176  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 12.92, Length: 8
DEBUG (Env): Episode done for env 35. Reward: -19.29, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 20.73, Length: 11
DEBUG (Env): Episode done for env 39. Reward: 14.10, Length: 27
DEBUG (Env): Episode done for env 47. Reward: 26.51, Length: 8
DEBUG (Env): Episode done for env 57. Reward: 38.12, Length: 8
2372
Time taken for simulation:  7.427147150039673
average overall reward:  0.21437038  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.03401094  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 13. Reward: -18.85, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 6.45, Length: 35
DEBUG (Env): Episode done for env 85. Reward: 13.39, Length: 11
DEBUG (Env): Episode done for env 96. Reward: -3.00, Length: 6
2373
Time taken for simulation:  7.498212099075317
average overall reward:  1.2260283  average fail penalty:  -0.0703125  and average goal bonus:  1.0829761  and average same cell penalty:  -0.21881628 average distance reward:  0.48004138  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 18. Reward: 18.21, Length: 18
DEBUG (Env): Episode done for env 31. Reward: -14.09, Length: 36
DEBUG (Env): Episode done for env 42. Reward: 15.02, Length: 28
DEBUG (Env): Episode done for env 51. Reward: 27.41, Length: 3
DEBUG (Env): Episode done for env 53. Reward: 23.96, Length: 28
DEBUG (Env): Episode done for env 63. Reward: -19.95, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 3.48, Length: 25
DEBUG (Env): Episode done for env 78. Reward: 28.20, Length: 8
DEBUG (Env): Episode done for env 81. Reward: 30.34, Length: 7
DEBUG (Env): Episode done for env 103. Reward: -11.18, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 20.65, Length: 35
2374
Time taken for simulation:  7.295249700546265
average overall reward:  0.88609886  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.24455938 average distance reward:  0.25435218  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 26. Reward: 22.40, Length: 9
DEBUG (Env): Episode done for env 39. Reward: 24.13, Length: 3
DEBUG (Env): Episode done for env 57. Reward: 18.19, Length: 3
DEBUG (Env): Episode done for env 60. Reward: -10.80, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 24.02, Length: 6
DEBUG (Env): Episode done for env 98. Reward: 16.89, Length: 9
DEBUG (Env): Episode done for env 110. Reward: 19.72, Length: 4
DEBUG (Env): Episode done for env 114. Reward: 10.56, Length: 31
2375
Time taken for simulation:  7.405527830123901
average overall reward:  1.0063667  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.2574309 average distance reward:  0.27555695  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 46. Reward: 31.10, Length: 16
DEBUG (Env): Episode done for env 48. Reward: 13.13, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 36.47, Length: 6
DEBUG (Env): Episode done for env 72. Reward: 25.23, Length: 11
DEBUG (Env): Episode done for env 75. Reward: 21.11, Length: 5
DEBUG (Env): Episode done for env 83. Reward: 20.45, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 17.65, Length: 3
DEBUG (Env): Episode done for env 111. Reward: 8.05, Length: 35
2376
Time taken for simulation:  7.494126081466675
average overall reward:  0.4691381  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.37887943  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 65. Reward: 26.48, Length: 3
DEBUG (Env): Episode done for env 88. Reward: -20.76, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 39.03, Length: 15
DEBUG (Env): Episode done for env 125. Reward: 19.54, Length: 14
2377
Time taken for simulation:  7.304505825042725
average overall reward:  1.0905447  average fail penalty:  -0.0234375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.23168781 average distance reward:  0.17518228  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 12. Reward: 20.29, Length: 23
DEBUG (Env): Episode done for env 27. Reward: 15.72, Length: 12
DEBUG (Env): Episode done for env 31. Reward: 29.22, Length: 4
DEBUG (Env): Episode done for env 62. Reward: 25.70, Length: 7
DEBUG (Env): Episode done for env 64. Reward: 40.16, Length: 8
DEBUG (Env): Episode done for env 76. Reward: 16.94, Length: 17
DEBUG (Env): Episode done for env 82. Reward: -24.36, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 19.53, Length: 3
DEBUG (Env): Episode done for env 115. Reward: 6.95, Length: 34
DEBUG (Env): Episode done for env 122. Reward: 18.17, Length: 17
2378
Time taken for simulation:  7.27303671836853
average overall reward:  0.8661854  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168783 average distance reward:  0.24500461  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: 12.14, Length: 26
DEBUG (Env): Episode done for env 49. Reward: -21.70, Length: 36
DEBUG (Env): Episode done for env 70. Reward: -23.80, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 27.50, Length: 5
DEBUG (Env): Episode done for env 99. Reward: 20.30, Length: 15
DEBUG (Env): Episode done for env 103. Reward: 26.13, Length: 5
DEBUG (Env): Episode done for env 106. Reward: 28.49, Length: 16
DEBUG (Env): Episode done for env 110. Reward: 16.78, Length: 4
DEBUG (Env): Episode done for env 121. Reward: 37.92, Length: 10
2379
Time taken for simulation:  7.59654688835144
average overall reward:  0.9958619  average fail penalty:  0.0  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.38594887  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: 5.93, Length: 29
DEBUG (Env): Episode done for env 10. Reward: 11.14, Length: 17
DEBUG (Env): Episode done for env 13. Reward: 17.65, Length: 7
DEBUG (Env): Episode done for env 35. Reward: 18.41, Length: 8
DEBUG (Env): Episode done for env 71. Reward: 20.79, Length: 18
DEBUG (Env): Episode done for env 85. Reward: 37.84, Length: 7
2380
Time taken for simulation:  7.084312915802002
average overall reward:  0.7973441  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.21881628 average distance reward:  0.45747328  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 17. Reward: -18.63, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -21.63, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 22.74, Length: 10
DEBUG (Env): Episode done for env 75. Reward: 32.75, Length: 5
DEBUG (Env): Episode done for env 81. Reward: 30.66, Length: 7
DEBUG (Env): Episode done for env 93. Reward: 19.11, Length: 32
DEBUG (Env): Episode done for env 98. Reward: 26.45, Length: 6
DEBUG (Env): Episode done for env 108. Reward: -12.55, Length: 36
2381
Time taken for simulation:  7.1453235149383545
average overall reward:  1.2809802  average fail penalty:  -0.09375  and average goal bonus:  1.0829761  and average same cell penalty:  -0.2574309 average distance reward:  0.5970455  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 34. Reward: -22.33, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 46.42, Length: 10
DEBUG (Env): Episode done for env 41. Reward: -8.14, Length: 36
DEBUG (Env): Episode done for env 43. Reward: -14.57, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 56.92, Length: 8
DEBUG (Env): Episode done for env 77. Reward: 14.20, Length: 35
DEBUG (Env): Episode done for env 84. Reward: 9.71, Length: 28
DEBUG (Env): Episode done for env 85. Reward: 18.01, Length: 2
DEBUG (Env): Episode done for env 86. Reward: -18.60, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 26.88, Length: 1
DEBUG (Env): Episode done for env 114. Reward: 30.96, Length: 4
DEBUG (Env): Episode done for env 122. Reward: 20.45, Length: 4
2382
Time taken for simulation:  7.0768351554870605
average overall reward:  0.71085227  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1930732 average distance reward:  0.5691074  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 18. Reward: 37.89, Length: 9
DEBUG (Env): Episode done for env 43. Reward: 22.12, Length: 1
DEBUG (Env): Episode done for env 80. Reward: 11.49, Length: 29
DEBUG (Env): Episode done for env 100. Reward: -8.44, Length: 36
2383
Time taken for simulation:  7.188239336013794
average overall reward:  1.0893198  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.23168781 average distance reward:  0.33276695  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 14. Reward: 15.51, Length: 13
DEBUG (Env): Episode done for env 30. Reward: 27.24, Length: 17
DEBUG (Env): Episode done for env 40. Reward: 16.25, Length: 34
DEBUG (Env): Episode done for env 54. Reward: 17.55, Length: 30
DEBUG (Env): Episode done for env 83. Reward: 28.58, Length: 8
DEBUG (Env): Episode done for env 101. Reward: -25.45, Length: 36
DEBUG (Env): Episode done for env 105. Reward: -17.27, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 44.43, Length: 5
DEBUG (Env): Episode done for env 107. Reward: 20.35, Length: 32
DEBUG (Env): Episode done for env 121. Reward: 31.97, Length: 5
2384
Time taken for simulation:  7.0862812995910645
average overall reward:  0.21156287  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168783 average distance reward:  0.29067966  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 32. Reward: -27.62, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 25.85, Length: 11
DEBUG (Env): Episode done for env 61. Reward: -22.06, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 22.99, Length: 4
DEBUG (Env): Episode done for env 87. Reward: -6.83, Length: 36
2385
Time taken for simulation:  7.224811553955078
average overall reward:  0.7552069  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.16873127  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 24.35, Length: 14
DEBUG (Env): Episode done for env 11. Reward: -0.02, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 24.08, Length: 23
DEBUG (Env): Episode done for env 32. Reward: 24.66, Length: 1
DEBUG (Env): Episode done for env 78. Reward: 22.26, Length: 7
DEBUG (Env): Episode done for env 95. Reward: 13.47, Length: 21
2386
Time taken for simulation:  7.11115288734436
average overall reward:  0.5786423  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.27030247 average distance reward:  0.21994524  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: 19.61, Length: 27
DEBUG (Env): Episode done for env 52. Reward: 18.31, Length: 17
DEBUG (Env): Episode done for env 70. Reward: 26.68, Length: 8
DEBUG (Env): Episode done for env 93. Reward: 28.08, Length: 6
DEBUG (Env): Episode done for env 105. Reward: 19.46, Length: 3
2387
Time taken for simulation:  7.3881330490112305
average overall reward:  0.27268928  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.06819046  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -17.37, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 18.64, Length: 3
DEBUG (Env): Episode done for env 52. Reward: 17.39, Length: 1
DEBUG (Env): Episode done for env 65. Reward: 19.72, Length: 11
DEBUG (Env): Episode done for env 90. Reward: -13.57, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 3.16, Length: 32
DEBUG (Env): Episode done for env 124. Reward: -30.94, Length: 36
2388
Time taken for simulation:  7.2159483432769775
average overall reward:  0.54090786  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.253225  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 54. Reward: 36.57, Length: 5
DEBUG (Env): Episode done for env 77. Reward: 25.27, Length: 7
DEBUG (Env): Episode done for env 91. Reward: 25.12, Length: 25
DEBUG (Env): Episode done for env 93. Reward: 24.02, Length: 2
2389
Time taken for simulation:  7.2140514850616455
average overall reward:  0.2800418  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.13829699  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 36. Reward: -11.31, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 15.03, Length: 31
DEBUG (Env): Episode done for env 88. Reward: 21.94, Length: 13
DEBUG (Env): Episode done for env 102. Reward: 6.18, Length: 29
2390
Time taken for simulation:  7.529889106750488
average overall reward:  0.09241845  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.29604554 average distance reward:  0.100520976  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: -13.05, Length: 36
DEBUG (Env): Episode done for env 23. Reward: -17.73, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 21.13, Length: 4
DEBUG (Env): Episode done for env 50. Reward: -11.64, Length: 36
DEBUG (Env): Episode done for env 85. Reward: 28.32, Length: 9
DEBUG (Env): Episode done for env 127. Reward: 11.88, Length: 17
2391
Time taken for simulation:  7.157730340957642
average overall reward:  0.0706576  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.13690284  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: -18.98, Length: 36
DEBUG (Env): Episode done for env 6. Reward: -17.53, Length: 36
DEBUG (Env): Episode done for env 8. Reward: 19.69, Length: 12
DEBUG (Env): Episode done for env 14. Reward: 23.12, Length: 8
DEBUG (Env): Episode done for env 104. Reward: -14.85, Length: 36
2392
Time taken for simulation:  7.049259185791016
average overall reward:  0.2510979  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.061776247  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: 25.26, Length: 5
DEBUG (Env): Episode done for env 40. Reward: 23.01, Length: 9
DEBUG (Env): Episode done for env 59. Reward: -34.93, Length: 36
DEBUG (Env): Episode done for env 79. Reward: 9.26, Length: 31
DEBUG (Env): Episode done for env 80. Reward: 28.93, Length: 10
DEBUG (Env): Episode done for env 113. Reward: -13.19, Length: 36
2393
Time taken for simulation:  7.056574821472168
average overall reward:  0.53512883  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  0.35707492  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 79. Reward: 26.73, Length: 1
DEBUG (Env): Episode done for env 96. Reward: 19.22, Length: 18
DEBUG (Env): Episode done for env 114. Reward: 29.74, Length: 12
2394
Time taken for simulation:  7.040804862976074
average overall reward:  -0.1429215  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  0.035258263  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 24. Reward: -14.39, Length: 36
DEBUG (Env): Episode done for env 28. Reward: -17.72, Length: 36
DEBUG (Env): Episode done for env 36. Reward: 19.25, Length: 5
2395
Time taken for simulation:  7.077542304992676
average overall reward:  0.38526624  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.45151153  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 6. Reward: 20.75, Length: 4
DEBUG (Env): Episode done for env 11. Reward: 26.07, Length: 10
DEBUG (Env): Episode done for env 20. Reward: -22.19, Length: 36
DEBUG (Env): Episode done for env 66. Reward: -17.51, Length: 36
DEBUG (Env): Episode done for env 109. Reward: -23.82, Length: 36
2396
Time taken for simulation:  7.1872398853302
average overall reward:  0.66635895  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.2878734  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 2. Reward: -12.43, Length: 36
DEBUG (Env): Episode done for env 9. Reward: 12.47, Length: 31
DEBUG (Env): Episode done for env 55. Reward: -24.87, Length: 36
DEBUG (Env): Episode done for env 58. Reward: -15.73, Length: 36
DEBUG (Env): Episode done for env 71. Reward: 23.15, Length: 17
DEBUG (Env): Episode done for env 72. Reward: 17.09, Length: 21
DEBUG (Env): Episode done for env 87. Reward: 24.55, Length: 12
DEBUG (Env): Episode done for env 99. Reward: 13.71, Length: 18
2397
Time taken for simulation:  7.109943389892578
average overall reward:  0.52701414  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.102972366 average distance reward:  0.136359  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 51. Reward: 21.94, Length: 10
DEBUG (Env): Episode done for env 68. Reward: 28.64, Length: 17
DEBUG (Env): Episode done for env 102. Reward: 50.37, Length: 8
DEBUG (Env): Episode done for env 121. Reward: 14.00, Length: 14
2398
Time taken for simulation:  7.300689697265625
average overall reward:  0.9839013  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.45947784  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 9. Reward: 25.72, Length: 2
DEBUG (Env): Episode done for env 10. Reward: 28.67, Length: 19
DEBUG (Env): Episode done for env 37. Reward: -3.64, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 31.64, Length: 10
DEBUG (Env): Episode done for env 56. Reward: 22.09, Length: 9
DEBUG (Env): Episode done for env 83. Reward: 26.00, Length: 15
DEBUG (Env): Episode done for env 100. Reward: 33.01, Length: 16
DEBUG (Env): Episode done for env 119. Reward: -20.21, Length: 36
2399
Time taken for simulation:  7.59102463722229
average overall reward:  0.973849  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168783 average distance reward:  0.30579317  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 20. Reward: 23.21, Length: 4
DEBUG (Env): Episode done for env 22. Reward: 13.03, Length: 31
DEBUG (Env): Episode done for env 29. Reward: 9.67, Length: 31
DEBUG (Env): Episode done for env 56. Reward: 29.09, Length: 1
DEBUG (Env): Episode done for env 60. Reward: 29.58, Length: 25
DEBUG (Env): Episode done for env 90. Reward: 26.02, Length: 12
DEBUG (Env): Episode done for env 96. Reward: 13.05, Length: 6
2400
Time taken for simulation:  7.021998167037964
average overall reward:  0.44389445  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594472 average distance reward:  0.04427711  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 23.01, Length: 10
DEBUG (Env): Episode done for env 41. Reward: 7.34, Length: 19
DEBUG (Env): Episode done for env 57. Reward: 11.48, Length: 26
DEBUG (Env): Episode done for env 108. Reward: 40.00, Length: 20
DEBUG (Env): Episode done for env 122. Reward: 9.37, Length: 19
DEBUG (Env): Episode done for env 126. Reward: -25.19, Length: 36
2401
Time taken for simulation:  7.269728422164917
average overall reward:  0.9193924  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  0.25133663  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: 30.28, Length: 3
DEBUG (Env): Episode done for env 14. Reward: 36.99, Length: 10
DEBUG (Env): Episode done for env 20. Reward: 24.42, Length: 2
DEBUG (Env): Episode done for env 31. Reward: 25.67, Length: 24
DEBUG (Env): Episode done for env 51. Reward: 28.68, Length: 4
DEBUG (Env): Episode done for env 108. Reward: 12.64, Length: 1
DEBUG (Env): Episode done for env 116. Reward: 9.16, Length: 32
2402
Time taken for simulation:  7.100222110748291
average overall reward:  0.3614048  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.15445855 average distance reward:  0.49866438  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 46. Reward: 19.72, Length: 27
DEBUG (Env): Episode done for env 74. Reward: -24.23, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -25.74, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -17.78, Length: 36
2403
Time taken for simulation:  7.435134410858154
average overall reward:  -0.002038926  average fail penalty:  -0.1171875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.15445855 average distance reward:  0.046723653  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 19. Reward: -16.10, Length: 36
DEBUG (Env): Episode done for env 45. Reward: -26.15, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 29.96, Length: 17
DEBUG (Env): Episode done for env 92. Reward: -27.49, Length: 36
DEBUG (Env): Episode done for env 99. Reward: 39.20, Length: 7
DEBUG (Env): Episode done for env 112. Reward: -20.08, Length: 36
DEBUG (Env): Episode done for env 117. Reward: -24.75, Length: 36
2404
Time taken for simulation:  7.162917137145996
average overall reward:  0.1608547  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  -0.062470466  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 2. Reward: 32.35, Length: 8
DEBUG (Env): Episode done for env 47. Reward: 17.01, Length: 33
DEBUG (Env): Episode done for env 80. Reward: 32.62, Length: 12
DEBUG (Env): Episode done for env 85. Reward: 15.65, Length: 14
2405
Time taken for simulation:  7.045287609100342
average overall reward:  0.32899278  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455938 average distance reward:  0.061740085  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 0. Reward: -15.77, Length: 36
DEBUG (Env): Episode done for env 4. Reward: -16.16, Length: 36
DEBUG (Env): Episode done for env 16. Reward: -21.26, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -20.35, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 3.74, Length: 27
DEBUG (Env): Episode done for env 55. Reward: 26.81, Length: 9
DEBUG (Env): Episode done for env 69. Reward: 6.77, Length: 30
DEBUG (Env): Episode done for env 88. Reward: 25.29, Length: 16
DEBUG (Env): Episode done for env 97. Reward: 16.02, Length: 18
DEBUG (Env): Episode done for env 120. Reward: -16.80, Length: 36
2406
Time taken for simulation:  7.122805833816528
average overall reward:  0.38796163  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.33466017 average distance reward:  0.38780385  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 84. Reward: 30.82, Length: 25
DEBUG (Env): Episode done for env 89. Reward: -20.63, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 28.25, Length: 3
DEBUG (Env): Episode done for env 126. Reward: 32.27, Length: 6
2407
Time taken for simulation:  7.246438026428223
average overall reward:  0.6034355  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.3672388  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 20. Reward: 41.20, Length: 6
DEBUG (Env): Episode done for env 37. Reward: 20.88, Length: 9
DEBUG (Env): Episode done for env 38. Reward: 15.43, Length: 26
DEBUG (Env): Episode done for env 126. Reward: 19.84, Length: 1
2408
Time taken for simulation:  7.230513334274292
average overall reward:  0.3637586  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  -0.035858825  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 37. Reward: 18.66, Length: 1
DEBUG (Env): Episode done for env 44. Reward: -14.62, Length: 36
DEBUG (Env): Episode done for env 87. Reward: 19.90, Length: 12
DEBUG (Env): Episode done for env 92. Reward: 27.75, Length: 5
DEBUG (Env): Episode done for env 97. Reward: 27.48, Length: 3
DEBUG (Env): Episode done for env 108. Reward: 16.69, Length: 7
2409
Time taken for simulation:  7.066202878952026
average overall reward:  -0.03186749  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  -0.1115601  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 21. Reward: 16.67, Length: 24
DEBUG (Env): Episode done for env 42. Reward: -12.65, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 17.17, Length: 27
DEBUG (Env): Episode done for env 53. Reward: -14.46, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 14.15, Length: 23
2410
Time taken for simulation:  7.192135810852051
average overall reward:  -0.15068002  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.32178867 average distance reward:  -0.116834424  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 0. Reward: 39.69, Length: 5
DEBUG (Env): Episode done for env 17. Reward: 13.84, Length: 30
DEBUG (Env): Episode done for env 20. Reward: 22.65, Length: 3
DEBUG (Env): Episode done for env 26. Reward: -19.66, Length: 36
DEBUG (Env): Episode done for env 39. Reward: -10.06, Length: 36
DEBUG (Env): Episode done for env 67. Reward: -18.16, Length: 36
2411
Time taken for simulation:  7.386986494064331
average overall reward:  0.792743  average fail penalty:  -0.046875  and average goal bonus:  0.94760424  and average same cell penalty:  -0.283174 average distance reward:  0.22304833  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 31. Reward: 23.99, Length: 10
DEBUG (Env): Episode done for env 37. Reward: 32.87, Length: 3
DEBUG (Env): Episode done for env 39. Reward: 35.45, Length: 1
DEBUG (Env): Episode done for env 48. Reward: -0.58, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 12.18, Length: 19
DEBUG (Env): Episode done for env 70. Reward: 27.50, Length: 8
DEBUG (Env): Episode done for env 95. Reward: 6.84, Length: 26
DEBUG (Env): Episode done for env 103. Reward: 12.98, Length: 33
DEBUG (Env): Episode done for env 111. Reward: -17.43, Length: 36
2412
Time taken for simulation:  7.086289882659912
average overall reward:  0.6835666  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.23168781 average distance reward:  0.3331298  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 6.73, Length: 17
DEBUG (Env): Episode done for env 40. Reward: 23.40, Length: 20
DEBUG (Env): Episode done for env 45. Reward: 12.63, Length: 9
DEBUG (Env): Episode done for env 78. Reward: 14.59, Length: 27
DEBUG (Env): Episode done for env 107. Reward: 28.26, Length: 29
DEBUG (Env): Episode done for env 123. Reward: -29.83, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -17.53, Length: 36
2413
Time taken for simulation:  7.021852493286133
average overall reward:  1.1298748  average fail penalty:  -0.1640625  and average goal bonus:  0.9476042  and average same cell penalty:  -0.15445855 average distance reward:  0.54865223  and average step penalty:  -0.04786053509430681
Number of done instances:  13
DEBUG (Env): Episode done for env 12. Reward: -10.57, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -7.27, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 30.45, Length: 8
DEBUG (Env): Episode done for env 39. Reward: 10.96, Length: 2
DEBUG (Env): Episode done for env 61. Reward: 2.05, Length: 29
DEBUG (Env): Episode done for env 62. Reward: -17.18, Length: 36
DEBUG (Env): Episode done for env 64. Reward: -23.57, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -22.16, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -16.53, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 25.35, Length: 7
DEBUG (Env): Episode done for env 88. Reward: 17.37, Length: 8
DEBUG (Env): Episode done for env 104. Reward: 35.80, Length: 22
DEBUG (Env): Episode done for env 115. Reward: 1.59, Length: 36
2414
Time taken for simulation:  7.310497760772705
average overall reward:  0.12788124  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.115843914 average distance reward:  0.06771662  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 1. Reward: 18.27, Length: 22
DEBUG (Env): Episode done for env 3. Reward: -28.64, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 11.00, Length: 33
DEBUG (Env): Episode done for env 110. Reward: -20.31, Length: 36
2415
Time taken for simulation:  7.21088981628418
average overall reward:  0.7124626  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594473 average distance reward:  0.2009107  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 13. Reward: -6.92, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 30.32, Length: 10
DEBUG (Env): Episode done for env 24. Reward: 42.22, Length: 21
DEBUG (Env): Episode done for env 35. Reward: -16.39, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 32.23, Length: 8
DEBUG (Env): Episode done for env 39. Reward: 20.81, Length: 2
DEBUG (Env): Episode done for env 103. Reward: 22.20, Length: 4
DEBUG (Env): Episode done for env 118. Reward: 29.79, Length: 13
2416
Time taken for simulation:  7.426076412200928
average overall reward:  0.64137983  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.16733009 average distance reward:  0.22658537  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 6.30, Length: 11
DEBUG (Env): Episode done for env 56. Reward: 16.37, Length: 17
DEBUG (Env): Episode done for env 73. Reward: -22.58, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -15.64, Length: 36
DEBUG (Env): Episode done for env 83. Reward: 19.51, Length: 18
DEBUG (Env): Episode done for env 89. Reward: 29.55, Length: 10
DEBUG (Env): Episode done for env 105. Reward: 21.28, Length: 7
2417
Time taken for simulation:  7.144176483154297
average overall reward:  0.4542426  average fail penalty:  -0.0703125  and average goal bonus:  0.67686015  and average same cell penalty:  -0.16733009 average distance reward:  0.06288557  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 34. Reward: -16.95, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 23.08, Length: 17
DEBUG (Env): Episode done for env 48. Reward: 19.97, Length: 6
DEBUG (Env): Episode done for env 80. Reward: 15.33, Length: 13
DEBUG (Env): Episode done for env 86. Reward: -25.81, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 20.16, Length: 9
DEBUG (Env): Episode done for env 98. Reward: -20.75, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 24.80, Length: 1
2418
Time taken for simulation:  7.5496437549591064
average overall reward:  1.2699624  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.15445855 average distance reward:  0.54811484  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 3. Reward: 14.53, Length: 4
DEBUG (Env): Episode done for env 15. Reward: 15.67, Length: 18
DEBUG (Env): Episode done for env 18. Reward: -14.22, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 40.46, Length: 5
DEBUG (Env): Episode done for env 34. Reward: 22.19, Length: 1
DEBUG (Env): Episode done for env 35. Reward: 12.58, Length: 3
DEBUG (Env): Episode done for env 94. Reward: 30.23, Length: 16
DEBUG (Env): Episode done for env 107. Reward: 19.51, Length: 6
2419
Time taken for simulation:  7.155974388122559
average overall reward:  0.2838607  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.16324773  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: 20.02, Length: 18
DEBUG (Env): Episode done for env 30. Reward: -14.97, Length: 36
DEBUG (Env): Episode done for env 58. Reward: 20.68, Length: 23
DEBUG (Env): Episode done for env 67. Reward: 32.35, Length: 9
DEBUG (Env): Episode done for env 101. Reward: -12.78, Length: 36
DEBUG (Env): Episode done for env 106. Reward: -15.48, Length: 36
2420
Time taken for simulation:  7.229090929031372
average overall reward:  0.49475303  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.2305077  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 25. Reward: 7.88, Length: 30
DEBUG (Env): Episode done for env 75. Reward: -15.71, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 28.48, Length: 7
DEBUG (Env): Episode done for env 106. Reward: 24.01, Length: 1
DEBUG (Env): Episode done for env 111. Reward: 17.93, Length: 9
2421
Time taken for simulation:  6.954583406448364
average overall reward:  -0.6242044  average fail penalty:  -0.046875  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  -0.27203792  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 7. Reward: -18.99, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -16.08, Length: 36
2422
Time taken for simulation:  7.257012367248535
average overall reward:  1.0273433  average fail penalty:  0.0  and average goal bonus:  1.0829761  and average same cell penalty:  -0.16733009 average distance reward:  0.15955786  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 24. Reward: 16.47, Length: 7
DEBUG (Env): Episode done for env 35. Reward: 27.71, Length: 4
DEBUG (Env): Episode done for env 80. Reward: 16.67, Length: 5
DEBUG (Env): Episode done for env 88. Reward: 7.17, Length: 2
DEBUG (Env): Episode done for env 100. Reward: 18.66, Length: 24
DEBUG (Env): Episode done for env 108. Reward: 23.02, Length: 14
DEBUG (Env): Episode done for env 114. Reward: 18.29, Length: 29
DEBUG (Env): Episode done for env 126. Reward: 22.40, Length: 15
2423
Time taken for simulation:  7.4161131381988525
average overall reward:  1.0136395  average fail penalty:  -0.0703125  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.6608971  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 32. Reward: 17.99, Length: 2
DEBUG (Env): Episode done for env 38. Reward: 30.94, Length: 8
DEBUG (Env): Episode done for env 52. Reward: -20.03, Length: 36
DEBUG (Env): Episode done for env 63. Reward: 29.44, Length: 9
DEBUG (Env): Episode done for env 65. Reward: -17.91, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 26.46, Length: 6
DEBUG (Env): Episode done for env 106. Reward: 15.20, Length: 3
DEBUG (Env): Episode done for env 124. Reward: -7.55, Length: 36
2424
Time taken for simulation:  7.186016082763672
average overall reward:  0.119931914  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020163 average distance reward:  -0.123181514  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 9. Reward: 16.99, Length: 5
DEBUG (Env): Episode done for env 27. Reward: 25.59, Length: 6
DEBUG (Env): Episode done for env 37. Reward: 27.80, Length: 13
DEBUG (Env): Episode done for env 77. Reward: -6.22, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 21.15, Length: 1
DEBUG (Env): Episode done for env 91. Reward: -23.31, Length: 36
DEBUG (Env): Episode done for env 93. Reward: -12.23, Length: 36
2425
Time taken for simulation:  7.53199315071106
average overall reward:  0.21703756  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  -0.0062875897  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 6. Reward: 19.85, Length: 13
DEBUG (Env): Episode done for env 35. Reward: 21.64, Length: 3
DEBUG (Env): Episode done for env 67. Reward: 24.25, Length: 6
DEBUG (Env): Episode done for env 71. Reward: 7.31, Length: 29
2426
Time taken for simulation:  7.301004886627197
average overall reward:  0.71175444  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.20594473 average distance reward:  0.088268064  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 12. Reward: 31.35, Length: 13
DEBUG (Env): Episode done for env 23. Reward: -18.47, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 27.77, Length: 2
DEBUG (Env): Episode done for env 50. Reward: -20.14, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 13.08, Length: 21
DEBUG (Env): Episode done for env 98. Reward: 17.74, Length: 9
DEBUG (Env): Episode done for env 105. Reward: 22.38, Length: 9
DEBUG (Env): Episode done for env 115. Reward: 24.74, Length: 13
DEBUG (Env): Episode done for env 118. Reward: 24.08, Length: 11
DEBUG (Env): Episode done for env 127. Reward: -25.67, Length: 36
2427
Time taken for simulation:  7.066577196121216
average overall reward:  0.51745033  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594475 average distance reward:  0.27664244  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 5. Reward: -6.57, Length: 36
DEBUG (Env): Episode done for env 8. Reward: -11.50, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 43.12, Length: 4
DEBUG (Env): Episode done for env 60. Reward: 23.64, Length: 28
DEBUG (Env): Episode done for env 75. Reward: 30.66, Length: 7
DEBUG (Env): Episode done for env 94. Reward: 20.10, Length: 9
2428
Time taken for simulation:  7.3507654666900635
average overall reward:  0.52731663  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.43705797  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 48. Reward: 26.97, Length: 11
DEBUG (Env): Episode done for env 69. Reward: 37.39, Length: 2
DEBUG (Env): Episode done for env 80. Reward: 34.07, Length: 6
DEBUG (Env): Episode done for env 113. Reward: -8.98, Length: 36
2429
Time taken for simulation:  7.125839710235596
average overall reward:  0.43510044  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.18372661  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: 32.89, Length: 11
DEBUG (Env): Episode done for env 41. Reward: 28.59, Length: 12
DEBUG (Env): Episode done for env 78. Reward: 20.37, Length: 17
DEBUG (Env): Episode done for env 79. Reward: -33.91, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 24.60, Length: 3
2430
Time taken for simulation:  7.2166197299957275
average overall reward:  0.9067936  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.24699813  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 4. Reward: 11.53, Length: 14
DEBUG (Env): Episode done for env 28. Reward: -25.46, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -23.53, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 25.65, Length: 4
DEBUG (Env): Episode done for env 60. Reward: 30.14, Length: 3
DEBUG (Env): Episode done for env 63. Reward: 30.72, Length: 7
DEBUG (Env): Episode done for env 69. Reward: 30.11, Length: 2
DEBUG (Env): Episode done for env 82. Reward: 23.14, Length: 17
DEBUG (Env): Episode done for env 104. Reward: 36.96, Length: 17
2431
Time taken for simulation:  7.04748272895813
average overall reward:  0.26540732  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  0.24776672  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 11. Reward: -12.36, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 10.83, Length: 29
DEBUG (Env): Episode done for env 66. Reward: -24.66, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 26.57, Length: 7
DEBUG (Env): Episode done for env 109. Reward: -24.43, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 21.57, Length: 5
2432
Time taken for simulation:  7.190771102905273
average overall reward:  0.1307796  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455938 average distance reward:  0.04052095  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 21. Reward: 27.20, Length: 23
DEBUG (Env): Episode done for env 72. Reward: -26.46, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 18.70, Length: 8
DEBUG (Env): Episode done for env 95. Reward: 18.25, Length: 21
2433
Time taken for simulation:  7.252598762512207
average overall reward:  0.70728934  average fail penalty:  -0.0703125  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  0.109546  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 5. Reward: 26.73, Length: 6
DEBUG (Env): Episode done for env 12. Reward: 16.04, Length: 7
DEBUG (Env): Episode done for env 21. Reward: 24.40, Length: 1
DEBUG (Env): Episode done for env 43. Reward: 19.12, Length: 24
DEBUG (Env): Episode done for env 68. Reward: -22.43, Length: 36
DEBUG (Env): Episode done for env 73. Reward: 7.33, Length: 17
DEBUG (Env): Episode done for env 84. Reward: 23.94, Length: 20
DEBUG (Env): Episode done for env 102. Reward: -18.63, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 41.58, Length: 18
DEBUG (Env): Episode done for env 121. Reward: -25.96, Length: 36
2434
Time taken for simulation:  7.1561689376831055
average overall reward:  -0.28288478  average fail penalty:  -0.0703125  and average goal bonus:  0.0  and average same cell penalty:  -0.141587 average distance reward:  -0.023124743  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 10. Reward: -23.97, Length: 36
DEBUG (Env): Episode done for env 54. Reward: -15.64, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -11.53, Length: 36
2435
Time taken for simulation:  7.149949789047241
average overall reward:  0.4425403  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030247 average distance reward:  0.3129652  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 0. Reward: 13.64, Length: 25
DEBUG (Env): Episode done for env 22. Reward: -10.21, Length: 36
DEBUG (Env): Episode done for env 29. Reward: -12.61, Length: 36
DEBUG (Env): Episode done for env 44. Reward: -2.22, Length: 27
DEBUG (Env): Episode done for env 71. Reward: 31.53, Length: 10
DEBUG (Env): Episode done for env 90. Reward: -14.40, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -20.02, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 27.57, Length: 9
2436
Time taken for simulation:  7.300546169281006
average overall reward:  0.65674144  average fail penalty:  -0.046875  and average goal bonus:  0.94760424  and average same cell penalty:  -0.21881628 average distance reward:  0.022689193  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 33. Reward: 14.42, Length: 23
DEBUG (Env): Episode done for env 49. Reward: 11.48, Length: 31
DEBUG (Env): Episode done for env 56. Reward: 22.53, Length: 20
DEBUG (Env): Episode done for env 57. Reward: -18.52, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 15.30, Length: 13
DEBUG (Env): Episode done for env 81. Reward: 11.61, Length: 20
DEBUG (Env): Episode done for env 106. Reward: 28.44, Length: 13
DEBUG (Env): Episode done for env 118. Reward: 20.69, Length: 5
DEBUG (Env): Episode done for env 122. Reward: -20.67, Length: 36
2437
Time taken for simulation:  7.348726749420166
average overall reward:  0.95251596  average fail penalty:  -0.0703125  and average goal bonus:  1.2183483  and average same cell penalty:  -0.21881628 average distance reward:  0.07115694  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 14. Reward: -12.46, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 11.88, Length: 26
DEBUG (Env): Episode done for env 51. Reward: -5.03, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 18.16, Length: 12
DEBUG (Env): Episode done for env 86. Reward: 33.22, Length: 5
DEBUG (Env): Episode done for env 88. Reward: 15.48, Length: 15
DEBUG (Env): Episode done for env 91. Reward: 23.21, Length: 6
DEBUG (Env): Episode done for env 93. Reward: 28.99, Length: 13
DEBUG (Env): Episode done for env 108. Reward: 23.94, Length: 15
DEBUG (Env): Episode done for env 116. Reward: -7.86, Length: 36
DEBUG (Env): Episode done for env 127. Reward: 31.20, Length: 11
2438
Time taken for simulation:  7.639811277389526
average overall reward:  0.54915786  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.40741295  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 16. Reward: 13.97, Length: 23
DEBUG (Env): Episode done for env 74. Reward: -17.39, Length: 36
DEBUG (Env): Episode done for env 102. Reward: 36.31, Length: 5
DEBUG (Env): Episode done for env 113. Reward: 23.30, Length: 10
2439
Time taken for simulation:  7.459571838378906
average overall reward:  0.06810498  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.29604554 average distance reward:  0.21157952  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 19. Reward: -15.81, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 27.76, Length: 7
DEBUG (Env): Episode done for env 96. Reward: 33.33, Length: 4
DEBUG (Env): Episode done for env 99. Reward: -31.70, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -16.74, Length: 36
2440
Time taken for simulation:  7.058919906616211
average overall reward:  0.5709127  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.20594473 average distance reward:  0.48891437  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: -14.48, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 41.76, Length: 4
DEBUG (Env): Episode done for env 44. Reward: 18.49, Length: 5
DEBUG (Env): Episode done for env 47. Reward: -17.33, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -16.26, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 34.97, Length: 11
2441
Time taken for simulation:  7.4275805950164795
average overall reward:  0.47615492  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.21881628 average distance reward:  0.24821869  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 55. Reward: -25.77, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 22.30, Length: 5
DEBUG (Env): Episode done for env 90. Reward: 17.83, Length: 6
DEBUG (Env): Episode done for env 108. Reward: 26.59, Length: 4
DEBUG (Env): Episode done for env 113. Reward: 20.03, Length: 3
DEBUG (Env): Episode done for env 120. Reward: -27.69, Length: 36
2442
Time taken for simulation:  7.338395595550537
average overall reward:  0.54645085  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  -0.09816742  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 32. Reward: 20.16, Length: 19
DEBUG (Env): Episode done for env 45. Reward: 14.06, Length: 30
DEBUG (Env): Episode done for env 64. Reward: 27.03, Length: 29
DEBUG (Env): Episode done for env 67. Reward: 16.76, Length: 5
DEBUG (Env): Episode done for env 89. Reward: 6.11, Length: 26
DEBUG (Env): Episode done for env 90. Reward: 23.68, Length: 1
DEBUG (Env): Episode done for env 110. Reward: 17.41, Length: 28
DEBUG (Env): Episode done for env 117. Reward: -22.31, Length: 36
2443
Time taken for simulation:  7.119811534881592
average overall reward:  0.23397619  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.030179165  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 6. Reward: 16.22, Length: 18
DEBUG (Env): Episode done for env 54. Reward: 26.62, Length: 9
DEBUG (Env): Episode done for env 61. Reward: 1.58, Length: 30
2444
Time taken for simulation:  7.275394678115845
average overall reward:  0.609689  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.19307318 average distance reward:  0.22063765  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 4. Reward: 14.48, Length: 14
DEBUG (Env): Episode done for env 12. Reward: 27.93, Length: 11
DEBUG (Env): Episode done for env 46. Reward: 10.07, Length: 13
DEBUG (Env): Episode done for env 53. Reward: 19.61, Length: 35
DEBUG (Env): Episode done for env 73. Reward: 14.68, Length: 11
DEBUG (Env): Episode done for env 87. Reward: -18.56, Length: 36
DEBUG (Env): Episode done for env 97. Reward: -20.48, Length: 36
2445
Time taken for simulation:  7.04017972946167
average overall reward:  0.3489047  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.368275  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 4. Reward: 12.28, Length: 1
DEBUG (Env): Episode done for env 22. Reward: 29.72, Length: 10
DEBUG (Env): Episode done for env 42. Reward: -25.46, Length: 36
2446
Time taken for simulation:  7.329746961593628
average overall reward:  0.4555532  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.19956818  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 11. Reward: 16.01, Length: 15
DEBUG (Env): Episode done for env 17. Reward: -20.87, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -18.93, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -23.97, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 17.12, Length: 13
DEBUG (Env): Episode done for env 95. Reward: 35.35, Length: 14
DEBUG (Env): Episode done for env 100. Reward: 12.84, Length: 24
2447
Time taken for simulation:  7.352585315704346
average overall reward:  0.5786206  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.18020163 average distance reward:  -0.0940464  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 37. Reward: 30.21, Length: 23
DEBUG (Env): Episode done for env 50. Reward: 20.73, Length: 17
DEBUG (Env): Episode done for env 59. Reward: -16.19, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 23.97, Length: 17
DEBUG (Env): Episode done for env 70. Reward: -19.86, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 41.05, Length: 8
DEBUG (Env): Episode done for env 94. Reward: 13.69, Length: 20
DEBUG (Env): Episode done for env 110. Reward: 26.37, Length: 5
DEBUG (Env): Episode done for env 126. Reward: 12.41, Length: 25
2448
Time taken for simulation:  7.630178928375244
average overall reward:  1.0783114  average fail penalty:  -0.0703125  and average goal bonus:  1.0829761  and average same cell penalty:  -0.2574309 average distance reward:  0.3709393  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 20. Reward: 18.80, Length: 2
DEBUG (Env): Episode done for env 34. Reward: 10.14, Length: 30
DEBUG (Env): Episode done for env 40. Reward: -19.91, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 40.12, Length: 19
DEBUG (Env): Episode done for env 57. Reward: 18.27, Length: 12
DEBUG (Env): Episode done for env 71. Reward: 27.69, Length: 13
DEBUG (Env): Episode done for env 74. Reward: 9.68, Length: 10
DEBUG (Env): Episode done for env 79. Reward: 20.62, Length: 19
DEBUG (Env): Episode done for env 97. Reward: 39.02, Length: 4
DEBUG (Env): Episode done for env 123. Reward: -20.79, Length: 36
DEBUG (Env): Episode done for env 125. Reward: -24.91, Length: 36
2449
Time taken for simulation:  7.348658323287964
average overall reward:  0.73975736  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.24107704  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 11. Reward: 25.43, Length: 3
DEBUG (Env): Episode done for env 33. Reward: 18.10, Length: 9
DEBUG (Env): Episode done for env 43. Reward: 23.53, Length: 16
DEBUG (Env): Episode done for env 62. Reward: -19.93, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 16.37, Length: 7
DEBUG (Env): Episode done for env 76. Reward: -27.13, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 18.87, Length: 3
DEBUG (Env): Episode done for env 116. Reward: 16.69, Length: 12
2450
Time taken for simulation:  7.117424011230469
average overall reward:  0.71754515  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020165 average distance reward:  0.15681276  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: -23.72, Length: 36
DEBUG (Env): Episode done for env 16. Reward: 24.04, Length: 12
DEBUG (Env): Episode done for env 52. Reward: 14.54, Length: 27
DEBUG (Env): Episode done for env 58. Reward: 9.95, Length: 31
DEBUG (Env): Episode done for env 89. Reward: 15.15, Length: 8
DEBUG (Env): Episode done for env 109. Reward: 18.10, Length: 19
DEBUG (Env): Episode done for env 126. Reward: 20.18, Length: 3
2451
Time taken for simulation:  7.186928987503052
average overall reward:  0.61280197  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.3719942  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 2. Reward: 30.27, Length: 11
DEBUG (Env): Episode done for env 7. Reward: 23.92, Length: 30
DEBUG (Env): Episode done for env 13. Reward: -20.97, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 28.63, Length: 14
DEBUG (Env): Episode done for env 36. Reward: 16.51, Length: 21
DEBUG (Env): Episode done for env 39. Reward: -28.35, Length: 36
2452
Time taken for simulation:  7.077931880950928
average overall reward:  0.7106818  average fail penalty:  -0.0234375  and average goal bonus:  0.67686015  and average same cell penalty:  -0.18020165 average distance reward:  0.2853213  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 77. Reward: 6.35, Length: 28
DEBUG (Env): Episode done for env 83. Reward: -27.55, Length: 36
DEBUG (Env): Episode done for env 96. Reward: 36.22, Length: 13
DEBUG (Env): Episode done for env 98. Reward: 23.79, Length: 12
DEBUG (Env): Episode done for env 99. Reward: 25.81, Length: 13
DEBUG (Env): Episode done for env 112. Reward: 32.17, Length: 13
2453
Time taken for simulation:  7.322794198989868
average overall reward:  0.34571898  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.22971722  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 0. Reward: 13.96, Length: 18
DEBUG (Env): Episode done for env 92. Reward: -19.97, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 29.10, Length: 20
DEBUG (Env): Episode done for env 107. Reward: 23.04, Length: 35
2454
Time taken for simulation:  7.574420213699341
average overall reward:  1.3750901  average fail penalty:  -0.046875  and average goal bonus:  1.3537203  and average same cell penalty:  -0.11584391 average distance reward:  0.23194927  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 7. Reward: 18.73, Length: 3
DEBUG (Env): Episode done for env 15. Reward: -17.29, Length: 36
DEBUG (Env): Episode done for env 18. Reward: -21.02, Length: 36
DEBUG (Env): Episode done for env 54. Reward: 25.03, Length: 11
DEBUG (Env): Episode done for env 61. Reward: 33.87, Length: 11
DEBUG (Env): Episode done for env 77. Reward: 20.56, Length: 2
DEBUG (Env): Episode done for env 85. Reward: 20.36, Length: 14
DEBUG (Env): Episode done for env 95. Reward: 9.87, Length: 8
DEBUG (Env): Episode done for env 109. Reward: 25.28, Length: 4
DEBUG (Env): Episode done for env 111. Reward: 7.77, Length: 34
DEBUG (Env): Episode done for env 123. Reward: 25.17, Length: 6
DEBUG (Env): Episode done for env 126. Reward: 19.13, Length: 4
2455
Time taken for simulation:  7.1215972900390625
average overall reward:  0.6377137  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.34541968  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 18. Reward: 22.87, Length: 1
DEBUG (Env): Episode done for env 30. Reward: -17.68, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 33.96, Length: 7
DEBUG (Env): Episode done for env 64. Reward: 26.60, Length: 13
DEBUG (Env): Episode done for env 69. Reward: 14.88, Length: 25
DEBUG (Env): Episode done for env 101. Reward: -20.35, Length: 36
2456
Time taken for simulation:  7.237580060958862
average overall reward:  0.6259957  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.31026423  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: 4.94, Length: 34
DEBUG (Env): Episode done for env 25. Reward: -22.80, Length: 36
DEBUG (Env): Episode done for env 39. Reward: 34.30, Length: 5
DEBUG (Env): Episode done for env 50. Reward: 24.56, Length: 9
DEBUG (Env): Episode done for env 58. Reward: 27.39, Length: 6
2457
Time taken for simulation:  7.0125672817230225
average overall reward:  0.5368866  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.16733009 average distance reward:  0.34596106  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 5. Reward: 10.60, Length: 24
DEBUG (Env): Episode done for env 95. Reward: 33.04, Length: 3
DEBUG (Env): Episode done for env 99. Reward: 39.54, Length: 5
2458
Time taken for simulation:  7.36163330078125
average overall reward:  0.7387749  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.13942783  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 18.21, Length: 24
DEBUG (Env): Episode done for env 22. Reward: 17.38, Length: 13
DEBUG (Env): Episode done for env 64. Reward: 28.72, Length: 3
DEBUG (Env): Episode done for env 112. Reward: 33.78, Length: 6
DEBUG (Env): Episode done for env 114. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 116. Reward: 20.97, Length: 9
DEBUG (Env): Episode done for env 126. Reward: 47.11, Length: 4
2459
Time taken for simulation:  7.2568442821502686
average overall reward:  0.2986579  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.08589876  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 22.77, Length: 9
DEBUG (Env): Episode done for env 69. Reward: 21.12, Length: 4
DEBUG (Env): Episode done for env 78. Reward: 5.51, Length: 30
DEBUG (Env): Episode done for env 80. Reward: 8.81, Length: 31
DEBUG (Env): Episode done for env 124. Reward: -18.80, Length: 36
2460
Time taken for simulation:  7.230749130249023
average overall reward:  0.2156167  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.23168781 average distance reward:  0.112486504  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 9. Reward: -14.77, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 16.62, Length: 27
DEBUG (Env): Episode done for env 67. Reward: 25.61, Length: 11
DEBUG (Env): Episode done for env 86. Reward: 25.72, Length: 23
2461
Time taken for simulation:  7.288514852523804
average overall reward:  1.0500307  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.12871546 average distance reward:  0.167068  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 12. Reward: 17.68, Length: 17
DEBUG (Env): Episode done for env 20. Reward: 24.85, Length: 13
DEBUG (Env): Episode done for env 21. Reward: 14.62, Length: 1
DEBUG (Env): Episode done for env 25. Reward: 28.36, Length: 5
DEBUG (Env): Episode done for env 32. Reward: 15.12, Length: 19
DEBUG (Env): Episode done for env 35. Reward: -21.96, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 17.36, Length: 7
DEBUG (Env): Episode done for env 102. Reward: 3.37, Length: 23
DEBUG (Env): Episode done for env 107. Reward: 39.57, Length: 8
2462
Time taken for simulation:  7.30735182762146
average overall reward:  0.7292371  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.12871546 average distance reward:  0.1638934  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 15. Reward: 21.20, Length: 8
DEBUG (Env): Episode done for env 23. Reward: -17.63, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -18.28, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 34.27, Length: 12
DEBUG (Env): Episode done for env 58. Reward: 22.14, Length: 6
DEBUG (Env): Episode done for env 99. Reward: 16.56, Length: 5
DEBUG (Env): Episode done for env 106. Reward: 39.48, Length: 26
DEBUG (Env): Episode done for env 115. Reward: -15.76, Length: 36
DEBUG (Env): Episode done for env 120. Reward: 12.63, Length: 21
2463
Time taken for simulation:  7.345387697219849
average overall reward:  1.0919719  average fail penalty:  -0.0703125  and average goal bonus:  1.0829762  and average same cell penalty:  -0.19307318 average distance reward:  0.320242  and average step penalty:  -0.04786053509430681
Number of done instances:  11
DEBUG (Env): Episode done for env 6. Reward: 17.41, Length: 20
DEBUG (Env): Episode done for env 8. Reward: -3.38, Length: 36
DEBUG (Env): Episode done for env 10. Reward: 14.38, Length: 5
DEBUG (Env): Episode done for env 26. Reward: 20.88, Length: 17
DEBUG (Env): Episode done for env 38. Reward: -16.29, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 34.68, Length: 15
DEBUG (Env): Episode done for env 51. Reward: 17.36, Length: 26
DEBUG (Env): Episode done for env 55. Reward: 16.46, Length: 22
DEBUG (Env): Episode done for env 69. Reward: 31.70, Length: 4
DEBUG (Env): Episode done for env 75. Reward: -12.97, Length: 36
DEBUG (Env): Episode done for env 101. Reward: 33.69, Length: 8
2464
Time taken for simulation:  7.047035455703735
average overall reward:  0.43119353  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.1673301 average distance reward:  0.1283336  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 46. Reward: 7.98, Length: 20
DEBUG (Env): Episode done for env 48. Reward: -24.98, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 19.34, Length: 17
DEBUG (Env): Episode done for env 67. Reward: 29.95, Length: 4
DEBUG (Env): Episode done for env 74. Reward: 15.64, Length: 16
2465
Time taken for simulation:  7.131685733795166
average overall reward:  -0.28577745  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.23168783 average distance reward:  0.017208435  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 3. Reward: -29.57, Length: 36
2466
Time taken for simulation:  7.4433372020721436
average overall reward:  0.6746261  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.19707769  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 5. Reward: 15.88, Length: 9
DEBUG (Env): Episode done for env 6. Reward: 28.13, Length: 3
DEBUG (Env): Episode done for env 15. Reward: 34.36, Length: 4
DEBUG (Env): Episode done for env 16. Reward: 19.16, Length: 16
DEBUG (Env): Episode done for env 28. Reward: -29.03, Length: 36
DEBUG (Env): Episode done for env 63. Reward: -24.65, Length: 36
DEBUG (Env): Episode done for env 82. Reward: -20.52, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 21.42, Length: 24
DEBUG (Env): Episode done for env 104. Reward: -15.87, Length: 36
DEBUG (Env): Episode done for env 123. Reward: 15.74, Length: 12
2467
Time taken for simulation:  7.081264495849609
average overall reward:  0.9595748  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168783 average distance reward:  0.31495646  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 8. Reward: 27.09, Length: 4
DEBUG (Env): Episode done for env 17. Reward: 38.52, Length: 21
DEBUG (Env): Episode done for env 30. Reward: 36.47, Length: 12
DEBUG (Env): Episode done for env 41. Reward: 23.45, Length: 4
DEBUG (Env): Episode done for env 66. Reward: -9.55, Length: 36
DEBUG (Env): Episode done for env 78. Reward: 23.85, Length: 8
DEBUG (Env): Episode done for env 101. Reward: 23.85, Length: 4
DEBUG (Env): Episode done for env 106. Reward: 22.68, Length: 5
2468
Time taken for simulation:  7.1870081424713135
average overall reward:  0.19522363  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.030041292  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 8. Reward: 20.16, Length: 1
DEBUG (Env): Episode done for env 101. Reward: 23.78, Length: 1
DEBUG (Env): Episode done for env 121. Reward: 6.45, Length: 35
2469
Time taken for simulation:  7.439198732376099
average overall reward:  0.7251176  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.1673301 average distance reward:  0.2868856  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 19.97, Length: 3
DEBUG (Env): Episode done for env 16. Reward: 33.48, Length: 3
DEBUG (Env): Episode done for env 19. Reward: 8.89, Length: 30
DEBUG (Env): Episode done for env 52. Reward: 32.35, Length: 7
DEBUG (Env): Episode done for env 68. Reward: -14.12, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 15.66, Length: 20
2470
Time taken for simulation:  7.3218793869018555
average overall reward:  0.14155959  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.21881628 average distance reward:  0.025557816  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 28. Reward: 24.60, Length: 4
DEBUG (Env): Episode done for env 77. Reward: 21.71, Length: 16
DEBUG (Env): Episode done for env 93. Reward: 10.31, Length: 33
DEBUG (Env): Episode done for env 119. Reward: -18.01, Length: 36
2471
Time taken for simulation:  7.041033983230591
average overall reward:  0.19573762  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.28317398 average distance reward:  0.30290306  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 29. Reward: -18.80, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 16.74, Length: 7
DEBUG (Env): Episode done for env 69. Reward: 25.73, Length: 8
DEBUG (Env): Episode done for env 105. Reward: -15.43, Length: 36
2472
Time taken for simulation:  7.155982255935669
average overall reward:  0.2365427  average fail penalty:  -0.1171875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.283174 average distance reward:  0.007904574  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 13. Reward: 10.37, Length: 21
DEBUG (Env): Episode done for env 23. Reward: 22.99, Length: 10
DEBUG (Env): Episode done for env 49. Reward: -20.15, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 15.19, Length: 31
DEBUG (Env): Episode done for env 58. Reward: 28.05, Length: 10
DEBUG (Env): Episode done for env 65. Reward: -8.99, Length: 36
DEBUG (Env): Episode done for env 81. Reward: -16.45, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -21.35, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 10.50, Length: 36
2473
Time taken for simulation:  7.3911120891571045
average overall reward:  0.7945295  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.316981  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 14. Reward: -15.49, Length: 36
DEBUG (Env): Episode done for env 56. Reward: 24.34, Length: 1
DEBUG (Env): Episode done for env 64. Reward: 38.87, Length: 15
DEBUG (Env): Episode done for env 71. Reward: 15.18, Length: 25
DEBUG (Env): Episode done for env 72. Reward: 23.87, Length: 26
DEBUG (Env): Episode done for env 88. Reward: -12.72, Length: 36
DEBUG (Env): Episode done for env 91. Reward: -10.60, Length: 36
DEBUG (Env): Episode done for env 97. Reward: 16.84, Length: 25
DEBUG (Env): Episode done for env 121. Reward: 28.59, Length: 5
DEBUG (Env): Episode done for env 127. Reward: -16.82, Length: 36
2474
Time taken for simulation:  7.5683300495147705
average overall reward:  0.48170933  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.1673301 average distance reward:  0.2907839  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 72. Reward: 29.78, Length: 1
DEBUG (Env): Episode done for env 78. Reward: 17.13, Length: 7
DEBUG (Env): Episode done for env 96. Reward: 19.38, Length: 22
2475
Time taken for simulation:  7.1130266189575195
average overall reward:  0.66695076  average fail penalty:  0.0  and average goal bonus:  0.8122322  and average same cell penalty:  -0.21881628 average distance reward:  0.12139544  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 15. Reward: 36.12, Length: 6
DEBUG (Env): Episode done for env 23. Reward: 21.01, Length: 3
DEBUG (Env): Episode done for env 30. Reward: 25.06, Length: 8
DEBUG (Env): Episode done for env 58. Reward: 23.29, Length: 3
DEBUG (Env): Episode done for env 84. Reward: 15.98, Length: 29
DEBUG (Env): Episode done for env 118. Reward: 20.17, Length: 3
2476
Time taken for simulation:  7.314940452575684
average overall reward:  0.36871707  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.2574309 average distance reward:  0.044023443  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 2. Reward: 19.76, Length: 25
DEBUG (Env): Episode done for env 43. Reward: 18.76, Length: 27
DEBUG (Env): Episode done for env 44. Reward: -24.11, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 26.41, Length: 34
DEBUG (Env): Episode done for env 47. Reward: -23.78, Length: 36
DEBUG (Env): Episode done for env 75. Reward: 13.40, Length: 13
DEBUG (Env): Episode done for env 107. Reward: 23.70, Length: 15
2477
Time taken for simulation:  7.345114231109619
average overall reward:  0.54790026  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.16733009 average distance reward:  0.13310574  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 60. Reward: 14.36, Length: 30
DEBUG (Env): Episode done for env 66. Reward: 10.27, Length: 10
DEBUG (Env): Episode done for env 75. Reward: 15.84, Length: 1
DEBUG (Env): Episode done for env 77. Reward: 23.33, Length: 7
DEBUG (Env): Episode done for env 97. Reward: 20.62, Length: 4
DEBUG (Env): Episode done for env 108. Reward: -13.62, Length: 36
DEBUG (Env): Episode done for env 113. Reward: -14.47, Length: 36
2478
Time taken for simulation:  7.340207576751709
average overall reward:  0.2772542  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.18020163 average distance reward:  0.25800982  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 14. Reward: 17.05, Length: 5
DEBUG (Env): Episode done for env 23. Reward: 38.95, Length: 3
DEBUG (Env): Episode done for env 117. Reward: -23.18, Length: 36
2479
Time taken for simulation:  7.288865804672241
average overall reward:  0.42764145  average fail penalty:  0.0  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594472 average distance reward:  0.13995862  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 45. Reward: 42.98, Length: 3
DEBUG (Env): Episode done for env 57. Reward: 1.08, Length: 31
DEBUG (Env): Episode done for env 58. Reward: 17.14, Length: 4
DEBUG (Env): Episode done for env 88. Reward: 18.76, Length: 6
2480
Time taken for simulation:  7.197937250137329
average overall reward:  -0.34808806  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.1207277  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 40. Reward: 11.80, Length: 25
DEBUG (Env): Episode done for env 53. Reward: -12.74, Length: 36
DEBUG (Env): Episode done for env 73. Reward: -23.53, Length: 36
DEBUG (Env): Episode done for env 87. Reward: -25.64, Length: 36
2481
Time taken for simulation:  7.550100564956665
average overall reward:  0.5343307  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  0.25490826  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 4. Reward: -24.59, Length: 36
DEBUG (Env): Episode done for env 37. Reward: 9.28, Length: 34
DEBUG (Env): Episode done for env 42. Reward: -12.65, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 24.42, Length: 9
DEBUG (Env): Episode done for env 63. Reward: 31.53, Length: 15
DEBUG (Env): Episode done for env 79. Reward: 15.79, Length: 33
2482
Time taken for simulation:  7.512176275253296
average overall reward:  0.7656461  average fail penalty:  0.0  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.05897565  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: 13.96, Length: 16
DEBUG (Env): Episode done for env 18. Reward: 11.46, Length: 27
DEBUG (Env): Episode done for env 27. Reward: 10.52, Length: 20
DEBUG (Env): Episode done for env 28. Reward: 30.24, Length: 12
DEBUG (Env): Episode done for env 34. Reward: 2.04, Length: 34
DEBUG (Env): Episode done for env 76. Reward: 22.38, Length: 13
DEBUG (Env): Episode done for env 123. Reward: 30.40, Length: 16
2483
Time taken for simulation:  7.5606677532196045
average overall reward:  0.9462787  average fail penalty:  -0.0703125  and average goal bonus:  0.81223214  and average same cell penalty:  -0.20594473 average distance reward:  0.45816422  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 20. Reward: 20.58, Length: 22
DEBUG (Env): Episode done for env 60. Reward: 24.31, Length: 6
DEBUG (Env): Episode done for env 61. Reward: 25.25, Length: 22
DEBUG (Env): Episode done for env 65. Reward: 22.65, Length: 11
DEBUG (Env): Episode done for env 70. Reward: -12.91, Length: 36
DEBUG (Env): Episode done for env 80. Reward: -0.11, Length: 24
DEBUG (Env): Episode done for env 94. Reward: 0.11, Length: 36
DEBUG (Env): Episode done for env 110. Reward: -13.29, Length: 36
DEBUG (Env): Episode done for env 122. Reward: 14.54, Length: 11
2484
Time taken for simulation:  7.110466480255127
average overall reward:  0.77263474  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.15445855 average distance reward:  0.45690325  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 7. Reward: 2.65, Length: 30
DEBUG (Env): Episode done for env 45. Reward: 24.46, Length: 5
DEBUG (Env): Episode done for env 71. Reward: 27.65, Length: 11
DEBUG (Env): Episode done for env 108. Reward: 36.06, Length: 7
DEBUG (Env): Episode done for env 125. Reward: -8.28, Length: 36
2485
Time taken for simulation:  7.3936004638671875
average overall reward:  0.6322789  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.16733009 average distance reward:  0.12898742  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 11. Reward: -21.36, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 24.39, Length: 24
DEBUG (Env): Episode done for env 23. Reward: 27.22, Length: 7
DEBUG (Env): Episode done for env 33. Reward: 18.41, Length: 36
DEBUG (Env): Episode done for env 62. Reward: -21.46, Length: 36
DEBUG (Env): Episode done for env 67. Reward: 23.46, Length: 14
DEBUG (Env): Episode done for env 97. Reward: 23.69, Length: 8
DEBUG (Env): Episode done for env 100. Reward: -19.93, Length: 36
DEBUG (Env): Episode done for env 114. Reward: -3.51, Length: 27
2486
Time taken for simulation:  7.277054309844971
average overall reward:  0.69972444  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.15445855 average distance reward:  0.113248914  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 12. Reward: 15.14, Length: 25
DEBUG (Env): Episode done for env 18. Reward: 19.21, Length: 4
DEBUG (Env): Episode done for env 89. Reward: -24.45, Length: 36
DEBUG (Env): Episode done for env 100. Reward: 17.58, Length: 1
DEBUG (Env): Episode done for env 105. Reward: 17.21, Length: 15
DEBUG (Env): Episode done for env 106. Reward: 14.68, Length: 19
DEBUG (Env): Episode done for env 116. Reward: 9.17, Length: 28
2487
Time taken for simulation:  7.165773391723633
average overall reward:  1.4675298  average fail penalty:  -0.046875  and average goal bonus:  1.0829761  and average same cell penalty:  -0.283174 average distance reward:  0.762463  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 14. Reward: -12.22, Length: 9
DEBUG (Env): Episode done for env 20. Reward: 50.49, Length: 4
DEBUG (Env): Episode done for env 31. Reward: -8.36, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -23.51, Length: 36
DEBUG (Env): Episode done for env 38. Reward: 21.47, Length: 24
DEBUG (Env): Episode done for env 45. Reward: 20.80, Length: 3
DEBUG (Env): Episode done for env 49. Reward: 28.65, Length: 6
DEBUG (Env): Episode done for env 57. Reward: 18.67, Length: 8
DEBUG (Env): Episode done for env 114. Reward: 20.32, Length: 2
DEBUG (Env): Episode done for env 118. Reward: 31.14, Length: 12
2488
Time taken for simulation:  7.147789478302002
average overall reward:  0.538797  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.24455938 average distance reward:  0.06585975  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 72. Reward: 11.27, Length: 14
DEBUG (Env): Episode done for env 77. Reward: 30.35, Length: 11
DEBUG (Env): Episode done for env 83. Reward: -30.38, Length: 36
DEBUG (Env): Episode done for env 98. Reward: -16.16, Length: 36
DEBUG (Env): Episode done for env 106. Reward: 23.96, Length: 2
DEBUG (Env): Episode done for env 112. Reward: 13.94, Length: 30
DEBUG (Env): Episode done for env 115. Reward: 32.11, Length: 26
DEBUG (Env): Episode done for env 125. Reward: 38.31, Length: 4
2489
Time taken for simulation:  7.441503524780273
average overall reward:  0.47442496  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455936 average distance reward:  0.29566926  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: -11.03, Length: 36
DEBUG (Env): Episode done for env 21. Reward: 38.63, Length: 4
DEBUG (Env): Episode done for env 24. Reward: 10.89, Length: 33
DEBUG (Env): Episode done for env 58. Reward: 29.19, Length: 10
DEBUG (Env): Episode done for env 88. Reward: 24.08, Length: 10
DEBUG (Env): Episode done for env 92. Reward: -2.85, Length: 36
DEBUG (Env): Episode done for env 103. Reward: -14.09, Length: 36
2490
Time taken for simulation:  7.336133718490601
average overall reward:  1.5061576  average fail penalty:  -0.09375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.19307318 average distance reward:  0.62249315  and average step penalty:  -0.04786053509430681
Number of done instances:  13
DEBUG (Env): Episode done for env 2. Reward: 17.98, Length: 14
DEBUG (Env): Episode done for env 16. Reward: 11.88, Length: 21
DEBUG (Env): Episode done for env 24. Reward: 22.52, Length: 1
DEBUG (Env): Episode done for env 38. Reward: 28.47, Length: 3
DEBUG (Env): Episode done for env 43. Reward: 31.45, Length: 14
DEBUG (Env): Episode done for env 54. Reward: -18.46, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 18.85, Length: 7
DEBUG (Env): Episode done for env 85. Reward: -22.54, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 20.72, Length: 1
DEBUG (Env): Episode done for env 95. Reward: 40.33, Length: 33
DEBUG (Env): Episode done for env 109. Reward: -14.22, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -15.05, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 2.77, Length: 31
2491
Time taken for simulation:  7.715661287307739
average overall reward:  0.7561476  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.18020165 average distance reward:  0.30734968  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 24. Reward: 30.89, Length: 1
DEBUG (Env): Episode done for env 90. Reward: 18.40, Length: 25
DEBUG (Env): Episode done for env 105. Reward: 20.62, Length: 5
DEBUG (Env): Episode done for env 114. Reward: 35.81, Length: 4
DEBUG (Env): Episode done for env 115. Reward: 25.05, Length: 3
2492
Time taken for simulation:  7.2859437465667725
average overall reward:  -0.21659797  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.24455938 average distance reward:  -0.012675069  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 39. Reward: -29.67, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 4.00, Length: 5
DEBUG (Env): Episode done for env 50. Reward: -9.81, Length: 36
2493
Time taken for simulation:  7.241299867630005
average overall reward:  0.915619  average fail penalty:  0.0  and average goal bonus:  0.6768601  and average same cell penalty:  -0.21881628 average distance reward:  0.50543576  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 11. Reward: 24.00, Length: 8
DEBUG (Env): Episode done for env 56. Reward: 30.29, Length: 20
DEBUG (Env): Episode done for env 72. Reward: 23.65, Length: 5
DEBUG (Env): Episode done for env 80. Reward: 39.40, Length: 10
DEBUG (Env): Episode done for env 122. Reward: 13.47, Length: 10
2494
Time taken for simulation:  7.286658048629761
average overall reward:  0.38682926  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.20594473 average distance reward:  0.14602144  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 7. Reward: 47.62, Length: 10
DEBUG (Env): Episode done for env 22. Reward: -12.54, Length: 36
DEBUG (Env): Episode done for env 41. Reward: 6.33, Length: 27
DEBUG (Env): Episode done for env 58. Reward: 22.04, Length: 5
DEBUG (Env): Episode done for env 88. Reward: 34.58, Length: 5
DEBUG (Env): Episode done for env 126. Reward: -14.75, Length: 36
2495
Time taken for simulation:  7.344943046569824
average overall reward:  0.3728512  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.24455936 average distance reward:  0.01184845  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: -11.74, Length: 36
DEBUG (Env): Episode done for env 4. Reward: 29.24, Length: 14
DEBUG (Env): Episode done for env 39. Reward: 25.34, Length: 3
DEBUG (Env): Episode done for env 61. Reward: 21.55, Length: 5
DEBUG (Env): Episode done for env 97. Reward: 18.57, Length: 10
DEBUG (Env): Episode done for env 112. Reward: 24.68, Length: 7
2496
Time taken for simulation:  7.311680316925049
average overall reward:  0.25902408  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.0053447075  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 9. Reward: -15.39, Length: 36
DEBUG (Env): Episode done for env 28. Reward: 25.85, Length: 14
DEBUG (Env): Episode done for env 31. Reward: 24.98, Length: 9
DEBUG (Env): Episode done for env 67. Reward: 22.75, Length: 11
DEBUG (Env): Episode done for env 86. Reward: -18.60, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 23.33, Length: 6
2497
Time taken for simulation:  7.535313844680786
average overall reward:  0.260046  average fail penalty:  -0.09375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.16733009 average distance reward:  0.29824257  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 25. Reward: -14.27, Length: 36
DEBUG (Env): Episode done for env 32. Reward: -16.50, Length: 36
DEBUG (Env): Episode done for env 35. Reward: -11.05, Length: 36
DEBUG (Env): Episode done for env 59. Reward: 3.17, Length: 33
DEBUG (Env): Episode done for env 102. Reward: -18.13, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 45.88, Length: 8
2498
Time taken for simulation:  7.243002891540527
average overall reward:  0.2140083  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  -0.052542597  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 45. Reward: 31.17, Length: 6
DEBUG (Env): Episode done for env 63. Reward: 21.94, Length: 17
DEBUG (Env): Episode done for env 69. Reward: 9.40, Length: 27
DEBUG (Env): Episode done for env 99. Reward: -16.24, Length: 36
DEBUG (Env): Episode done for env 113. Reward: 16.96, Length: 21
DEBUG (Env): Episode done for env 120. Reward: -21.12, Length: 36
2499
Time taken for simulation:  7.198808908462524
average overall reward:  0.40883076  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.3373984  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: -12.18, Length: 36
DEBUG (Env): Episode done for env 26. Reward: -19.13, Length: 36
DEBUG (Env): Episode done for env 51. Reward: -16.03, Length: 36
DEBUG (Env): Episode done for env 55. Reward: -12.40, Length: 36
DEBUG (Env): Episode done for env 89. Reward: 28.81, Length: 13
DEBUG (Env): Episode done for env 114. Reward: 27.51, Length: 8
DEBUG (Env): Episode done for env 118. Reward: 27.56, Length: 12
2500
Time taken for simulation:  6.965922594070435
average overall reward:  0.51501954  average fail penalty:  -0.0703125  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.38153508  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 1. Reward: 22.64, Length: 5
DEBUG (Env): Episode done for env 46. Reward: -20.59, Length: 36
DEBUG (Env): Episode done for env 48. Reward: -34.56, Length: 36
DEBUG (Env): Episode done for env 74. Reward: -12.37, Length: 36
DEBUG (Env): Episode done for env 86. Reward: 20.61, Length: 4
DEBUG (Env): Episode done for env 125. Reward: 25.78, Length: 12
2501
Time taken for simulation:  7.155032157897949
average overall reward:  0.4247644  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168783 average distance reward:  0.18626216  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 3. Reward: -15.21, Length: 36
DEBUG (Env): Episode done for env 52. Reward: 6.75, Length: 32
DEBUG (Env): Episode done for env 61. Reward: 24.28, Length: 6
DEBUG (Env): Episode done for env 100. Reward: 25.12, Length: 15
DEBUG (Env): Episode done for env 126. Reward: 15.42, Length: 7
2502
Time taken for simulation:  7.41636848449707
average overall reward:  0.011061847  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.2574309 average distance reward:  0.25129378  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 5. Reward: -18.02, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 27.84, Length: 19
DEBUG (Env): Episode done for env 82. Reward: -22.45, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -12.68, Length: 36
2503
Time taken for simulation:  7.095752477645874
average overall reward:  0.04831838  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.11584391 average distance reward:  -0.035283685  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 17. Reward: -33.43, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 18.63, Length: 20
DEBUG (Env): Episode done for env 67. Reward: 25.86, Length: 7
2504
Time taken for simulation:  7.272448539733887
average overall reward:  0.34984148  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.096162096  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: -16.32, Length: 36
DEBUG (Env): Episode done for env 24. Reward: 23.52, Length: 13
DEBUG (Env): Episode done for env 53. Reward: 9.82, Length: 24
DEBUG (Env): Episode done for env 73. Reward: 16.58, Length: 24
DEBUG (Env): Episode done for env 99. Reward: 29.99, Length: 6
DEBUG (Env): Episode done for env 101. Reward: -18.84, Length: 36
2505
Time taken for simulation:  7.380054235458374
average overall reward:  0.77239996  average fail penalty:  -0.046875  and average goal bonus:  0.9476042  and average same cell penalty:  -0.23168781 average distance reward:  0.15121917  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 7. Reward: 14.49, Length: 11
DEBUG (Env): Episode done for env 12. Reward: 39.61, Length: 19
DEBUG (Env): Episode done for env 19. Reward: -0.40, Length: 36
DEBUG (Env): Episode done for env 62. Reward: 47.55, Length: 20
DEBUG (Env): Episode done for env 63. Reward: 27.48, Length: 7
DEBUG (Env): Episode done for env 68. Reward: -22.77, Length: 36
DEBUG (Env): Episode done for env 94. Reward: 14.01, Length: 22
DEBUG (Env): Episode done for env 98. Reward: 11.94, Length: 17
2506
Time taken for simulation:  7.310229063034058
average overall reward:  0.5941508  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.20594473 average distance reward:  0.21797092  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 32. Reward: 15.28, Length: 9
DEBUG (Env): Episode done for env 90. Reward: 13.59, Length: 15
DEBUG (Env): Episode done for env 93. Reward: -11.20, Length: 36
DEBUG (Env): Episode done for env 103. Reward: 23.47, Length: 9
DEBUG (Env): Episode done for env 106. Reward: 31.92, Length: 18
DEBUG (Env): Episode done for env 113. Reward: 35.82, Length: 8
DEBUG (Env): Episode done for env 119. Reward: -19.78, Length: 36
2507
Time taken for simulation:  7.4123406410217285
average overall reward:  -0.06229441  average fail penalty:  -0.0234375  and average goal bonus:  0.13537203  and average same cell penalty:  -0.29604554 average distance reward:  0.16967715  and average step penalty:  -0.04786053509430681
Number of done instances:  2
DEBUG (Env): Episode done for env 29. Reward: -17.87, Length: 36
DEBUG (Env): Episode done for env 69. Reward: 28.36, Length: 9
2508
Time taken for simulation:  7.167984962463379
average overall reward:  0.7895073  average fail penalty:  -0.046875  and average goal bonus:  0.6768601  and average same cell penalty:  -0.15445855 average distance reward:  0.36184132  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 5. Reward: 18.19, Length: 6
DEBUG (Env): Episode done for env 13. Reward: -30.05, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 0.31, Length: 12
DEBUG (Env): Episode done for env 53. Reward: 32.35, Length: 4
DEBUG (Env): Episode done for env 67. Reward: 23.57, Length: 5
DEBUG (Env): Episode done for env 74. Reward: 29.52, Length: 8
DEBUG (Env): Episode done for env 81. Reward: -25.51, Length: 36
2509
Time taken for simulation:  7.2583417892456055
average overall reward:  0.39309692  average fail penalty:  -0.09375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.2574309 average distance reward:  -0.020093814  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 1. Reward: 20.07, Length: 9
DEBUG (Env): Episode done for env 28. Reward: 17.59, Length: 13
DEBUG (Env): Episode done for env 32. Reward: 17.08, Length: 3
DEBUG (Env): Episode done for env 41. Reward: 39.41, Length: 15
DEBUG (Env): Episode done for env 63. Reward: 11.15, Length: 4
DEBUG (Env): Episode done for env 64. Reward: -14.61, Length: 36
DEBUG (Env): Episode done for env 91. Reward: 13.34, Length: 36
DEBUG (Env): Episode done for env 121. Reward: -17.58, Length: 36
DEBUG (Env): Episode done for env 126. Reward: 12.37, Length: 8
DEBUG (Env): Episode done for env 127. Reward: -17.72, Length: 36
2510
Time taken for simulation:  7.458105802536011
average overall reward:  0.48851317  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.18020165 average distance reward:  0.22196221  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 18.81, Length: 9
DEBUG (Env): Episode done for env 4. Reward: 24.12, Length: 15
DEBUG (Env): Episode done for env 46. Reward: 39.83, Length: 10
DEBUG (Env): Episode done for env 73. Reward: 17.06, Length: 6
DEBUG (Env): Episode done for env 78. Reward: -26.77, Length: 36
DEBUG (Env): Episode done for env 96. Reward: -17.14, Length: 36
2511
Time taken for simulation:  7.533547639846802
average overall reward:  0.10764597  average fail penalty:  -0.0703125  and average goal bonus:  0.5414881  and average same cell penalty:  -0.16733009 average distance reward:  -0.14833897  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 1. Reward: 22.98, Length: 2
DEBUG (Env): Episode done for env 15. Reward: -14.31, Length: 36
DEBUG (Env): Episode done for env 30. Reward: -17.47, Length: 36
DEBUG (Env): Episode done for env 43. Reward: 9.11, Length: 21
DEBUG (Env): Episode done for env 84. Reward: -20.83, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 34.06, Length: 5
DEBUG (Env): Episode done for env 123. Reward: 13.92, Length: 29
2512
Time taken for simulation:  7.031285047531128
average overall reward:  0.30043077  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.23168781 average distance reward:  0.3795476  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 44. Reward: -36.83, Length: 36
DEBUG (Env): Episode done for env 47. Reward: -22.20, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 22.22, Length: 13
DEBUG (Env): Episode done for env 100. Reward: 22.58, Length: 11
DEBUG (Env): Episode done for env 107. Reward: -20.93, Length: 36
2513
Time taken for simulation:  7.893077611923218
average overall reward:  0.034548044  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.090100825 average distance reward:  -0.051359616  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 32. Reward: 38.76, Length: 4
DEBUG (Env): Episode done for env 45. Reward: 18.04, Length: 15
DEBUG (Env): Episode done for env 66. Reward: -13.01, Length: 36
DEBUG (Env): Episode done for env 75. Reward: -13.74, Length: 36
2514
Time taken for simulation:  7.261017799377441
average overall reward:  0.84080726  average fail penalty:  -0.0234375  and average goal bonus:  1.2183483  and average same cell penalty:  -0.15445855 average distance reward:  -0.15178442  and average step penalty:  -0.04786053509430681
Number of done instances:  10
DEBUG (Env): Episode done for env 11. Reward: 19.84, Length: 21
DEBUG (Env): Episode done for env 15. Reward: 26.51, Length: 3
DEBUG (Env): Episode done for env 73. Reward: 14.83, Length: 4
DEBUG (Env): Episode done for env 79. Reward: 23.37, Length: 33
DEBUG (Env): Episode done for env 85. Reward: 11.50, Length: 24
DEBUG (Env): Episode done for env 102. Reward: 36.77, Length: 17
DEBUG (Env): Episode done for env 105. Reward: 17.12, Length: 23
DEBUG (Env): Episode done for env 114. Reward: 24.93, Length: 15
DEBUG (Env): Episode done for env 117. Reward: -20.70, Length: 36
DEBUG (Env): Episode done for env 118. Reward: 9.94, Length: 15
2515
Time taken for simulation:  7.064300775527954
average overall reward:  0.42631757  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.11584391 average distance reward:  0.18390591  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 61. Reward: 27.90, Length: 14
DEBUG (Env): Episode done for env 104. Reward: 16.08, Length: 13
DEBUG (Env): Episode done for env 114. Reward: 14.74, Length: 1
2516
Time taken for simulation:  7.099187850952148
average overall reward:  1.2578807  average fail penalty:  -0.046875  and average goal bonus:  1.3537202  and average same cell penalty:  -0.23168781 average distance reward:  0.2305837  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 29. Reward: 16.97, Length: 9
DEBUG (Env): Episode done for env 30. Reward: 26.75, Length: 5
DEBUG (Env): Episode done for env 40. Reward: -16.12, Length: 36
DEBUG (Env): Episode done for env 72. Reward: 11.07, Length: 23
DEBUG (Env): Episode done for env 87. Reward: -17.43, Length: 36
DEBUG (Env): Episode done for env 88. Reward: 12.13, Length: 22
DEBUG (Env): Episode done for env 90. Reward: 18.31, Length: 5
DEBUG (Env): Episode done for env 101. Reward: 34.45, Length: 12
DEBUG (Env): Episode done for env 104. Reward: 25.06, Length: 1
DEBUG (Env): Episode done for env 113. Reward: 24.80, Length: 10
DEBUG (Env): Episode done for env 118. Reward: 25.98, Length: 2
DEBUG (Env): Episode done for env 123. Reward: 31.41, Length: 5
2517
Time taken for simulation:  7.077187776565552
average overall reward:  0.37365985  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.24455936 average distance reward:  0.30683863  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: 22.65, Length: 6
DEBUG (Env): Episode done for env 37. Reward: -16.15, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -10.41, Length: 36
DEBUG (Env): Episode done for env 55. Reward: 20.52, Length: 18
DEBUG (Env): Episode done for env 98. Reward: 29.36, Length: 12
2518
Time taken for simulation:  7.197811603546143
average overall reward:  0.30777955  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.24455938 average distance reward:  0.15246138  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 6. Reward: -24.76, Length: 36
DEBUG (Env): Episode done for env 27. Reward: -12.79, Length: 36
DEBUG (Env): Episode done for env 31. Reward: 14.96, Length: 10
DEBUG (Env): Episode done for env 34. Reward: -15.10, Length: 36
DEBUG (Env): Episode done for env 76. Reward: -10.03, Length: 36
DEBUG (Env): Episode done for env 81. Reward: 23.01, Length: 10
DEBUG (Env): Episode done for env 91. Reward: 23.57, Length: 9
DEBUG (Env): Episode done for env 95. Reward: 14.18, Length: 28
2519
Time taken for simulation:  7.189453601837158
average overall reward:  0.09070741  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.27030244 average distance reward:  -0.085742705  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 44. Reward: 22.15, Length: 7
DEBUG (Env): Episode done for env 51. Reward: 30.31, Length: 7
DEBUG (Env): Episode done for env 70. Reward: -17.83, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 11.85, Length: 8
DEBUG (Env): Episode done for env 96. Reward: 40.07, Length: 9
DEBUG (Env): Episode done for env 110. Reward: -10.65, Length: 36
2520
Time taken for simulation:  7.335550546646118
average overall reward:  0.14816219  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.19307318 average distance reward:  0.30059892  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 71. Reward: -26.46, Length: 36
DEBUG (Env): Episode done for env 108. Reward: -10.97, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 17.30, Length: 24
2521
Time taken for simulation:  7.212229490280151
average overall reward:  0.6676271  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.16894674  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 10. Reward: 22.40, Length: 22
DEBUG (Env): Episode done for env 23. Reward: 13.41, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -21.86, Length: 36
DEBUG (Env): Episode done for env 40. Reward: 25.41, Length: 5
DEBUG (Env): Episode done for env 71. Reward: 20.02, Length: 1
DEBUG (Env): Episode done for env 86. Reward: 19.86, Length: 21
DEBUG (Env): Episode done for env 110. Reward: 19.63, Length: 2
2522
Time taken for simulation:  7.115398645401001
average overall reward:  0.62685597  average fail penalty:  -0.046875  and average goal bonus:  0.8122322  and average same cell penalty:  -0.29604554 average distance reward:  0.20540495  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 18. Reward: -17.46, Length: 36
DEBUG (Env): Episode done for env 53. Reward: 17.21, Length: 14
DEBUG (Env): Episode done for env 73. Reward: 28.01, Length: 8
DEBUG (Env): Episode done for env 81. Reward: 20.16, Length: 4
DEBUG (Env): Episode done for env 98. Reward: 28.05, Length: 5
DEBUG (Env): Episode done for env 105. Reward: 21.67, Length: 8
DEBUG (Env): Episode done for env 113. Reward: 18.94, Length: 6
DEBUG (Env): Episode done for env 116. Reward: -23.20, Length: 36
2523
Time taken for simulation:  7.142101049423218
average overall reward:  0.33441  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.15104312  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 4. Reward: 27.08, Length: 13
DEBUG (Env): Episode done for env 14. Reward: 1.86, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -20.01, Length: 36
DEBUG (Env): Episode done for env 36. Reward: -16.84, Length: 36
DEBUG (Env): Episode done for env 49. Reward: -19.67, Length: 36
DEBUG (Env): Episode done for env 57. Reward: -24.60, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 22.24, Length: 10
DEBUG (Env): Episode done for env 83. Reward: 10.18, Length: 35
2524
Time taken for simulation:  7.292658805847168
average overall reward:  1.3750404  average fail penalty:  -0.0234375  and average goal bonus:  1.0829761  and average same cell penalty:  -0.141587 average distance reward:  0.5049493  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 2. Reward: 6.54, Length: 34
DEBUG (Env): Episode done for env 23. Reward: 18.73, Length: 3
DEBUG (Env): Episode done for env 29. Reward: 21.76, Length: 8
DEBUG (Env): Episode done for env 61. Reward: 12.35, Length: 9
DEBUG (Env): Episode done for env 77. Reward: -13.69, Length: 36
DEBUG (Env): Episode done for env 90. Reward: 27.98, Length: 8
DEBUG (Env): Episode done for env 100. Reward: 39.06, Length: 12
DEBUG (Env): Episode done for env 103. Reward: 8.44, Length: 18
DEBUG (Env): Episode done for env 121. Reward: 20.03, Length: 15
2525
Time taken for simulation:  7.37592625617981
average overall reward:  1.4805713  average fail penalty:  -0.046875  and average goal bonus:  1.3537203  and average same cell penalty:  -0.20594473 average distance reward:  0.42753118  and average step penalty:  -0.04786053509430681
Number of done instances:  12
DEBUG (Env): Episode done for env 0. Reward: -9.50, Length: 36
DEBUG (Env): Episode done for env 18. Reward: 20.61, Length: 3
DEBUG (Env): Episode done for env 21. Reward: -19.18, Length: 36
DEBUG (Env): Episode done for env 46. Reward: 24.74, Length: 15
DEBUG (Env): Episode done for env 53. Reward: 26.57, Length: 3
DEBUG (Env): Episode done for env 55. Reward: 36.00, Length: 8
DEBUG (Env): Episode done for env 76. Reward: 31.29, Length: 7
DEBUG (Env): Episode done for env 78. Reward: 23.56, Length: 15
DEBUG (Env): Episode done for env 93. Reward: 20.92, Length: 19
DEBUG (Env): Episode done for env 95. Reward: 29.58, Length: 7
DEBUG (Env): Episode done for env 117. Reward: 23.28, Length: 11
DEBUG (Env): Episode done for env 122. Reward: 1.26, Length: 32
2526
Time taken for simulation:  7.348478555679321
average overall reward:  1.5163  average fail penalty:  -0.140625  and average goal bonus:  1.3537203  and average same cell penalty:  -0.18020163 average distance reward:  0.53126687  and average step penalty:  -0.04786053509430681
Number of done instances:  16
DEBUG (Env): Episode done for env 11. Reward: 22.77, Length: 12
DEBUG (Env): Episode done for env 16. Reward: -19.53, Length: 36
DEBUG (Env): Episode done for env 25. Reward: 19.25, Length: 29
DEBUG (Env): Episode done for env 28. Reward: 16.49, Length: 17
DEBUG (Env): Episode done for env 36. Reward: 33.04, Length: 3
DEBUG (Env): Episode done for env 38. Reward: -18.69, Length: 36
DEBUG (Env): Episode done for env 47. Reward: 40.83, Length: 14
DEBUG (Env): Episode done for env 51. Reward: 24.75, Length: 7
DEBUG (Env): Episode done for env 54. Reward: -19.53, Length: 36
DEBUG (Env): Episode done for env 61. Reward: 19.77, Length: 2
DEBUG (Env): Episode done for env 77. Reward: 22.47, Length: 2
DEBUG (Env): Episode done for env 82. Reward: 11.41, Length: 24
DEBUG (Env): Episode done for env 92. Reward: -18.55, Length: 36
DEBUG (Env): Episode done for env 98. Reward: 32.42, Length: 4
DEBUG (Env): Episode done for env 109. Reward: -14.70, Length: 36
DEBUG (Env): Episode done for env 111. Reward: -18.97, Length: 36
2527
Time taken for simulation:  7.284904956817627
average overall reward:  1.0425582  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.19307318 average distance reward:  0.49469733  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 63. Reward: 26.00, Length: 18
DEBUG (Env): Episode done for env 87. Reward: 48.37, Length: 11
DEBUG (Env): Episode done for env 98. Reward: 19.08, Length: 1
DEBUG (Env): Episode done for env 115. Reward: -20.38, Length: 36
DEBUG (Env): Episode done for env 117. Reward: 45.60, Length: 2
DEBUG (Env): Episode done for env 121. Reward: 22.24, Length: 3
DEBUG (Env): Episode done for env 124. Reward: 26.45, Length: 7
2528
Time taken for simulation:  7.363324403762817
average overall reward:  0.909794  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.19307318 average distance reward:  0.22656105  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 21. Reward: 21.31, Length: 3
DEBUG (Env): Episode done for env 45. Reward: 31.93, Length: 15
DEBUG (Env): Episode done for env 50. Reward: -18.96, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 23.78, Length: 2
DEBUG (Env): Episode done for env 66. Reward: 17.28, Length: 5
DEBUG (Env): Episode done for env 78. Reward: 24.00, Length: 3
DEBUG (Env): Episode done for env 93. Reward: 23.38, Length: 3
DEBUG (Env): Episode done for env 113. Reward: 21.95, Length: 6
2529
Time taken for simulation:  7.20632004737854
average overall reward:  0.65322536  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.24455938 average distance reward:  0.31566015  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 25. Reward: 23.00, Length: 3
DEBUG (Env): Episode done for env 40. Reward: 30.04, Length: 8
DEBUG (Env): Episode done for env 56. Reward: -25.94, Length: 36
DEBUG (Env): Episode done for env 76. Reward: 25.96, Length: 4
DEBUG (Env): Episode done for env 80. Reward: -22.63, Length: 36
DEBUG (Env): Episode done for env 105. Reward: 26.63, Length: 7
DEBUG (Env): Episode done for env 107. Reward: 35.49, Length: 17
2530
Time taken for simulation:  7.27376389503479
average overall reward:  0.78095937  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.18020163 average distance reward:  0.24366444  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 22. Reward: -21.54, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 10.51, Length: 31
DEBUG (Env): Episode done for env 55. Reward: 24.02, Length: 5
DEBUG (Env): Episode done for env 58. Reward: -26.00, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 16.50, Length: 27
DEBUG (Env): Episode done for env 100. Reward: 25.43, Length: 6
DEBUG (Env): Episode done for env 109. Reward: 20.52, Length: 4
DEBUG (Env): Episode done for env 116. Reward: 29.71, Length: 8
2531
Time taken for simulation:  7.348084926605225
average overall reward:  -0.17988984  average fail penalty:  -0.0703125  and average goal bonus:  0.13537203  and average same cell penalty:  -0.21881628 average distance reward:  0.021727476  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 39. Reward: -13.02, Length: 36
DEBUG (Env): Episode done for env 65. Reward: 14.40, Length: 1
DEBUG (Env): Episode done for env 97. Reward: -21.95, Length: 36
DEBUG (Env): Episode done for env 112. Reward: -16.18, Length: 36
2532
Time taken for simulation:  7.568464994430542
average overall reward:  0.5324347  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.19307318 average distance reward:  0.2553178  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 9. Reward: -22.88, Length: 36
DEBUG (Env): Episode done for env 13. Reward: 14.70, Length: 24
DEBUG (Env): Episode done for env 86. Reward: 21.66, Length: 11
DEBUG (Env): Episode done for env 110. Reward: 35.42, Length: 11
DEBUG (Env): Episode done for env 123. Reward: 19.82, Length: 16
2533
Time taken for simulation:  7.159090518951416
average overall reward:  1.0386608  average fail penalty:  -0.046875  and average goal bonus:  0.81223214  and average same cell penalty:  -0.21881628 average distance reward:  0.5399805  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 34. Reward: 13.59, Length: 15
DEBUG (Env): Episode done for env 35. Reward: -13.18, Length: 36
DEBUG (Env): Episode done for env 44. Reward: 41.89, Length: 14
DEBUG (Env): Episode done for env 46. Reward: 38.92, Length: 8
DEBUG (Env): Episode done for env 59. Reward: -27.62, Length: 36
DEBUG (Env): Episode done for env 70. Reward: 23.39, Length: 14
DEBUG (Env): Episode done for env 103. Reward: 25.08, Length: 9
DEBUG (Env): Episode done for env 124. Reward: 33.39, Length: 6
2534
Time taken for simulation:  7.263725757598877
average overall reward:  0.6289901  average fail penalty:  -0.0234375  and average goal bonus:  0.81223214  and average same cell penalty:  -0.141587 average distance reward:  0.029642902  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 17.59, Length: 9
DEBUG (Env): Episode done for env 84. Reward: 14.29, Length: 15
DEBUG (Env): Episode done for env 90. Reward: 29.56, Length: 10
DEBUG (Env): Episode done for env 91. Reward: 19.70, Length: 16
DEBUG (Env): Episode done for env 113. Reward: 22.75, Length: 6
DEBUG (Env): Episode done for env 120. Reward: -12.22, Length: 36
DEBUG (Env): Episode done for env 124. Reward: 19.53, Length: 1
2535
Time taken for simulation:  7.314819097518921
average overall reward:  0.35739836  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.20594475 average distance reward:  0.36389706  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 82. Reward: 23.81, Length: 9
DEBUG (Env): Episode done for env 89. Reward: -22.72, Length: 36
DEBUG (Env): Episode done for env 114. Reward: 13.87, Length: 20
2536
Time taken for simulation:  7.308246374130249
average overall reward:  0.43258294  average fail penalty:  -0.046875  and average goal bonus:  0.27074406  and average same cell penalty:  -0.21881628 average distance reward:  0.4753907  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 48. Reward: -20.49, Length: 36
DEBUG (Env): Episode done for env 84. Reward: 25.67, Length: 2
DEBUG (Env): Episode done for env 113. Reward: 27.69, Length: 2
DEBUG (Env): Episode done for env 125. Reward: -21.46, Length: 36
2537
Time taken for simulation:  7.300712585449219
average overall reward:  1.1449652  average fail penalty:  -0.0234375  and average goal bonus:  1.0829762  and average same cell penalty:  -0.102972366 average distance reward:  0.23625939  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 3. Reward: 22.57, Length: 27
DEBUG (Env): Episode done for env 52. Reward: -29.05, Length: 36
DEBUG (Env): Episode done for env 66. Reward: 38.21, Length: 9
DEBUG (Env): Episode done for env 67. Reward: 5.25, Length: 29
DEBUG (Env): Episode done for env 69. Reward: 12.87, Length: 30
DEBUG (Env): Episode done for env 75. Reward: 32.57, Length: 24
DEBUG (Env): Episode done for env 93. Reward: 20.37, Length: 9
DEBUG (Env): Episode done for env 99. Reward: 21.16, Length: 33
DEBUG (Env): Episode done for env 103. Reward: 25.92, Length: 4
2538
Time taken for simulation:  7.253704309463501
average overall reward:  0.7917874  average fail penalty:  -0.0234375  and average goal bonus:  0.6768601  and average same cell penalty:  -0.20594473 average distance reward:  0.39217  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 35. Reward: 19.21, Length: 5
DEBUG (Env): Episode done for env 58. Reward: 36.70, Length: 8
DEBUG (Env): Episode done for env 60. Reward: -14.15, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 34.59, Length: 12
DEBUG (Env): Episode done for env 105. Reward: 18.15, Length: 9
DEBUG (Env): Episode done for env 117. Reward: 45.69, Length: 11
2539
Time taken for simulation:  7.194250822067261
average overall reward:  0.33193362  average fail penalty:  -0.0234375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.09343141  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: -26.47, Length: 36
DEBUG (Env): Episode done for env 49. Reward: 19.35, Length: 16
DEBUG (Env): Episode done for env 53. Reward: 24.01, Length: 14
DEBUG (Env): Episode done for env 65. Reward: 24.50, Length: 8
DEBUG (Env): Episode done for env 73. Reward: 11.97, Length: 17
2540
Time taken for simulation:  7.083491325378418
average overall reward:  0.3164093  average fail penalty:  -0.046875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.141587 average distance reward:  0.011243798  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 8. Reward: -23.55, Length: 36
DEBUG (Env): Episode done for env 24. Reward: -22.54, Length: 36
DEBUG (Env): Episode done for env 27. Reward: 28.90, Length: 22
DEBUG (Env): Episode done for env 52. Reward: 21.44, Length: 3
DEBUG (Env): Episode done for env 84. Reward: 32.48, Length: 4
DEBUG (Env): Episode done for env 90. Reward: 32.12, Length: 6
2541
Time taken for simulation:  7.172648668289185
average overall reward:  -0.09962838  average fail penalty:  -0.140625  and average goal bonus:  0.40611607  and average same cell penalty:  -0.27030247 average distance reward:  -0.046956483  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 7. Reward: -25.40, Length: 36
DEBUG (Env): Episode done for env 12. Reward: -13.11, Length: 36
DEBUG (Env): Episode done for env 19. Reward: -13.86, Length: 36
DEBUG (Env): Episode done for env 26. Reward: 20.39, Length: 11
DEBUG (Env): Episode done for env 52. Reward: 16.89, Length: 1
DEBUG (Env): Episode done for env 57. Reward: 14.21, Length: 18
DEBUG (Env): Episode done for env 62. Reward: -5.82, Length: 36
DEBUG (Env): Episode done for env 68. Reward: -17.61, Length: 36
DEBUG (Env): Episode done for env 94. Reward: -14.81, Length: 36
2542
Time taken for simulation:  7.075486421585083
average overall reward:  0.68871075  average fail penalty:  -0.046875  and average goal bonus:  0.8122322  and average same cell penalty:  -0.15445855 average distance reward:  0.12567267  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 18. Reward: 31.30, Length: 8
DEBUG (Env): Episode done for env 67. Reward: 27.85, Length: 5
DEBUG (Env): Episode done for env 68. Reward: 23.72, Length: 1
DEBUG (Env): Episode done for env 89. Reward: 29.75, Length: 7
DEBUG (Env): Episode done for env 90. Reward: 24.74, Length: 2
DEBUG (Env): Episode done for env 106. Reward: 9.02, Length: 36
DEBUG (Env): Episode done for env 119. Reward: -26.59, Length: 36
2543
Time taken for simulation:  7.4902684688568115
average overall reward:  0.69234866  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.15445855 average distance reward:  0.48855162  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 0. Reward: 12.95, Length: 18
DEBUG (Env): Episode done for env 27. Reward: 25.42, Length: 3
DEBUG (Env): Episode done for env 66. Reward: 4.92, Length: 6
2544
Time taken for simulation:  8.021974802017212
average overall reward:  0.0032228604  average fail penalty:  -0.046875  and average goal bonus:  0.40611607  and average same cell penalty:  -0.18020165 average distance reward:  -0.12795605  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 5. Reward: -16.78, Length: 36
DEBUG (Env): Episode done for env 48. Reward: 32.95, Length: 8
DEBUG (Env): Episode done for env 56. Reward: 26.98, Length: 15
DEBUG (Env): Episode done for env 73. Reward: 37.69, Length: 5
DEBUG (Env): Episode done for env 74. Reward: -10.47, Length: 36
2545
Time taken for simulation:  7.18665337562561
average overall reward:  0.49221197  average fail penalty:  -0.09375  and average goal bonus:  0.5414881  and average same cell penalty:  -0.23168781 average distance reward:  0.32402226  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 14. Reward: 22.67, Length: 22
DEBUG (Env): Episode done for env 41. Reward: -14.08, Length: 36
DEBUG (Env): Episode done for env 50. Reward: 21.36, Length: 17
DEBUG (Env): Episode done for env 64. Reward: -20.31, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 33.23, Length: 3
DEBUG (Env): Episode done for env 123. Reward: 38.40, Length: 13
DEBUG (Env): Episode done for env 126. Reward: -19.71, Length: 36
DEBUG (Env): Episode done for env 127. Reward: -19.73, Length: 36
2546
Time taken for simulation:  7.191316604614258
average overall reward:  0.6034061  average fail penalty:  0.0  and average goal bonus:  0.67686015  and average same cell penalty:  -0.18020165 average distance reward:  0.1546081  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 17. Reward: 32.30, Length: 7
DEBUG (Env): Episode done for env 43. Reward: 10.51, Length: 35
DEBUG (Env): Episode done for env 61. Reward: 7.72, Length: 20
DEBUG (Env): Episode done for env 88. Reward: 8.97, Length: 30
DEBUG (Env): Episode done for env 107. Reward: 21.51, Length: 17
2547
Time taken for simulation:  7.151718854904175
average overall reward:  0.7061603  average fail penalty:  0.0  and average goal bonus:  0.8122322  and average same cell penalty:  -0.20594473 average distance reward:  0.14773346  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 3. Reward: 21.90, Length: 10
DEBUG (Env): Episode done for env 11. Reward: 27.74, Length: 21
DEBUG (Env): Episode done for env 25. Reward: 22.60, Length: 18
DEBUG (Env): Episode done for env 51. Reward: 16.15, Length: 19
DEBUG (Env): Episode done for env 93. Reward: 20.23, Length: 10
DEBUG (Env): Episode done for env 123. Reward: 16.69, Length: 2
2548
Time taken for simulation:  7.4157044887542725
average overall reward:  0.55155873  average fail penalty:  0.0  and average goal bonus:  0.8122322  and average same cell penalty:  -0.21881628 average distance reward:  0.006003365  and average step penalty:  -0.04786053509430681
Number of done instances:  6
DEBUG (Env): Episode done for env 17. Reward: 15.52, Length: 2
DEBUG (Env): Episode done for env 26. Reward: 18.73, Length: 7
DEBUG (Env): Episode done for env 27. Reward: 18.64, Length: 5
DEBUG (Env): Episode done for env 50. Reward: 29.72, Length: 3
DEBUG (Env): Episode done for env 83. Reward: 8.74, Length: 25
DEBUG (Env): Episode done for env 92. Reward: 24.88, Length: 10
2549
Time taken for simulation:  7.704895973205566
average overall reward:  -0.093848996  average fail penalty:  -0.0234375  and average goal bonus:  0.0  and average same cell penalty:  -0.2574309 average distance reward:  0.23488  and average step penalty:  -0.04786053509430681
Number of done instances:  1
DEBUG (Env): Episode done for env 32. Reward: -22.83, Length: 36
2550
Time taken for simulation:  7.518963575363159
average overall reward:  0.45231605  average fail penalty:  -0.09375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3089171 average distance reward:  0.49672762  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 14. Reward: 29.67, Length: 5
DEBUG (Env): Episode done for env 15. Reward: -6.73, Length: 36
DEBUG (Env): Episode done for env 60. Reward: 14.79, Length: 12
DEBUG (Env): Episode done for env 79. Reward: -24.74, Length: 36
DEBUG (Env): Episode done for env 85. Reward: -17.70, Length: 36
DEBUG (Env): Episode done for env 102. Reward: -24.01, Length: 36
DEBUG (Env): Episode done for env 109. Reward: 20.50, Length: 20
2551
Time taken for simulation:  7.167765855789185
average overall reward:  0.1766337  average fail penalty:  0.0  and average goal bonus:  0.40611607  and average same cell penalty:  -0.19307318 average distance reward:  0.011451349  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 56. Reward: 38.43, Length: 7
DEBUG (Env): Episode done for env 73. Reward: 40.54, Length: 7
DEBUG (Env): Episode done for env 106. Reward: 35.73, Length: 9
2552
Time taken for simulation:  7.167644500732422
average overall reward:  0.2421776  average fail penalty:  -0.1171875  and average goal bonus:  0.5414881  and average same cell penalty:  -0.2574309 average distance reward:  0.12316843  and average step penalty:  -0.04786053509430681
Number of done instances:  9
DEBUG (Env): Episode done for env 24. Reward: 28.25, Length: 12
DEBUG (Env): Episode done for env 30. Reward: -19.21, Length: 36
DEBUG (Env): Episode done for env 35. Reward: 10.02, Length: 14
DEBUG (Env): Episode done for env 48. Reward: 36.42, Length: 8
DEBUG (Env): Episode done for env 57. Reward: 15.21, Length: 11
DEBUG (Env): Episode done for env 72. Reward: -17.47, Length: 36
DEBUG (Env): Episode done for env 101. Reward: -25.00, Length: 36
DEBUG (Env): Episode done for env 104. Reward: -17.27, Length: 36
DEBUG (Env): Episode done for env 118. Reward: -13.25, Length: 36
2553
Time taken for simulation:  6.994459390640259
average overall reward:  -0.17241769  average fail penalty:  -0.0703125  and average goal bonus:  0.27074406  and average same cell penalty:  -0.32178867 average distance reward:  -0.0032000542  and average step penalty:  -0.04786053509430681
Number of done instances:  5
DEBUG (Env): Episode done for env 1. Reward: -15.18, Length: 36
DEBUG (Env): Episode done for env 17. Reward: 25.23, Length: 5
DEBUG (Env): Episode done for env 37. Reward: -11.01, Length: 36
DEBUG (Env): Episode done for env 42. Reward: -27.33, Length: 36
DEBUG (Env): Episode done for env 68. Reward: 22.82, Length: 8
2554
Time taken for simulation:  7.380261659622192
average overall reward:  0.5182376  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.23168781 average distance reward:  0.16780084  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 6. Reward: -21.70, Length: 36
DEBUG (Env): Episode done for env 14. Reward: 32.82, Length: 4
DEBUG (Env): Episode done for env 31. Reward: -19.23, Length: 36
DEBUG (Env): Episode done for env 51. Reward: 38.76, Length: 7
DEBUG (Env): Episode done for env 99. Reward: 17.58, Length: 17
DEBUG (Env): Episode done for env 106. Reward: 25.70, Length: 3
DEBUG (Env): Episode done for env 114. Reward: 19.84, Length: 19
2555
Time taken for simulation:  7.330951690673828
average overall reward:  -0.011674538  average fail penalty:  -0.0234375  and average goal bonus:  0.40611607  and average same cell penalty:  -0.3089171 average distance reward:  -0.037575494  and average step penalty:  -0.04786053509430681
Number of done instances:  4
DEBUG (Env): Episode done for env 67. Reward: 18.80, Length: 13
DEBUG (Env): Episode done for env 71. Reward: 22.51, Length: 34
DEBUG (Env): Episode done for env 77. Reward: 12.88, Length: 29
DEBUG (Env): Episode done for env 96. Reward: -13.41, Length: 36
2556
Time taken for simulation:  7.131320238113403
average overall reward:  0.38624403  average fail penalty:  -0.0234375  and average goal bonus:  0.27074406  and average same cell penalty:  -0.2574309 average distance reward:  0.44422895  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 76. Reward: 6.71, Length: 27
DEBUG (Env): Episode done for env 100. Reward: 20.37, Length: 26
DEBUG (Env): Episode done for env 108. Reward: -20.41, Length: 36
2557
Time taken for simulation:  7.392516851425171
average overall reward:  1.0262879  average fail penalty:  -0.046875  and average goal bonus:  0.67686015  and average same cell penalty:  -0.141587 average distance reward:  0.5857502  and average step penalty:  -0.04786053509430681
Number of done instances:  7
DEBUG (Env): Episode done for env 0. Reward: 21.98, Length: 14
DEBUG (Env): Episode done for env 10. Reward: -23.66, Length: 36
DEBUG (Env): Episode done for env 33. Reward: -22.83, Length: 36
DEBUG (Env): Episode done for env 45. Reward: 22.71, Length: 29
DEBUG (Env): Episode done for env 50. Reward: 25.54, Length: 9
DEBUG (Env): Episode done for env 59. Reward: 12.37, Length: 24
DEBUG (Env): Episode done for env 75. Reward: 33.11, Length: 20
2558
Time taken for simulation:  7.456740379333496
average overall reward:  1.514873  average fail penalty:  -0.0234375  and average goal bonus:  0.9476042  and average same cell penalty:  -0.24455938 average distance reward:  0.88312626  and average step penalty:  -0.04786053509430681
Number of done instances:  8
DEBUG (Env): Episode done for env 41. Reward: 44.72, Length: 13
DEBUG (Env): Episode done for env 42. Reward: 39.90, Length: 5
DEBUG (Env): Episode done for env 44. Reward: 15.73, Length: 25
DEBUG (Env): Episode done for env 61. Reward: 17.52, Length: 12
DEBUG (Env): Episode done for env 81. Reward: -21.08, Length: 36
DEBUG (Env): Episode done for env 92. Reward: 20.15, Length: 10
DEBUG (Env): Episode done for env 105. Reward: 17.59, Length: 20
DEBUG (Env): Episode done for env 117. Reward: 27.43, Length: 20
2559
Time taken for simulation:  7.0722174644470215
average overall reward:  -0.40353376  average fail penalty:  -0.046875  and average goal bonus:  0.13537203  and average same cell penalty:  -0.18020163 average distance reward:  -0.26396862  and average step penalty:  -0.04786053509430681
Number of done instances:  3
DEBUG (Env): Episode done for env 4. Reward: -20.17, Length: 36
DEBUG (Env): Episode done for env 20. Reward: -18.60, Length: 36
DEBUG (Env): Episode done for env 33. Reward: 29.36, Length: 2
2560
Training finished.
Saving trained model to ../celloracle_data/optuna_hpo_models2/trial_49.zip...
Model saved.
Closing environment.
Environment closed.
--- Training Run Finished ---
Optuna Trial 49 completed. Final Metric (Mean Reward): 11.0874
Finishing W&B run for trial 49 (Status: completed)
