_wandb:
    value:
        cli_version: 0.19.10
        m: []
        python_version: 3.10.17
        t:
            "1":
                - 1
                - 5
                - 35
                - 53
                - 55
            "2":
                - 1
                - 5
                - 35
                - 53
                - 55
            "3":
                - 1
                - 2
                - 13
                - 14
                - 16
                - 23
                - 34
                - 35
                - 55
                - 62
            "4": 3.10.17
            "5": 0.19.10
            "8":
                - 1
                - 5
            "10":
                - 20
            "12": 0.19.10
            "13": linux-x86_64
ACTIVATION_FN:
    value: torch.nn.modules.activation.ReLU
ALLOW_GENE_ACTIVATION:
    value: true
BATCH_SIZE:
    value: 128
CLIP_RANGE:
    value: 0.24207321045586905
DEVICE:
    value: auto
DISTANCE_GAMMA:
    value: 0.987961822183782
DISTANCE_REWARD_SCALE:
    value: 65.64610901864404
DIVIDER_OF_TOTAL_STEPS_FOR_CURRICULUM_LEARNING:
    value: 20
ENT_COEF:
    value: 0.01506771837430503
FAIL_PENALTY:
    value: -3
GAE_LAMBDA:
    value: 0.95
GAMMA:
    value: 0.9816993318027057
GENE_ACTIVITY_THRESHOLD:
    value: 0.01
GOAL_BONUS:
    value: 17.327620265313794
HPO_FIXED_MAX_STEPS_PER_EPISODE:
    value: 30
LEARNING_RATE:
    value: 0.00023960899115892331
LOG_DIR:
    value: ../celloracle_data/optuna_hpo_logs2/trial_49
LOG_DIR_BASE:
    value: ../celloracle_data/optuna_hpo_logs2
LOG_INTERVAL:
    value: 10
MAX_GRAD_NORM:
    value: 0.5
MAX_STEP_INCREASE_PER_PHASE:
    value: 8
MAX_STEPS_FIRST_PHASE:
    value: 50000
MAX_STEPS_PER_EPISODE:
    value: 36
MODEL_SAVE_PATH:
    value: ../celloracle_data/optuna_hpo_models2/trial_49
MODEL_SAVE_PATH_BASE:
    value: ../celloracle_data/optuna_hpo_models2
ORACLE_PATH:
    value: ../celloracle_data/celloracle_object/new_promoter_without_mescs_trimmed_test_own_umap/ready_oracle.pkl
PARAMETER_TUNING:
    value: true
PHASE_STEP_INCREASE:
    value: 15000
PI_ARCH:
    value:
        - 512
        - 512
PPO_N_EPOCHS:
    value: 12
PPO_N_STEPS:
    value: 256
RESET_NUM_TIMESTEPS:
    value: false
SAME_CELL_PENALTY:
    value: -1.647557804056219
STANDARD_SD_FACTOR:
    value: 1.5
STEP_PENALTY:
    value: -0.04786053509430681
STEP_SAVE_FREQ:
    value: 1000000000
TARGET_CELLS_PER_PHASE:
    value: 6
TARGET_DISTANCE_THRESHOLD:
    value: 0.1
TOTAL_TIMESTEPS:
    value: 320000
TOTAL_TIMESTEPS_HPO:
    value: 320000
USE_LEARNING_RATE_SCHEDULE:
    value: false
USE_MASKABLE_PPO:
    value: false
USE_NEW_INPUT:
    value: true
USE_PREV_KNOCKOUT:
    value: true
USE_PROGRESS_BAR:
    value: false
USE_SIMILARITY_REWARD:
    value: true
VERBOSE:
    value: 0
VF_ARCH:
    value:
        - 512
        - 512
VF_COEF:
    value: 0.5911860449836062
WANDB_RUN_ID:
    value: optuna_hpo_trial_49
WANDB_RUN_NAME:
    value: t49_lr2.4e-04_ent0.02
optuna_trial_obj:
    value: <optuna.trial._trial.Trial object at 0x72d4a9682fb0>
